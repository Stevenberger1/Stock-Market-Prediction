{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5e0dd8",
   "metadata": {},
   "source": [
    "# In this notebook we will train the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "354d5047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Complete [00h 01m 39s]\n",
      "val_weighted_f1: 0.22747260332107544\n",
      "\n",
      "Best val_weighted_f1 So Far: 0.5337280035018921\n",
      "Total elapsed time: 00h 06m 33s\n",
      "\n",
      "Best hyper-parameters (max val-weighted-F1):\n",
      "  units   : 32\n",
      "  dropout : 0.4\n",
      "  lr      : 0.0012789451776909946\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "5-minute hyper-parameter sweep for a BTC-direction LSTM\n",
    "(predicts Up/Down for the NEXT close price).\n",
    "\n",
    "Prereqs:\n",
    "    pip install pandas numpy scikit-learn tensorflow keras-tuner\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np, pandas as pd, tensorflow as tf, keras_tuner as kt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH  = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_data_final_version_with_features_2016_final.csv\"\n",
    "DROP_COLS = [\"vol_ratio_24h\", \"macd_diff\", \"macd_line\", \"upper_shadow\", \"lower_shadow\"]\n",
    "SEQ_LEN   = 60          # past 60 hours â†’ predict next hour\n",
    "VAL_FRAC  = 0.20        # final 20 % of samples for validation\n",
    "W_PREC    = 2.0         # precision weight in weighted-F1\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Load & label â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df[\"Volume BTC\"] = np.log1p(df[\"Volume BTC\"])\n",
    "\n",
    "# 1 = Up, 0 = Down (next close vs current close)\n",
    "df[\"target\"] = (df[\"close\"].shift(-1) > df[\"close\"]).astype(int)\n",
    "df = df.dropna().select_dtypes(include=[np.number])   # drop last row (NaN label)\n",
    "\n",
    "feature_cols = df.columns.drop(\"target\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Chronological train/val split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "split_raw = int(len(df) * (1 - VAL_FRAC))\n",
    "train_raw, val_raw = df.iloc[:split_raw], df.iloc[split_raw:]\n",
    "\n",
    "scaler = StandardScaler().fit(train_raw[feature_cols])\n",
    "\n",
    "df_scaled = pd.DataFrame(\n",
    "    scaler.transform(df[feature_cols]),\n",
    "    columns=feature_cols,\n",
    "    index=df.index\n",
    ")\n",
    "labels = df[\"target\"].values.astype(np.float32)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Build sequences â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_sequences(mat, tgt, length):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(length, len(mat)):\n",
    "        Xs.append(mat[i-length:i])\n",
    "        ys.append(tgt[i])\n",
    "    return np.array(Xs, dtype=np.float32), np.array(ys, dtype=np.float32)\n",
    "\n",
    "X_all, y_all = make_sequences(df_scaled.values, labels, SEQ_LEN)\n",
    "\n",
    "split_seq = int(len(X_all) * (1 - VAL_FRAC))\n",
    "X_train, X_val = X_all[:split_seq], X_all[split_seq:]\n",
    "y_train, y_val = y_all[:split_seq], y_all[split_seq:]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Custom weighted-F1 metric â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class WeightedF1(tf.keras.metrics.Metric):\n",
    "    def __init__(self, weight=2.0, name=\"weighted_f1\", threshold=0.5, **kw):\n",
    "        super().__init__(name=name, **kw)\n",
    "        self.w = weight\n",
    "        self.th = threshold\n",
    "        self.tp = self.add_weight(name=\"tp\", initializer=\"zeros\")\n",
    "        self.fp = self.add_weight(name=\"fp\", initializer=\"zeros\")\n",
    "        self.fn = self.add_weight(name=\"fn\", initializer=\"zeros\")\n",
    "\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred >= self.th, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        self.tp.assign_add(tf.reduce_sum(y_true * y_pred))\n",
    "        self.fp.assign_add(tf.reduce_sum((1 - y_true) * y_pred))\n",
    "        self.fn.assign_add(tf.reduce_sum(y_true * (1 - y_pred)))\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.tp / (self.tp + self.fp + 1e-7)\n",
    "        recall    = self.tp / (self.tp + self.fn + 1e-7)\n",
    "        return (1 + self.w) * precision * recall / (self.w * precision + recall + 1e-7)\n",
    "\n",
    "    def reset_states(self):\n",
    "        for var in (self.tp, self.fp, self.fn):\n",
    "            var.assign(0.)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Hyper-model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(SEQ_LEN, X_train.shape[2])),\n",
    "        tf.keras.layers.LSTM(\n",
    "            units=hp.Int(\"units\", 32, 128, step=32),\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            dropout=hp.Float(\"dropout\", 0.0, 0.4, step=0.1)\n",
    "        ),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[WeightedF1(weight=W_PREC)]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=kt.Objective(\"val_weighted_f1\", direction=\"max\"),\n",
    "    max_trials=7,\n",
    "    executions_per_trial=1,\n",
    "    directory=\"lstm_tune\",\n",
    "    project_name=\"btc_dir_quick\"\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=3,            # tiny â†’ ~5 min\n",
    "    batch_size=64,\n",
    "    shuffle=False,       # keep order!\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "best = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"\\nBest hyper-parameters (max val-weighted-F1):\")\n",
    "print(f\"  units   : {best.get('units')}\")\n",
    "print(f\"  dropout : {best.get('dropout')}\")\n",
    "print(f\"  lr      : {best.get('lr')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "799d589d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m504/504\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "ðŸ” Precision by class:\n",
      "  Class 0: 0.4977\n",
      "  Class 1: 0.5173\n",
      "\n",
      "ðŸ” Recall by class:\n",
      "  Class 0: 0.4637\n",
      "  Class 1: 0.5512\n",
      "\n",
      "âœ… Overall Accuracy: 0.5083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Get predictions as probabilities\n",
    "y_pred_proba = best_model.predict(X_val).flatten()\n",
    "\n",
    "# Convert to class labels\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# Compute metrics\n",
    "precision_per_class = precision_score(y_val, y_pred, average=None)\n",
    "recall_per_class    = recall_score(y_val, y_pred, average=None)\n",
    "accuracy            = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Print results clearly\n",
    "print(f\"ðŸ” Precision by class:\")\n",
    "print(f\"  Class 0: {precision_per_class[0]:.4f}\")\n",
    "print(f\"  Class 1: {precision_per_class[1]:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ” Recall by class:\")\n",
    "print(f\"  Class 0: {recall_per_class[0]:.4f}\")\n",
    "print(f\"  Class 1: {recall_per_class[1]:.4f}\")\n",
    "\n",
    "print(f\"\\nâœ… Overall Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd4dbab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1008/1008 - 8s - 8ms/step - accuracy: 0.5181 - loss: 0.6933 - val_accuracy: 0.5066 - val_loss: 0.6967\n",
      "Epoch 2/30\n",
      "1008/1008 - 7s - 7ms/step - accuracy: 0.5160 - loss: 0.6924 - val_accuracy: 0.5054 - val_loss: 0.6947\n",
      "Epoch 3/30\n",
      "1008/1008 - 7s - 7ms/step - accuracy: 0.5184 - loss: 0.6920 - val_accuracy: 0.5070 - val_loss: 0.6941\n",
      "Epoch 4/30\n",
      "1008/1008 - 7s - 7ms/step - accuracy: 0.5190 - loss: 0.6918 - val_accuracy: 0.5047 - val_loss: 0.6952\n",
      "Epoch 5/30\n",
      "1008/1008 - 7s - 7ms/step - accuracy: 0.5232 - loss: 0.6914 - val_accuracy: 0.5087 - val_loss: 0.6956\n",
      "Epoch 6/30\n",
      "1008/1008 - 7s - 7ms/step - accuracy: 0.5210 - loss: 0.6914 - val_accuracy: 0.5105 - val_loss: 0.6935\n",
      "Epoch 7/30\n",
      "1008/1008 - 7s - 7ms/step - accuracy: 0.5238 - loss: 0.6913 - val_accuracy: 0.5081 - val_loss: 0.6947\n",
      "Epoch 8/30\n",
      "1008/1008 - 7s - 7ms/step - accuracy: 0.5235 - loss: 0.6911 - val_accuracy: 0.5101 - val_loss: 0.6955\n",
      "Epoch 9/30\n",
      "1008/1008 - 7s - 7ms/step - accuracy: 0.5240 - loss: 0.6911 - val_accuracy: 0.5108 - val_loss: 0.6938\n",
      "Epoch 10/30\n",
      "1008/1008 - 7s - 7ms/step - accuracy: 0.5272 - loss: 0.6909 - val_accuracy: 0.5131 - val_loss: 0.6956\n",
      "Epoch 11/30\n",
      "1008/1008 - 7s - 7ms/step - accuracy: 0.5267 - loss: 0.6911 - val_accuracy: 0.5121 - val_loss: 0.6949\n",
      "\u001b[1m252/252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€ Validation metrics (threshold = 0.50) â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Accuracy          :  0.510\n",
      "Class 0 (Down) â†’  Precision:  0.500   Recall:  0.607   F1:  0.548\n",
      "Class 1 (Up  ) â†’  Precision:  0.526   Recall:  0.418   F1:  0.466\n",
      "Macro-F1          :  0.507\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Final training + evaluation for BTC-direction LSTM\n",
    "==================================================\n",
    "Label: 1 if next-hour close > current close, else 0.\n",
    "Metrics printed: precision, recall, F1 for both classes and overall accuracy.\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€ Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np, pandas as pd, tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# â”€â”€â”€â”€â”€ File & column config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH  = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_data_final_version_with_features_2016_final.csv\"\n",
    "DROP_COLS = [\"vol_ratio_24h\", \"macd_diff\", \"macd_line\", \"upper_shadow\", \"lower_shadow\"]\n",
    "\n",
    "SEQ_LEN   = 60      # past 60 hours â†’ predict next hour\n",
    "VAL_FRAC  = 0.20    # last 20 % of sequences become validation\n",
    "\n",
    "# â”€â”€â”€â”€â”€ Hyper-parameters found in tuning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "UNITS     = 32\n",
    "DROPOUT   = 0.4\n",
    "LR        = 0.0012789451776909946\n",
    "EPOCHS    = 30      # upper bound (early stopping will usually finish sooner)\n",
    "BATCH     = 64\n",
    "\n",
    "# â”€â”€â”€â”€â”€ Load, clean, engineer label â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df[\"Volume BTC\"] = np.log1p(df[\"Volume BTC\"])\n",
    "\n",
    "df[\"target\"] = (df[\"close\"].shift(-1) > df[\"close\"]).astype(int)\n",
    "df = df.dropna().select_dtypes(include=[np.number])          # remove final NaN label row\n",
    "\n",
    "feature_cols = df.columns.drop(\"target\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€ Chronological train / validation split (raw rows) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "split_raw = int(len(df) * (1 - VAL_FRAC))\n",
    "train_raw, val_raw = df.iloc[:split_raw], df.iloc[split_raw:]\n",
    "\n",
    "# scale INPUT features with params from *train* only\n",
    "scaler = StandardScaler().fit(train_raw[feature_cols])\n",
    "df_scaled = pd.DataFrame(\n",
    "    scaler.transform(df[feature_cols]),\n",
    "    columns=feature_cols,\n",
    "    index=df.index\n",
    ")\n",
    "labels = df[\"target\"].values.astype(np.float32)\n",
    "\n",
    "# â”€â”€â”€â”€â”€ Convert to rolling sequences â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_sequences(mat, tgt, length):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(length, len(mat)):\n",
    "        Xs.append(mat[i-length:i])\n",
    "        ys.append(tgt[i])\n",
    "    return np.array(Xs, dtype=np.float32), np.array(ys, dtype=np.float32)\n",
    "\n",
    "X_all, y_all = make_sequences(df_scaled.values, labels, SEQ_LEN)\n",
    "split_seq = int(len(X_all) * (1 - VAL_FRAC))\n",
    "X_train, X_val = X_all[:split_seq], X_all[split_seq:]\n",
    "y_train, y_val = y_all[:split_seq], y_all[split_seq:]\n",
    "\n",
    "# â”€â”€â”€â”€â”€ Model definition â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(SEQ_LEN, X_train.shape[2])),\n",
    "    tf.keras.layers.LSTM(UNITS, dropout=DROPOUT, activation=\"tanh\",\n",
    "                         recurrent_activation=\"sigmoid\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=5,\n",
    "                                              restore_best_weights=True,\n",
    "                                              monitor=\"val_loss\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€ Train â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=False,          # keep chronological order\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€ Evaluate on validation set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "y_prob = model.predict(X_val, batch_size=BATCH).flatten()\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    y_val, y_pred, labels=[0, 1], zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nâ”€â”€â”€â”€â”€â”€â”€â”€ Validation metrics (threshold = 0.50) â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(f\"Accuracy          : {acc:6.3f}\")\n",
    "print(f\"Class 0 (Down) â†’  Precision: {prec[0]:6.3f}   Recall: {rec[0]:6.3f}   F1: {f1[0]:6.3f}\")\n",
    "print(f\"Class 1 (Up  ) â†’  Precision: {prec[1]:6.3f}   Recall: {rec[1]:6.3f}   F1: {f1[1]:6.3f}\")\n",
    "print(f\"Macro-F1          : {f1.mean():6.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

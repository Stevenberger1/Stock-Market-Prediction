{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a75b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep \n",
    "atr_14  , OBV\n",
    "\n",
    "drop\n",
    "\n",
    "'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'trending_market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7131221",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lstm_cnn = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'rsi_overbought', 'stoch_oversold', 'cci_oversold',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6','ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801781b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 12:51:22,414] A new study created in memory with name: no-name-4a13c6ca-8c08-4449-91d3-c10d60bb8970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀  Starting 100-trial search …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 00 | Fα2=0.554 P=0.524 R=0.570 F1=0.546 Acc=0.506 lstm_conv win=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [02:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 12:53:27,827] Trial 0 finished with value: -0.5537355173791451 and parameters: {'arch': 'lstm_conv', 'window': 60, 'filters': 128, 'kernel': 5, 'units': 96, 'conv_drop': 0.05454749016213018, 'lstm_drop': 0.055021352956030146, 'dense': 64, 'dropout': 0.11649165607921677, 'l2': 6.847920095574779e-05, 'lr': 8.851384099881297e-05, 'batch': 128, 'act': 'elu', 'pool': 'gmp', 'conv_blocks': 2, 'optim': 'nadam'}. Best is trial 0 with value: -0.5537355173791451.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   1%|          | 1/100 [02:06<3:29:03, 126.71s/it, 126.70/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 01 | Fα2=0.280 P=0.547 R=0.225 F1=0.319 Acc=0.499 conv_lstm win=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   1%|          | 1/100 [02:30<3:29:03, 126.71s/it, 126.70/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 12:53:53,177] Trial 1 finished with value: -0.2801113360323887 and parameters: {'arch': 'conv_lstm', 'window': 30, 'filters': 48, 'kernel': 2, 'units': 32, 'conv_drop': 0.16401308380298388, 'lstm_drop': 0.05545633665765811, 'dense': 32, 'dropout': 0.35793094017105953, 'l2': 6.218704727769077e-05, 'lr': 0.0021787220464104273, 'batch': 128, 'act': 'relu', 'pool': 'gmp', 'conv_blocks': 1, 'optim': 'nadam'}. Best is trial 0 with value: -0.5537355173791451.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   2%|▏         | 2/100 [02:32<1:49:39, 67.14s/it, 152.15/3600 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 02 | Fα2=0.090 P=0.554 R=0.064 F1=0.114 Acc=0.485 lstm_conv win=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   2%|▏         | 2/100 [05:56<1:49:39, 67.14s/it, 152.15/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 12:57:18,623] Trial 2 finished with value: -0.09008746355685131 and parameters: {'arch': 'lstm_conv', 'window': 60, 'filters': 64, 'kernel': 6, 'units': 128, 'conv_drop': 0.09926940745579475, 'lstm_drop': 0.01906750508580709, 'dense': 128, 'dropout': 0.25502298854208527, 'l2': 0.0004588156549160974, 'lr': 0.000345652389857876, 'batch': 64, 'act': 'relu', 'pool': 'gmp', 'conv_blocks': 1, 'optim': 'nadam'}. Best is trial 0 with value: -0.5537355173791451.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   3%|▎         | 3/100 [05:57<3:30:39, 130.30s/it, 357.61/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 03 | Fα2=0.567 P=0.519 R=0.594 F1=0.554 Acc=0.501 lstm_conv win=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   3%|▎         | 3/100 [08:27<3:30:39, 130.30s/it, 357.61/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 12:59:50,245] Trial 3 finished with value: -0.5669152276295134 and parameters: {'arch': 'lstm_conv', 'window': 66, 'filters': 64, 'kernel': 3, 'units': 64, 'conv_drop': 0.24110162306973432, 'lstm_drop': 0.05597101766581075, 'dense': 32, 'dropout': 0.3584365199693973, 'l2': 8.995191735587168e-06, 'lr': 7.846192726793281e-05, 'batch': 128, 'act': 'elu', 'pool': 'gmp', 'conv_blocks': 1, 'optim': 'adamw'}. Best is trial 3 with value: -0.5669152276295134.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: -0.566915:   4%|▍         | 4/100 [08:29<3:41:57, 138.72s/it, 509.24/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 04 | Fα2=0.000 P=0.000 R=0.000 F1=0.000 Acc=0.478 lstm_conv win=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: -0.566915:   4%|▍         | 4/100 [09:25<3:41:57, 138.72s/it, 509.24/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:00:47,566] Trial 4 finished with value: 0.0 and parameters: {'arch': 'lstm_conv', 'window': 30, 'filters': 32, 'kernel': 3, 'units': 64, 'conv_drop': 0.2724797657899961, 'lstm_drop': 0.07186856720009173, 'dense': 128, 'dropout': 0.09682210860460017, 'l2': 0.00010385003379927417, 'lr': 0.0011304331263607352, 'batch': 32, 'act': 'relu', 'pool': 'gap', 'conv_blocks': 1, 'optim': 'nadam'}. Best is trial 3 with value: -0.5669152276295134.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: -0.566915:   5%|▌         | 5/100 [09:26<2:53:11, 109.39s/it, 566.61/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 05 | Fα2=0.586 P=0.526 R=0.622 F1=0.570 Acc=0.510 conv_lstm win=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: -0.566915:   5%|▌         | 5/100 [12:03<2:53:11, 109.39s/it, 566.61/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:03:26,190] Trial 5 finished with value: -0.5861405197305101 and parameters: {'arch': 'conv_lstm', 'window': 42, 'filters': 96, 'kernel': 7, 'units': 128, 'conv_drop': 0.07738248831454668, 'lstm_drop': 0.1979952138102537, 'dense': 32, 'dropout': 0.09674091636018067, 'l2': 1.902428324748959e-06, 'lr': 0.001969497011745637, 'batch': 16, 'act': 'elu', 'pool': 'gmp', 'conv_blocks': 2, 'optim': 'nadam'}. Best is trial 5 with value: -0.5861405197305101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:   6%|▌         | 6/100 [12:05<3:17:34, 126.11s/it, 725.20/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 06 | Fα2=0.030 P=0.559 R=0.020 F1=0.039 Acc=0.480 conv_lstm win=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:   6%|▌         | 6/100 [14:33<3:17:34, 126.11s/it, 725.20/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:05:56,316] Trial 6 finished with value: -0.029525797793021172 and parameters: {'arch': 'conv_lstm', 'window': 18, 'filters': 128, 'kernel': 5, 'units': 192, 'conv_drop': 0.1948898697141644, 'lstm_drop': 0.2547670231482534, 'dense': 32, 'dropout': 0.1470863212237734, 'l2': 6.24607368131809e-06, 'lr': 0.00013577521331829283, 'batch': 16, 'act': 'relu', 'pool': 'gmp', 'conv_blocks': 1, 'optim': 'adam'}. Best is trial 5 with value: -0.5861405197305101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:   7%|▋         | 7/100 [16:16<3:27:36, 133.94s/it, 875.24/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:07:39,087] Trial 7 pruned. Trial was pruned at epoch 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:   8%|▊         | 8/100 [16:35<3:10:11, 124.04s/it, 978.09/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:07:57,890] Trial 8 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:   9%|▉         | 9/100 [16:53<2:18:12, 91.13s/it, 996.86/3600 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:08:15,914] Trial 9 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  10%|█         | 10/100 [16:54<1:42:50, 68.56s/it, 1014.89/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 | Fα2=0.000 P=0.000 R=0.000 F1=0.000 Acc=0.478 conv_lstm win=36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  10%|█         | 10/100 [19:48<1:42:50, 68.56s/it, 1014.89/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:11:11,403] Trial 10 finished with value: 0.0 and parameters: {'arch': 'conv_lstm', 'window': 36, 'filters': 32, 'kernel': 6, 'units': 128, 'conv_drop': 0.07202341203296447, 'lstm_drop': 0.18814920204905028, 'dense': 64, 'dropout': 0.03425733184657786, 'l2': 3.0695249234567865e-06, 'lr': 0.001418232376111356, 'batch': 16, 'act': 'relu', 'pool': 'gmp', 'conv_blocks': 1, 'optim': 'nadam'}. Best is trial 5 with value: -0.5861405197305101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  11%|█         | 11/100 [19:50<2:30:14, 101.29s/it, 1190.37/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 | Fα2=0.508 P=0.519 R=0.502 F1=0.511 Acc=0.497 lstm_conv win=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  11%|█         | 11/100 [26:21<2:30:14, 101.29s/it, 1190.37/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:17:44,047] Trial 11 finished with value: -0.5077978789769183 and parameters: {'arch': 'lstm_conv', 'window': 66, 'filters': 64, 'kernel': 3, 'units': 128, 'conv_drop': 0.2757420493320118, 'lstm_drop': 0.09027008622194727, 'dense': 32, 'dropout': 0.3870562117313163, 'l2': 1.1071142752856649e-05, 'lr': 0.00012710261905184188, 'batch': 128, 'act': 'relu', 'pool': 'gap', 'conv_blocks': 1, 'optim': 'adamw'}. Best is trial 5 with value: -0.5861405197305101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  12%|█▏        | 12/100 [26:44<4:38:34, 189.93s/it, 1583.06/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:18:07,157] Trial 12 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  13%|█▎        | 13/100 [27:01<3:22:06, 139.39s/it, 1606.14/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:18:24,090] Trial 13 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  14%|█▍        | 14/100 [27:03<2:26:47, 102.41s/it, 1623.10/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 | Fα2=0.766 P=0.522 R=1.000 F1=0.686 Acc=0.522 conv_lstm win=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  14%|█▍        | 14/100 [33:35<2:26:47, 102.41s/it, 1623.10/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:24:58,034] Trial 14 finished with value: -0.7657869934024506 and parameters: {'arch': 'conv_lstm', 'window': 54, 'filters': 96, 'kernel': 7, 'units': 192, 'conv_drop': 0.023002858013431764, 'lstm_drop': 0.20388968390933723, 'dense': 32, 'dropout': 0.15387612135152867, 'l2': 6.633730435337335e-06, 'lr': 0.0027802249303014543, 'batch': 16, 'act': 'elu', 'pool': 'gap', 'conv_blocks': 2, 'optim': 'nadam'}. Best is trial 14 with value: -0.7657869934024506.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: -0.765787:  15%|█▌        | 15/100 [34:11<4:29:33, 190.28s/it, 2017.03/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:25:34,111] Trial 15 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: -0.765787:  16%|█▌        | 16/100 [34:13<3:21:25, 143.87s/it, 2053.13/3600 seconds]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "cnn_lstm_optuna_search.py  · 2025-06-11\n",
    "────────────────────────────────────────────────────────────────────────\n",
    "Optuna hyper-parameter search for a CNN–LSTM classifier\n",
    "optimising weighted-F1 with α = 2 (precision ×2 weight).\n",
    "\n",
    "Outputs\n",
    "-------\n",
    "• cnn_lstm_scaler.pkl\n",
    "• best_params_cnn_lstm_<ts>.json\n",
    "• trials_cnn_lstm_<ts>.csv\n",
    "• history_cnn_lstm_<ts>.png\n",
    "\"\"\"\n",
    "\n",
    "# ───────── imports & runtime hygiene ─────────\n",
    "import os, json, gc, warnings, optuna\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             f1_score, accuracy_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from optuna_integration.tfkeras import TFKerasPruningCallback\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED, VAL_FRAC, ALPHA  = 42, 0.20, 2.0\n",
    "N_TRIALS, TIMEOUT      = 100, 60 * 60      # ← 100 trials, 1 hour max\n",
    "\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "SCALER_PKL = \"cnn_lstm_scaler.pkl\"\n",
    "\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20'\n",
    "     ,'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'rsi_overbought', 'stoch_oversold', 'cci_oversold',\n",
    "    'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6','ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal','close'\n",
    "]\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ───────── data load & scale ─────────\n",
    "df = (pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "        .loc[\"2018-01-01\":]\n",
    "        .drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "        .dropna(subset=[\"target\"]).dropna())\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_feat = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "pos = y_tr_raw.mean()\n",
    "W0, W1 = np.float32(1.0), np.float32((1 - pos) / pos if pos else 1.0)\n",
    "\n",
    "# ───────── window helper (cache) ─────────\n",
    "_CACHE: Dict[Tuple[int,int,int], Tuple[np.ndarray,np.ndarray]] = {}\n",
    "def make_windows(arr, lab, win):\n",
    "    k = (len(arr), win, arr.shape[1])\n",
    "    if k in _CACHE: return _CACHE[k]\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i-win:i]); y.append(lab[i])\n",
    "    Xw, yw = np.asarray(X,np.float32), np.asarray(y,np.int8)\n",
    "    if Xw.nbytes+yw.nbytes < 1e9: _CACHE[k]=(Xw,yw)\n",
    "    return Xw, yw\n",
    "\n",
    "def wf1(y, p, alpha=ALPHA):\n",
    "    hat = (p>=.5).astype(int)\n",
    "    pr, rc = precision_score(y,hat,zero_division=0), recall_score(y,hat,zero_division=0)\n",
    "    return 0 if pr+rc==0 else (1+alpha)*pr*rc/(alpha*pr+rc)\n",
    "\n",
    "# ───────── model factory ─────────\n",
    "def build(cfg):\n",
    "    l2 = regularizers.l2(cfg[\"l2\"])\n",
    "    inp = layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    if cfg[\"arch\"] == \"conv_lstm\":\n",
    "        x = inp\n",
    "        for _ in range(cfg[\"conv_blocks\"]):\n",
    "            x = layers.Conv1D(cfg[\"filters\"], cfg[\"kernel\"], padding=\"causal\",\n",
    "                              activation=cfg[\"act\"], kernel_regularizer=l2)(x)\n",
    "            x = layers.Dropout(cfg[\"conv_drop\"])(x)\n",
    "        x = layers.LSTM(cfg[\"units\"], dropout=cfg[\"lstm_drop\"])(x)\n",
    "    else:  # lstm_conv\n",
    "        x = layers.LSTM(cfg[\"units\"], dropout=cfg[\"lstm_drop\"],\n",
    "                        return_sequences=True)(inp)\n",
    "        x = layers.Conv1D(cfg[\"filters\"], cfg[\"kernel\"], padding=\"same\",\n",
    "                          activation=cfg[\"act\"], kernel_regularizer=l2)(x)\n",
    "        x = (layers.GlobalMaxPooling1D()(x) if cfg[\"pool\"]==\"gmp\"\n",
    "             else layers.GlobalAveragePooling1D()(x))\n",
    "\n",
    "    x = layers.Dense(cfg[\"dense\"], activation=cfg[\"act\"], kernel_regularizer=l2)(x)\n",
    "    x = layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    def wbce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t,1), W1, W0); w = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    # choose optimiser\n",
    "    if cfg[\"optim\"] == \"adamw\":\n",
    "        opt = keras.optimizers.AdamW(cfg[\"lr\"], weight_decay=cfg[\"l2\"])\n",
    "    elif cfg[\"optim\"] == \"nadam\":\n",
    "        opt = keras.optimizers.Nadam(cfg[\"lr\"])\n",
    "    else:\n",
    "        opt = keras.optimizers.Adam(cfg[\"lr\"])\n",
    "\n",
    "    model.compile(opt, loss=wbce)\n",
    "    return model\n",
    "\n",
    "# ───────── Optuna objective ─────────\n",
    "def objective(trial):\n",
    "    cfg = dict(\n",
    "        arch        = trial.suggest_categorical(\"arch\", [\"conv_lstm\",\"lstm_conv\"]),\n",
    "        window      = trial.suggest_int(\"window\", 12, 72, step=6),\n",
    "        filters     = trial.suggest_categorical(\"filters\",[32,48,64,96,128]),\n",
    "        kernel      = trial.suggest_int(\"kernel\", 2, 7),\n",
    "        units       = trial.suggest_categorical(\"units\",  [32,64,96,128,192]),\n",
    "        conv_drop   = trial.suggest_float(\"conv_drop\", 0,.3),\n",
    "        lstm_drop   = trial.suggest_float(\"lstm_drop\", 0,.3),\n",
    "        dense       = trial.suggest_categorical(\"dense\",[32,64,128]),\n",
    "        dropout     = trial.suggest_float(\"dropout\", 0,.4),\n",
    "        l2          = trial.suggest_float(\"l2\", 1e-6,1e-3,log=True),\n",
    "        lr          = trial.suggest_float(\"lr\", 5e-5,3e-3,log=True),\n",
    "        batch       = trial.suggest_categorical(\"batch\",[16,32,64,128]),\n",
    "        act         = trial.suggest_categorical(\"act\", [\"relu\",\"elu\"]),\n",
    "        pool        = trial.suggest_categorical(\"pool\",[\"gmp\",\"gap\"]),\n",
    "        conv_blocks = trial.suggest_int(\"conv_blocks\",1,2),\n",
    "        optim       = trial.suggest_categorical(\"optim\",[\"adam\",\"adamw\",\"nadam\"])\n",
    "    )\n",
    "\n",
    "    X_tr,y_tr = make_windows(X_tr_raw,y_tr_raw,cfg[\"window\"])\n",
    "    X_va,y_va = make_windows(X_va_raw,y_va_raw,cfg[\"window\"])\n",
    "    if len(X_tr) < cfg[\"batch\"]*8: return float(\"inf\")\n",
    "\n",
    "    tf.keras.backend.clear_session(); gc.collect()\n",
    "    model = build(cfg)\n",
    "    cb = [\n",
    "        keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True,verbose=0),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=5,factor=.5,min_lr=1e-6,verbose=0),\n",
    "        TFKerasPruningCallback(trial,\"val_loss\")\n",
    "    ]\n",
    "    model.fit(X_tr,y_tr,epochs=100,batch_size=cfg[\"batch\"],\n",
    "              validation_data=(X_va,y_va),callbacks=cb,\n",
    "              shuffle=False,verbose=0)\n",
    "\n",
    "    prob = model.predict(X_va,batch_size=cfg[\"batch\"],verbose=0).ravel()\n",
    "    hat  = (prob>=.5).astype(int)\n",
    "    score= wf1(y_va,prob)\n",
    "    pr   = precision_score(y_va,hat,zero_division=0)\n",
    "    rc   = recall_score   (y_va,hat,zero_division=0)\n",
    "    f1   = f1_score       (y_va,hat,zero_division=0)\n",
    "    acc  = accuracy_score (y_va,hat)\n",
    "\n",
    "    trial.set_user_attr(\"precision\",pr)\n",
    "    trial.set_user_attr(\"recall\",rc)\n",
    "\n",
    "    print(f\"Trial {trial.number:02d} | Fα2={score:.3f} P={pr:.3f} R={rc:.3f} \"\n",
    "          f\"F1={f1:.3f} Acc={acc:.3f} {cfg['arch']} win={cfg['window']}\")\n",
    "\n",
    "    del model; tf.keras.backend.clear_session(); gc.collect()\n",
    "    return -score\n",
    "\n",
    "# ───────── run search ─────────\n",
    "study = optuna.create_study(direction=\"minimize\",\n",
    "                            sampler=optuna.samplers.TPESampler(seed=SEED,\n",
    "                                                               multivariate=True),\n",
    "                            pruner=optuna.pruners.MedianPruner(n_startup_trials=5))\n",
    "\n",
    "print(f\"\\n🚀  Starting {N_TRIALS}-trial search …\")\n",
    "study.optimize(objective, n_trials=N_TRIALS,\n",
    "               timeout=TIMEOUT, show_progress_bar=True, gc_after_trial=True)\n",
    "\n",
    "best, ts = study.best_trial, datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(\"\\n✅ BEST TRIAL\")\n",
    "print(json.dumps({**best.params,\n",
    "                  \"Fα2\": -best.value,\n",
    "                  \"P\"  : best.user_attrs[\"precision\"],\n",
    "                  \"R\"  : best.user_attrs[\"recall\"]}, indent=2))\n",
    "\n",
    "json.dump(best.params, open(f\"best_params_cnn_lstm_{ts}.json\",\"w\"), indent=2)\n",
    "study.trials_dataframe().to_csv(f\"trials_cnn_lstm_{ts}.csv\", index=False)\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "    plt.tight_layout(); plt.savefig(f\"history_cnn_lstm_{ts}.png\", dpi=300); plt.close()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(f\"\\n📝 Artefacts saved with timestamp {ts}.  Scaler → {SCALER_PKL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e77ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ─── imports ───────────────────────────────────────────────────\n",
    "import os, json, gc, warnings, joblib, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             precision_score, recall_score, f1_score,\n",
    "                             accuracy_score, roc_curve, auc,\n",
    "                             precision_recall_curve)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping,\n",
    "                                        ReduceLROnPlateau)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# ─── fixed params from Optuna ───────────────────────────────────────────\n",
    "BEST_PARAMS = dict(\n",
    "    arch=\"lstm_conv\", window=24, filters=64, kernel=5, units=32,\n",
    "    conv_drop=0.220, lstm_drop=0.285, dense=32, dropout=0.378,\n",
    "    l2=1.449e-6, lr=0.00135, batch=32, act=\"relu\", pool=\"gmp\"\n",
    ")\n",
    "\n",
    "# ─── paths & config ────────────────────────────────────────────\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "DROP_COLS = [\"open\",\"high\",\"low\",\"close\",\"typical_price\",\n",
    "             \"EMA_21\",\"SMA_20\",\"vwap_24h\",\"close_4h\"]\n",
    "\n",
    "SEED, VAL_FRAC, TEST_FRAC, ALPHA = 42, .15, .15, 2.0\n",
    "EPOCHS, PATIENCE = 200, 20\n",
    "\n",
    "OUT_DIR = Path(\"model_outputs\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "STAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# GPU setup with feedback\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    for g in gpus:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    print(f\"✅ Found {len(gpus)} GPU(s)\")\n",
    "else:\n",
    "    print(\"⚠️ No GPU found, using CPU\")\n",
    "\n",
    "# ─── data load & split ─────────────────────────────────────────────────\n",
    "print(\"📊 Loading data...\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns], errors='ignore')\n",
    "df = df.dropna(subset=[\"target\"]).dropna()\n",
    "\n",
    "# Store feature names before dropping target\n",
    "feat_names = [col for col in df.columns if col != \"target\"]\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values.astype(np.float32)\n",
    "y_raw = df[\"target\"].astype(np.int8).values\n",
    "n_feat = X_raw.shape[1]\n",
    "\n",
    "n = len(df)\n",
    "val_start = int(n * (1 - VAL_FRAC - TEST_FRAC))\n",
    "test_start = int(n * (1 - TEST_FRAC))\n",
    "train_idx = np.arange(0, val_start)\n",
    "val_idx = np.arange(val_start, test_start)\n",
    "test_idx = np.arange(test_start, n)\n",
    "\n",
    "scaler = StandardScaler().fit(X_raw[train_idx])\n",
    "X_train = scaler.transform(X_raw[train_idx])\n",
    "y_train = y_raw[train_idx]\n",
    "X_val = scaler.transform(X_raw[val_idx])\n",
    "y_val = y_raw[val_idx]\n",
    "X_test = scaler.transform(X_raw[test_idx])\n",
    "y_test = y_raw[test_idx]\n",
    "\n",
    "joblib.dump(scaler, OUT_DIR / f\"scaler_{STAMP}.pkl\")\n",
    "\n",
    "pos = y_train.mean()\n",
    "W0, W1 = 1.0, (1-pos)/pos if pos else 1.0\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")\n",
    "print(f\"Positive rate: {pos:.3f}, Weights: W0={W0:.2f}, W1={W1:.2f}\")\n",
    "\n",
    "# ─── window helper ─────────────────────────────────────────────────────\n",
    "def windows(X, y, w):\n",
    "    xs, ys = [], []\n",
    "    for i in range(w, len(X)):\n",
    "        xs.append(X[i-w:i])\n",
    "        ys.append(y[i])\n",
    "    return np.asarray(xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "win = BEST_PARAMS[\"window\"]\n",
    "X_tr_w, y_tr_w = windows(X_train, y_train, win)\n",
    "X_va_w, y_va_w = windows(X_val, y_val, win)\n",
    "X_te_w, y_te_w = windows(X_test, y_test, win)\n",
    "\n",
    "print(f\"Window size: {win}, Train windows: {len(X_tr_w)}\")\n",
    "\n",
    "# ─── weighted F1 score ─────────────────────────────────────────────────\n",
    "def wf1(y, proba, alpha=ALPHA):\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    pr = precision_score(y, preds, zero_division=0)\n",
    "    rc = recall_score(y, preds, zero_division=0)\n",
    "    return 0 if pr + rc == 0 else (1 + alpha) * pr * rc / (alpha * pr + rc)\n",
    "\n",
    "# ─── model builder ─────────────────────────────────────────────\n",
    "def build(cfg):\n",
    "    l2 = regularizers.l2(cfg[\"l2\"])\n",
    "    inp = layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    # LSTM → Conv1D branch\n",
    "    x = layers.LSTM(cfg[\"units\"], dropout=cfg[\"lstm_drop\"],\n",
    "                    return_sequences=True,\n",
    "                    kernel_regularizer=l2)(inp)\n",
    "    x = layers.Conv1D(cfg[\"filters\"], cfg[\"kernel\"], padding=\"same\",\n",
    "                      activation=cfg[\"act\"], kernel_regularizer=l2)(x)\n",
    "    x = (layers.GlobalMaxPooling1D()(x) if cfg[\"pool\"]==\"gmp\"\n",
    "         else layers.GlobalAveragePooling1D()(x))\n",
    "    x = layers.Dropout(cfg[\"conv_drop\"])(x)\n",
    "\n",
    "    x = layers.Dense(cfg[\"dense\"], activation=cfg[\"act\"],\n",
    "                     kernel_regularizer=l2)(x)\n",
    "    x = layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    w0 = tf.constant(W0, dtype=tf.float32)\n",
    "    w1 = tf.constant(W1, dtype=tf.float32)\n",
    "    \n",
    "    def wbce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, tf.float32)\n",
    "        w = tf.where(tf.equal(y_t, 1), w1, w0)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(keras.optimizers.Adam(cfg[\"lr\"]), loss=wbce,\n",
    "                  metrics=['accuracy',\n",
    "                           keras.metrics.Precision(name='precision'),\n",
    "                           keras.metrics.Recall(name='recall'),\n",
    "                           keras.metrics.AUC(name='auc')])\n",
    "    return model\n",
    "\n",
    "print(\"\\n🏗️ Building model...\")\n",
    "model = build(BEST_PARAMS)\n",
    "model.summary()\n",
    "\n",
    "# ─── callbacks & training ──────────────────────────────────────────────\n",
    "print(\"\\n🚀 Starting training...\")\n",
    "ckpt_path = OUT_DIR / f\"best_model_{STAMP}.keras\"\n",
    "\n",
    "history = model.fit(\n",
    "    X_tr_w, y_tr_w,\n",
    "    validation_data=(X_va_w, y_va_w),\n",
    "    epochs=EPOCHS, batch_size=BEST_PARAMS[\"batch\"],\n",
    "    class_weight={0: W0, 1: W1},\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(str(ckpt_path), save_best_only=True, monitor='val_loss', verbose=1),\n",
    "        EarlyStopping(patience=PATIENCE, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(patience=10, factor=.5, min_lr=1e-6, verbose=1)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save(OUT_DIR / f\"final_model_{STAMP}.keras\")\n",
    "\n",
    "# ─── evaluation helper ─────────────────────────────────────────────────\n",
    "def evaluate(X, y, name):\n",
    "    proba = model.predict(X, verbose=0).ravel()\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    pr = precision_score(y, preds, zero_division=0)\n",
    "    rc = recall_score(y, preds, zero_division=0)\n",
    "    f1 = f1_score(y, preds, zero_division=0)\n",
    "    fα = wf1(y, proba)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    print(f\"{name:<11} P={pr:.3f} R={rc:.3f} F1={f1:.3f} Fα2={fα:.3f} Acc={acc:.3f}\")\n",
    "    return dict(p=pr, r=rc, f1=f1, fα=fα, acc=acc, proba=proba, preds=preds, y=y)\n",
    "\n",
    "print(\"\\n📊 Metrics (0.5 threshold)\")\n",
    "train_res = evaluate(X_tr_w, y_tr_w, \"Train\")\n",
    "val_res = evaluate(X_va_w, y_va_w, \"Val\")\n",
    "test_res = evaluate(X_te_w, y_te_w, \"Test\")\n",
    "\n",
    "# ─── visualizations ─────────────────────────────────────────────────\n",
    "print(\"\\n📈 Creating visualizations...\")\n",
    "\n",
    "# 1. Training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes[0,0].plot(history.history['loss'], label='Train')\n",
    "axes[0,0].plot(history.history['val_loss'], label='Val')\n",
    "axes[0,0].set_title('Loss'); axes[0,0].legend()\n",
    "\n",
    "axes[0,1].plot(history.history['accuracy'], label='Train')\n",
    "axes[0,1].plot(history.history['val_accuracy'], label='Val')\n",
    "axes[0,1].set_title('Accuracy'); axes[0,1].legend()\n",
    "\n",
    "axes[1,0].plot(history.history['precision'], label='Train')\n",
    "axes[1,0].plot(history.history['val_precision'], label='Val')\n",
    "axes[1,0].set_title('Precision'); axes[1,0].legend()\n",
    "\n",
    "axes[1,1].plot(history.history['recall'], label='Train')\n",
    "axes[1,1].plot(history.history['val_recall'], label='Val')\n",
    "axes[1,1].set_title('Recall'); axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / f\"training_history_{STAMP}.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# 2. Confusion Matrix (Test Set)\n",
    "cm = confusion_matrix(test_res['y'], test_res['preds'])\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.savefig(OUT_DIR / f\"confusion_matrix_{STAMP}.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ─── save JSON summary ─────────────────────────────────────────────────\n",
    "json.dump(\n",
    "    {\"params\": BEST_PARAMS,\n",
    "     \"train\": {k: v for k, v in train_res.items() if not isinstance(v, np.ndarray)},\n",
    "     \"val\": {k: v for k, v in val_res.items() if not isinstance(v, np.ndarray)},\n",
    "     \"test\": {k: v for k, v in test_res.items() if not isinstance(v, np.ndarray)}},\n",
    "    open(OUT_DIR / f\"results_{STAMP}.json\", \"w\"), indent=2\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ All artifacts saved in {OUT_DIR} ({STAMP})\")\n",
    "print(f\"   - Model: final_model_{STAMP}.keras\")\n",
    "print(f\"   - Scaler: scaler_{STAMP}.pkl\")\n",
    "print(f\"   - Results: results_{STAMP}.json\")\n",
    "print(f\"   - Plots: *_{STAMP}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0becd50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"arch\": \"conv_lstm\",\n",
    "  \"window\": 66,\n",
    "  \"filters\": 32,\n",
    "  \"kernel\": 5,\n",
    "  \"units\": 32,\n",
    "  \"conv_drop\": 0.1990,\n",
    "  \"lstm_drop\": 0.0056,\n",
    "  \"dense\": 32,\n",
    "  \"dropout\": 0.3674,\n",
    "  \"l2\": 1.73e-06,\n",
    "  \"lr\": 5.455e-05,\n",
    "  \"batch\": 32,\n",
    "  \"act\": \"relu\",\n",
    "  \"pool\": \"gap\",\n",
    "  \"conv_blocks\": 2,\n",
    "  \"optim\": \"nadam\",\n",
    "  \"precision\": 0.554,\n",
    "  \"recall\": 0.501,\n",
    "  \"f_alpha\": 0.518\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"arch\": \"conv_lstm\",\n",
    "  \"window\": 72,\n",
    "  \"filters\": 96,\n",
    "  \"kernel\": 4,\n",
    "  \"units\": 32,\n",
    "  \"conv_drop\": 0.2349,\n",
    "  \"lstm_drop\": 0.0741,\n",
    "  \"dense\": 128,\n",
    "  \"dropout\": 0.3562,\n",
    "  \"l2\": 1.93e-06,\n",
    "  \"lr\": 8.557e-05,\n",
    "  \"batch\": 128,\n",
    "  \"act\": \"relu\",\n",
    "  \"pool\": \"gmp\",\n",
    "  \"conv_blocks\": 2,\n",
    "  \"optim\": \"nadam\",\n",
    "  \"precision\": 0.547,\n",
    "  \"recall\": 0.371,\n",
    "  \"f_alpha\": 0.415\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b51a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"arch\": \"lstm_conv\",\n",
    "  \"window\": 66,\n",
    "  \"filters\": 64,\n",
    "  \"kernel\": 3,\n",
    "  \"units\": 64,\n",
    "  \"conv_drop\": 0.2411,\n",
    "  \"lstm_drop\": 0.0560,\n",
    "  \"dense\": 32,\n",
    "  \"dropout\": 0.3584,\n",
    "  \"l2\": 8.995e-06,\n",
    "  \"lr\": 7.846e-05,\n",
    "  \"batch\": 128,\n",
    "  \"act\": \"elu\",\n",
    "  \"pool\": \"gmp\",\n",
    "  \"conv_blocks\": 1,\n",
    "  \"optim\": \"adamw\",\n",
    "  \"precision\": 0.533,\n",
    "  \"recall\": 0.722,\n",
    "  \"f_alpha\": 0.646\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

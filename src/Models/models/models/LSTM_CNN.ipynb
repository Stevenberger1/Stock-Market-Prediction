{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a75b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep \n",
    "atr_14  , OBV\n",
    "\n",
    "drop\n",
    "\n",
    "'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'trending_market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7131221",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lstm_cnn = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'rsi_overbought', 'stoch_oversold', 'cci_oversold',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6','ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801781b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 12:51:22,414] A new study created in memory with name: no-name-4a13c6ca-8c08-4449-91d3-c10d60bb8970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ  Starting 100-trial search ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 00 | FŒ±2=0.554 P=0.524 R=0.570 F1=0.546 Acc=0.506 lstm_conv win=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [02:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 12:53:27,827] Trial 0 finished with value: -0.5537355173791451 and parameters: {'arch': 'lstm_conv', 'window': 60, 'filters': 128, 'kernel': 5, 'units': 96, 'conv_drop': 0.05454749016213018, 'lstm_drop': 0.055021352956030146, 'dense': 64, 'dropout': 0.11649165607921677, 'l2': 6.847920095574779e-05, 'lr': 8.851384099881297e-05, 'batch': 128, 'act': 'elu', 'pool': 'gmp', 'conv_blocks': 2, 'optim': 'nadam'}. Best is trial 0 with value: -0.5537355173791451.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   1%|          | 1/100 [02:06<3:29:03, 126.71s/it, 126.70/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 01 | FŒ±2=0.280 P=0.547 R=0.225 F1=0.319 Acc=0.499 conv_lstm win=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   1%|          | 1/100 [02:30<3:29:03, 126.71s/it, 126.70/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 12:53:53,177] Trial 1 finished with value: -0.2801113360323887 and parameters: {'arch': 'conv_lstm', 'window': 30, 'filters': 48, 'kernel': 2, 'units': 32, 'conv_drop': 0.16401308380298388, 'lstm_drop': 0.05545633665765811, 'dense': 32, 'dropout': 0.35793094017105953, 'l2': 6.218704727769077e-05, 'lr': 0.0021787220464104273, 'batch': 128, 'act': 'relu', 'pool': 'gmp', 'conv_blocks': 1, 'optim': 'nadam'}. Best is trial 0 with value: -0.5537355173791451.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   2%|‚ñè         | 2/100 [02:32<1:49:39, 67.14s/it, 152.15/3600 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 02 | FŒ±2=0.090 P=0.554 R=0.064 F1=0.114 Acc=0.485 lstm_conv win=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   2%|‚ñè         | 2/100 [05:56<1:49:39, 67.14s/it, 152.15/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 12:57:18,623] Trial 2 finished with value: -0.09008746355685131 and parameters: {'arch': 'lstm_conv', 'window': 60, 'filters': 64, 'kernel': 6, 'units': 128, 'conv_drop': 0.09926940745579475, 'lstm_drop': 0.01906750508580709, 'dense': 128, 'dropout': 0.25502298854208527, 'l2': 0.0004588156549160974, 'lr': 0.000345652389857876, 'batch': 64, 'act': 'relu', 'pool': 'gmp', 'conv_blocks': 1, 'optim': 'nadam'}. Best is trial 0 with value: -0.5537355173791451.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   3%|‚ñé         | 3/100 [05:57<3:30:39, 130.30s/it, 357.61/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 03 | FŒ±2=0.567 P=0.519 R=0.594 F1=0.554 Acc=0.501 lstm_conv win=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.553736:   3%|‚ñé         | 3/100 [08:27<3:30:39, 130.30s/it, 357.61/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 12:59:50,245] Trial 3 finished with value: -0.5669152276295134 and parameters: {'arch': 'lstm_conv', 'window': 66, 'filters': 64, 'kernel': 3, 'units': 64, 'conv_drop': 0.24110162306973432, 'lstm_drop': 0.05597101766581075, 'dense': 32, 'dropout': 0.3584365199693973, 'l2': 8.995191735587168e-06, 'lr': 7.846192726793281e-05, 'batch': 128, 'act': 'elu', 'pool': 'gmp', 'conv_blocks': 1, 'optim': 'adamw'}. Best is trial 3 with value: -0.5669152276295134.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: -0.566915:   4%|‚ñç         | 4/100 [08:29<3:41:57, 138.72s/it, 509.24/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 04 | FŒ±2=0.000 P=0.000 R=0.000 F1=0.000 Acc=0.478 lstm_conv win=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: -0.566915:   4%|‚ñç         | 4/100 [09:25<3:41:57, 138.72s/it, 509.24/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:00:47,566] Trial 4 finished with value: 0.0 and parameters: {'arch': 'lstm_conv', 'window': 30, 'filters': 32, 'kernel': 3, 'units': 64, 'conv_drop': 0.2724797657899961, 'lstm_drop': 0.07186856720009173, 'dense': 128, 'dropout': 0.09682210860460017, 'l2': 0.00010385003379927417, 'lr': 0.0011304331263607352, 'batch': 32, 'act': 'relu', 'pool': 'gap', 'conv_blocks': 1, 'optim': 'nadam'}. Best is trial 3 with value: -0.5669152276295134.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: -0.566915:   5%|‚ñå         | 5/100 [09:26<2:53:11, 109.39s/it, 566.61/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 05 | FŒ±2=0.586 P=0.526 R=0.622 F1=0.570 Acc=0.510 conv_lstm win=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: -0.566915:   5%|‚ñå         | 5/100 [12:03<2:53:11, 109.39s/it, 566.61/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:03:26,190] Trial 5 finished with value: -0.5861405197305101 and parameters: {'arch': 'conv_lstm', 'window': 42, 'filters': 96, 'kernel': 7, 'units': 128, 'conv_drop': 0.07738248831454668, 'lstm_drop': 0.1979952138102537, 'dense': 32, 'dropout': 0.09674091636018067, 'l2': 1.902428324748959e-06, 'lr': 0.001969497011745637, 'batch': 16, 'act': 'elu', 'pool': 'gmp', 'conv_blocks': 2, 'optim': 'nadam'}. Best is trial 5 with value: -0.5861405197305101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:   6%|‚ñå         | 6/100 [12:05<3:17:34, 126.11s/it, 725.20/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 06 | FŒ±2=0.030 P=0.559 R=0.020 F1=0.039 Acc=0.480 conv_lstm win=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:   6%|‚ñå         | 6/100 [14:33<3:17:34, 126.11s/it, 725.20/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:05:56,316] Trial 6 finished with value: -0.029525797793021172 and parameters: {'arch': 'conv_lstm', 'window': 18, 'filters': 128, 'kernel': 5, 'units': 192, 'conv_drop': 0.1948898697141644, 'lstm_drop': 0.2547670231482534, 'dense': 32, 'dropout': 0.1470863212237734, 'l2': 6.24607368131809e-06, 'lr': 0.00013577521331829283, 'batch': 16, 'act': 'relu', 'pool': 'gmp', 'conv_blocks': 1, 'optim': 'adam'}. Best is trial 5 with value: -0.5861405197305101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:   7%|‚ñã         | 7/100 [16:16<3:27:36, 133.94s/it, 875.24/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:07:39,087] Trial 7 pruned. Trial was pruned at epoch 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:   8%|‚ñä         | 8/100 [16:35<3:10:11, 124.04s/it, 978.09/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:07:57,890] Trial 8 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:   9%|‚ñâ         | 9/100 [16:53<2:18:12, 91.13s/it, 996.86/3600 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:08:15,914] Trial 9 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  10%|‚ñà         | 10/100 [16:54<1:42:50, 68.56s/it, 1014.89/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 | FŒ±2=0.000 P=0.000 R=0.000 F1=0.000 Acc=0.478 conv_lstm win=36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  10%|‚ñà         | 10/100 [19:48<1:42:50, 68.56s/it, 1014.89/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:11:11,403] Trial 10 finished with value: 0.0 and parameters: {'arch': 'conv_lstm', 'window': 36, 'filters': 32, 'kernel': 6, 'units': 128, 'conv_drop': 0.07202341203296447, 'lstm_drop': 0.18814920204905028, 'dense': 64, 'dropout': 0.03425733184657786, 'l2': 3.0695249234567865e-06, 'lr': 0.001418232376111356, 'batch': 16, 'act': 'relu', 'pool': 'gmp', 'conv_blocks': 1, 'optim': 'nadam'}. Best is trial 5 with value: -0.5861405197305101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  11%|‚ñà         | 11/100 [19:50<2:30:14, 101.29s/it, 1190.37/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 | FŒ±2=0.508 P=0.519 R=0.502 F1=0.511 Acc=0.497 lstm_conv win=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  11%|‚ñà         | 11/100 [26:21<2:30:14, 101.29s/it, 1190.37/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:17:44,047] Trial 11 finished with value: -0.5077978789769183 and parameters: {'arch': 'lstm_conv', 'window': 66, 'filters': 64, 'kernel': 3, 'units': 128, 'conv_drop': 0.2757420493320118, 'lstm_drop': 0.09027008622194727, 'dense': 32, 'dropout': 0.3870562117313163, 'l2': 1.1071142752856649e-05, 'lr': 0.00012710261905184188, 'batch': 128, 'act': 'relu', 'pool': 'gap', 'conv_blocks': 1, 'optim': 'adamw'}. Best is trial 5 with value: -0.5861405197305101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  12%|‚ñà‚ñè        | 12/100 [26:44<4:38:34, 189.93s/it, 1583.06/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:18:07,157] Trial 12 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  13%|‚ñà‚ñé        | 13/100 [27:01<3:22:06, 139.39s/it, 1606.14/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:18:24,090] Trial 13 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  14%|‚ñà‚ñç        | 14/100 [27:03<2:26:47, 102.41s/it, 1623.10/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 | FŒ±2=0.766 P=0.522 R=1.000 F1=0.686 Acc=0.522 conv_lstm win=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: -0.586141:  14%|‚ñà‚ñç        | 14/100 [33:35<2:26:47, 102.41s/it, 1623.10/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:24:58,034] Trial 14 finished with value: -0.7657869934024506 and parameters: {'arch': 'conv_lstm', 'window': 54, 'filters': 96, 'kernel': 7, 'units': 192, 'conv_drop': 0.023002858013431764, 'lstm_drop': 0.20388968390933723, 'dense': 32, 'dropout': 0.15387612135152867, 'l2': 6.633730435337335e-06, 'lr': 0.0027802249303014543, 'batch': 16, 'act': 'elu', 'pool': 'gap', 'conv_blocks': 2, 'optim': 'nadam'}. Best is trial 14 with value: -0.7657869934024506.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: -0.765787:  15%|‚ñà‚ñå        | 15/100 [34:11<4:29:33, 190.28s/it, 2017.03/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-11 13:25:34,111] Trial 15 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: -0.765787:  16%|‚ñà‚ñå        | 16/100 [34:13<3:21:25, 143.87s/it, 2053.13/3600 seconds]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "cnn_lstm_optuna_search.py  ¬∑ 2025-06-11\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Optuna hyper-parameter search for a CNN‚ÄìLSTM classifier\n",
    "optimising weighted-F1 with Œ± = 2 (precision √ó2 weight).\n",
    "\n",
    "Outputs\n",
    "-------\n",
    "‚Ä¢ cnn_lstm_scaler.pkl\n",
    "‚Ä¢ best_params_cnn_lstm_<ts>.json\n",
    "‚Ä¢ trials_cnn_lstm_<ts>.csv\n",
    "‚Ä¢ history_cnn_lstm_<ts>.png\n",
    "\"\"\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ imports & runtime hygiene ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import os, json, gc, warnings, optuna\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             f1_score, accuracy_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from optuna_integration.tfkeras import TFKerasPruningCallback\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED, VAL_FRAC, ALPHA  = 42, 0.20, 2.0\n",
    "N_TRIALS, TIMEOUT      = 100, 60 * 60      # ‚Üê 100 trials, 1 hour max\n",
    "\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "SCALER_PKL = \"cnn_lstm_scaler.pkl\"\n",
    "\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20'\n",
    "     ,'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'rsi_overbought', 'stoch_oversold', 'cci_oversold',\n",
    "    'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6','ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal','close'\n",
    "]\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ data load & scale ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "df = (pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "        .loc[\"2018-01-01\":]\n",
    "        .drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "        .dropna(subset=[\"target\"]).dropna())\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_feat = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "pos = y_tr_raw.mean()\n",
    "W0, W1 = np.float32(1.0), np.float32((1 - pos) / pos if pos else 1.0)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ window helper (cache) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "_CACHE: Dict[Tuple[int,int,int], Tuple[np.ndarray,np.ndarray]] = {}\n",
    "def make_windows(arr, lab, win):\n",
    "    k = (len(arr), win, arr.shape[1])\n",
    "    if k in _CACHE: return _CACHE[k]\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i-win:i]); y.append(lab[i])\n",
    "    Xw, yw = np.asarray(X,np.float32), np.asarray(y,np.int8)\n",
    "    if Xw.nbytes+yw.nbytes < 1e9: _CACHE[k]=(Xw,yw)\n",
    "    return Xw, yw\n",
    "\n",
    "def wf1(y, p, alpha=ALPHA):\n",
    "    hat = (p>=.5).astype(int)\n",
    "    pr, rc = precision_score(y,hat,zero_division=0), recall_score(y,hat,zero_division=0)\n",
    "    return 0 if pr+rc==0 else (1+alpha)*pr*rc/(alpha*pr+rc)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ model factory ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def build(cfg):\n",
    "    l2 = regularizers.l2(cfg[\"l2\"])\n",
    "    inp = layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    if cfg[\"arch\"] == \"conv_lstm\":\n",
    "        x = inp\n",
    "        for _ in range(cfg[\"conv_blocks\"]):\n",
    "            x = layers.Conv1D(cfg[\"filters\"], cfg[\"kernel\"], padding=\"causal\",\n",
    "                              activation=cfg[\"act\"], kernel_regularizer=l2)(x)\n",
    "            x = layers.Dropout(cfg[\"conv_drop\"])(x)\n",
    "        x = layers.LSTM(cfg[\"units\"], dropout=cfg[\"lstm_drop\"])(x)\n",
    "    else:  # lstm_conv\n",
    "        x = layers.LSTM(cfg[\"units\"], dropout=cfg[\"lstm_drop\"],\n",
    "                        return_sequences=True)(inp)\n",
    "        x = layers.Conv1D(cfg[\"filters\"], cfg[\"kernel\"], padding=\"same\",\n",
    "                          activation=cfg[\"act\"], kernel_regularizer=l2)(x)\n",
    "        x = (layers.GlobalMaxPooling1D()(x) if cfg[\"pool\"]==\"gmp\"\n",
    "             else layers.GlobalAveragePooling1D()(x))\n",
    "\n",
    "    x = layers.Dense(cfg[\"dense\"], activation=cfg[\"act\"], kernel_regularizer=l2)(x)\n",
    "    x = layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    def wbce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t,1), W1, W0); w = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    # choose optimiser\n",
    "    if cfg[\"optim\"] == \"adamw\":\n",
    "        opt = keras.optimizers.AdamW(cfg[\"lr\"], weight_decay=cfg[\"l2\"])\n",
    "    elif cfg[\"optim\"] == \"nadam\":\n",
    "        opt = keras.optimizers.Nadam(cfg[\"lr\"])\n",
    "    else:\n",
    "        opt = keras.optimizers.Adam(cfg[\"lr\"])\n",
    "\n",
    "    model.compile(opt, loss=wbce)\n",
    "    return model\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Optuna objective ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def objective(trial):\n",
    "    cfg = dict(\n",
    "        arch        = trial.suggest_categorical(\"arch\", [\"conv_lstm\",\"lstm_conv\"]),\n",
    "        window      = trial.suggest_int(\"window\", 12, 72, step=6),\n",
    "        filters     = trial.suggest_categorical(\"filters\",[32,48,64,96,128]),\n",
    "        kernel      = trial.suggest_int(\"kernel\", 2, 7),\n",
    "        units       = trial.suggest_categorical(\"units\",  [32,64,96,128,192]),\n",
    "        conv_drop   = trial.suggest_float(\"conv_drop\", 0,.3),\n",
    "        lstm_drop   = trial.suggest_float(\"lstm_drop\", 0,.3),\n",
    "        dense       = trial.suggest_categorical(\"dense\",[32,64,128]),\n",
    "        dropout     = trial.suggest_float(\"dropout\", 0,.4),\n",
    "        l2          = trial.suggest_float(\"l2\", 1e-6,1e-3,log=True),\n",
    "        lr          = trial.suggest_float(\"lr\", 5e-5,3e-3,log=True),\n",
    "        batch       = trial.suggest_categorical(\"batch\",[16,32,64,128]),\n",
    "        act         = trial.suggest_categorical(\"act\", [\"relu\",\"elu\"]),\n",
    "        pool        = trial.suggest_categorical(\"pool\",[\"gmp\",\"gap\"]),\n",
    "        conv_blocks = trial.suggest_int(\"conv_blocks\",1,2),\n",
    "        optim       = trial.suggest_categorical(\"optim\",[\"adam\",\"adamw\",\"nadam\"])\n",
    "    )\n",
    "\n",
    "    X_tr,y_tr = make_windows(X_tr_raw,y_tr_raw,cfg[\"window\"])\n",
    "    X_va,y_va = make_windows(X_va_raw,y_va_raw,cfg[\"window\"])\n",
    "    if len(X_tr) < cfg[\"batch\"]*8: return float(\"inf\")\n",
    "\n",
    "    tf.keras.backend.clear_session(); gc.collect()\n",
    "    model = build(cfg)\n",
    "    cb = [\n",
    "        keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True,verbose=0),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=5,factor=.5,min_lr=1e-6,verbose=0),\n",
    "        TFKerasPruningCallback(trial,\"val_loss\")\n",
    "    ]\n",
    "    model.fit(X_tr,y_tr,epochs=100,batch_size=cfg[\"batch\"],\n",
    "              validation_data=(X_va,y_va),callbacks=cb,\n",
    "              shuffle=False,verbose=0)\n",
    "\n",
    "    prob = model.predict(X_va,batch_size=cfg[\"batch\"],verbose=0).ravel()\n",
    "    hat  = (prob>=.5).astype(int)\n",
    "    score= wf1(y_va,prob)\n",
    "    pr   = precision_score(y_va,hat,zero_division=0)\n",
    "    rc   = recall_score   (y_va,hat,zero_division=0)\n",
    "    f1   = f1_score       (y_va,hat,zero_division=0)\n",
    "    acc  = accuracy_score (y_va,hat)\n",
    "\n",
    "    trial.set_user_attr(\"precision\",pr)\n",
    "    trial.set_user_attr(\"recall\",rc)\n",
    "\n",
    "    print(f\"Trial {trial.number:02d} | FŒ±2={score:.3f} P={pr:.3f} R={rc:.3f} \"\n",
    "          f\"F1={f1:.3f} Acc={acc:.3f} {cfg['arch']} win={cfg['window']}\")\n",
    "\n",
    "    del model; tf.keras.backend.clear_session(); gc.collect()\n",
    "    return -score\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ run search ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "study = optuna.create_study(direction=\"minimize\",\n",
    "                            sampler=optuna.samplers.TPESampler(seed=SEED,\n",
    "                                                               multivariate=True),\n",
    "                            pruner=optuna.pruners.MedianPruner(n_startup_trials=5))\n",
    "\n",
    "print(f\"\\nüöÄ  Starting {N_TRIALS}-trial search ‚Ä¶\")\n",
    "study.optimize(objective, n_trials=N_TRIALS,\n",
    "               timeout=TIMEOUT, show_progress_bar=True, gc_after_trial=True)\n",
    "\n",
    "best, ts = study.best_trial, datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(\"\\n‚úÖ BEST TRIAL\")\n",
    "print(json.dumps({**best.params,\n",
    "                  \"FŒ±2\": -best.value,\n",
    "                  \"P\"  : best.user_attrs[\"precision\"],\n",
    "                  \"R\"  : best.user_attrs[\"recall\"]}, indent=2))\n",
    "\n",
    "json.dump(best.params, open(f\"best_params_cnn_lstm_{ts}.json\",\"w\"), indent=2)\n",
    "study.trials_dataframe().to_csv(f\"trials_cnn_lstm_{ts}.csv\", index=False)\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "    plt.tight_layout(); plt.savefig(f\"history_cnn_lstm_{ts}.png\", dpi=300); plt.close()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(f\"\\nüìù Artefacts saved with timestamp {ts}.  Scaler ‚Üí {SCALER_PKL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e77ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ imports ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import os, json, gc, warnings, joblib, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             precision_score, recall_score, f1_score,\n",
    "                             accuracy_score, roc_curve, auc,\n",
    "                             precision_recall_curve)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping,\n",
    "                                        ReduceLROnPlateau)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ fixed params from Optuna ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "BEST_PARAMS = dict(\n",
    "    arch=\"lstm_conv\", window=24, filters=64, kernel=5, units=32,\n",
    "    conv_drop=0.220, lstm_drop=0.285, dense=32, dropout=0.378,\n",
    "    l2=1.449e-6, lr=0.00135, batch=32, act=\"relu\", pool=\"gmp\"\n",
    ")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ paths & config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "DROP_COLS = [\"open\",\"high\",\"low\",\"close\",\"typical_price\",\n",
    "             \"EMA_21\",\"SMA_20\",\"vwap_24h\",\"close_4h\"]\n",
    "\n",
    "SEED, VAL_FRAC, TEST_FRAC, ALPHA = 42, .15, .15, 2.0\n",
    "EPOCHS, PATIENCE = 200, 20\n",
    "\n",
    "OUT_DIR = Path(\"model_outputs\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "STAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# GPU setup with feedback\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    for g in gpus:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    print(f\"‚úÖ Found {len(gpus)} GPU(s)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU found, using CPU\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ data load & split ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"üìä Loading data...\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns], errors='ignore')\n",
    "df = df.dropna(subset=[\"target\"]).dropna()\n",
    "\n",
    "# Store feature names before dropping target\n",
    "feat_names = [col for col in df.columns if col != \"target\"]\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values.astype(np.float32)\n",
    "y_raw = df[\"target\"].astype(np.int8).values\n",
    "n_feat = X_raw.shape[1]\n",
    "\n",
    "n = len(df)\n",
    "val_start = int(n * (1 - VAL_FRAC - TEST_FRAC))\n",
    "test_start = int(n * (1 - TEST_FRAC))\n",
    "train_idx = np.arange(0, val_start)\n",
    "val_idx = np.arange(val_start, test_start)\n",
    "test_idx = np.arange(test_start, n)\n",
    "\n",
    "scaler = StandardScaler().fit(X_raw[train_idx])\n",
    "X_train = scaler.transform(X_raw[train_idx])\n",
    "y_train = y_raw[train_idx]\n",
    "X_val = scaler.transform(X_raw[val_idx])\n",
    "y_val = y_raw[val_idx]\n",
    "X_test = scaler.transform(X_raw[test_idx])\n",
    "y_test = y_raw[test_idx]\n",
    "\n",
    "joblib.dump(scaler, OUT_DIR / f\"scaler_{STAMP}.pkl\")\n",
    "\n",
    "pos = y_train.mean()\n",
    "W0, W1 = 1.0, (1-pos)/pos if pos else 1.0\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")\n",
    "print(f\"Positive rate: {pos:.3f}, Weights: W0={W0:.2f}, W1={W1:.2f}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ window helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def windows(X, y, w):\n",
    "    xs, ys = [], []\n",
    "    for i in range(w, len(X)):\n",
    "        xs.append(X[i-w:i])\n",
    "        ys.append(y[i])\n",
    "    return np.asarray(xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "win = BEST_PARAMS[\"window\"]\n",
    "X_tr_w, y_tr_w = windows(X_train, y_train, win)\n",
    "X_va_w, y_va_w = windows(X_val, y_val, win)\n",
    "X_te_w, y_te_w = windows(X_test, y_test, win)\n",
    "\n",
    "print(f\"Window size: {win}, Train windows: {len(X_tr_w)}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ weighted F1 score ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def wf1(y, proba, alpha=ALPHA):\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    pr = precision_score(y, preds, zero_division=0)\n",
    "    rc = recall_score(y, preds, zero_division=0)\n",
    "    return 0 if pr + rc == 0 else (1 + alpha) * pr * rc / (alpha * pr + rc)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ model builder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def build(cfg):\n",
    "    l2 = regularizers.l2(cfg[\"l2\"])\n",
    "    inp = layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    # LSTM ‚Üí Conv1D branch\n",
    "    x = layers.LSTM(cfg[\"units\"], dropout=cfg[\"lstm_drop\"],\n",
    "                    return_sequences=True,\n",
    "                    kernel_regularizer=l2)(inp)\n",
    "    x = layers.Conv1D(cfg[\"filters\"], cfg[\"kernel\"], padding=\"same\",\n",
    "                      activation=cfg[\"act\"], kernel_regularizer=l2)(x)\n",
    "    x = (layers.GlobalMaxPooling1D()(x) if cfg[\"pool\"]==\"gmp\"\n",
    "         else layers.GlobalAveragePooling1D()(x))\n",
    "    x = layers.Dropout(cfg[\"conv_drop\"])(x)\n",
    "\n",
    "    x = layers.Dense(cfg[\"dense\"], activation=cfg[\"act\"],\n",
    "                     kernel_regularizer=l2)(x)\n",
    "    x = layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    w0 = tf.constant(W0, dtype=tf.float32)\n",
    "    w1 = tf.constant(W1, dtype=tf.float32)\n",
    "    \n",
    "    def wbce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, tf.float32)\n",
    "        w = tf.where(tf.equal(y_t, 1), w1, w0)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(keras.optimizers.Adam(cfg[\"lr\"]), loss=wbce,\n",
    "                  metrics=['accuracy',\n",
    "                           keras.metrics.Precision(name='precision'),\n",
    "                           keras.metrics.Recall(name='recall'),\n",
    "                           keras.metrics.AUC(name='auc')])\n",
    "    return model\n",
    "\n",
    "print(\"\\nüèóÔ∏è Building model...\")\n",
    "model = build(BEST_PARAMS)\n",
    "model.summary()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ callbacks & training ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "ckpt_path = OUT_DIR / f\"best_model_{STAMP}.keras\"\n",
    "\n",
    "history = model.fit(\n",
    "    X_tr_w, y_tr_w,\n",
    "    validation_data=(X_va_w, y_va_w),\n",
    "    epochs=EPOCHS, batch_size=BEST_PARAMS[\"batch\"],\n",
    "    class_weight={0: W0, 1: W1},\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(str(ckpt_path), save_best_only=True, monitor='val_loss', verbose=1),\n",
    "        EarlyStopping(patience=PATIENCE, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(patience=10, factor=.5, min_lr=1e-6, verbose=1)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save(OUT_DIR / f\"final_model_{STAMP}.keras\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ evaluation helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def evaluate(X, y, name):\n",
    "    proba = model.predict(X, verbose=0).ravel()\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    pr = precision_score(y, preds, zero_division=0)\n",
    "    rc = recall_score(y, preds, zero_division=0)\n",
    "    f1 = f1_score(y, preds, zero_division=0)\n",
    "    fŒ± = wf1(y, proba)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    print(f\"{name:<11} P={pr:.3f} R={rc:.3f} F1={f1:.3f} FŒ±2={fŒ±:.3f} Acc={acc:.3f}\")\n",
    "    return dict(p=pr, r=rc, f1=f1, fŒ±=fŒ±, acc=acc, proba=proba, preds=preds, y=y)\n",
    "\n",
    "print(\"\\nüìä Metrics (0.5 threshold)\")\n",
    "train_res = evaluate(X_tr_w, y_tr_w, \"Train\")\n",
    "val_res = evaluate(X_va_w, y_va_w, \"Val\")\n",
    "test_res = evaluate(X_te_w, y_te_w, \"Test\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ visualizations ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\nüìà Creating visualizations...\")\n",
    "\n",
    "# 1. Training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes[0,0].plot(history.history['loss'], label='Train')\n",
    "axes[0,0].plot(history.history['val_loss'], label='Val')\n",
    "axes[0,0].set_title('Loss'); axes[0,0].legend()\n",
    "\n",
    "axes[0,1].plot(history.history['accuracy'], label='Train')\n",
    "axes[0,1].plot(history.history['val_accuracy'], label='Val')\n",
    "axes[0,1].set_title('Accuracy'); axes[0,1].legend()\n",
    "\n",
    "axes[1,0].plot(history.history['precision'], label='Train')\n",
    "axes[1,0].plot(history.history['val_precision'], label='Val')\n",
    "axes[1,0].set_title('Precision'); axes[1,0].legend()\n",
    "\n",
    "axes[1,1].plot(history.history['recall'], label='Train')\n",
    "axes[1,1].plot(history.history['val_recall'], label='Val')\n",
    "axes[1,1].set_title('Recall'); axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / f\"training_history_{STAMP}.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# 2. Confusion Matrix (Test Set)\n",
    "cm = confusion_matrix(test_res['y'], test_res['preds'])\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.savefig(OUT_DIR / f\"confusion_matrix_{STAMP}.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ save JSON summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "json.dump(\n",
    "    {\"params\": BEST_PARAMS,\n",
    "     \"train\": {k: v for k, v in train_res.items() if not isinstance(v, np.ndarray)},\n",
    "     \"val\": {k: v for k, v in val_res.items() if not isinstance(v, np.ndarray)},\n",
    "     \"test\": {k: v for k, v in test_res.items() if not isinstance(v, np.ndarray)}},\n",
    "    open(OUT_DIR / f\"results_{STAMP}.json\", \"w\"), indent=2\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ All artifacts saved in {OUT_DIR} ({STAMP})\")\n",
    "print(f\"   - Model: final_model_{STAMP}.keras\")\n",
    "print(f\"   - Scaler: scaler_{STAMP}.pkl\")\n",
    "print(f\"   - Results: results_{STAMP}.json\")\n",
    "print(f\"   - Plots: *_{STAMP}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0becd50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"arch\": \"conv_lstm\",\n",
    "  \"window\": 66,\n",
    "  \"filters\": 32,\n",
    "  \"kernel\": 5,\n",
    "  \"units\": 32,\n",
    "  \"conv_drop\": 0.1990,\n",
    "  \"lstm_drop\": 0.0056,\n",
    "  \"dense\": 32,\n",
    "  \"dropout\": 0.3674,\n",
    "  \"l2\": 1.73e-06,\n",
    "  \"lr\": 5.455e-05,\n",
    "  \"batch\": 32,\n",
    "  \"act\": \"relu\",\n",
    "  \"pool\": \"gap\",\n",
    "  \"conv_blocks\": 2,\n",
    "  \"optim\": \"nadam\",\n",
    "  \"precision\": 0.554,\n",
    "  \"recall\": 0.501,\n",
    "  \"f_alpha\": 0.518\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"arch\": \"conv_lstm\",\n",
    "  \"window\": 72,\n",
    "  \"filters\": 96,\n",
    "  \"kernel\": 4,\n",
    "  \"units\": 32,\n",
    "  \"conv_drop\": 0.2349,\n",
    "  \"lstm_drop\": 0.0741,\n",
    "  \"dense\": 128,\n",
    "  \"dropout\": 0.3562,\n",
    "  \"l2\": 1.93e-06,\n",
    "  \"lr\": 8.557e-05,\n",
    "  \"batch\": 128,\n",
    "  \"act\": \"relu\",\n",
    "  \"pool\": \"gmp\",\n",
    "  \"conv_blocks\": 2,\n",
    "  \"optim\": \"nadam\",\n",
    "  \"precision\": 0.547,\n",
    "  \"recall\": 0.371,\n",
    "  \"f_alpha\": 0.415\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b51a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"arch\": \"lstm_conv\",\n",
    "  \"window\": 66,\n",
    "  \"filters\": 64,\n",
    "  \"kernel\": 3,\n",
    "  \"units\": 64,\n",
    "  \"conv_drop\": 0.2411,\n",
    "  \"lstm_drop\": 0.0560,\n",
    "  \"dense\": 32,\n",
    "  \"dropout\": 0.3584,\n",
    "  \"l2\": 8.995e-06,\n",
    "  \"lr\": 7.846e-05,\n",
    "  \"batch\": 128,\n",
    "  \"act\": \"elu\",\n",
    "  \"pool\": \"gmp\",\n",
    "  \"conv_blocks\": 1,\n",
    "  \"optim\": \"adamw\",\n",
    "  \"precision\": 0.533,\n",
    "  \"recall\": 0.722,\n",
    "  \"f_alpha\": 0.646\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

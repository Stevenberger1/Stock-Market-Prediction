{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62dcffa1",
   "metadata": {},
   "source": [
    "# In this notebook we would build the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb3fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep \n",
    "atr_14  , obv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becba6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep \n",
    "atr_14  , obv\n",
    "\n",
    "drop\n",
    "\n",
    "ema_cross_up, macd_cross_up, oversold_reversal, overbought_reversal, trending_market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1bf238",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cnn = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_7', 'EMA_21', 'SMA_20', \n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower', \n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'bollinger_width', 'volatility_regime',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6''ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'trending_market'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc938698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 23:32:15,056] A new study created in memory with name: no-name-20976309-b2e8-42fd-ad22-832de27308a7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Scaler fitted on 12684 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.515 | Recall=0.736 | F1=0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.445697:   3%|▎         | 1/30 [00:13<06:19, 13.07s/it, 13.07/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.488 | Recall=0.453 | F1=0.464\n",
      "[I 2025-06-07 23:32:28,130] Trial 0 finished with value: 0.44569688452624034 and parameters: {'window': 24, 'batch': 32, 'lr': 0.0010401663679887319, 'epochs': 20, 'conv_blocks': 1, 'filters': 32, 'kernel': 4, 'act': 'elu', 'dropout': 0.2924774630404986, 'dense': 128, 'l2': 4.335281794951567e-06, 'pool': 'gmp', 'extra_dense': False}. Best is trial 0 with value: 0.44569688452624034.\n",
      "🔁 Fold 0 | Precision=0.521 | Recall=0.679 | F1=0.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.445697:   7%|▋         | 2/30 [00:26<06:16, 13.46s/it, 26.80/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.499 | Recall=0.240 | F1=0.290\n",
      "[I 2025-06-07 23:32:41,855] Trial 1 finished with value: 0.5463172571239047 and parameters: {'window': 30, 'batch': 64, 'lr': 0.00017258215396625024, 'epochs': 20, 'conv_blocks': 1, 'filters': 64, 'kernel': 4, 'act': 'selu', 'dropout': 0.061612603179999434, 'dense': 128, 'l2': 3.247673570627449e-06, 'pool': 'gmp', 'extra_dense': True}. Best is trial 0 with value: 0.44569688452624034.\n",
      "🔁 Fold 0 | Precision=0.520 | Recall=0.682 | F1=0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x000001FAAE233910>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\weakref.py\", line 371, in remove\n",
      "    self = selfref()\n",
      "KeyboardInterrupt: \n",
      "Best trial: 0. Best value: 0.445697:  10%|█         | 3/30 [00:36<05:16, 11.71s/it, 36.43/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.505 | Recall=0.336 | F1=0.378\n",
      "[I 2025-06-07 23:32:51,486] Trial 2 finished with value: 0.5021802351884824 and parameters: {'window': 24, 'batch': 64, 'lr': 0.0005595074635794797, 'epochs': 20, 'conv_blocks': 1, 'filters': 32, 'kernel': 4, 'act': 'elu', 'dropout': 0.1800170052944527, 'dense': 128, 'l2': 3.5856126103453987e-06, 'pool': 'gap', 'extra_dense': True}. Best is trial 0 with value: 0.44569688452624034.\n",
      "🔁 Fold 0 | Precision=0.526 | Recall=0.364 | F1=0.405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.445697:  13%|█▎        | 4/30 [00:52<05:53, 13.61s/it, 52.94/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.489 | Recall=0.605 | F1=0.561\n",
      "[I 2025-06-07 23:33:07,998] Trial 3 finished with value: 0.5169144614752496 and parameters: {'window': 36, 'batch': 32, 'lr': 0.000215262809722153, 'epochs': 20, 'conv_blocks': 1, 'filters': 64, 'kernel': 2, 'act': 'relu', 'dropout': 0.18567402078956213, 'dense': 64, 'l2': 0.0002550298070162893, 'pool': 'gmp', 'extra_dense': True}. Best is trial 0 with value: 0.44569688452624034.\n",
      "🔁 Fold 0 | Precision=0.524 | Recall=0.755 | F1=0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.445697:  17%|█▋        | 5/30 [01:02<05:03, 12.15s/it, 62.50/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.499 | Recall=0.422 | F1=0.445\n",
      "[I 2025-06-07 23:33:17,561] Trial 4 finished with value: 0.4483698581832408 and parameters: {'window': 12, 'batch': 32, 'lr': 0.001732053535845956, 'epochs': 60, 'conv_blocks': 1, 'filters': 64, 'kernel': 2, 'act': 'relu', 'dropout': 0.06588958757150591, 'dense': 64, 'l2': 9.4525713910723e-06, 'pool': 'gap', 'extra_dense': True}. Best is trial 0 with value: 0.44569688452624034.\n",
      "🔁 Fold 0 | Precision=0.532 | Recall=0.291 | F1=0.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.445697:  20%|██        | 6/30 [01:10<04:19, 10.79s/it, 70.66/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.495 | Recall=0.629 | F1=0.577\n",
      "[I 2025-06-07 23:33:25,723] Trial 5 finished with value: 0.5402358459247456 and parameters: {'window': 12, 'batch': 64, 'lr': 0.0008986552644007198, 'epochs': 60, 'conv_blocks': 1, 'filters': 64, 'kernel': 3, 'act': 'elu', 'dropout': 0.20910260281594512, 'dense': 64, 'l2': 3.35515102272148e-05, 'pool': 'gap', 'extra_dense': False}. Best is trial 0 with value: 0.44569688452624034.\n",
      "🔁 Fold 0 | Precision=0.535 | Recall=0.583 | F1=0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.445697:  23%|██▎       | 7/30 [01:23<04:24, 11.52s/it, 83.67/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.496 | Recall=0.751 | F1=0.641\n",
      "[I 2025-06-07 23:33:38,729] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.445697:  27%|██▋       | 8/30 [01:38<04:34, 12.47s/it, 98.18/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.516 | Recall=0.916 | F1=0.728\n",
      "[I 2025-06-07 23:33:53,237] Trial 7 pruned. \n",
      "🔁 Fold 0 | Precision=0.528 | Recall=0.440 | F1=0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  30%|███       | 9/30 [01:47<04:00, 11.47s/it, 107.46/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.491 | Recall=0.835 | F1=0.677\n",
      "[I 2025-06-07 23:34:02,523] Trial 8 finished with value: 0.4284524824342044 and parameters: {'window': 18, 'batch': 64, 'lr': 0.0007145565133513971, 'epochs': 20, 'conv_blocks': 1, 'filters': 96, 'kernel': 2, 'act': 'selu', 'dropout': 0.1105138178778751, 'dense': 128, 'l2': 0.00019268985325226193, 'pool': 'gmp', 'extra_dense': False}. Best is trial 8 with value: 0.4284524824342044.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  33%|███▎      | 10/30 [01:51<03:04,  9.23s/it, 111.68/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.516 | Recall=0.844 | F1=0.697\n",
      "[I 2025-06-07 23:34:06,743] Trial 9 pruned. \n",
      "🔁 Fold 0 | Precision=0.531 | Recall=0.551 | F1=0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  37%|███▋      | 11/30 [03:17<10:18, 32.54s/it, 197.05/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.510 | Recall=0.337 | F1=0.380\n",
      "[I 2025-06-07 23:35:32,111] Trial 10 finished with value: 0.537817116157062 and parameters: {'window': 48, 'batch': 64, 'lr': 0.004438277669999281, 'epochs': 40, 'conv_blocks': 2, 'filters': 96, 'kernel': 2, 'act': 'selu', 'dropout': 0.12569671136254235, 'dense': 128, 'l2': 0.00010833315697328629, 'pool': 'gmp', 'extra_dense': False}. Best is trial 8 with value: 0.4284524824342044.\n",
      "🔁 Fold 0 | Precision=0.514 | Recall=0.592 | F1=0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  40%|████      | 12/30 [03:43<09:12, 30.68s/it, 223.48/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.498 | Recall=0.461 | F1=0.473\n",
      "[I 2025-06-07 23:35:58,539] Trial 11 pruned. \n",
      "🔁 Fold 0 | Precision=0.515 | Recall=0.506 | F1=0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  43%|████▎     | 13/30 [03:59<07:24, 26.12s/it, 239.11/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.489 | Recall=0.279 | F1=0.326\n",
      "[I 2025-06-07 23:36:14,165] Trial 12 finished with value: 0.5828336054231582 and parameters: {'window': 24, 'batch': 32, 'lr': 0.0012766043558568817, 'epochs': 20, 'conv_blocks': 1, 'filters': 96, 'kernel': 2, 'act': 'selu', 'dropout': 0.27852232036578506, 'dense': 128, 'l2': 1.0950172157239298e-06, 'pool': 'gmp', 'extra_dense': False}. Best is trial 8 with value: 0.4284524824342044.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  47%|████▋     | 14/30 [04:02<05:06, 19.13s/it, 242.08/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.516 | Recall=0.719 | F1=0.635\n",
      "[I 2025-06-07 23:36:17,139] Trial 13 pruned. \n",
      "🔁 Fold 0 | Precision=0.522 | Recall=0.479 | F1=0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  50%|█████     | 15/30 [04:13<04:13, 16.88s/it, 253.77/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.491 | Recall=0.701 | F1=0.614\n",
      "[I 2025-06-07 23:36:28,824] Trial 14 pruned. \n",
      "🔁 Fold 0 | Precision=0.525 | Recall=0.420 | F1=0.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  53%|█████▎    | 16/30 [04:23<03:24, 14.60s/it, 263.08/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.493 | Recall=0.445 | F1=0.460\n",
      "[I 2025-06-07 23:36:38,135] Trial 15 finished with value: 0.5451165802588686 and parameters: {'window': 30, 'batch': 32, 'lr': 0.0015451137873775404, 'epochs': 40, 'conv_blocks': 1, 'filters': 96, 'kernel': 4, 'act': 'elu', 'dropout': 0.14016979925138917, 'dense': 128, 'l2': 0.00016893806027344123, 'pool': 'gmp', 'extra_dense': False}. Best is trial 8 with value: 0.4284524824342044.\n",
      "🔁 Fold 0 | Precision=0.508 | Recall=0.353 | F1=0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  57%|█████▋    | 17/30 [04:33<02:53, 13.37s/it, 273.56/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.496 | Recall=0.473 | F1=0.480\n",
      "[I 2025-06-07 23:36:48,619] Trial 16 finished with value: 0.5631972004019259 and parameters: {'window': 18, 'batch': 64, 'lr': 0.000476858612051083, 'epochs': 20, 'conv_blocks': 1, 'filters': 32, 'kernel': 2, 'act': 'elu', 'dropout': 0.1477743480555192, 'dense': 128, 'l2': 1.444317644730438e-05, 'pool': 'gmp', 'extra_dense': False}. Best is trial 8 with value: 0.4284524824342044.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  60%|██████    | 18/30 [04:40<02:18, 11.54s/it, 280.85/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.523 | Recall=0.571 | F1=0.554\n",
      "[I 2025-06-07 23:36:55,908] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  63%|██████▎   | 19/30 [04:43<01:39,  9.01s/it, 283.96/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.530 | Recall=0.749 | F1=0.658\n",
      "[I 2025-06-07 23:36:59,015] Trial 18 pruned. \n",
      "🔁 Fold 0 | Precision=0.518 | Recall=0.466 | F1=0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  67%|██████▋   | 20/30 [05:08<02:15, 13.59s/it, 308.24/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.490 | Recall=0.586 | F1=0.550\n",
      "[I 2025-06-07 23:37:23,302] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  70%|███████   | 21/30 [05:16<01:47, 11.98s/it, 316.44/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.526 | Recall=0.766 | F1=0.665\n",
      "[I 2025-06-07 23:37:31,502] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  73%|███████▎  | 22/30 [05:20<01:15,  9.45s/it, 320.01/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.535 | Recall=0.516 | F1=0.522\n",
      "[I 2025-06-07 23:37:35,069] Trial 21 pruned. \n",
      "🔁 Fold 0 | Precision=0.528 | Recall=0.471 | F1=0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  77%|███████▋  | 23/30 [05:28<01:04,  9.24s/it, 328.77/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.498 | Recall=0.589 | F1=0.556\n",
      "[I 2025-06-07 23:37:43,830] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  80%|████████  | 24/30 [05:32<00:45,  7.60s/it, 332.54/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.521 | Recall=0.919 | F1=0.733\n",
      "[I 2025-06-07 23:37:47,599] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  83%|████████▎ | 25/30 [05:36<00:32,  6.55s/it, 336.64/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.528 | Recall=0.591 | F1=0.568\n",
      "[I 2025-06-07 23:37:51,700] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  87%|████████▋ | 26/30 [05:40<00:22,  5.60s/it, 340.03/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.527 | Recall=0.621 | F1=0.586\n",
      "[I 2025-06-07 23:37:55,084] Trial 25 pruned. \n",
      "🔁 Fold 0 | Precision=0.524 | Recall=0.499 | F1=0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  90%|█████████ | 27/30 [05:49<00:20,  6.67s/it, 349.20/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.488 | Recall=0.657 | F1=0.589\n",
      "[I 2025-06-07 23:38:04,259] Trial 26 pruned. \n",
      "🔁 Fold 0 | Precision=0.521 | Recall=0.502 | F1=0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  93%|█████████▎| 28/30 [06:03<00:17,  8.93s/it, 363.41/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.492 | Recall=0.846 | F1=0.682\n",
      "[I 2025-06-07 23:38:18,465] Trial 27 pruned. \n",
      "🔁 Fold 0 | Precision=0.546 | Recall=0.484 | F1=0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452:  97%|█████████▋| 29/30 [06:12<00:09,  9.06s/it, 372.76/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.499 | Recall=0.681 | F1=0.607\n",
      "[I 2025-06-07 23:38:27,820] Trial 28 pruned. \n",
      "🔁 Fold 0 | Precision=0.524 | Recall=0.495 | F1=0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.428452: 100%|██████████| 30/30 [06:22<00:00, 12.75s/it, 382.58/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.496 | Recall=0.569 | F1=0.542\n",
      "[I 2025-06-07 23:38:37,637] Trial 29 pruned. \n",
      "\n",
      "🏆 Best Weighted-F1 (α=2): 0.5715\n",
      "📜 Best Hyperparameters:\n",
      "{\n",
      "  \"window\": 18,\n",
      "  \"batch\": 64,\n",
      "  \"lr\": 0.0007145565133513971,\n",
      "  \"epochs\": 20,\n",
      "  \"conv_blocks\": 1,\n",
      "  \"filters\": 96,\n",
      "  \"kernel\": 2,\n",
      "  \"act\": \"selu\",\n",
      "  \"dropout\": 0.1105138178778751,\n",
      "  \"dense\": 128,\n",
      "  \"l2\": 0.00019268985325226193,\n",
      "  \"pool\": \"gmp\",\n",
      "  \"extra_dense\": false\n",
      "}\n",
      "✅ Saved parameters → cnn_best_params.json\n",
      "✅ Saved scaler     → cnn_scaler.pkl\n",
      "⏰ Finished at: 2025-06-07 23:38:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, json, warnings, joblib, optuna\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# ─────── Setup ─────────────────────────────────────────────────────────\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ─────── Config ────────────────────────────────────────────────────────\n",
    "CSV_PATH   = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                  r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "VAL_RATIO  = 0.20\n",
    "WF_FOLDS   = 2         # speed-up: reduce from 3 to 2\n",
    "ALPHA      = 2.0\n",
    "N_TRIALS   = 30        # speed-up: reduce from 60\n",
    "TIMEOUT    = 35 * 60\n",
    "SCALER_OUT = \"cnn_scaler.pkl\"\n",
    "PARAMS_OUT = \"cnn_best_params.json\"\n",
    "\n",
    "DROP_COLS = ['open', 'high', 'low', 'typical_price', 'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower', 'resistance_level',\n",
    "    'support_level', 'high_low', 'high_close', 'low_close', 'true_range', 'volume_mean_20',\n",
    "    'MACD_line', 'MACD_signal', 'bollinger_width', 'volatility_regime', 'CCI', 'stoch_%D',\n",
    "    'parkinson_vol', 'ema_cross_down', 'macd_cross_down', 'vol_spike_1_5x', 'near_upper_band',\n",
    "    'near_lower_band', 'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive', 'volume_breakout',\n",
    "    'volume_breakdown', 'stoch_overbought', 'stoch_oversold', 'cci_overbought', 'cci_oversold',\n",
    "    'trending_market', 'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6', 'bearish_scenario_1',\n",
    "    'bearish_scenario_2', 'bearish_scenario_3', 'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'close'\n",
    "]\n",
    "\n",
    "# ─────── Helpers ───────────────────────────────────────────────────────\n",
    "def weighted_f1(y_true, y_pred):\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score(y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + ALPHA) * p * r / (ALPHA * p + r)\n",
    "\n",
    "def make_windows(arr, labels, win):\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i-win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.asarray(X, np.float32), np.asarray(y, np.int8)\n",
    "\n",
    "def load_and_scale():\n",
    "    df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "    df = df.loc[\"2018-01-01\":]\n",
    "    df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "    df = df.dropna(subset=[\"target\"]).dropna()\n",
    "\n",
    "    X_all = df.drop(columns=\"target\").values\n",
    "    y_all = df[\"target\"].astype(int).values\n",
    "    split_real = int(len(df) * (1 - VAL_RATIO))\n",
    "    scaler = StandardScaler().fit(X_all[:split_real])\n",
    "    X_scaled = scaler.transform(X_all)\n",
    "\n",
    "    joblib.dump(scaler, SCALER_OUT)\n",
    "    print(f\"✔ Scaler fitted on {split_real} rows\")\n",
    "    return X_scaled, y_all, scaler, split_real, X_all.shape[1]\n",
    "\n",
    "# ─────── Data Load ─────────────────────────────────────────────────────\n",
    "X_SCALED, Y_ALL, SCALER, REAL_SPLIT_IDX, N_FEATS = load_and_scale()\n",
    "\n",
    "# ─────── CNN Model ─────────────────────────────────────────────────────\n",
    "def build_model(trial, win):\n",
    "    conv_blocks = trial.suggest_int(\"conv_blocks\", 1, 2)\n",
    "    base_filters = trial.suggest_int(\"filters\", 32, 96, step=32)\n",
    "    kernel = trial.suggest_int(\"kernel\", 2, 4)\n",
    "    activation = trial.suggest_categorical(\"act\", [\"relu\", \"elu\", \"selu\"])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.05, 0.3)\n",
    "    dense_units = trial.suggest_int(\"dense\", 64, 128, step=64)\n",
    "    l2reg = trial.suggest_float(\"l2\", 1e-6, 1e-3, log=True)\n",
    "\n",
    "    inp = layers.Input(shape=(win, N_FEATS))\n",
    "    x = inp\n",
    "    for b in range(conv_blocks):\n",
    "        f = base_filters * (2**b)\n",
    "        y = layers.Conv1D(f, kernel, padding=\"causal\", activation=activation,\n",
    "                          kernel_regularizer=regularizers.l2(l2reg))(x)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "        if x.shape[-1] != y.shape[-1]:\n",
    "            x = layers.Conv1D(f, 1, padding=\"same\")(x)\n",
    "        x = layers.add([x, y])\n",
    "\n",
    "    pool = trial.suggest_categorical(\"pool\", [\"gap\", \"gmp\"])\n",
    "    x = layers.GlobalMaxPooling1D()(x) if POOL_TYPE == \"gmp\" else layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    if trial.suggest_categorical(\"extra_dense\", [True, False]):\n",
    "        x = layers.Dense(dense_units, activation=activation,\n",
    "                         kernel_regularizer=regularizers.l2(l2reg))(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inp, out)\n",
    "\n",
    "# ─────── Optuna Objective ──────────────────────────────────────────────\n",
    "def objective(trial):\n",
    "    win = trial.suggest_int(\"window\", 12, 48, step=6)\n",
    "    batch = trial.suggest_categorical(\"batch\", [32, 64])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    epochs = trial.suggest_int(\"epochs\", 20, 60, step=20)\n",
    "\n",
    "    data_len = REAL_SPLIT_IDX - win\n",
    "    val_size = data_len // (WF_FOLDS + 1)\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold in range(WF_FOLDS):\n",
    "        val_start = data_len - (WF_FOLDS - fold) * val_size\n",
    "        val_end = val_start + val_size\n",
    "        if val_start < win * 2:\n",
    "            continue\n",
    "\n",
    "        X_fold = X_SCALED[:val_end + win]\n",
    "        y_fold = Y_ALL[:val_end + win]\n",
    "        X_win, y_win = make_windows(X_fold, y_fold, win)\n",
    "        train_end = val_start\n",
    "        X_tr, y_tr = X_win[:train_end], y_win[:train_end]\n",
    "        X_va, y_va = X_win[val_start:val_end], y_win[val_start:val_end]\n",
    "\n",
    "        if len(X_tr) < 10 or len(X_va) < 5:\n",
    "            continue\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = build_model(trial, win)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                      loss=\"binary_crossentropy\")\n",
    "\n",
    "        model.fit(X_tr, y_tr,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch,\n",
    "                  validation_data=(X_va, y_va),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=5,\n",
    "                                                           restore_best_weights=True)],\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = (model.predict(X_va, verbose=0).ravel() >= 0.5).astype(int)\n",
    "        p = precision_score(y_va, preds, zero_division=0)\n",
    "        r = recall_score(y_va, preds, zero_division=0)\n",
    "        f1 = weighted_f1(y_va, preds)\n",
    "        print(f\"🔁 Fold {fold} | Precision={p:.3f} | Recall={r:.3f} | F1={f1:.3f}\")\n",
    "        fold_scores.append(f1)\n",
    "\n",
    "        trial.report(np.mean(fold_scores), step=fold)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return 1.0 - np.mean(fold_scores) if fold_scores else 1.0\n",
    "\n",
    "# ─────── Run Optuna ────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\",\n",
    "                                sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "                                pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=N_TRIALS,\n",
    "                   timeout=TIMEOUT, show_progress_bar=True)\n",
    "\n",
    "    best_f1 = 1.0 - study.best_value\n",
    "    print(f\"\\n🏆 Best Weighted-F1 (α=2): {best_f1:.4f}\")\n",
    "    print(\"📜 Best Hyperparameters:\")\n",
    "    print(json.dumps(study.best_params, indent=2))\n",
    "\n",
    "    with open(PARAMS_OUT, \"w\") as f:\n",
    "        json.dump(study.best_params, f, indent=2)\n",
    "    print(f\"✅ Saved parameters → {PARAMS_OUT}\")\n",
    "    print(f\"✅ Saved scaler     → {SCALER_OUT}\")\n",
    "    print(\"⏰ Finished at:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f783ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 18:39:30,875] A new study created in memory with name: no-name-8c826d58-ed73-47ce-849b-d6a3bc1d3886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Scaler fitted on 12684 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.525 | Recall=0.672 | Fβ=0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.48291:   3%|▎         | 1/30 [00:20<10:06, 20.93s/it, 20.93/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.488 | Recall=0.457 | Fβ=0.480\n",
      "[I 2025-06-07 18:39:51,804] Trial 0 finished with value: 0.4829096358918845 and parameters: {'window': 24, 'batch': 32, 'lr': 0.0010401663679887319, 'epochs': 20, 'conv_blocks': 1, 'filters': 32, 'kernel': 4, 'act': 'elu', 'dropout': 0.2924774630404986, 'dense': 128, 'l2': 4.335281794951567e-06, 'pool': 'gmp', 'extra_dense': False}. Best is trial 0 with value: 0.4829096358918845.\n",
      "🔁 Fold 0 | Precision=0.527 | Recall=0.315 | Fβ=0.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.48291:   7%|▋         | 2/30 [00:44<10:27, 22.41s/it, 44.38/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.484 | Recall=0.570 | Fβ=0.502\n",
      "[I 2025-06-07 18:40:15,253] Trial 1 finished with value: 0.5219072338479555 and parameters: {'window': 30, 'batch': 64, 'lr': 0.00017258215396625024, 'epochs': 20, 'conv_blocks': 2, 'filters': 64, 'kernel': 4, 'act': 'selu', 'dropout': 0.061612603179999434, 'dense': 128, 'l2': 3.247673570627449e-06, 'pool': 'gmp', 'extra_dense': True}. Best is trial 0 with value: 0.4829096358918845.\n",
      "🔁 Fold 0 | Precision=0.516 | Recall=0.773 | Fβ=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  10%|█         | 3/30 [01:02<09:10, 20.38s/it, 62.35/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.490 | Recall=0.613 | Fβ=0.515\n",
      "[I 2025-06-07 18:40:33,222] Trial 2 finished with value: 0.46235122560284614 and parameters: {'window': 24, 'batch': 64, 'lr': 0.0005595074635794797, 'epochs': 20, 'conv_blocks': 2, 'filters': 32, 'kernel': 4, 'act': 'elu', 'dropout': 0.1800170052944527, 'dense': 128, 'l2': 3.5856126103453987e-06, 'pool': 'gap', 'extra_dense': True}. Best is trial 2 with value: 0.46235122560284614.\n",
      "🔁 Fold 0 | Precision=0.527 | Recall=0.676 | Fβ=0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  13%|█▎        | 4/30 [01:31<10:16, 23.72s/it, 91.18/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.483 | Recall=0.674 | Fβ=0.518\n",
      "[I 2025-06-07 18:41:02,057] Trial 3 finished with value: 0.46300977613833094 and parameters: {'window': 36, 'batch': 32, 'lr': 0.000215262809722153, 'epochs': 20, 'conv_blocks': 1, 'filters': 64, 'kernel': 2, 'act': 'relu', 'dropout': 0.18567402078956213, 'dense': 64, 'l2': 0.0002550298070162893, 'pool': 'gmp', 'extra_dense': True}. Best is trial 2 with value: 0.46235122560284614.\n",
      "🔁 Fold 0 | Precision=0.518 | Recall=0.417 | Fβ=0.490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  17%|█▋        | 5/30 [01:47<08:47, 21.11s/it, 107.67/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.510 | Recall=0.533 | Fβ=0.515\n",
      "[I 2025-06-07 18:41:18,546] Trial 4 finished with value: 0.49748838219048075 and parameters: {'window': 12, 'batch': 32, 'lr': 0.001732053535845956, 'epochs': 60, 'conv_blocks': 1, 'filters': 64, 'kernel': 2, 'act': 'relu', 'dropout': 0.06588958757150591, 'dense': 64, 'l2': 9.4525713910723e-06, 'pool': 'gap', 'extra_dense': True}. Best is trial 2 with value: 0.46235122560284614.\n",
      "🔁 Fold 0 | Precision=0.527 | Recall=0.528 | Fβ=0.528\n",
      "🔁 Fold 1 | Precision=0.495 | Recall=0.586 | Fβ=0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  20%|██        | 6/30 [02:14<09:14, 23.10s/it, 134.64/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 18:41:45,511] Trial 5 pruned. \n",
      "🔁 Fold 0 | Precision=0.521 | Recall=0.570 | Fβ=0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  23%|██▎       | 7/30 [05:55<33:37, 87.72s/it, 355.40/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.502 | Recall=0.764 | Fβ=0.546\n",
      "[I 2025-06-07 18:45:26,274] Trial 6 pruned. \n",
      "🔁 Fold 0 | Precision=0.517 | Recall=0.395 | Fβ=0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  27%|██▋       | 8/30 [06:24<25:15, 68.90s/it, 384.01/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.497 | Recall=0.407 | Fβ=0.472\n",
      "[I 2025-06-07 18:45:54,883] Trial 7 finished with value: 0.5232915107380718 and parameters: {'window': 42, 'batch': 32, 'lr': 0.0007374699809816792, 'epochs': 40, 'conv_blocks': 1, 'filters': 32, 'kernel': 3, 'act': 'relu', 'dropout': 0.22575473972379445, 'dense': 64, 'l2': 0.0008228984573308163, 'pool': 'gap', 'extra_dense': True}. Best is trial 2 with value: 0.46235122560284614.\n",
      "🔁 Fold 0 | Precision=0.527 | Recall=0.326 | Fβ=0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  30%|███       | 9/30 [06:37<18:04, 51.63s/it, 397.66/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.491 | Recall=0.649 | Fβ=0.521\n",
      "[I 2025-06-07 18:46:08,537] Trial 8 finished with value: 0.50995318656849 and parameters: {'window': 18, 'batch': 64, 'lr': 0.0007145565133513971, 'epochs': 20, 'conv_blocks': 1, 'filters': 96, 'kernel': 2, 'act': 'selu', 'dropout': 0.1105138178778751, 'dense': 128, 'l2': 0.00019268985325226193, 'pool': 'gmp', 'extra_dense': False}. Best is trial 2 with value: 0.46235122560284614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  33%|███▎      | 10/30 [06:45<12:39, 38.00s/it, 405.13/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.520 | Recall=0.619 | Fβ=0.541\n",
      "[I 2025-06-07 18:46:16,003] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  37%|███▋      | 11/30 [08:07<16:19, 51.54s/it, 487.37/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.520 | Recall=0.845 | Fβ=0.572\n",
      "[I 2025-06-07 18:47:38,245] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  40%|████      | 12/30 [08:22<12:08, 40.48s/it, 502.56/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.534 | Recall=0.456 | Fβ=0.513\n",
      "[I 2025-06-07 18:47:53,439] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  43%|████▎     | 13/30 [08:39<09:28, 33.45s/it, 519.82/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.516 | Recall=0.485 | Fβ=0.508\n",
      "[I 2025-06-07 18:48:10,694] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  47%|████▋     | 14/30 [08:49<07:00, 26.30s/it, 529.62/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.518 | Recall=0.663 | Fβ=0.546\n",
      "[I 2025-06-07 18:48:20,496] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  50%|█████     | 15/30 [09:07<05:56, 23.75s/it, 547.47/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.522 | Recall=0.420 | Fβ=0.493\n",
      "[I 2025-06-07 18:48:38,343] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  53%|█████▎    | 16/30 [09:15<04:24, 18.91s/it, 555.14/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.516 | Recall=0.732 | Fβ=0.555\n",
      "[I 2025-06-07 18:48:46,013] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  57%|█████▋    | 17/30 [09:25<03:30, 16.21s/it, 565.05/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.518 | Recall=0.709 | Fβ=0.554\n",
      "[I 2025-06-07 18:48:55,922] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  60%|██████    | 18/30 [10:47<07:14, 36.24s/it, 647.94/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.520 | Recall=1.000 | Fβ=0.587\n",
      "[I 2025-06-07 18:50:18,816] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  63%|██████▎   | 19/30 [10:54<05:01, 27.44s/it, 654.85/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.519 | Recall=0.720 | Fβ=0.556\n",
      "[I 2025-06-07 18:50:25,728] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  67%|██████▋   | 20/30 [11:11<04:01, 24.18s/it, 671.44/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.528 | Recall=0.474 | Fβ=0.514\n",
      "[I 2025-06-07 18:50:42,320] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  70%|███████   | 21/30 [11:24<03:07, 20.85s/it, 684.53/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.519 | Recall=0.784 | Fβ=0.564\n",
      "[I 2025-06-07 18:50:55,410] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  73%|███████▎  | 22/30 [11:35<02:22, 17.75s/it, 695.06/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.521 | Recall=0.716 | Fβ=0.557\n",
      "[I 2025-06-07 18:51:05,933] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  77%|███████▋  | 23/30 [11:50<01:58, 16.91s/it, 710.01/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.521 | Recall=0.540 | Fβ=0.526\n",
      "[I 2025-06-07 18:51:20,884] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  80%|████████  | 24/30 [11:57<01:25, 14.20s/it, 717.87/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.528 | Recall=0.399 | Fβ=0.490\n",
      "[I 2025-06-07 18:51:28,749] Trial 23 pruned. \n",
      "🔁 Fold 0 | Precision=0.518 | Recall=0.380 | Fβ=0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  83%|████████▎ | 25/30 [12:23<01:28, 17.75s/it, 743.90/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.493 | Recall=0.594 | Fβ=0.514\n",
      "[I 2025-06-07 18:51:54,779] Trial 24 finished with value: 0.5049048718884204 and parameters: {'window': 18, 'batch': 32, 'lr': 0.0005543398004074266, 'epochs': 20, 'conv_blocks': 1, 'filters': 32, 'kernel': 4, 'act': 'elu', 'dropout': 0.09475936144251602, 'dense': 128, 'l2': 6.413009116721392e-06, 'pool': 'gmp', 'extra_dense': False}. Best is trial 2 with value: 0.46235122560284614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  87%|████████▋ | 26/30 [12:39<01:08, 17.02s/it, 759.22/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.522 | Recall=0.501 | Fβ=0.517\n",
      "[I 2025-06-07 18:52:10,092] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  90%|█████████ | 27/30 [12:48<00:43, 14.63s/it, 768.29/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.525 | Recall=0.527 | Fβ=0.525\n",
      "[I 2025-06-07 18:52:19,167] Trial 26 pruned. \n",
      "🔁 Fold 0 | Precision=0.520 | Recall=0.204 | Fβ=0.380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  93%|█████████▎| 28/30 [13:14<00:36, 18.14s/it, 794.61/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1 | Precision=0.487 | Recall=0.615 | Fβ=0.513\n",
      "[I 2025-06-07 18:52:45,491] Trial 27 finished with value: 0.5538786574581488 and parameters: {'window': 30, 'batch': 32, 'lr': 0.0020194297281664743, 'epochs': 40, 'conv_blocks': 2, 'filters': 64, 'kernel': 3, 'act': 'elu', 'dropout': 0.14723199156647648, 'dense': 128, 'l2': 4.984439020021232e-05, 'pool': 'gmp', 'extra_dense': True}. Best is trial 2 with value: 0.46235122560284614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351:  97%|█████████▋| 29/30 [13:26<00:16, 16.13s/it, 806.05/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.529 | Recall=0.625 | Fβ=0.549\n",
      "[I 2025-06-07 18:52:56,925] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.462351: 100%|██████████| 30/30 [14:08<00:00, 28.30s/it, 848.93/2100 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 0 | Precision=0.516 | Recall=0.537 | Fβ=0.521\n",
      "[I 2025-06-07 18:53:39,807] Trial 29 pruned. \n",
      "\n",
      "🏆 Best Weighted-Fβ (β=0.56): 0.5376\n",
      "📜 Best Hyperparameters:\n",
      "{\n",
      "  \"window\": 24,\n",
      "  \"batch\": 64,\n",
      "  \"lr\": 0.0005595074635794797,\n",
      "  \"epochs\": 20,\n",
      "  \"conv_blocks\": 2,\n",
      "  \"filters\": 32,\n",
      "  \"kernel\": 4,\n",
      "  \"act\": \"elu\",\n",
      "  \"dropout\": 0.1800170052944527,\n",
      "  \"dense\": 128,\n",
      "  \"l2\": 3.5856126103453987e-06,\n",
      "  \"pool\": \"gap\",\n",
      "  \"extra_dense\": true\n",
      "}\n",
      "✅ Saved parameters → cnn_best_params.json\n",
      "✅ Saved scaler     → cnn_scaler.pkl\n",
      "⏰ Finished at: 2025-06-07 18:53:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# cnn_optuna_f0_56.py\n",
    "import os, json, warnings, joblib, optuna\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# ─────── Setup ─────────────────────────────────────────────────────────\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ─────── Config ────────────────────────────────────────────────────────\n",
    "CSV_PATH   = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                  r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "VAL_RATIO  = 0.20\n",
    "WF_FOLDS   = 2\n",
    "BETA       = 0.56\n",
    "N_TRIALS   = 30\n",
    "TIMEOUT    = 35 * 60\n",
    "SCALER_OUT = \"cnn_scaler.pkl\"\n",
    "PARAMS_OUT = \"cnn_best_params.json\"\n",
    "\n",
    "DROP_COLS = ['open', 'high', 'low', 'typical_price', 'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower', 'resistance_level',\n",
    "    'support_level', 'high_low', 'high_close', 'low_close', 'true_range', 'volume_mean_20',\n",
    "    'MACD_line', 'MACD_signal', 'bollinger_width', 'volatility_regime', 'CCI', 'stoch_%D',\n",
    "    'parkinson_vol', 'ema_cross_down', 'macd_cross_down', 'vol_spike_1_5x', 'near_upper_band',\n",
    "    'near_lower_band', 'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive', 'volume_breakout',\n",
    "    'volume_breakdown', 'stoch_overbought', 'stoch_oversold', 'cci_overbought', 'cci_oversold',\n",
    "    'trending_market', 'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6', 'bearish_scenario_1',\n",
    "    'bearish_scenario_2', 'bearish_scenario_3', 'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'close'\n",
    "]\n",
    "\n",
    "# ─────── Helpers ───────────────────────────────────────────────────────\n",
    "def f_beta_score(y_true, y_pred, beta=BETA):\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score(y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + beta**2) * p * r / (beta**2 * p + r)\n",
    "\n",
    "def make_windows(arr, labels, win):\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i-win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.asarray(X, np.float32), np.asarray(y, np.int8)\n",
    "\n",
    "def load_and_scale():\n",
    "    df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "    df = df.loc[\"2018-01-01\":]\n",
    "    df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "    df = df.dropna(subset=[\"target\"]).dropna()\n",
    "\n",
    "    X_all = df.drop(columns=\"target\").values\n",
    "    y_all = df[\"target\"].astype(int).values\n",
    "    split_real = int(len(df) * (1 - VAL_RATIO))\n",
    "    scaler = StandardScaler().fit(X_all[:split_real])\n",
    "    X_scaled = scaler.transform(X_all)\n",
    "\n",
    "    joblib.dump(scaler, SCALER_OUT)\n",
    "    print(f\"✔ Scaler fitted on {split_real} rows\")\n",
    "    return X_scaled, y_all, scaler, split_real, X_all.shape[1]\n",
    "\n",
    "# ─────── Data Load ─────────────────────────────────────────────────────\n",
    "X_SCALED, Y_ALL, SCALER, REAL_SPLIT_IDX, N_FEATS = load_and_scale()\n",
    "\n",
    "# ─────── CNN Model ─────────────────────────────────────────────────────\n",
    "def build_model(trial, win):\n",
    "    conv_blocks = trial.suggest_int(\"conv_blocks\", 1, 3)\n",
    "    base_filters = trial.suggest_int(\"filters\", 32, 96, step=32)\n",
    "    kernel = trial.suggest_int(\"kernel\", 2, 4)\n",
    "    activation = trial.suggest_categorical(\"act\", [\"relu\", \"elu\", \"selu\"])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.05, 0.3)\n",
    "    dense_units = trial.suggest_int(\"dense\", 64, 128, step=64)\n",
    "    l2reg = trial.suggest_float(\"l2\", 1e-6, 1e-3, log=True)\n",
    "\n",
    "    inp = layers.Input(shape=(win, N_FEATS))\n",
    "    x = inp\n",
    "    for b in range(conv_blocks):\n",
    "        f = base_filters * (2**b)\n",
    "        y = layers.Conv1D(f, kernel, padding=\"causal\", activation=activation,\n",
    "                          kernel_regularizer=regularizers.l2(l2reg))(x)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "        if x.shape[-1] != y.shape[-1]:\n",
    "            x = layers.Conv1D(f, 1, padding=\"same\")(x)\n",
    "        x = layers.add([x, y])\n",
    "\n",
    "    pool = trial.suggest_categorical(\"pool\", [\"gap\", \"gmp\"])\n",
    "    x = layers.GlobalAveragePooling1D()(x) if pool == \"gap\" else layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "    if trial.suggest_categorical(\"extra_dense\", [True, False]):\n",
    "        x = layers.Dense(dense_units, activation=activation,\n",
    "                         kernel_regularizer=regularizers.l2(l2reg))(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inp, out)\n",
    "\n",
    "# ─────── Optuna Objective ──────────────────────────────────────────────\n",
    "def objective(trial):\n",
    "    win = trial.suggest_int(\"window\", 12, 48, step=6)\n",
    "    batch = trial.suggest_categorical(\"batch\", [32, 64])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    epochs = trial.suggest_int(\"epochs\", 20, 60, step=20)\n",
    "\n",
    "    data_len = REAL_SPLIT_IDX - win\n",
    "    val_size = data_len // (WF_FOLDS + 1)\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold in range(WF_FOLDS):\n",
    "        val_start = data_len - (WF_FOLDS - fold) * val_size\n",
    "        val_end = val_start + val_size\n",
    "        if val_start < win * 2:\n",
    "            continue\n",
    "\n",
    "        X_fold = X_SCALED[:val_end + win]\n",
    "        y_fold = Y_ALL[:val_end + win]\n",
    "        X_win, y_win = make_windows(X_fold, y_fold, win)\n",
    "        train_end = val_start\n",
    "        X_tr, y_tr = X_win[:train_end], y_win[:train_end]\n",
    "        X_va, y_va = X_win[val_start:val_end], y_win[val_start:val_end]\n",
    "\n",
    "        if len(X_tr) < 10 or len(X_va) < 5:\n",
    "            continue\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = build_model(trial, win)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                      loss=\"binary_crossentropy\")\n",
    "\n",
    "        model.fit(X_tr, y_tr,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch,\n",
    "                  validation_data=(X_va, y_va),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)],\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = (model.predict(X_va, verbose=0).ravel() >= 0.5).astype(int)\n",
    "        p = precision_score(y_va, preds, zero_division=0)\n",
    "        r = recall_score(y_va, preds, zero_division=0)\n",
    "        f = f_beta_score(y_va, preds, beta=BETA)\n",
    "        print(f\"🔁 Fold {fold} | Precision={p:.3f} | Recall={r:.3f} | Fβ={f:.3f}\")\n",
    "        fold_scores.append(f)\n",
    "\n",
    "        trial.report(np.mean(fold_scores), step=fold)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return 1.0 - np.mean(fold_scores) if fold_scores else 1.0\n",
    "\n",
    "# ─────── Run Optuna ────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\",\n",
    "                                sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "                                pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=N_TRIALS, timeout=TIMEOUT, show_progress_bar=True)\n",
    "\n",
    "    best_fbeta = 1.0 - study.best_value\n",
    "    print(f\"\\n🏆 Best Weighted-Fβ (β={BETA}): {best_fbeta:.4f}\")\n",
    "    print(\"📜 Best Hyperparameters:\")\n",
    "    print(json.dumps(study.best_params, indent=2))\n",
    "\n",
    "    with open(PARAMS_OUT, \"w\") as f:\n",
    "        json.dump(study.best_params, f, indent=2)\n",
    "    print(f\"✅ Saved parameters → {PARAMS_OUT}\")\n",
    "    print(f\"✅ Saved scaler     → {SCALER_OUT}\")\n",
    "    print(\"⏰ Finished at:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "🏆 Top 5 Trials by F1-Score:\n",
    "Rank\tTrial\tPrecision\tRecall\tF1 Score\tNotable Hyperparameters Summary\n",
    "1️⃣\t#3\t0.527\t0.676\t0.593\twindow=36, batch=32, lr=0.00021, filters=64, kernel=2, act=relu, dropout=0.186, dense=64, conv_blocks=1, pool=gmp, extra_dense=True\n",
    "2️⃣\t#2\t0.516\t0.773\t0.620\twindow=24, batch=64, lr=0.00056, filters=32, kernel=4, act=elu, dropout=0.180, dense=128, conv_blocks=2, pool=gap, extra_dense=True\n",
    "3️⃣\t#27\t0.487\t0.615\t0.544\twindow=30, batch=32, lr=0.00202, filters=64, kernel=3, act=elu, dropout=0.147, dense=128, conv_blocks=2, pool=gmp, extra_dense=True\n",
    "4️⃣\t#4\t0.527\t0.528\t0.527\twindow=12, batch=32, lr=0.00173, filters=64, kernel=2, act=relu, dropout=0.066, dense=64, conv_blocks=1, pool=gap, extra_dense=True\n",
    "5️⃣\t#24\t0.528\t0.399\t0.454\twindow=18, batch=32, lr=0.00055, filters=32, kernel=4, act=elu, dropout=0.094, dense=128, conv_blocks=1, pool=gmp, extra_dense=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118251e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loading & preprocessing …\n",
      "   Train windows : 12,648\n",
      "   Val   windows : 3,135\n",
      "   Features      : 19\n",
      "\n",
      "🏗️ Building model …\n",
      "\n",
      "🚀 Training …\n",
      "Epoch 1/100\n",
      "396/396 - 2s - 4ms/step - accuracy: 0.4934 - loss: 1.0171 - val_accuracy: 0.4995 - val_loss: 0.7132 - learning_rate: 2.1000e-04\n",
      "Epoch 2/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5015 - loss: 0.7806 - val_accuracy: 0.5100 - val_loss: 0.7036 - learning_rate: 2.1000e-04\n",
      "Epoch 3/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5137 - loss: 0.7283 - val_accuracy: 0.5196 - val_loss: 0.6983 - learning_rate: 2.1000e-04\n",
      "Epoch 4/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.4959 - loss: 0.7119 - val_accuracy: 0.5132 - val_loss: 0.6948 - learning_rate: 2.1000e-04\n",
      "Epoch 5/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5074 - loss: 0.7025 - val_accuracy: 0.5072 - val_loss: 0.6936 - learning_rate: 2.1000e-04\n",
      "Epoch 6/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5050 - loss: 0.6987 - val_accuracy: 0.5033 - val_loss: 0.6932 - learning_rate: 2.1000e-04\n",
      "Epoch 7/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5021 - loss: 0.6996 - val_accuracy: 0.4982 - val_loss: 0.6928 - learning_rate: 2.1000e-04\n",
      "Epoch 8/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5152 - loss: 0.6937 - val_accuracy: 0.5110 - val_loss: 0.6930 - learning_rate: 2.1000e-04\n",
      "Epoch 9/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5082 - loss: 0.6945 - val_accuracy: 0.5053 - val_loss: 0.6929 - learning_rate: 2.1000e-04\n",
      "Epoch 10/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5018 - loss: 0.6952 - val_accuracy: 0.5094 - val_loss: 0.6930 - learning_rate: 2.1000e-04\n",
      "Epoch 11/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5067 - loss: 0.6932 - val_accuracy: 0.5132 - val_loss: 0.6931 - learning_rate: 2.1000e-04\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001049999991664663.\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5102 - loss: 0.6937 - val_accuracy: 0.5024 - val_loss: 0.6931 - learning_rate: 2.1000e-04\n",
      "Epoch 13/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5123 - loss: 0.6930 - val_accuracy: 0.5046 - val_loss: 0.6930 - learning_rate: 1.0500e-04\n",
      "Epoch 14/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5051 - loss: 0.6940 - val_accuracy: 0.5142 - val_loss: 0.6929 - learning_rate: 1.0500e-04\n",
      "Epoch 15/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5202 - loss: 0.6926 - val_accuracy: 0.5094 - val_loss: 0.6929 - learning_rate: 1.0500e-04\n",
      "Epoch 16/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5029 - loss: 0.6937 - val_accuracy: 0.5088 - val_loss: 0.6930 - learning_rate: 1.0500e-04\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 5.249999958323315e-05.\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5138 - loss: 0.6932 - val_accuracy: 0.5088 - val_loss: 0.6928 - learning_rate: 1.0500e-04\n",
      "Epoch 18/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5131 - loss: 0.6932 - val_accuracy: 0.5116 - val_loss: 0.6928 - learning_rate: 5.2500e-05\n",
      "Epoch 19/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5117 - loss: 0.6932 - val_accuracy: 0.5091 - val_loss: 0.6929 - learning_rate: 5.2500e-05\n",
      "Epoch 20/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5154 - loss: 0.6928 - val_accuracy: 0.5097 - val_loss: 0.6930 - learning_rate: 5.2500e-05\n",
      "Epoch 21/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5165 - loss: 0.6927 - val_accuracy: 0.5078 - val_loss: 0.6930 - learning_rate: 5.2500e-05\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.6249999791616574e-05.\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5140 - loss: 0.6930 - val_accuracy: 0.5116 - val_loss: 0.6930 - learning_rate: 5.2500e-05\n",
      "Epoch 23/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5108 - loss: 0.6935 - val_accuracy: 0.5123 - val_loss: 0.6930 - learning_rate: 2.6250e-05\n",
      "Epoch 24/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5149 - loss: 0.6929 - val_accuracy: 0.5104 - val_loss: 0.6930 - learning_rate: 2.6250e-05\n",
      "Epoch 25/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5112 - loss: 0.6937 - val_accuracy: 0.5091 - val_loss: 0.6930 - learning_rate: 2.6250e-05\n",
      "Epoch 26/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5100 - loss: 0.6930 - val_accuracy: 0.5078 - val_loss: 0.6930 - learning_rate: 2.6250e-05\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.3124999895808287e-05.\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5134 - loss: 0.6923 - val_accuracy: 0.5040 - val_loss: 0.6931 - learning_rate: 2.6250e-05\n",
      "Epoch 28/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5155 - loss: 0.6928 - val_accuracy: 0.5059 - val_loss: 0.6931 - learning_rate: 1.3125e-05\n",
      "Epoch 29/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5183 - loss: 0.6925 - val_accuracy: 0.5046 - val_loss: 0.6931 - learning_rate: 1.3125e-05\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\n",
      "── Validation metrics ──\n",
      "accuracy            :  0.509\n",
      "precision           :  0.524\n",
      "recall              :  0.659\n",
      "weighted_f1_a2      :  0.606\n",
      "auc                 :  0.511\n",
      "\n",
      "Classification report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.48      0.35      0.40      1498\n",
      "          Up       0.52      0.66      0.58      1637\n",
      "\n",
      "    accuracy                           0.51      3135\n",
      "   macro avg       0.50      0.50      0.49      3135\n",
      "weighted avg       0.50      0.51      0.50      3135\n",
      "\n",
      "\n",
      "Confusion-matrix:\n",
      "[[ 517  981]\n",
      " [ 559 1078]]\n",
      "\n",
      "💾 Saving artefacts …\n",
      "\n",
      "✅ Model   saved → cnn_optimal_val20.h5\n",
      "✅ Scaler  saved → cnn_scaler.pkl\n",
      "✅ Summary saved → cnn_training_summary.json\n",
      "🎉 Training complete.\n"
     ]
    }
   ],
   "source": [
    "# cnn_final_train_fixed.py\n",
    "# ----------------------------------------------------------\n",
    "# Trains a 1-D CNN with the optimal hyper-parameters you supplied.\n",
    "\n",
    "import os, json, joblib, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "import tensorflow as tf\n",
    "from   tensorflow import keras\n",
    "from   tensorflow.keras import layers, regularizers\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "from   sklearn.metrics       import (accuracy_score, precision_score,\n",
    "                                     recall_score, roc_auc_score,\n",
    "                                     confusion_matrix,\n",
    "                                     classification_report)\n",
    "\n",
    "# ═══════════════ Seeds / GPU set-up ══════════════════════\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ═══════════════ Paths & constants ═══════════════════════\n",
    "CSV_PATH      = Path(r\"C:/Users/ADMIN/Desktop/Coding_projects/stock_market_prediction/\"\n",
    "                     r\"Stock-Market-Prediction/data/processed/\"\n",
    "                     r\"gemini_btc_with_features_4h.csv\")\n",
    "MODEL_OUT     = \"cnn_optimal_val20.h5\"\n",
    "SCALER_OUT    = \"cnn_scaler.pkl\"\n",
    "SUMMARY_JSON  = \"cnn_training_summary.json\"\n",
    "\n",
    "# ---- hyper-parameters (fixed) ----\n",
    "WIN,  BATCH   = 36, 32\n",
    "LR            = 2.1e-4\n",
    "FILTERS       = 64\n",
    "KERNEL        = 2\n",
    "ACT           = \"relu\"\n",
    "DROPOUT       = 0.186\n",
    "DENSE_UNITS   = 64\n",
    "CONV_BLOCKS   = 1\n",
    "POOL_TYPE     = \"gmp\"      # gmp | gap\n",
    "EXTRA_DENSE   = True\n",
    "L2_REG        = 1e-6\n",
    "EPOCHS        = 100\n",
    "EARLY_STOP    = 12\n",
    "ALPHA         = 2.0        # precision weight in weighted-F\n",
    "VAL_FRAC      = 0.20\n",
    "\n",
    "# ---- columns we must drop to avoid leakage ----\n",
    "DROP_COLS = [\n",
    "    'open','high','low','typical_price','EMA_7','EMA_21','SMA_20','SMA_50',\n",
    "    'vwap_24h','close_4h','bollinger_upper','bollinger_lower','resistance_level',\n",
    "    'support_level','high_low','high_close','low_close','true_range',\n",
    "    'volume_mean_20','MACD_line','MACD_signal','bollinger_width',\n",
    "    'volatility_regime','CCI','stoch_%D','parkinson_vol','ema_cross_down',\n",
    "    'macd_cross_down','vol_spike_1_5x','near_upper_band','near_lower_band',\n",
    "    'break_upper_band','break_lower_band','rsi_oversold','rsi_overbought',\n",
    "    'above_sma20','above_sma50','ema7_above_ema21','macd_positive',\n",
    "    'volume_breakout','volume_breakdown','stoch_overbought','stoch_oversold',\n",
    "    'cci_overbought','cci_oversold','trending_market','bullish_scenario_1',\n",
    "    'bullish_scenario_2','bullish_scenario_3','bullish_scenario_4',\n",
    "    'bullish_scenario_5','bullish_scenario_6','bearish_scenario_1',\n",
    "    'bearish_scenario_2','bearish_scenario_3','bearish_scenario_4',\n",
    "    'bearish_scenario_6','ema_cross_up','macd_cross_up',\n",
    "    'oversold_reversal','overbought_reversal','close'\n",
    "]\n",
    "\n",
    "# ═══════════════ helpers ═════════════════════════════════\n",
    "def make_windows(arr: np.ndarray, labels: np.ndarray, win: int):\n",
    "    xs, ys = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        xs.append(arr[i-win:i])\n",
    "        ys.append(labels[i])\n",
    "    return np.asarray(xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "def weighted_f(alpha: float, p: float, r: float) -> float:\n",
    "    if p + r == 0:\n",
    "        return 0.0\n",
    "    return (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def build_model(win: int, n_features: int) -> keras.Model:\n",
    "    \"\"\"**Fixed**: pooling layers are *called* on tensors.\"\"\"\n",
    "    inp = layers.Input(shape=(win, n_features))\n",
    "    x   = inp\n",
    "\n",
    "    for b in range(CONV_BLOCKS):\n",
    "        f = FILTERS * (2 ** b)\n",
    "        y = layers.Conv1D(f, KERNEL, padding=\"causal\",\n",
    "                          activation=ACT,\n",
    "                          kernel_regularizer=regularizers.l2(L2_REG))(x)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "\n",
    "        if CONV_BLOCKS > 1:          # skip-connection only if >1 block\n",
    "            if x.shape[-1] != y.shape[-1]:\n",
    "                x = layers.Conv1D(f, 1, padding=\"same\")(x)\n",
    "            x = layers.Add()([x, y])\n",
    "        else:\n",
    "            x = y\n",
    "\n",
    "    if POOL_TYPE == \"gmp\":\n",
    "        x = layers.GlobalMaxPooling1D()(x)       # <- () executes the layer\n",
    "    else:\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = layers.Dropout(DROPOUT)(x)\n",
    "\n",
    "    if EXTRA_DENSE:\n",
    "        x = layers.Dense(DENSE_UNITS, activation=ACT,\n",
    "                         kernel_regularizer=regularizers.l2(L2_REG))(x)\n",
    "        x = layers.Dropout(DROPOUT)(x)\n",
    "\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inp, out)\n",
    "\n",
    "# ═══════════════ 1. DATA ═════════════════════════════════\n",
    "print(\"📊 Loading & preprocessing …\")\n",
    "df = (pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "        .loc[\"2018-01-01\":]\n",
    "        .drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "        .dropna(subset=[\"target\"])\n",
    "        .dropna())\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler    = StandardScaler().fit(X_raw[:split_idx])\n",
    "\n",
    "X_train_s = scaler.transform(X_raw[:split_idx]).astype(np.float32)\n",
    "X_val_s   = scaler.transform(X_raw[ split_idx:]).astype(np.float32)\n",
    "y_train   = y_raw[: split_idx]\n",
    "y_val     = y_raw[ split_idx:]\n",
    "\n",
    "X_train, y_train = make_windows(X_train_s, y_train, WIN)\n",
    "X_val,   y_val   = make_windows(X_val_s,   y_val,   WIN)\n",
    "\n",
    "print(f\"   Train windows : {len(X_train):,}\")\n",
    "print(f\"   Val   windows : {len(X_val):,}\")\n",
    "print(f\"   Features      : {n_features}\")\n",
    "\n",
    "# ═══════════════ 2. MODEL ═══════════════════════════════\n",
    "print(\"\\n🏗️ Building model …\")\n",
    "tf.keras.backend.clear_session()\n",
    "model = build_model(WIN, n_features)\n",
    "model.compile(optimizer=keras.optimizers.Adam(LR),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# ═══════════════ 3. TRAIN ═══════════════════════════════\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=EARLY_STOP,\n",
    "                                  restore_best_weights=True,\n",
    "                                  verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.5,\n",
    "                                      patience=5,\n",
    "                                      verbose=1,\n",
    "                                      min_lr=1e-7)\n",
    "]\n",
    "\n",
    "print(\"\\n🚀 Training …\")\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "# ═══════════════ 4. EVALUATION ══════════════════════════\n",
    "prob = model.predict(X_val, verbose=0).ravel()\n",
    "pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "precision = precision_score(y_val, pred, zero_division=0)\n",
    "recall    = recall_score(y_val, pred, zero_division=0)\n",
    "wf1       = weighted_f(ALPHA, precision, recall)\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\"      : accuracy_score(y_val, pred),\n",
    "    \"precision\"     : precision,\n",
    "    \"recall\"        : recall,\n",
    "    \"weighted_f1_a2\": wf1,\n",
    "    \"auc\"           : roc_auc_score(y_val, prob)\n",
    "}\n",
    "\n",
    "print(\"\\n── Validation metrics ──\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k:20s}: {v:6.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_val, pred, target_names=[\"Down\", \"Up\"]))\n",
    "\n",
    "cm = confusion_matrix(y_val, pred)\n",
    "print(\"\\nConfusion-matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# ═══════════════ 5. SAVE ═══════════════════════════════=\n",
    "print(\"\\n💾 Saving artefacts …\")\n",
    "keras.models.save_model(model, MODEL_OUT)\n",
    "joblib.dump(scaler, SCALER_OUT)\n",
    "\n",
    "with open(SUMMARY_JSON, \"w\") as fp:\n",
    "    json.dump({\n",
    "        \"timestamp\"      : datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "        \"window_size\"    : WIN,\n",
    "        \"n_features\"     : n_features,\n",
    "        \"train_windows\"  : int(len(X_train)),\n",
    "        \"val_windows\"    : int(len(X_val)),\n",
    "        \"metrics\"        : {k: float(v) for k, v in metrics.items()},\n",
    "        \"hyperparameters\": {\n",
    "            \"filters\" : FILTERS, \"kernel\": KERNEL, \"activation\": ACT,\n",
    "            \"dropout\" : DROPOUT, \"dense_units\": DENSE_UNITS,\n",
    "            \"conv_blocks\": CONV_BLOCKS, \"pool\": POOL_TYPE,\n",
    "            \"extra_dense\": EXTRA_DENSE, \"lr\": LR, \"batch\": BATCH,\n",
    "            \"l2_reg\": L2_REG\n",
    "        },\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    }, fp, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Model   saved → {MODEL_OUT}\")\n",
    "print(f\"✅ Scaler  saved → {SCALER_OUT}\")\n",
    "print(f\"✅ Summary saved → {SUMMARY_JSON}\")\n",
    "print(\"🎉 Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae59bae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loading & scaling data …\n",
      "\n",
      "Run-01  (win=12, filt=64, pool=gap)\n",
      "───────────────────────────────────\n",
      "Precision : 0.530   Recall : 0.492   F1 : 0.511\n",
      "\n",
      "Run-02  (win=30, filt=96, pool=gmp)\n",
      "───────────────────────────────────\n",
      "Precision : 0.491   Recall : 0.144   F1 : 0.223\n",
      "\n",
      "Run-03  (win=36, filt=64, pool=gmp)\n",
      "───────────────────────────────────\n",
      "Precision : 0.515   Recall : 0.535   F1 : 0.525\n",
      "\n",
      "Run-04  (win=24, filt=32, pool=gmp)\n",
      "───────────────────────────────────\n",
      "Precision : 0.525   Recall : 0.659   F1 : 0.584\n",
      "\n",
      "Run-05  (win=30, filt=64, pool=gmp)\n",
      "───────────────────────────────────\n",
      "Precision : 0.535   Recall : 0.138   F1 : 0.220\n",
      "\n",
      "Run-06  (win=12, filt=64, pool=gap)\n",
      "───────────────────────────────────\n",
      "Precision : 0.530   Recall : 0.437   F1 : 0.479\n",
      "\n",
      "🏆  Leaderboard (sorted by F1)\n",
      " 1. F1=0.584  P=0.525  R=0.659  (win=24, filt=32, pool=gmp)\n",
      " 2. F1=0.525  P=0.515  R=0.535  (win=36, filt=64, pool=gmp)\n",
      " 3. F1=0.511  P=0.530  R=0.492  (win=12, filt=64, pool=gap)\n",
      " 4. F1=0.479  P=0.530  R=0.437  (win=12, filt=64, pool=gap)\n",
      " 5. F1=0.223  P=0.491  R=0.144  (win=30, filt=96, pool=gmp)\n",
      " 6. F1=0.220  P=0.535  R=0.138  (win=30, filt=64, pool=gmp)\n",
      "\n",
      "📑 Comparison summary saved → cnn_param_comparison_summary.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "cnn_compare_param_sets.py\n",
    "─────────────────────────\n",
    "Trains - and compares - several 1-D CNN configurations on the 4-hour BTC data.\n",
    "Each configuration is built exactly from the hyper-parameter dictionary you\n",
    "supply in `PARAM_SETS`.\n",
    "The script prints Precision, Recall, F1 for every run and a final leaderboard.\n",
    "\"\"\"\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# Imports & global set-up\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "import os, json, joblib, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score,\n",
    "                             accuracy_score, roc_auc_score)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# Data paths & constants\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "CSV_PATH = Path(r\"C:/Users/ADMIN/Desktop/Coding_projects/stock_market_prediction/\"\n",
    "                r\"Stock-Market-Prediction/data/processed/\"\n",
    "                r\"gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC   = 0.20          # last 20 % is the validation window\n",
    "EPOCHS     = 80            # same for every run\n",
    "EARLY_STOP = 12\n",
    "L2_REG_DEF = 1e-6          # fallback if a param dict misses 'l2'\n",
    "CONV_BLOCKS = 1            # fixed depth – keep the test fast\n",
    "\n",
    "# Columns to drop (same list you tuned on – prevents data leakage)\n",
    "DROP_COLS = [  # … (list exactly as before – shortened for brevity here)\n",
    "    'open','high','low','typical_price','EMA_7','EMA_21','SMA_20','SMA_50',\n",
    "    'vwap_24h','close_4h','bollinger_upper','bollinger_lower','resistance_level',\n",
    "    'support_level','high_low','high_close','low_close','true_range',\n",
    "    #  … snip …\n",
    "    'overbought_reversal','close'\n",
    "]\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# The six candidate hyper-parameter sets\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "PARAM_SETS = [\n",
    "    {'window': 12, 'batch': 64, 'lr': 0.000898, 'filters': 64, 'kernel': 3,\n",
    "     'act': 'elu',  'dropout': 0.209, 'dense': 64,  'l2': 3.35e-05,\n",
    "     'pool': 'gap', 'extra_dense': False},\n",
    "\n",
    "    {'window': 30, 'batch': 32, 'lr': 0.001545, 'filters': 96, 'kernel': 4,\n",
    "     'act': 'elu',  'dropout': 0.14,  'dense': 128, 'l2': 0.000168,\n",
    "     'pool': 'gmp', 'extra_dense': False},\n",
    "\n",
    "    {'window': 36, 'batch': 32, 'lr': 0.000215, 'filters': 64, 'kernel': 2,\n",
    "     'act': 'relu', 'dropout': 0.186, 'dense': 64,  'l2': 0.000255,\n",
    "     'pool': 'gmp', 'extra_dense': True},\n",
    "\n",
    "    {'window': 24, 'batch': 32, 'lr': 0.00104,  'filters': 32, 'kernel': 4,\n",
    "     'act': 'elu',  'dropout': 0.292, 'dense': 128, 'l2': 4.33e-06,\n",
    "     'pool': 'gmp', 'extra_dense': False},\n",
    "\n",
    "    {'window': 30, 'batch': 64, 'lr': 0.000172, 'filters': 64, 'kernel': 4,\n",
    "     'act': 'selu','dropout': 0.061, 'dense': 128, 'l2': 3.24e-06,\n",
    "     'pool': 'gmp', 'extra_dense': True},\n",
    "\n",
    "    # Duplicate of the first – still included for completeness\n",
    "    {'window': 12, 'batch': 64, 'lr': 0.000898, 'filters': 64, 'kernel': 3,\n",
    "     'act': 'elu',  'dropout': 0.209, 'dense': 64,  'l2': 3.35e-05,\n",
    "     'pool': 'gap', 'extra_dense': False}\n",
    "]\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# Data prep helpers\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "def make_windows(arr, labels, win):\n",
    "    xs, ys = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        xs.append(arr[i-win:i])\n",
    "        ys.append(labels[i])\n",
    "    return (np.asarray(xs, np.float32), np.asarray(ys, np.int8))\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# Model factory\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "def build_model(cfg, n_features):\n",
    "    \"\"\"Construct a simple residual-style 1-D CNN from cfg dict.\"\"\"\n",
    "    l2 = cfg.get(\"l2\", L2_REG_DEF)\n",
    "    inp = layers.Input(shape=(cfg[\"window\"], n_features))\n",
    "    x   = inp\n",
    "\n",
    "    for b in range(CONV_BLOCKS):\n",
    "        f = cfg[\"filters\"] * (2 ** b)\n",
    "        y = layers.Conv1D(f, cfg[\"kernel\"], padding=\"causal\",\n",
    "                          activation=cfg[\"act\"],\n",
    "                          kernel_regularizer=regularizers.l2(l2))(x)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "\n",
    "        if CONV_BLOCKS > 1:\n",
    "            if x.shape[-1] != y.shape[-1]:\n",
    "                x = layers.Conv1D(f, 1, padding=\"same\")(x)\n",
    "            x = layers.Add()([x, y])\n",
    "        else:\n",
    "            x = y\n",
    "\n",
    "    pool = layers.GlobalMaxPooling1D if cfg[\"pool\"] == \"gmp\" else layers.GlobalAveragePooling1D\n",
    "    x    = pool()(x)\n",
    "    x    = layers.Dropout(cfg[\"dropout\"])(x)\n",
    "\n",
    "    if cfg[\"extra_dense\"]:\n",
    "        x = layers.Dense(cfg[\"dense\"], activation=cfg[\"act\"],\n",
    "                         kernel_regularizer=regularizers.l2(l2))(x)\n",
    "        x = layers.Dropout(cfg[\"dropout\"])(x)\n",
    "\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inp, out)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# 1. Load / scale data once\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "print(\"📊 Loading & scaling data …\")\n",
    "df = (pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "        .loc[\"2018-01-01\":]\n",
    "        .drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "        .dropna(subset=[\"target\"]).dropna())\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "X_train_scaled = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_val_scaled   = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_train_raw    = y_raw[:split]\n",
    "y_val_raw      = y_raw[split:]\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# 2. Iterate over parameter sets\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "results = []\n",
    "\n",
    "for idx, cfg in enumerate(PARAM_SETS, 1):\n",
    "    tag = f\"Run-{idx:02d}  (win={cfg['window']}, filt={cfg['filters']}, pool={cfg['pool']})\"\n",
    "    print(f\"\\n{tag}\\n\" + \"─\" * len(tag))\n",
    "\n",
    "    # --- prepare windows for this window size\n",
    "    X_tr, y_tr = make_windows(X_train_scaled, y_train_raw, cfg[\"window\"])\n",
    "    X_va, y_va = make_windows(X_val_scaled,   y_val_raw,   cfg[\"window\"])\n",
    "\n",
    "    # --- build & train\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = build_model(cfg, n_features)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(cfg[\"lr\"]),\n",
    "                  loss=\"binary_crossentropy\")\n",
    "\n",
    "    cb = [keras.callbacks.EarlyStopping(patience=EARLY_STOP,\n",
    "                                        restore_best_weights=True,\n",
    "                                        verbose=0)]\n",
    "    model.fit(X_tr, y_tr,\n",
    "              epochs=EPOCHS,\n",
    "              batch_size=cfg[\"batch\"],\n",
    "              validation_data=(X_va, y_va),\n",
    "              callbacks=cb,\n",
    "              verbose=0)\n",
    "\n",
    "    # --- evaluate\n",
    "    prob = model.predict(X_va, verbose=0).ravel()\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "    prec = precision_score(y_va, pred, zero_division=0)\n",
    "    rec  = recall_score(y_va, pred,    zero_division=0)\n",
    "    f1   = f1_score(y_va, pred,        zero_division=0)\n",
    "\n",
    "    print(f\"Precision : {prec:5.3f}   Recall : {rec:5.3f}   F1 : {f1:5.3f}\")\n",
    "\n",
    "    results.append({\n",
    "        **cfg,\n",
    "        \"precision\": prec,\n",
    "        \"recall\"   : rec,\n",
    "        \"f1\"       : f1,\n",
    "        \"auc\"      : roc_auc_score(y_va, prob)\n",
    "    })\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# 3. Leaderboard\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "print(\"\\n🏆  Leaderboard (sorted by F1)\")\n",
    "results_sorted = sorted(results, key=lambda d: d[\"f1\"], reverse=True)\n",
    "\n",
    "for rk, res in enumerate(results_sorted, 1):\n",
    "    print(f\"{rk:>2}. F1={res['f1']:.3f}  \"\n",
    "          f\"P={res['precision']:.3f}  R={res['recall']:.3f}  \"\n",
    "          f\"(win={res['window']}, filt={res['filters']}, pool={res['pool']})\")\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "# 4. Optional – save summary JSON\n",
    "# ═══════════════════════════════════════════════════════════════════════\n",
    "summary_path = \"cnn_param_comparison_summary.json\"\n",
    "with open(summary_path, \"w\") as fp:\n",
    "    json.dump({\n",
    "        \"timestamp\" : datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "        \"metrics\"   : results_sorted\n",
    "    }, fp, indent=2)\n",
    "\n",
    "print(f\"\\n📑 Comparison summary saved → {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4aee03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loading & preprocessing …\n",
      "   Train windows : 12,660\n",
      "   Val   windows : 3,147\n",
      "   Features      : 19\n",
      "\n",
      "🏗️ Building model …\n",
      "WARNING:tensorflow:From c:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "🚀 Training …\n",
      "Epoch 1/100\n",
      "396/396 - 2s - 4ms/step - accuracy: 0.5092 - loss: 0.8559 - val_accuracy: 0.4986 - val_loss: 0.7030 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5043 - loss: 0.7407 - val_accuracy: 0.5005 - val_loss: 0.6970 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5069 - loss: 0.7090 - val_accuracy: 0.5011 - val_loss: 0.6947 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5086 - loss: 0.6994 - val_accuracy: 0.5068 - val_loss: 0.6941 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5164 - loss: 0.6947 - val_accuracy: 0.5059 - val_loss: 0.6937 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5137 - loss: 0.6948 - val_accuracy: 0.5043 - val_loss: 0.6938 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5122 - loss: 0.6937 - val_accuracy: 0.5024 - val_loss: 0.6937 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5201 - loss: 0.6927 - val_accuracy: 0.5160 - val_loss: 0.6927 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5213 - loss: 0.6925 - val_accuracy: 0.5014 - val_loss: 0.6936 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5179 - loss: 0.6926 - val_accuracy: 0.5059 - val_loss: 0.6934 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5163 - loss: 0.6928 - val_accuracy: 0.5145 - val_loss: 0.6935 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5266 - loss: 0.6913 - val_accuracy: 0.5017 - val_loss: 0.6936 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005200000014156103.\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5170 - loss: 0.6936 - val_accuracy: 0.5040 - val_loss: 0.6934 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5288 - loss: 0.6912 - val_accuracy: 0.4995 - val_loss: 0.6938 - learning_rate: 5.2000e-04\n",
      "Epoch 15/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5270 - loss: 0.6906 - val_accuracy: 0.4983 - val_loss: 0.6939 - learning_rate: 5.2000e-04\n",
      "Epoch 16/100\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5320 - loss: 0.6900 - val_accuracy: 0.5024 - val_loss: 0.6942 - learning_rate: 5.2000e-04\n",
      "Epoch 17/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5341 - loss: 0.6892 - val_accuracy: 0.5021 - val_loss: 0.6948 - learning_rate: 5.2000e-04\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00026000000070780516.\n",
      "396/396 - 1s - 2ms/step - accuracy: 0.5266 - loss: 0.6905 - val_accuracy: 0.4979 - val_loss: 0.6948 - learning_rate: 5.2000e-04\n",
      "Epoch 19/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5333 - loss: 0.6894 - val_accuracy: 0.4906 - val_loss: 0.6956 - learning_rate: 2.6000e-04\n",
      "Epoch 20/100\n",
      "396/396 - 1s - 1ms/step - accuracy: 0.5398 - loss: 0.6890 - val_accuracy: 0.4919 - val_loss: 0.6954 - learning_rate: 2.6000e-04\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\n",
      "── Validation metrics ──\n",
      "accuracy            :  0.516\n",
      "precision           :  0.525\n",
      "recall              :  0.764\n",
      "weighted_f1_a2      :  0.663\n",
      "auc                 :  0.506\n",
      "\n",
      "Classification report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.49      0.24      0.33      1503\n",
      "          Up       0.53      0.76      0.62      1644\n",
      "\n",
      "    accuracy                           0.52      3147\n",
      "   macro avg       0.51      0.50      0.47      3147\n",
      "weighted avg       0.51      0.52      0.48      3147\n",
      "\n",
      "\n",
      "Confusion-matrix:\n",
      "[[ 368 1135]\n",
      " [ 388 1256]]\n",
      "\n",
      "💾 Saving artefacts …\n",
      "\n",
      "✅ Model   saved → cnn_optimal_val20.h5\n",
      "✅ Scaler  saved → cnn_scaler.pkl\n",
      "✅ Summary saved → cnn_training_summary.json\n",
      "🎉 Training complete.\n"
     ]
    }
   ],
   "source": [
    "# cnn_final_train_fixed.py\n",
    "# ----------------------------------------------------------\n",
    "# Trains a 1-D CNN with the optimal hyper-parameters you supplied.\n",
    "\n",
    "import os, json, joblib, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "import tensorflow as tf\n",
    "from   tensorflow import keras\n",
    "from   tensorflow.keras import layers, regularizers\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "from   sklearn.metrics       import (accuracy_score, precision_score,\n",
    "                                     recall_score, roc_auc_score,\n",
    "                                     confusion_matrix,\n",
    "                                     classification_report)\n",
    "\n",
    "# ═══════════════ Seeds / GPU set-up ══════════════════════\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ═══════════════ Paths & constants ═══════════════════════\n",
    "CSV_PATH      = Path(r\"C:/Users/ADMIN/Desktop/Coding_projects/stock_market_prediction/\"\n",
    "                     r\"Stock-Market-Prediction/data/processed/\"\n",
    "                     r\"gemini_btc_with_features_4h.csv\")\n",
    "MODEL_OUT     = \"cnn_optimal_val20.h5\"\n",
    "SCALER_OUT    = \"cnn_scaler.pkl\"\n",
    "SUMMARY_JSON  = \"cnn_training_summary.json\"\n",
    "\n",
    "# ---- hyper-parameters (fixed) ----\n",
    "WIN,  BATCH   = 24, 32\n",
    "LR            = 0.00104\n",
    "FILTERS       = 32\n",
    "KERNEL        = 4\n",
    "ACT           = \"elu\"\n",
    "DROPOUT       = 0.292\n",
    "DENSE_UNITS   = 128\n",
    "CONV_BLOCKS   = 1\n",
    "POOL_TYPE     = \"gmp\"      # gmp | gap\n",
    "EXTRA_DENSE   = False\n",
    "L2_REG        = 4.33e-06\n",
    "EPOCHS        = 100\n",
    "EARLY_STOP    = 12\n",
    "ALPHA         = 2.0        # precision weight in weighted-F\n",
    "VAL_FRAC      = 0.20\n",
    "\n",
    "DROP_COLS = [\n",
    "    'open','high','low','typical_price','EMA_7','EMA_21','SMA_20','SMA_50',\n",
    "    'vwap_24h','close_4h','bollinger_upper','bollinger_lower','resistance_level',\n",
    "    'support_level','high_low','high_close','low_close','true_range',\n",
    "    'volume_mean_20','MACD_line','MACD_signal','bollinger_width',\n",
    "    'volatility_regime','CCI','stoch_%D','parkinson_vol','ema_cross_down',\n",
    "    'macd_cross_down','vol_spike_1_5x','near_upper_band','near_lower_band',\n",
    "    'break_upper_band','break_lower_band','rsi_oversold','rsi_overbought',\n",
    "    'above_sma20','above_sma50','ema7_above_ema21','macd_positive',\n",
    "    'volume_breakout','volume_breakdown','stoch_overbought','stoch_oversold',\n",
    "    'cci_overbought','cci_oversold','trending_market','bullish_scenario_1',\n",
    "    'bullish_scenario_2','bullish_scenario_3','bullish_scenario_4',\n",
    "    'bullish_scenario_5','bullish_scenario_6','bearish_scenario_1',\n",
    "    'bearish_scenario_2','bearish_scenario_3','bearish_scenario_4',\n",
    "    'bearish_scenario_6','ema_cross_up','macd_cross_up',\n",
    "    'oversold_reversal','overbought_reversal','close'\n",
    "]\n",
    "\n",
    "# ═══════════════ helpers ═════════════════════════════════\n",
    "def make_windows(arr: np.ndarray, labels: np.ndarray, win: int):\n",
    "    xs, ys = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        xs.append(arr[i-win:i])\n",
    "        ys.append(labels[i])\n",
    "    return np.asarray(xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "def weighted_f(alpha: float, p: float, r: float) -> float:\n",
    "    if p + r == 0:\n",
    "        return 0.0\n",
    "    return (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def build_model(win: int, n_features: int) -> keras.Model:\n",
    "    \"\"\"**Fixed**: pooling layers are *called* on tensors.\"\"\"\n",
    "    inp = layers.Input(shape=(win, n_features))\n",
    "    x   = inp\n",
    "\n",
    "    for b in range(CONV_BLOCKS):\n",
    "        f = FILTERS * (2 ** b)\n",
    "        y = layers.Conv1D(f, KERNEL, padding=\"causal\",\n",
    "                          activation=ACT,\n",
    "                          kernel_regularizer=regularizers.l2(L2_REG))(x)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "\n",
    "        if CONV_BLOCKS > 1:\n",
    "            if x.shape[-1] != y.shape[-1]:\n",
    "                x = layers.Conv1D(f, 1, padding=\"same\")(x)\n",
    "            x = layers.Add()([x, y])\n",
    "        else:\n",
    "            x = y\n",
    "\n",
    "    if POOL_TYPE == \"gmp\":\n",
    "        x = layers.GlobalMaxPooling1D()(x)\n",
    "    else:\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = layers.Dropout(DROPOUT)(x)\n",
    "\n",
    "    if EXTRA_DENSE:\n",
    "        x = layers.Dense(DENSE_UNITS, activation=ACT,\n",
    "                         kernel_regularizer=regularizers.l2(L2_REG))(x)\n",
    "        x = layers.Dropout(DROPOUT)(x)\n",
    "\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inp, out)\n",
    "\n",
    "# ═══════════════ 1. DATA ═════════════════════════════════\n",
    "print(\"📊 Loading & preprocessing …\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"]).dropna()\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler    = StandardScaler().fit(X_raw[:split_idx])\n",
    "\n",
    "X_train_s = scaler.transform(X_raw[:split_idx]).astype(np.float32)\n",
    "X_val_s   = scaler.transform(X_raw[ split_idx:]).astype(np.float32)\n",
    "y_train   = y_raw[: split_idx]\n",
    "y_val     = y_raw[ split_idx:]\n",
    "\n",
    "X_train, y_train = make_windows(X_train_s, y_train, WIN)\n",
    "X_val,   y_val   = make_windows(X_val_s,   y_val,   WIN)\n",
    "\n",
    "print(f\"   Train windows : {len(X_train):,}\")\n",
    "print(f\"   Val   windows : {len(X_val):,}\")\n",
    "print(f\"   Features      : {n_features}\")\n",
    "\n",
    "# ═══════════════ 2. MODEL ═══════════════════════════════\n",
    "print(\"\\n🏗️ Building model …\")\n",
    "tf.keras.backend.clear_session()\n",
    "model = build_model(WIN, n_features)\n",
    "model.compile(optimizer=keras.optimizers.Adam(LR),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# ═══════════════ 3. TRAIN ═══════════════════════════════\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=EARLY_STOP,\n",
    "                                  restore_best_weights=True,\n",
    "                                  verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.5,\n",
    "                                      patience=5,\n",
    "                                      verbose=1,\n",
    "                                      min_lr=1e-7)\n",
    "]\n",
    "\n",
    "print(\"\\n🚀 Training …\")\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "# ═══════════════ 4. EVALUATION ══════════════════════════\n",
    "prob = model.predict(X_val, verbose=0).ravel()\n",
    "pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "precision = precision_score(y_val, pred, zero_division=0)\n",
    "recall    = recall_score(y_val, pred, zero_division=0)\n",
    "wf1       = weighted_f(ALPHA, precision, recall)\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\"      : accuracy_score(y_val, pred),\n",
    "    \"precision\"     : precision,\n",
    "    \"recall\"        : recall,\n",
    "    \"weighted_f1_a2\": wf1,\n",
    "    \"auc\"           : roc_auc_score(y_val, prob)\n",
    "}\n",
    "\n",
    "print(\"\\n── Validation metrics ──\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k:20s}: {v:6.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_val, pred, target_names=[\"Down\", \"Up\"]))\n",
    "\n",
    "cm = confusion_matrix(y_val, pred)\n",
    "print(\"\\nConfusion-matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# ═══════════════ 5. SAVE ═══════════════════════════════=\n",
    "print(\"\\n💾 Saving artefacts …\")\n",
    "keras.models.save_model(model, MODEL_OUT)\n",
    "joblib.dump(scaler, SCALER_OUT)\n",
    "\n",
    "with open(SUMMARY_JSON, \"w\") as fp:\n",
    "    json.dump({\n",
    "        \"timestamp\"      : datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "        \"window_size\"    : WIN,\n",
    "        \"n_features\"     : n_features,\n",
    "        \"train_windows\"  : int(len(X_train)),\n",
    "        \"val_windows\"    : int(len(X_val)),\n",
    "        \"metrics\"        : {k: float(v) for k, v in metrics.items()},\n",
    "        \"hyperparameters\": {\n",
    "            \"filters\" : FILTERS, \"kernel\": KERNEL, \"activation\": ACT,\n",
    "            \"dropout\" : DROPOUT, \"dense_units\": DENSE_UNITS,\n",
    "            \"conv_blocks\": CONV_BLOCKS, \"pool\": POOL_TYPE,\n",
    "            \"extra_dense\": EXTRA_DENSE, \"lr\": LR, \"batch\": BATCH,\n",
    "            \"l2_reg\": L2_REG\n",
    "        },\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    }, fp, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Model   saved → {MODEL_OUT}\")\n",
    "print(f\"✅ Scaler  saved → {SCALER_OUT}\")\n",
    "print(f\"✅ Summary saved → {SUMMARY_JSON}\")\n",
    "print(\"🎉 Training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

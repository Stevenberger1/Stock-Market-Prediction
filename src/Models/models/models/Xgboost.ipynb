{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf7cf9ef",
   "metadata": {},
   "source": [
    "# In this notebook we will train the xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b672a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_xgboost_4h = [\n",
    "    'open', 'high', 'low',\n",
    "    'high_low', 'high_close', 'low_close', 'typical_price',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3', \n",
    "    'bearish_scenario_6',\n",
    "    'volume_breakout', 'volume_breakdown', \n",
    "    'ema_cross_up', 'ema_cross_down', 'macd_cross_up', 'macd_cross_down',\n",
    "    'trending_market', 'trend_alignment', 'momentum_alignment',\n",
    "  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c74bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_catboost_4h = [\n",
    "    # Raw OHLC (keep close for analysis)\n",
    "    'open', 'high', 'low',\n",
    "    \n",
    "    # ATR intermediate calculations\n",
    "    'high_low', 'high_close', 'low_close',\n",
    "    \n",
    "    # Helper calculation\n",
    "    'typical_price',\n",
    "    \n",
    "    # Derivable position flags\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21',\n",
    "    \n",
    "    # Optional: Complex scenario features (test individually!)\n",
    "    'bullish_scenario_1',\n",
    "    'bullish_scenario_5', 'bearish_scenario_1'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed80e7",
   "metadata": {},
   "source": [
    "DROP_COLS = [ \n",
    "    'open', 'high', 'low', 'high_low', 'high_close', 'low_close', 'typical_price',\n",
    "    'volume_breakout', 'volume_breakdown', 'break_upper_band', 'break_lower_band',\n",
    "    'vol_spike_1_5x', 'rsi_oversold', 'rsi_overbought', 'stoch_overbought',\n",
    "    'stoch_oversold', 'cci_overbought', 'cci_oversold', 'near_upper_band',\n",
    "    'near_lower_band', 'overbought_reversal', 'oversold_reversal',\n",
    "    'ema_cross_up', 'ema_cross_down', 'macd_cross_up', 'macd_cross_down',\n",
    "    'trending_market', 'trend_alignment', 'ema7_above_ema21', 'macd_rising',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bullish_scenario_1',\n",
    "    'bullish_scenario_5', 'bearish_scenario_1'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remmber to add drop columns list + make 250 iterations insted of 100 and also in the end print the top 5\n",
    "#  results with their metrics precison , recall , f1 and not only the best one\n",
    "\n",
    "# also remmber to add rop columns to the both the model trainig and paramter finding code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "881ee5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU acceleration available and enabled!\n",
      "   XGBoost version: 3.0.2\n",
      "Loading dataset...\n",
      "Dataset shape: (20718, 67)\n",
      "Features shape after dropping columns: (20718, 54)\n",
      "Auto-detected: Classification (2 classes)\n",
      "Encoding categorical columns: ['timestamp']\n",
      "Class distribution: {0: np.int64(9967), 1: np.int64(10751)}\n",
      "üïê Using chronological split for time series data...\n",
      "Training set shape: (16574, 54)\n",
      "Test set shape: (4144, 54)\n",
      "Starting F0.5-optimized hyperparameter search...\n",
      "F0.5 gives 2x weight to precision vs recall - perfect for trading!\n",
      "Number of trials: 100\n",
      "Timeout: 3600 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 16:38:59,227] A new study created in memory with name: xgboost_f05_optimization\n",
      "Best trial: 0. Best value: 0.52196:   1%|          | 1/100 [00:58<1:36:30, 58.49s/it, 58.49/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial   0: Precision=0.5370 | Recall=0.5181 | F1=0.5127 | F0.5=0.5220\n",
      "[I 2025-06-12 16:39:57,718] Trial 0 finished with value: 0.5219603551381751 and parameters: {'n_estimators': 812, 'max_depth': 15, 'learning_rate': 0.14553179565665345, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'colsample_bylevel': 0.662397808134481, 'colsample_bynode': 0.6232334448672797, 'reg_alpha': 0.6245760287469893, 'reg_lambda': 0.002570603566117598, 'min_child_weight': 8, 'gamma': 0.10292247147901223, 'max_bin': 505}. Best is trial 0 with value: 0.5219603551381751.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.52196:   2%|‚ñè         | 2/100 [01:57<1:35:50, 58.68s/it, 117.30/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial   1: Precision=0.5449 | Recall=0.4658 | F1=0.4890 | F0.5=0.5172\n",
      "[I 2025-06-12 16:40:56,526] Trial 1 finished with value: 0.5172440089416588 and parameters: {'n_estimators': 1682, 'max_depth': 5, 'learning_rate': 0.011551009439226469, 'subsample': 0.6733618039413735, 'colsample_bytree': 0.7216968971838151, 'colsample_bylevel': 0.8099025726528951, 'colsample_bynode': 0.7727780074568463, 'reg_alpha': 4.17890272377219e-06, 'reg_lambda': 0.0032112643094417484, 'min_child_weight': 2, 'gamma': 1.4607232426760908, 'max_bin': 350}. Best is trial 0 with value: 0.5219603551381751.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.537634:   3%|‚ñé         | 3/100 [02:18<1:07:26, 41.71s/it, 138.82/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial   2: Precision=0.5512 | Recall=0.5182 | F1=0.5245 | F0.5=0.5376\n",
      "[I 2025-06-12 16:41:18,050] Trial 2 finished with value: 0.5376342597478997 and parameters: {'n_estimators': 966, 'max_depth': 13, 'learning_rate': 0.01254057843022616, 'subsample': 0.8056937753654446, 'colsample_bytree': 0.836965827544817, 'colsample_bylevel': 0.6185801650879991, 'colsample_bynode': 0.8430179407605753, 'reg_alpha': 3.425445902633376e-07, 'reg_lambda': 3.850031979199519e-08, 'min_child_weight': 10, 'gamma': 4.828160165372797, 'max_bin': 463}. Best is trial 2 with value: 0.5376342597478997.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.537634:   4%|‚ñç         | 4/100 [02:29<46:57, 29.35s/it, 149.22/3600 seconds]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial   3: Precision=0.5435 | Recall=0.4768 | F1=0.4894 | F0.5=0.5153\n",
      "[I 2025-06-12 16:41:28,448] Trial 3 finished with value: 0.515256107618009 and parameters: {'n_estimators': 679, 'max_depth': 4, 'learning_rate': 0.11679817513130797, 'subsample': 0.7760609974958406, 'colsample_bytree': 0.6488152939379115, 'colsample_bylevel': 0.798070764044508, 'colsample_bynode': 0.6137554084460873, 'reg_alpha': 1.527156759251193, 'reg_lambda': 2.133142332373004e-06, 'min_child_weight': 7, 'gamma': 1.5585553804470549, 'max_bin': 389}. Best is trial 2 with value: 0.5376342597478997.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.537634:   5%|‚ñå         | 5/100 [02:48<40:55, 25.85s/it, 168.85/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial   4: Precision=0.5331 | Recall=0.4726 | F1=0.4944 | F0.5=0.5153\n",
      "[I 2025-06-12 16:41:48,078] Trial 4 finished with value: 0.5152561647628653 and parameters: {'n_estimators': 1139, 'max_depth': 5, 'learning_rate': 0.43464957555697725, 'subsample': 0.9100531293444458, 'colsample_bytree': 0.9757995766256756, 'colsample_bylevel': 0.9579309401710595, 'colsample_bynode': 0.8391599915244341, 'reg_alpha': 1.9809253750493907, 'reg_lambda': 6.257956190096665e-08, 'min_child_weight': 2, 'gamma': 0.22613644455269033, 'max_bin': 339}. Best is trial 2 with value: 0.5376342597478997.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.537634:   6%|‚ñå         | 6/100 [02:58<31:51, 20.34s/it, 178.50/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial   5: Precision=0.5362 | Recall=0.5285 | F1=0.5174 | F0.5=0.5238\n",
      "[I 2025-06-12 16:41:57,731] Trial 5 finished with value: 0.5237587163945812 and parameters: {'n_estimators': 838, 'max_depth': 6, 'learning_rate': 0.22721919801680068, 'subsample': 0.7427013306774357, 'colsample_bytree': 0.7123738038749523, 'colsample_bylevel': 0.8170784332632994, 'colsample_bynode': 0.6563696899899051, 'reg_alpha': 0.16587190283399655, 'reg_lambda': 4.6876566400928895e-08, 'min_child_weight': 10, 'gamma': 3.861223846483287, 'max_bin': 307}. Best is trial 2 with value: 0.5376342597478997.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.537634:   7%|‚ñã         | 7/100 [03:07<25:53, 16.70s/it, 187.72/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial   6: Precision=0.5373 | Recall=0.4986 | F1=0.5039 | F0.5=0.5197\n",
      "[I 2025-06-12 16:42:06,944] Trial 6 finished with value: 0.5197215285150103 and parameters: {'n_estimators': 110, 'max_depth': 13, 'learning_rate': 0.12962378302375793, 'subsample': 0.8916028672163949, 'colsample_bytree': 0.9085081386743783, 'colsample_bylevel': 0.6296178606936361, 'colsample_bynode': 0.7433862914177091, 'reg_alpha': 1.1036250149900698e-07, 'reg_lambda': 0.5860448217200517, 'min_child_weight': 7, 'gamma': 1.654490124263246, 'max_bin': 272}. Best is trial 2 with value: 0.5376342597478997.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.537634:   8%|‚ñä         | 8/100 [03:15<21:12, 13.83s/it, 195.40/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial   7: Precision=0.5486 | Recall=0.4928 | F1=0.5016 | F0.5=0.5230\n",
      "[I 2025-06-12 16:42:14,632] Trial 7 finished with value: 0.5230174102019175 and parameters: {'n_estimators': 691, 'max_depth': 7, 'learning_rate': 0.14394028591544616, 'subsample': 0.8550229885420852, 'colsample_bytree': 0.9548850970305306, 'colsample_bylevel': 0.7888859700647797, 'colsample_bynode': 0.6478376983753207, 'reg_alpha': 0.02625445968759339, 'reg_lambda': 0.0703178263660987, 'min_child_weight': 6, 'gamma': 3.854835899772805, 'max_bin': 382}. Best is trial 2 with value: 0.5376342597478997.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.537634:   9%|‚ñâ         | 9/100 [04:48<58:36, 38.64s/it, 288.59/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial   8: Precision=0.5483 | Recall=0.4869 | F1=0.5006 | F0.5=0.5236\n",
      "[I 2025-06-12 16:43:47,815] Trial 8 finished with value: 0.5236472557691555 and parameters: {'n_estimators': 1093, 'max_depth': 8, 'learning_rate': 0.005620931047896532, 'subsample': 0.6431565707973218, 'colsample_bytree': 0.6125716742746937, 'colsample_bylevel': 0.8545641645055122, 'colsample_bynode': 0.7257423924305306, 'reg_alpha': 0.0003776906385115029, 'reg_lambda': 1.4726456718740824, 'min_child_weight': 3, 'gamma': 2.0519146151781484, 'max_bin': 450}. Best is trial 2 with value: 0.5376342597478997.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.537634:  10%|‚ñà         | 10/100 [04:58<44:47, 29.87s/it, 298.81/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial   9: Precision=0.5566 | Recall=0.4921 | F1=0.5104 | F0.5=0.5340\n",
      "[I 2025-06-12 16:43:58,036] Trial 9 finished with value: 0.5339511590919626 and parameters: {'n_estimators': 534, 'max_depth': 4, 'learning_rate': 0.01898772399339208, 'subsample': 0.6644885149016018, 'colsample_bytree': 0.9718790609370292, 'colsample_bylevel': 0.9232481518257668, 'colsample_bynode': 0.8533615026041694, 'reg_alpha': 0.6968596391373533, 'reg_lambda': 0.1710207048797339, 'min_child_weight': 2, 'gamma': 4.462794992449889, 'max_bin': 394}. Best is trial 2 with value: 0.5376342597478997.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.54767:  11%|‚ñà         | 11/100 [05:14<37:54, 25.56s/it, 314.61/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  10: Precision=0.5423 | Recall=0.5898 | F1=0.5595 | F0.5=0.5477\n",
      "[I 2025-06-12 16:44:13,836] Trial 10 finished with value: 0.5476695253418271 and parameters: {'n_estimators': 1577, 'max_depth': 11, 'learning_rate': 0.03621799474202486, 'subsample': 0.9729161367647149, 'colsample_bytree': 0.8466707575873181, 'colsample_bylevel': 0.7151465108916805, 'colsample_bynode': 0.9768664324728544, 'reg_alpha': 1.2784194237583953e-08, 'reg_lambda': 1.030757695829262e-05, 'min_child_weight': 10, 'gamma': 4.96202058341917, 'max_bin': 499}. Best is trial 10 with value: 0.5476695253418271.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.54767:  12%|‚ñà‚ñè        | 12/100 [05:29<32:44, 22.32s/it, 329.53/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  11: Precision=0.5413 | Recall=0.5772 | F1=0.5528 | F0.5=0.5444\n",
      "[I 2025-06-12 16:44:28,755] Trial 11 finished with value: 0.544376115149263 and parameters: {'n_estimators': 1617, 'max_depth': 11, 'learning_rate': 0.044095880367849595, 'subsample': 0.9782637392221827, 'colsample_bytree': 0.8410499373345498, 'colsample_bylevel': 0.6871414335345349, 'colsample_bynode': 0.9801940060533646, 'reg_alpha': 1.0769715790317198e-08, 'reg_lambda': 9.546702333605166e-06, 'min_child_weight': 10, 'gamma': 4.985825626172574, 'max_bin': 500}. Best is trial 10 with value: 0.5476695253418271.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.54767:  13%|‚ñà‚ñé        | 13/100 [05:48<30:57, 21.36s/it, 348.66/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  12: Precision=0.5472 | Recall=0.4817 | F1=0.5052 | F0.5=0.5275\n",
      "[I 2025-06-12 16:44:47,882] Trial 12 finished with value: 0.5274692569813458 and parameters: {'n_estimators': 1909, 'max_depth': 10, 'learning_rate': 0.04465130455121415, 'subsample': 0.9984066126989742, 'colsample_bytree': 0.8288055772301383, 'colsample_bylevel': 0.708980611666942, 'colsample_bynode': 0.9997449754566204, 'reg_alpha': 1.0509212025163454e-08, 'reg_lambda': 9.658641762306647e-06, 'min_child_weight': 9, 'gamma': 3.210999781834424, 'max_bin': 512}. Best is trial 10 with value: 0.5476695253418271.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.54767:  14%|‚ñà‚ñç        | 14/100 [06:02<27:25, 19.14s/it, 362.67/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  13: Precision=0.5417 | Recall=0.5460 | F1=0.5395 | F0.5=0.5398\n",
      "[I 2025-06-12 16:45:01,894] Trial 13 finished with value: 0.5397882684453312 and parameters: {'n_estimators': 1479, 'max_depth': 10, 'learning_rate': 0.04288073747566629, 'subsample': 0.9984067957444853, 'colsample_bytree': 0.8688373577594762, 'colsample_bylevel': 0.7157541529215599, 'colsample_bynode': 0.992025551184718, 'reg_alpha': 2.0673298327150042e-05, 'reg_lambda': 2.7658555339141567e-05, 'min_child_weight': 4, 'gamma': 4.9863647064750936, 'max_bin': 460}. Best is trial 10 with value: 0.5476695253418271.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.54767:  15%|‚ñà‚ñå        | 15/100 [06:25<28:49, 20.35s/it, 385.84/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  14: Precision=0.5485 | Recall=0.5086 | F1=0.5148 | F0.5=0.5312\n",
      "[I 2025-06-12 16:45:25,063] Trial 14 finished with value: 0.5312499277307892 and parameters: {'n_estimators': 1448, 'max_depth': 12, 'learning_rate': 0.027967202614255386, 'subsample': 0.9383919204108254, 'colsample_bytree': 0.758730254741415, 'colsample_bylevel': 0.7253702586686225, 'colsample_bynode': 0.9287300763833096, 'reg_alpha': 1.1995224485250402e-08, 'reg_lambda': 0.00013710128828236596, 'min_child_weight': 9, 'gamma': 3.1466433301490775, 'max_bin': 432}. Best is trial 10 with value: 0.5476695253418271.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.54767:  16%|‚ñà‚ñå        | 16/100 [06:42<27:07, 19.37s/it, 402.94/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  15: Precision=0.5467 | Recall=0.5622 | F1=0.5499 | F0.5=0.5471\n",
      "[I 2025-06-12 16:45:42,166] Trial 15 finished with value: 0.5471393490929398 and parameters: {'n_estimators': 1981, 'max_depth': 11, 'learning_rate': 0.07359536390791321, 'subsample': 0.9438869784567316, 'colsample_bytree': 0.7753801906386225, 'colsample_bylevel': 0.6791639002034141, 'colsample_bynode': 0.9223912814117319, 'reg_alpha': 0.0007136002774640431, 'reg_lambda': 5.560213556234732e-07, 'min_child_weight': 10, 'gamma': 4.458116274002602, 'max_bin': 485}. Best is trial 10 with value: 0.5476695253418271.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.54767:  17%|‚ñà‚ñã        | 17/100 [07:03<27:09, 19.64s/it, 423.19/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  16: Precision=0.5405 | Recall=0.5358 | F1=0.5264 | F0.5=0.5319\n",
      "[I 2025-06-12 16:46:02,412] Trial 16 finished with value: 0.5319329636005378 and parameters: {'n_estimators': 1999, 'max_depth': 15, 'learning_rate': 0.07713498809547507, 'subsample': 0.9425421075079207, 'colsample_bytree': 0.7945598100372377, 'colsample_bylevel': 0.7481435303576582, 'colsample_bynode': 0.9169334932769577, 'reg_alpha': 0.002240796166722763, 'reg_lambda': 6.796618335327865e-07, 'min_child_weight': 5, 'gamma': 4.123161127609905, 'max_bin': 478}. Best is trial 10 with value: 0.5476695253418271.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.54767:  18%|‚ñà‚ñä        | 18/100 [07:22<26:33, 19.43s/it, 442.14/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  17: Precision=0.5419 | Recall=0.4720 | F1=0.4917 | F0.5=0.5173\n",
      "[I 2025-06-12 16:46:21,362] Trial 17 finished with value: 0.5173084462367754 and parameters: {'n_estimators': 1775, 'max_depth': 9, 'learning_rate': 0.06998364363488781, 'subsample': 0.8839426602349097, 'colsample_bytree': 0.7672616329128297, 'colsample_bylevel': 0.6566933721271898, 'colsample_bynode': 0.9167349555568116, 'reg_alpha': 3.017603616190815e-05, 'reg_lambda': 8.570674596098345e-07, 'min_child_weight': 8, 'gamma': 3.3140633328636833, 'max_bin': 424}. Best is trial 10 with value: 0.5476695253418271.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.54767:  19%|‚ñà‚ñâ        | 19/100 [07:51<30:15, 22.42s/it, 471.51/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  18: Precision=0.5512 | Recall=0.5019 | F1=0.5150 | F0.5=0.5336\n",
      "[I 2025-06-12 16:46:50,734] Trial 18 finished with value: 0.5336469617720808 and parameters: {'n_estimators': 1307, 'max_depth': 13, 'learning_rate': 0.024718249520416128, 'subsample': 0.9476077563455207, 'colsample_bytree': 0.8927667771131523, 'colsample_bylevel': 0.7500327051538141, 'colsample_bynode': 0.9496606563368475, 'reg_alpha': 0.002330119002013363, 'reg_lambda': 0.0006033236716118722, 'min_child_weight': 8, 'gamma': 2.664811828490935, 'max_bin': 481}. Best is trial 10 with value: 0.5476695253418271.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.54767:  20%|‚ñà‚ñà        | 20/100 [08:06<26:49, 20.12s/it, 486.27/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  19: Precision=0.5450 | Recall=0.4611 | F1=0.4815 | F0.5=0.5106\n",
      "[I 2025-06-12 16:47:05,493] Trial 19 finished with value: 0.5105561914934393 and parameters: {'n_estimators': 1768, 'max_depth': 11, 'learning_rate': 0.2979793595497296, 'subsample': 0.8462943284559303, 'colsample_bytree': 0.7144073207588191, 'colsample_bylevel': 0.886326432070599, 'colsample_bynode': 0.8802489778678998, 'reg_alpha': 1.7276342239547871e-06, 'reg_lambda': 2.1787040868512308e-07, 'min_child_weight': 9, 'gamma': 4.43362430254979, 'max_bin': 422}. Best is trial 10 with value: 0.5476695253418271.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.54767:  21%|‚ñà‚ñà        | 21/100 [08:25<26:06, 19.83s/it, 505.44/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  20: Precision=0.5389 | Recall=0.4944 | F1=0.4921 | F0.5=0.5127\n",
      "[I 2025-06-12 16:47:24,669] Trial 20 finished with value: 0.5127405105218916 and parameters: {'n_estimators': 1328, 'max_depth': 8, 'learning_rate': 0.06701148470475139, 'subsample': 0.7189657938948292, 'colsample_bytree': 0.9259308962023542, 'colsample_bylevel': 0.6708208464903006, 'colsample_bynode': 0.8923102962654635, 'reg_alpha': 0.0001338990232342393, 'reg_lambda': 3.7776039750477e-05, 'min_child_weight': 6, 'gamma': 3.691166955422932, 'max_bin': 441}. Best is trial 10 with value: 0.5476695253418271.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.548553:  22%|‚ñà‚ñà‚ñè       | 22/100 [08:41<24:16, 18.67s/it, 521.40/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  21: Precision=0.5441 | Recall=0.5771 | F1=0.5571 | F0.5=0.5486\n",
      "[I 2025-06-12 16:47:40,624] Trial 21 finished with value: 0.548552577178835 and parameters: {'n_estimators': 1566, 'max_depth': 11, 'learning_rate': 0.04087070319667424, 'subsample': 0.9731771324447516, 'colsample_bytree': 0.8506057901574333, 'colsample_bylevel': 0.6847908321350772, 'colsample_bynode': 0.9656310526559151, 'reg_alpha': 2.2800860383019682e-07, 'reg_lambda': 5.26307665133274e-06, 'min_child_weight': 10, 'gamma': 4.519283539617147, 'max_bin': 497}. Best is trial 21 with value: 0.548552577178835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.548553:  23%|‚ñà‚ñà‚ñé       | 23/100 [09:01<24:23, 19.00s/it, 541.18/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  22: Precision=0.5490 | Recall=0.5480 | F1=0.5410 | F0.5=0.5441\n",
      "[I 2025-06-12 16:48:00,406] Trial 22 finished with value: 0.544051795056762 and parameters: {'n_estimators': 1869, 'max_depth': 11, 'learning_rate': 0.029785466048449057, 'subsample': 0.9600239834936011, 'colsample_bytree': 0.7984617451987015, 'colsample_bylevel': 0.7596781750650533, 'colsample_bynode': 0.9578920226477285, 'reg_alpha': 1.8469408002336966e-07, 'reg_lambda': 2.687788315138241e-06, 'min_child_weight': 10, 'gamma': 4.55767033074189, 'max_bin': 484}. Best is trial 21 with value: 0.548552577178835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.548553:  24%|‚ñà‚ñà‚ñç       | 24/100 [09:25<26:11, 20.68s/it, 565.78/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  23: Precision=0.5544 | Recall=0.5119 | F1=0.5246 | F0.5=0.5403\n",
      "[I 2025-06-12 16:48:25,002] Trial 23 finished with value: 0.5403266450136892 and parameters: {'n_estimators': 1559, 'max_depth': 12, 'learning_rate': 0.018053833595599256, 'subsample': 0.915550509988609, 'colsample_bytree': 0.8581230277866595, 'colsample_bylevel': 0.6073813369775343, 'colsample_bynode': 0.9455848913690531, 'reg_alpha': 1.421930258992609e-06, 'reg_lambda': 1.0969787584030292e-08, 'min_child_weight': 9, 'gamma': 4.15884027996377, 'max_bin': 482}. Best is trial 21 with value: 0.548552577178835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.548553:  25%|‚ñà‚ñà‚ñå       | 25/100 [09:44<24:58, 19.98s/it, 584.12/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  24: Precision=0.5467 | Recall=0.5024 | F1=0.5087 | F0.5=0.5268\n",
      "[I 2025-06-12 16:48:43,348] Trial 24 finished with value: 0.5268347602216992 and parameters: {'n_estimators': 1983, 'max_depth': 9, 'learning_rate': 0.07553184283198304, 'subsample': 0.9732634059130094, 'colsample_bytree': 0.7774409052987044, 'colsample_bylevel': 0.6899327295692722, 'colsample_bynode': 0.8854991493083071, 'reg_alpha': 9.410586942975905e-08, 'reg_lambda': 0.00011329385505401162, 'min_child_weight': 10, 'gamma': 2.6867766784537865, 'max_bin': 512}. Best is trial 21 with value: 0.548552577178835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.548553:  26%|‚ñà‚ñà‚ñå       | 26/100 [10:01<23:33, 19.10s/it, 601.17/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  25: Precision=0.5503 | Recall=0.5028 | F1=0.5123 | F0.5=0.5304\n",
      "[I 2025-06-12 16:49:00,395] Trial 25 finished with value: 0.5304323380704737 and parameters: {'n_estimators': 1297, 'max_depth': 14, 'learning_rate': 0.032677079513305216, 'subsample': 0.920158613666429, 'colsample_bytree': 0.8176021736804028, 'colsample_bylevel': 0.635663367103597, 'colsample_bynode': 0.8074879828556969, 'reg_alpha': 0.00422918163231331, 'reg_lambda': 2.6434085113630614e-07, 'min_child_weight': 7, 'gamma': 4.315961451395856, 'max_bin': 464}. Best is trial 21 with value: 0.548552577178835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.548553:  27%|‚ñà‚ñà‚ñã       | 27/100 [10:18<22:36, 18.58s/it, 618.54/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  26: Precision=0.5434 | Recall=0.4790 | F1=0.5012 | F0.5=0.5238\n",
      "[I 2025-06-12 16:49:17,764] Trial 26 finished with value: 0.5238274619415298 and parameters: {'n_estimators': 1724, 'max_depth': 10, 'learning_rate': 0.10308860512127452, 'subsample': 0.8729459850123023, 'colsample_bytree': 0.8845492507353712, 'colsample_bylevel': 0.7220256569965204, 'colsample_bynode': 0.9688413287673938, 'reg_alpha': 0.00024017780984974437, 'reg_lambda': 6.292699047131376e-06, 'min_child_weight': 8, 'gamma': 3.4957385485199706, 'max_bin': 405}. Best is trial 21 with value: 0.548552577178835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.548553:  28%|‚ñà‚ñà‚ñä       | 28/100 [10:48<26:22, 21.98s/it, 648.43/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  27: Precision=0.5452 | Recall=0.5626 | F1=0.5497 | F0.5=0.5459\n",
      "[I 2025-06-12 16:49:47,659] Trial 27 finished with value: 0.5459391853252229 and parameters: {'n_estimators': 1473, 'max_depth': 12, 'learning_rate': 0.009071764613184001, 'subsample': 0.9633836472284151, 'colsample_bytree': 0.7436618712234054, 'colsample_bylevel': 0.7618059580785752, 'colsample_bynode': 0.9084371289858535, 'reg_alpha': 1.4878303528789412e-05, 'reg_lambda': 0.00048276694653757237, 'min_child_weight': 9, 'gamma': 4.540374072792889, 'max_bin': 494}. Best is trial 21 with value: 0.548552577178835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.548553:  29%|‚ñà‚ñà‚ñâ       | 29/100 [11:07<24:57, 21.10s/it, 667.48/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  28: Precision=0.5517 | Recall=0.4654 | F1=0.4849 | F0.5=0.5174\n",
      "[I 2025-06-12 16:50:06,710] Trial 28 finished with value: 0.5173790240844282 and parameters: {'n_estimators': 1810, 'max_depth': 9, 'learning_rate': 0.05674631281846962, 'subsample': 0.8037972054780158, 'colsample_bytree': 0.9316092203838099, 'colsample_bylevel': 0.9967825861452994, 'colsample_bynode': 0.950421444463226, 'reg_alpha': 3.510478039362202e-08, 'reg_lambda': 4.0317641429684866e-05, 'min_child_weight': 10, 'gamma': 4.698973644496409, 'max_bin': 468}. Best is trial 21 with value: 0.548552577178835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.548553:  30%|‚ñà‚ñà‚ñà       | 30/100 [11:42<29:33, 25.34s/it, 702.72/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  29: Precision=0.5378 | Recall=0.4948 | F1=0.5062 | F0.5=0.5220\n",
      "[I 2025-06-12 16:50:41,949] Trial 29 finished with value: 0.522008567305116 and parameters: {'n_estimators': 1177, 'max_depth': 14, 'learning_rate': 0.23309338190056256, 'subsample': 0.826708231624751, 'colsample_bytree': 0.686678017932716, 'colsample_bylevel': 0.6486193718268873, 'colsample_bynode': 0.8669966571256912, 'reg_alpha': 0.05271668899612626, 'reg_lambda': 0.002175253467538975, 'min_child_weight': 8, 'gamma': 0.4325847030953902, 'max_bin': 501}. Best is trial 21 with value: 0.548552577178835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.548553:  31%|‚ñà‚ñà‚ñà       | 31/100 [11:57<25:36, 22.27s/it, 717.84/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  30: Precision=0.5435 | Recall=0.4746 | F1=0.4960 | F0.5=0.5206\n",
      "[I 2025-06-12 16:50:57,067] Trial 30 finished with value: 0.5205584080586 and parameters: {'n_estimators': 1621, 'max_depth': 11, 'learning_rate': 0.0971520598963376, 'subsample': 0.9991831963752388, 'colsample_bytree': 0.8079334980877086, 'colsample_bylevel': 0.6776751690988333, 'colsample_bynode': 0.8127492272052791, 'reg_alpha': 6.63255423505478e-07, 'reg_lambda': 0.014097942328666799, 'min_child_weight': 1, 'gamma': 4.0139049709383885, 'max_bin': 368}. Best is trial 21 with value: 0.548552577178835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.548553:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [12:34<30:17, 26.73s/it, 754.98/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  31: Precision=0.5441 | Recall=0.5680 | F1=0.5507 | F0.5=0.5455\n",
      "[I 2025-06-12 16:51:34,211] Trial 31 finished with value: 0.5454894576348368 and parameters: {'n_estimators': 1507, 'max_depth': 12, 'learning_rate': 0.006122922554948297, 'subsample': 0.9675513355181776, 'colsample_bytree': 0.769121587482435, 'colsample_bylevel': 0.7695920480886287, 'colsample_bynode': 0.9070556888128793, 'reg_alpha': 1.6271967419416928e-05, 'reg_lambda': 0.0005532601126506948, 'min_child_weight': 9, 'gamma': 4.672171775083431, 'max_bin': 495}. Best is trial 21 with value: 0.548552577178835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.555201:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [13:01<29:43, 26.62s/it, 781.33/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  32: Precision=0.5466 | Recall=0.6246 | F1=0.5741 | F0.5=0.5552\n",
      "[I 2025-06-12 16:52:00,559] Trial 32 finished with value: 0.5552006126534292 and parameters: {'n_estimators': 1449, 'max_depth': 12, 'learning_rate': 0.00873136310405449, 'subsample': 0.9320977674696979, 'colsample_bytree': 0.732767891705755, 'colsample_bylevel': 0.6975562954606167, 'colsample_bynode': 0.9743944967971443, 'reg_alpha': 5.8082370616623436e-06, 'reg_lambda': 9.484492734942522, 'min_child_weight': 9, 'gamma': 4.310583941043495, 'max_bin': 493}. Best is trial 32 with value: 0.5552006126534292.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.555201:  34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [13:33<30:59, 28.18s/it, 813.14/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  33: Precision=0.5539 | Recall=0.5042 | F1=0.5160 | F0.5=0.5346\n",
      "[I 2025-06-12 16:52:32,366] Trial 33 finished with value: 0.5346386450855551 and parameters: {'n_estimators': 1369, 'max_depth': 10, 'learning_rate': 0.010856369900076553, 'subsample': 0.9294883624280914, 'colsample_bytree': 0.73001142408621, 'colsample_bylevel': 0.6978180038015371, 'colsample_bynode': 0.9730139774867229, 'reg_alpha': 3.82980766051907e-06, 'reg_lambda': 1.4926197574838971e-06, 'min_child_weight': 10, 'gamma': 3.5692584766977222, 'max_bin': 449}. Best is trial 32 with value: 0.5552006126534292.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.555201:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [16:11<1:12:49, 67.23s/it, 971.49/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  34: Precision=0.5417 | Recall=0.4928 | F1=0.5016 | F0.5=0.5208\n",
      "[I 2025-06-12 16:55:10,714] Trial 34 finished with value: 0.5207622458780856 and parameters: {'n_estimators': 1678, 'max_depth': 14, 'learning_rate': 0.016714859210100973, 'subsample': 0.900248950568752, 'colsample_bytree': 0.682495660155024, 'colsample_bylevel': 0.6577109056745363, 'colsample_bynode': 0.9327276775929254, 'reg_alpha': 3.883588227126541e-08, 'reg_lambda': 5.828138061838733, 'min_child_weight': 9, 'gamma': 0.7525251521966143, 'max_bin': 489}. Best is trial 32 with value: 0.5552006126534292.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.555201:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [16:49<1:02:16, 58.38s/it, 1009.24/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  35: Precision=0.5528 | Recall=0.5212 | F1=0.5278 | F0.5=0.5402\n",
      "[I 2025-06-12 16:55:48,466] Trial 35 finished with value: 0.5401541364012346 and parameters: {'n_estimators': 997, 'max_depth': 13, 'learning_rate': 0.007194204806373379, 'subsample': 0.8686997197483892, 'colsample_bytree': 0.8534198610278271, 'colsample_bylevel': 0.7375296225394153, 'colsample_bynode': 0.9959811761294098, 'reg_alpha': 4.3713173729117694e-07, 'reg_lambda': 2.685820443532729e-07, 'min_child_weight': 10, 'gamma': 4.228788374309182, 'max_bin': 471}. Best is trial 32 with value: 0.5552006126534292.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.555201:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [17:11<50:01, 47.64s/it, 1031.82/3600 seconds]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  36: Precision=0.5484 | Recall=0.5502 | F1=0.5415 | F0.5=0.5437\n",
      "[I 2025-06-12 16:56:11,047] Trial 36 finished with value: 0.5437260312600475 and parameters: {'n_estimators': 1880, 'max_depth': 11, 'learning_rate': 0.013690985284233514, 'subsample': 0.9310004992038493, 'colsample_bytree': 0.7881451951708002, 'colsample_bylevel': 0.6144471317043804, 'colsample_bynode': 0.9685862574916851, 'reg_alpha': 7.175785785228778e-05, 'reg_lambda': 0.004286014700333616, 'min_child_weight': 8, 'gamma': 4.843992743974768, 'max_bin': 330}. Best is trial 32 with value: 0.5552006126534292.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.555201:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [17:24<38:19, 37.08s/it, 1044.27/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  37: Precision=0.5469 | Recall=0.4335 | F1=0.4726 | F0.5=0.5099\n",
      "[I 2025-06-12 16:56:23,492] Trial 37 finished with value: 0.5098607032483572 and parameters: {'n_estimators': 1162, 'max_depth': 8, 'learning_rate': 0.20543273759035127, 'subsample': 0.7723917796530066, 'colsample_bytree': 0.99859276180781, 'colsample_bylevel': 0.7828478752504032, 'colsample_bynode': 0.9400216357620838, 'reg_alpha': 0.0008902626662806477, 'reg_lambda': 2.8517000246986644e-06, 'min_child_weight': 10, 'gamma': 3.852763592516491, 'max_bin': 453}. Best is trial 32 with value: 0.5552006126534292.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.555201:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [17:50<34:16, 33.72s/it, 1070.14/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  38: Precision=0.5449 | Recall=0.5159 | F1=0.5184 | F0.5=0.5308\n",
      "[I 2025-06-12 16:56:49,363] Trial 38 finished with value: 0.5307714536954766 and parameters: {'n_estimators': 1632, 'max_depth': 13, 'learning_rate': 0.033836180036302836, 'subsample': 0.9034131825433949, 'colsample_bytree': 0.7460753126942675, 'colsample_bylevel': 0.8190080137450199, 'colsample_bynode': 0.7595613226127185, 'reg_alpha': 5.337417845144726e-06, 'reg_lambda': 8.329810206868892, 'min_child_weight': 7, 'gamma': 2.839068314132084, 'max_bin': 505}. Best is trial 32 with value: 0.5552006126534292.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.555201:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [17:59<26:33, 26.56s/it, 1079.98/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  39: Precision=0.5441 | Recall=0.4812 | F1=0.5026 | F0.5=0.5242\n",
      "[I 2025-06-12 16:56:59,208] Trial 39 finished with value: 0.5241960470466804 and parameters: {'n_estimators': 207, 'max_depth': 12, 'learning_rate': 0.058426643781786566, 'subsample': 0.9786670061595744, 'colsample_bytree': 0.6412734162299398, 'colsample_bylevel': 0.6422350931437859, 'colsample_bynode': 0.8301017324209057, 'reg_alpha': 4.473261719456614e-08, 'reg_lambda': 6.793989026261535e-08, 'min_child_weight': 9, 'gamma': 1.9475183966457932, 'max_bin': 436}. Best is trial 32 with value: 0.5552006126534292.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [18:08<20:48, 21.16s/it, 1088.54/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  40: Precision=0.5431 | Recall=0.7307 | F1=0.6122 | F0.5=0.5669\n",
      "[I 2025-06-12 16:57:07,761] Trial 40 finished with value: 0.5669392783754172 and parameters: {'n_estimators': 840, 'max_depth': 15, 'learning_rate': 0.02043191222447267, 'subsample': 0.8236533680997633, 'colsample_bytree': 0.8275967238752004, 'colsample_bylevel': 0.7003577776855474, 'colsample_bynode': 0.9798228970498104, 'reg_alpha': 8.055925728983402, 'reg_lambda': 0.03492306849406356, 'min_child_weight': 10, 'gamma': 4.724880250422852, 'max_bin': 272}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [18:21<18:08, 18.76s/it, 1101.71/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  41: Precision=0.5506 | Recall=0.5593 | F1=0.5499 | F0.5=0.5492\n",
      "[I 2025-06-12 16:57:20,937] Trial 41 finished with value: 0.549195179491008 and parameters: {'n_estimators': 852, 'max_depth': 14, 'learning_rate': 0.022580346701738512, 'subsample': 0.9504780349608698, 'colsample_bytree': 0.8342516411267258, 'colsample_bylevel': 0.698175174113169, 'colsample_bynode': 0.9802655133895533, 'reg_alpha': 0.20222378936620905, 'reg_lambda': 0.10098874277389897, 'min_child_weight': 10, 'gamma': 4.796752648919635, 'max_bin': 289}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [18:30<14:58, 15.77s/it, 1110.50/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  42: Precision=0.5452 | Recall=0.6936 | F1=0.6000 | F0.5=0.5639\n",
      "[I 2025-06-12 16:57:29,730] Trial 42 finished with value: 0.5638511358313817 and parameters: {'n_estimators': 886, 'max_depth': 15, 'learning_rate': 0.02242415574450282, 'subsample': 0.6911609123582364, 'colsample_bytree': 0.8280983588787598, 'colsample_bylevel': 0.706139473430074, 'colsample_bynode': 0.6901392596118723, 'reg_alpha': 7.374304467802844, 'reg_lambda': 0.12576626805734917, 'min_child_weight': 10, 'gamma': 4.793727636943884, 'max_bin': 280}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [18:43<14:03, 15.06s/it, 1123.90/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  43: Precision=0.5544 | Recall=0.5752 | F1=0.5527 | F0.5=0.5509\n",
      "[I 2025-06-12 16:57:43,126] Trial 43 finished with value: 0.5509076105686496 and parameters: {'n_estimators': 882, 'max_depth': 15, 'learning_rate': 0.022927948070841274, 'subsample': 0.723400471212121, 'colsample_bytree': 0.8244563609172214, 'colsample_bylevel': 0.7000381289508535, 'colsample_bynode': 0.65760753492754, 'reg_alpha': 1.8164038205858364, 'reg_lambda': 0.05889686605356382, 'min_child_weight': 9, 'gamma': 4.7669834925629875, 'max_bin': 260}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [18:52<12:06, 13.21s/it, 1132.81/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  44: Precision=0.5410 | Recall=0.7239 | F1=0.6105 | F0.5=0.5654\n",
      "[I 2025-06-12 16:57:52,039] Trial 44 finished with value: 0.5653566147423431 and parameters: {'n_estimators': 870, 'max_depth': 15, 'learning_rate': 0.021244488098939363, 'subsample': 0.7059943781510246, 'colsample_bytree': 0.8241554450952232, 'colsample_bylevel': 0.7323314422351025, 'colsample_bynode': 0.6869595149770259, 'reg_alpha': 9.78210161373937, 'reg_lambda': 0.04792958864303784, 'min_child_weight': 9, 'gamma': 4.716585262981551, 'max_bin': 259}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [19:01<10:43, 11.91s/it, 1141.68/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  45: Precision=0.5413 | Recall=0.7263 | F1=0.6096 | F0.5=0.5649\n",
      "[I 2025-06-12 16:58:00,910] Trial 45 finished with value: 0.5648841443057494 and parameters: {'n_estimators': 665, 'max_depth': 15, 'learning_rate': 0.014226907405063946, 'subsample': 0.7021127353090769, 'colsample_bytree': 0.8188324671646067, 'colsample_bylevel': 0.7292714963802476, 'colsample_bynode': 0.7061574989222553, 'reg_alpha': 9.432601500264772, 'reg_lambda': 0.3795814473566724, 'min_child_weight': 9, 'gamma': 4.062505106079209, 'max_bin': 262}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [19:19<12:06, 13.71s/it, 1159.60/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  46: Precision=0.5525 | Recall=0.6034 | F1=0.5653 | F0.5=0.5543\n",
      "[I 2025-06-12 16:58:18,824] Trial 46 finished with value: 0.5542876824149888 and parameters: {'n_estimators': 676, 'max_depth': 15, 'learning_rate': 0.014133445245702246, 'subsample': 0.6072984616700416, 'colsample_bytree': 0.8882142178873919, 'colsample_bylevel': 0.7344307361167912, 'colsample_bynode': 0.7024844799072428, 'reg_alpha': 2.862834357957118, 'reg_lambda': 0.701880222024633, 'min_child_weight': 8, 'gamma': 3.957208372260329, 'max_bin': 286}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [19:28<10:32, 12.16s/it, 1168.13/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  47: Precision=0.5407 | Recall=0.7457 | F1=0.6155 | F0.5=0.5664\n",
      "[I 2025-06-12 16:58:27,362] Trial 47 finished with value: 0.5664400329994079 and parameters: {'n_estimators': 517, 'max_depth': 15, 'learning_rate': 0.009698747449097137, 'subsample': 0.6716198661529343, 'colsample_bytree': 0.8064353497672334, 'colsample_bylevel': 0.8036678889695075, 'colsample_bynode': 0.6938615949676818, 'reg_alpha': 8.976487718757294, 'reg_lambda': 2.3662036982925505, 'min_child_weight': 5, 'gamma': 4.24595228764478, 'max_bin': 311}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [20:13<18:46, 22.08s/it, 1213.37/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  48: Precision=0.5398 | Recall=0.6970 | F1=0.5971 | F0.5=0.5589\n",
      "[I 2025-06-12 16:59:12,599] Trial 48 finished with value: 0.5589297188817539 and parameters: {'n_estimators': 456, 'max_depth': 15, 'learning_rate': 0.01083126191845238, 'subsample': 0.6906386730375716, 'colsample_bytree': 0.871661393292218, 'colsample_bylevel': 0.83001985571456, 'colsample_bynode': 0.6890151050216389, 'reg_alpha': 7.974908322350467, 'reg_lambda': 0.31895621117595435, 'min_child_weight': 4, 'gamma': 1.2136197177811725, 'max_bin': 307}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [20:19<14:27, 17.34s/it, 1219.66/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  49: Precision=0.5431 | Recall=0.7188 | F1=0.6056 | F0.5=0.5640\n",
      "[I 2025-06-12 16:59:18,882] Trial 49 finished with value: 0.5639529787502768 and parameters: {'n_estimators': 539, 'max_depth': 3, 'learning_rate': 0.016946389824819896, 'subsample': 0.6618122305077638, 'colsample_bytree': 0.8090887993990578, 'colsample_bylevel': 0.798876907480499, 'colsample_bynode': 0.603683842837081, 'reg_alpha': 9.00226940838694, 'reg_lambda': 2.377925559907176, 'min_child_weight': 5, 'gamma': 3.708185549781133, 'max_bin': 257}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [20:28<12:03, 14.76s/it, 1228.39/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  50: Precision=0.5547 | Recall=0.5314 | F1=0.5353 | F0.5=0.5449\n",
      "[I 2025-06-12 16:59:27,614] Trial 50 finished with value: 0.5449283217782025 and parameters: {'n_estimators': 482, 'max_depth': 3, 'learning_rate': 0.014560240350811526, 'subsample': 0.642522873552565, 'colsample_bytree': 0.813328150217118, 'colsample_bylevel': 0.8598979651236012, 'colsample_bynode': 0.6008557500480102, 'reg_alpha': 0.8763341959705299, 'reg_lambda': 2.0325516047570025, 'min_child_weight': 5, 'gamma': 3.632081375831139, 'max_bin': 257}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [20:36<10:13, 12.79s/it, 1236.57/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  51: Precision=0.5425 | Recall=0.7274 | F1=0.6114 | F0.5=0.5664\n",
      "[I 2025-06-12 16:59:35,793] Trial 51 finished with value: 0.5663615542996865 and parameters: {'n_estimators': 632, 'max_depth': 6, 'learning_rate': 0.017367847148111418, 'subsample': 0.6875379713875098, 'colsample_bytree': 0.8332249419060557, 'colsample_bylevel': 0.7833557810617584, 'colsample_bynode': 0.6286376342413328, 'reg_alpha': 9.623143263496713, 'reg_lambda': 0.028527056497026974, 'min_child_weight': 5, 'gamma': 4.113798034457957, 'max_bin': 278}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [20:51<10:38, 13.58s/it, 1251.99/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  52: Precision=0.5446 | Recall=0.6619 | F1=0.5879 | F0.5=0.5590\n",
      "[I 2025-06-12 16:59:51,221] Trial 52 finished with value: 0.5589629141206515 and parameters: {'n_estimators': 724, 'max_depth': 5, 'learning_rate': 0.008612501152140958, 'subsample': 0.655644642528382, 'colsample_bytree': 0.7929241468680688, 'colsample_bylevel': 0.8043073638777856, 'colsample_bynode': 0.6341796547970331, 'reg_alpha': 3.6597558802587886, 'reg_lambda': 0.02845016096301351, 'min_child_weight': 4, 'gamma': 3.878391264901164, 'max_bin': 302}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [21:02<09:45, 12.72s/it, 1262.71/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  53: Precision=0.5518 | Recall=0.4793 | F1=0.4990 | F0.5=0.5258\n",
      "[I 2025-06-12 17:00:01,933] Trial 53 finished with value: 0.5257793422030059 and parameters: {'n_estimators': 591, 'max_depth': 4, 'learning_rate': 0.017258487657327543, 'subsample': 0.7680607030406901, 'colsample_bytree': 0.8094265342531655, 'colsample_bylevel': 0.7793583980593284, 'colsample_bynode': 0.6655639021633464, 'reg_alpha': 0.32819838802341034, 'reg_lambda': 1.8218462587095, 'min_child_weight': 5, 'gamma': 4.095028480168158, 'max_bin': 269}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [21:08<08:03, 10.74s/it, 1268.83/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  54: Precision=0.5412 | Recall=0.7379 | F1=0.6130 | F0.5=0.5658\n",
      "[I 2025-06-12 17:00:08,058] Trial 54 finished with value: 0.5658367166253966 and parameters: {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.011690816776238407, 'subsample': 0.686135732186061, 'colsample_bytree': 0.8405831400240064, 'colsample_bylevel': 0.8395251497859955, 'colsample_bynode': 0.6208036507335115, 'reg_alpha': 9.77146610577662, 'reg_lambda': 0.3546789848744898, 'min_child_weight': 6, 'gamma': 3.3323541118341278, 'max_bin': 321}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [21:26<09:19, 12.72s/it, 1286.17/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  55: Precision=0.5518 | Recall=0.5454 | F1=0.5386 | F0.5=0.5437\n",
      "[I 2025-06-12 17:00:25,402] Trial 55 finished with value: 0.5436764668961029 and parameters: {'n_estimators': 323, 'max_depth': 6, 'learning_rate': 0.011986572129781034, 'subsample': 0.7438578170204345, 'colsample_bytree': 0.837572863665288, 'colsample_bylevel': 0.8375241111504225, 'colsample_bynode': 0.7160686919108952, 'reg_alpha': 0.9972850658361334, 'reg_lambda': 0.3938975329452677, 'min_child_weight': 6, 'gamma': 2.246105363643599, 'max_bin': 321}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [21:55<12:43, 17.76s/it, 1315.69/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  56: Precision=0.5456 | Recall=0.6376 | F1=0.5773 | F0.5=0.5551\n",
      "[I 2025-06-12 17:00:54,922] Trial 56 finished with value: 0.5551272735938346 and parameters: {'n_estimators': 771, 'max_depth': 6, 'learning_rate': 0.005069021866570534, 'subsample': 0.6870407586898644, 'colsample_bytree': 0.8683196900141187, 'colsample_bylevel': 0.8684504603121886, 'colsample_bynode': 0.6263400993743132, 'reg_alpha': 3.197803546561169, 'reg_lambda': 0.011425614416277234, 'min_child_weight': 6, 'gamma': 3.0156718947533054, 'max_bin': 271}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [22:19<13:46, 19.67s/it, 1339.81/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  57: Precision=0.5519 | Recall=0.5288 | F1=0.5304 | F0.5=0.5405\n",
      "[I 2025-06-12 17:01:19,041] Trial 57 finished with value: 0.540461581838915 and parameters: {'n_estimators': 363, 'max_depth': 7, 'learning_rate': 0.007140510415470529, 'subsample': 0.7142766882429444, 'colsample_bytree': 0.9053110929024253, 'colsample_bylevel': 0.9100021705865327, 'colsample_bynode': 0.7773513756257858, 'reg_alpha': 0.07330729599295786, 'reg_lambda': 0.03696246277934606, 'min_child_weight': 7, 'gamma': 3.3751064026001827, 'max_bin': 297}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [22:39<13:32, 19.82s/it, 1359.97/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  58: Precision=0.5495 | Recall=0.4842 | F1=0.5061 | F0.5=0.5291\n",
      "[I 2025-06-12 17:01:39,198] Trial 58 finished with value: 0.5291426289875458 and parameters: {'n_estimators': 624, 'max_depth': 14, 'learning_rate': 0.020003279627052943, 'subsample': 0.6361622901501066, 'colsample_bytree': 0.842299993121889, 'colsample_bylevel': 0.836335647824599, 'colsample_bynode': 0.6755986460539962, 'reg_alpha': 0.47757492039361027, 'reg_lambda': 0.255777806726902, 'min_child_weight': 3, 'gamma': 4.393762054627373, 'max_bin': 314}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [22:47<10:48, 16.21s/it, 1367.78/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  59: Precision=0.5426 | Recall=0.7313 | F1=0.6088 | F0.5=0.5644\n",
      "[I 2025-06-12 17:01:47,003] Trial 59 finished with value: 0.5644482922549396 and parameters: {'n_estimators': 390, 'max_depth': 5, 'learning_rate': 0.009775364400355372, 'subsample': 0.8243304073291431, 'colsample_bytree': 0.7832574604629221, 'colsample_bylevel': 0.7448011823062505, 'colsample_bynode': 0.6425693192363874, 'reg_alpha': 4.543497549385998, 'reg_lambda': 0.6263569502413858, 'min_child_weight': 4, 'gamma': 4.18315923460196, 'max_bin': 346}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [23:01<10:06, 15.56s/it, 1381.81/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  60: Precision=0.5536 | Recall=0.4924 | F1=0.5136 | F0.5=0.5350\n",
      "[I 2025-06-12 17:02:01,040] Trial 60 finished with value: 0.5350053810522475 and parameters: {'n_estimators': 776, 'max_depth': 14, 'learning_rate': 0.02817280780291455, 'subsample': 0.6176965658094818, 'colsample_bytree': 0.8592774267970308, 'colsample_bylevel': 0.8180499053844527, 'colsample_bynode': 0.7316185691455833, 'reg_alpha': 1.095691654380794, 'reg_lambda': 0.006541856402629387, 'min_child_weight': 3, 'gamma': 4.989128429202502, 'max_bin': 280}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [23:09<08:25, 13.30s/it, 1389.84/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  61: Precision=0.5418 | Recall=0.7297 | F1=0.6112 | F0.5=0.5656\n",
      "[I 2025-06-12 17:02:09,063] Trial 61 finished with value: 0.5655874297408052 and parameters: {'n_estimators': 377, 'max_depth': 5, 'learning_rate': 0.010517814448258648, 'subsample': 0.7891959173838455, 'colsample_bytree': 0.7830252838578002, 'colsample_bylevel': 0.7911265195999753, 'colsample_bynode': 0.6429027657235413, 'reg_alpha': 4.158188519569336, 'reg_lambda': 0.6055839284622404, 'min_child_weight': 4, 'gamma': 4.206528257484835, 'max_bin': 340}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.566939:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [23:15<06:45, 10.97s/it, 1395.37/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  62: Precision=0.5480 | Recall=0.6411 | F1=0.5793 | F0.5=0.5572\n",
      "[I 2025-06-12 17:02:14,599] Trial 62 finished with value: 0.5572245560417434 and parameters: {'n_estimators': 290, 'max_depth': 4, 'learning_rate': 0.013354925251304198, 'subsample': 0.7869376836255098, 'colsample_bytree': 0.7529858214870782, 'colsample_bylevel': 0.7943229611631358, 'colsample_bynode': 0.6241253959176524, 'reg_alpha': 1.9931675502455484, 'reg_lambda': 0.9787682560882556, 'min_child_weight': 5, 'gamma': 4.577426678790172, 'max_bin': 330}. Best is trial 40 with value: 0.5669392783754172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [23:20<05:27,  9.10s/it, 1400.12/3600 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  63: Precision=0.5300 | Recall=0.8631 | F1=0.6518 | F0.5=0.5721\n",
      "[I 2025-06-12 17:02:19,347] Trial 63 finished with value: 0.5721398499838035 and parameters: {'n_estimators': 107, 'max_depth': 7, 'learning_rate': 0.007331979140441173, 'subsample': 0.6772174715021827, 'colsample_bytree': 0.8238805270933549, 'colsample_bylevel': 0.7730466620963483, 'colsample_bynode': 0.6682429822080043, 'reg_alpha': 5.409756188443174, 'reg_lambda': 0.0015524839266472987, 'min_child_weight': 6, 'gamma': 3.7995867106505936, 'max_bin': 365}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [23:25<04:40,  8.02s/it, 1405.62/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  64: Precision=0.5298 | Recall=0.8587 | F1=0.6500 | F0.5=0.5713\n",
      "[I 2025-06-12 17:02:24,850] Trial 64 finished with value: 0.5713058074611598 and parameters: {'n_estimators': 108, 'max_depth': 7, 'learning_rate': 0.0066794167205587104, 'subsample': 0.737550087542863, 'colsample_bytree': 0.7992992236693026, 'colsample_bylevel': 0.7755131010391862, 'colsample_bynode': 0.6473220990954631, 'reg_alpha': 4.449985680189529, 'reg_lambda': 0.0021333140223222364, 'min_child_weight': 6, 'gamma': 3.723859908980194, 'max_bin': 371}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [23:33<04:33,  8.05s/it, 1413.73/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  65: Precision=0.5376 | Recall=0.7546 | F1=0.6199 | F0.5=0.5662\n",
      "[I 2025-06-12 17:02:32,956] Trial 65 finished with value: 0.5662387176069805 and parameters: {'n_estimators': 111, 'max_depth': 7, 'learning_rate': 0.0073624529921689835, 'subsample': 0.7404910134245158, 'colsample_bytree': 0.8004739618785089, 'colsample_bylevel': 0.7690636414977658, 'colsample_bynode': 0.6485146319224603, 'reg_alpha': 0.49874457079229745, 'reg_lambda': 0.0034426057433537363, 'min_child_weight': 6, 'gamma': 3.7849892641563962, 'max_bin': 363}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [23:41<04:24,  8.02s/it, 1421.69/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  66: Precision=0.5353 | Recall=0.8068 | F1=0.6338 | F0.5=0.5689\n",
      "[I 2025-06-12 17:02:40,921] Trial 66 finished with value: 0.5689209648499247 and parameters: {'n_estimators': 102, 'max_depth': 7, 'learning_rate': 0.0065611336060062584, 'subsample': 0.7491646318181401, 'colsample_bytree': 0.7970746741721549, 'colsample_bylevel': 0.7709344929981289, 'colsample_bynode': 0.6181513825001085, 'reg_alpha': 0.3974712349795693, 'reg_lambda': 0.0015027899291334098, 'min_child_weight': 6, 'gamma': 3.402529771507778, 'max_bin': 362}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [23:49<04:10,  7.84s/it, 1429.10/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  67: Precision=0.5387 | Recall=0.7668 | F1=0.6241 | F0.5=0.5682\n",
      "[I 2025-06-12 17:02:48,323] Trial 67 finished with value: 0.5681774779073939 and parameters: {'n_estimators': 102, 'max_depth': 7, 'learning_rate': 0.007172076306665514, 'subsample': 0.7515275789431708, 'colsample_bytree': 0.7647437351040504, 'colsample_bylevel': 0.7720443152624298, 'colsample_bynode': 0.6654703681027022, 'reg_alpha': 0.01754464011021682, 'reg_lambda': 0.0012142274242723857, 'min_child_weight': 6, 'gamma': 3.742219382142196, 'max_bin': 357}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [24:00<04:33,  8.83s/it, 1440.25/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  68: Precision=0.5416 | Recall=0.7159 | F1=0.6082 | F0.5=0.5646\n",
      "[I 2025-06-12 17:02:59,481] Trial 68 finished with value: 0.5645959677754975 and parameters: {'n_estimators': 153, 'max_depth': 7, 'learning_rate': 0.00619102695105551, 'subsample': 0.7520804756449335, 'colsample_bytree': 0.7606015294132488, 'colsample_bylevel': 0.7740843836804723, 'colsample_bynode': 0.6752086496477364, 'reg_alpha': 0.009990136604793644, 'reg_lambda': 0.0015090051356874336, 'min_child_weight': 7, 'gamma': 3.124399504679622, 'max_bin': 367}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [24:22<06:29, 12.99s/it, 1462.93/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  69: Precision=0.5430 | Recall=0.6700 | F1=0.5917 | F0.5=0.5596\n",
      "[I 2025-06-12 17:03:22,160] Trial 69 finished with value: 0.5595645206227022 and parameters: {'n_estimators': 247, 'max_depth': 8, 'learning_rate': 0.0054664659925483736, 'subsample': 0.6727607549909511, 'colsample_bytree': 0.768904534474419, 'colsample_bylevel': 0.7556676280914802, 'colsample_bynode': 0.6735030085462365, 'reg_alpha': 0.12391059477228766, 'reg_lambda': 0.00013075893804259157, 'min_child_weight': 5, 'gamma': 3.533661923276618, 'max_bin': 383}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [24:33<05:58, 12.36s/it, 1473.84/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  70: Precision=0.5451 | Recall=0.6529 | F1=0.5874 | F0.5=0.5598\n",
      "[I 2025-06-12 17:03:33,061] Trial 70 finished with value: 0.5597752309336992 and parameters: {'n_estimators': 201, 'max_depth': 6, 'learning_rate': 0.006743843405280725, 'subsample': 0.729772927222651, 'colsample_bytree': 0.7998380702578699, 'colsample_bylevel': 0.8036606392812249, 'colsample_bynode': 0.6150684621409692, 'reg_alpha': 0.029109210488889092, 'reg_lambda': 0.001166374247654865, 'min_child_weight': 6, 'gamma': 3.453863012376693, 'max_bin': 375}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [24:43<05:24, 11.59s/it, 1483.62/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  71: Precision=0.5433 | Recall=0.7112 | F1=0.6049 | F0.5=0.5639\n",
      "[I 2025-06-12 17:03:42,847] Trial 71 finished with value: 0.5639286312950244 and parameters: {'n_estimators': 132, 'max_depth': 7, 'learning_rate': 0.007770752807297915, 'subsample': 0.758108444113857, 'colsample_bytree': 0.8004004944310117, 'colsample_bylevel': 0.7674424364164549, 'colsample_bynode': 0.6540272495085574, 'reg_alpha': 0.444264368365225, 'reg_lambda': 0.0009793343511557574, 'min_child_weight': 6, 'gamma': 3.774868504133222, 'max_bin': 360}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [24:50<04:38, 10.32s/it, 1490.99/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  72: Precision=0.5402 | Recall=0.7823 | F1=0.6279 | F0.5=0.5700\n",
      "[I 2025-06-12 17:03:50,217] Trial 72 finished with value: 0.5700218242504788 and parameters: {'n_estimators': 108, 'max_depth': 7, 'learning_rate': 0.00781380967254776, 'subsample': 0.737234900635758, 'colsample_bytree': 0.782826860309903, 'colsample_bylevel': 0.786336318809147, 'colsample_bynode': 0.6424942503123109, 'reg_alpha': 1.6095062932663466, 'reg_lambda': 0.00025399247146276735, 'min_child_weight': 6, 'gamma': 3.7711714100364158, 'max_bin': 357}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [25:05<05:03, 11.69s/it, 1505.86/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  73: Precision=0.5412 | Recall=0.7545 | F1=0.6199 | F0.5=0.5681\n",
      "[I 2025-06-12 17:04:05,085] Trial 73 finished with value: 0.56812923582838 and parameters: {'n_estimators': 226, 'max_depth': 8, 'learning_rate': 0.00586532580483948, 'subsample': 0.7312554131450413, 'colsample_bytree': 0.7816864261159612, 'colsample_bylevel': 0.7829785345613849, 'colsample_bynode': 0.6388004169465237, 'reg_alpha': 1.7583162558989778, 'reg_lambda': 0.00032272957691361254, 'min_child_weight': 7, 'gamma': 3.9360741683707348, 'max_bin': 399}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [25:18<05:00, 12.01s/it, 1518.62/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  74: Precision=0.5390 | Recall=0.7431 | F1=0.6132 | F0.5=0.5641\n",
      "[I 2025-06-12 17:04:17,845] Trial 74 finished with value: 0.5641492085128752 and parameters: {'n_estimators': 181, 'max_depth': 8, 'learning_rate': 0.006257624591624356, 'subsample': 0.8145259858104379, 'colsample_bytree': 0.7363417409151436, 'colsample_bylevel': 0.8152633240944951, 'colsample_bynode': 0.6368815934906719, 'reg_alpha': 1.5386989471372698, 'reg_lambda': 9.061901213381996e-05, 'min_child_weight': 7, 'gamma': 3.934213083315974, 'max_bin': 400}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [25:35<05:21, 13.40s/it, 1535.28/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  75: Precision=0.5508 | Recall=0.5766 | F1=0.5562 | F0.5=0.5513\n",
      "[I 2025-06-12 17:04:34,507] Trial 75 finished with value: 0.5512930563770864 and parameters: {'n_estimators': 253, 'max_depth': 7, 'learning_rate': 0.008788126559403522, 'subsample': 0.7871109797619362, 'colsample_bytree': 0.7741766727258813, 'colsample_bylevel': 0.7486500073593862, 'colsample_bynode': 0.6615702465068182, 'reg_alpha': 0.22930313338061875, 'reg_lambda': 0.00030762460380887247, 'min_child_weight': 7, 'gamma': 2.916275083184975, 'max_bin': 354}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [25:44<04:37, 12.08s/it, 1544.26/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  76: Precision=0.5263 | Recall=0.8857 | F1=0.6553 | F0.5=0.5706\n",
      "[I 2025-06-12 17:04:43,488] Trial 76 finished with value: 0.5705883117994586 and parameters: {'n_estimators': 105, 'max_depth': 8, 'learning_rate': 0.005040041472632554, 'subsample': 0.7315045755029569, 'colsample_bytree': 0.6978876037786749, 'colsample_bylevel': 0.8270460042189236, 'colsample_bynode': 0.6107312168264377, 'reg_alpha': 2.2521102114594034, 'reg_lambda': 0.00038525640227419795, 'min_child_weight': 6, 'gamma': 3.194247833014993, 'max_bin': 391}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [25:56<04:26, 12.12s/it, 1556.46/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  77: Precision=0.5329 | Recall=0.8376 | F1=0.6423 | F0.5=0.5703\n",
      "[I 2025-06-12 17:04:55,691] Trial 77 finished with value: 0.5702550620857474 and parameters: {'n_estimators': 103, 'max_depth': 9, 'learning_rate': 0.005217000368658448, 'subsample': 0.7308153424745538, 'colsample_bytree': 0.6964248488818299, 'colsample_bylevel': 0.8778333045131583, 'colsample_bynode': 0.6116428797860312, 'reg_alpha': 0.7200783783474446, 'reg_lambda': 0.0002441557634829753, 'min_child_weight': 6, 'gamma': 3.2496190417438267, 'max_bin': 408}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [26:10<04:27, 12.75s/it, 1570.69/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  78: Precision=0.5345 | Recall=0.8109 | F1=0.6330 | F0.5=0.5677\n",
      "[I 2025-06-12 17:05:09,911] Trial 78 finished with value: 0.5677333709938173 and parameters: {'n_estimators': 110, 'max_depth': 9, 'learning_rate': 0.005147213732287396, 'subsample': 0.7309102341491522, 'colsample_bytree': 0.7025410983745406, 'colsample_bylevel': 0.9017299564813295, 'colsample_bynode': 0.607651789069017, 'reg_alpha': 0.10085155033182866, 'reg_lambda': 0.00030364903007859415, 'min_child_weight': 6, 'gamma': 3.13626521932982, 'max_bin': 391}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [26:32<05:10, 15.53s/it, 1592.72/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  79: Precision=0.5435 | Recall=0.6678 | F1=0.5909 | F0.5=0.5596\n",
      "[I 2025-06-12 17:05:31,943] Trial 79 finished with value: 0.5596042024301472 and parameters: {'n_estimators': 251, 'max_depth': 8, 'learning_rate': 0.005806388572372572, 'subsample': 0.7634687370299973, 'colsample_bytree': 0.6293670218177179, 'colsample_bylevel': 0.8753579282888002, 'colsample_bynode': 0.6139287377563791, 'reg_alpha': 0.03076618046917154, 'reg_lambda': 7.177444938085959e-05, 'min_child_weight': 7, 'gamma': 3.2443031519262275, 'max_bin': 412}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [26:45<04:38, 14.64s/it, 1605.27/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  80: Precision=0.5436 | Recall=0.6748 | F1=0.5911 | F0.5=0.5590\n",
      "[I 2025-06-12 17:05:44,496] Trial 80 finished with value: 0.5589683942402066 and parameters: {'n_estimators': 171, 'max_depth': 7, 'learning_rate': 0.008074338981639078, 'subsample': 0.7460117836145307, 'colsample_bytree': 0.6714338435748402, 'colsample_bylevel': 0.8273587242074586, 'colsample_bynode': 0.6332277817413068, 'reg_alpha': 0.7138862492476481, 'reg_lambda': 0.00020243647653576006, 'min_child_weight': 6, 'gamma': 2.779190966094249, 'max_bin': 376}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [26:58<04:17, 14.30s/it, 1618.77/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  81: Precision=0.5331 | Recall=0.8227 | F1=0.6376 | F0.5=0.5688\n",
      "[I 2025-06-12 17:05:57,996] Trial 81 finished with value: 0.5688086434884753 and parameters: {'n_estimators': 106, 'max_depth': 9, 'learning_rate': 0.005227484161252132, 'subsample': 0.7258919806689674, 'colsample_bytree': 0.6979164966188788, 'colsample_bylevel': 0.942680146210864, 'colsample_bynode': 0.6091020576108279, 'reg_alpha': 0.08699160148144208, 'reg_lambda': 0.000298787893149148, 'min_child_weight': 6, 'gamma': 3.1364751233062456, 'max_bin': 391}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [27:09<03:42, 13.11s/it, 1629.12/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  82: Precision=0.5343 | Recall=0.7790 | F1=0.6246 | F0.5=0.5653\n",
      "[I 2025-06-12 17:06:08,351] Trial 82 finished with value: 0.5653496161108882 and parameters: {'n_estimators': 102, 'max_depth': 8, 'learning_rate': 0.006679444069952531, 'subsample': 0.712390960821805, 'colsample_bytree': 0.7058996673609591, 'colsample_bylevel': 0.9430127379623463, 'colsample_bynode': 0.6520306915639065, 'reg_alpha': 0.21051908302032435, 'reg_lambda': 0.0007918614207794981, 'min_child_weight': 6, 'gamma': 2.548983590901411, 'max_bin': 402}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [27:31<04:12, 15.79s/it, 1651.16/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  83: Precision=0.5433 | Recall=0.7076 | F1=0.6039 | F0.5=0.5637\n",
      "[I 2025-06-12 17:06:30,385] Trial 83 finished with value: 0.5637266262641092 and parameters: {'n_estimators': 312, 'max_depth': 9, 'learning_rate': 0.0055748755643001335, 'subsample': 0.7309950557014054, 'colsample_bytree': 0.6939141069413223, 'colsample_bylevel': 0.8493957018574548, 'colsample_bynode': 0.6129659467458368, 'reg_alpha': 2.152363008469773, 'reg_lambda': 2.2274648117999394e-05, 'min_child_weight': 7, 'gamma': 3.4475163912669333, 'max_bin': 409}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [27:45<03:51, 15.41s/it, 1665.68/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  84: Precision=0.5453 | Recall=0.6658 | F1=0.5913 | F0.5=0.5608\n",
      "[I 2025-06-12 17:06:44,909] Trial 84 finished with value: 0.5608466069545672 and parameters: {'n_estimators': 164, 'max_depth': 8, 'learning_rate': 0.0062074983284092404, 'subsample': 0.7373726234208966, 'colsample_bytree': 0.7199068159408657, 'colsample_bylevel': 0.9533477308902301, 'colsample_bynode': 0.6201733167321762, 'reg_alpha': 0.015996197627988425, 'reg_lambda': 0.0017340577735646334, 'min_child_weight': 6, 'gamma': 3.63628750532611, 'max_bin': 419}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [28:14<04:33, 19.52s/it, 1694.80/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  85: Precision=0.5460 | Recall=0.5829 | F1=0.5550 | F0.5=0.5471\n",
      "[I 2025-06-12 17:07:14,023] Trial 85 finished with value: 0.5471093314642397 and parameters: {'n_estimators': 266, 'max_depth': 9, 'learning_rate': 0.00783699728691316, 'subsample': 0.7001126932854694, 'colsample_bytree': 0.6694965917172988, 'colsample_bylevel': 0.9236455598554032, 'colsample_bynode': 0.6008803916574674, 'reg_alpha': 0.054651230830861604, 'reg_lambda': 0.0004135833923362384, 'min_child_weight': 6, 'gamma': 3.0859482161687684, 'max_bin': 395}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [28:43<04:51, 22.39s/it, 1723.86/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  86: Precision=0.5418 | Recall=0.6809 | F1=0.5961 | F0.5=0.5607\n",
      "[I 2025-06-12 17:07:43,091] Trial 86 finished with value: 0.5606827015751454 and parameters: {'n_estimators': 223, 'max_depth': 10, 'learning_rate': 0.005110078255026986, 'subsample': 0.7774794443432749, 'colsample_bytree': 0.7543572976698932, 'colsample_bylevel': 0.9753860194667788, 'colsample_bynode': 0.6696433322571939, 'reg_alpha': 0.9731815764722512, 'reg_lambda': 0.00020617387348768266, 'min_child_weight': 6, 'gamma': 3.2337234954776455, 'max_bin': 377}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [28:56<03:54, 19.57s/it, 1736.86/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  87: Precision=0.5441 | Recall=0.6595 | F1=0.5869 | F0.5=0.5582\n",
      "[I 2025-06-12 17:07:56,086] Trial 87 finished with value: 0.5582269762219225 and parameters: {'n_estimators': 197, 'max_depth': 7, 'learning_rate': 0.006788461071256822, 'subsample': 0.7562643966709325, 'colsample_bytree': 0.6508587211204147, 'colsample_bylevel': 0.7585192693226235, 'colsample_bynode': 0.6410039003973342, 'reg_alpha': 0.3758289107919516, 'reg_lambda': 0.006382467425317092, 'min_child_weight': 7, 'gamma': 3.5646241748473977, 'max_bin': 353}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [29:09<03:13, 17.59s/it, 1749.83/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  88: Precision=0.5352 | Recall=0.7859 | F1=0.6259 | F0.5=0.5660\n",
      "[I 2025-06-12 17:08:09,061] Trial 88 finished with value: 0.5660283239872204 and parameters: {'n_estimators': 145, 'max_depth': 8, 'learning_rate': 0.0056601968247941455, 'subsample': 0.7241985008238753, 'colsample_bytree': 0.7252400651990734, 'colsample_bylevel': 0.8880556818113331, 'colsample_bynode': 0.6290522273817837, 'reg_alpha': 1.355155175287897, 'reg_lambda': 5.097575069324027e-05, 'min_child_weight': 7, 'gamma': 3.3785056463477083, 'max_bin': 369}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [29:34<03:18, 19.80s/it, 1774.79/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  89: Precision=0.5465 | Recall=0.5740 | F1=0.5507 | F0.5=0.5458\n",
      "[I 2025-06-12 17:08:34,004] Trial 89 finished with value: 0.5458397885585452 and parameters: {'n_estimators': 330, 'max_depth': 9, 'learning_rate': 0.009488453152216553, 'subsample': 0.7117907452286933, 'colsample_bytree': 0.7419356517959415, 'colsample_bylevel': 0.7886302763977028, 'colsample_bynode': 0.6591071212328763, 'reg_alpha': 0.14378886707275348, 'reg_lambda': 0.002680038721509479, 'min_child_weight': 5, 'gamma': 3.750028457534956, 'max_bin': 381}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [29:36<02:10, 14.45s/it, 1776.77/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  90: Precision=0.5329 | Recall=0.5652 | F1=0.5372 | F0.5=0.5310\n",
      "[I 2025-06-12 17:08:35,998] Trial 90 finished with value: 0.5310246107730057 and parameters: {'n_estimators': 107, 'max_depth': 6, 'learning_rate': 0.4598201765055861, 'subsample': 0.7503985211755557, 'colsample_bytree': 0.6107144773304753, 'colsample_bylevel': 0.8090741111144374, 'colsample_bynode': 0.6110417793474496, 'reg_alpha': 4.575297294827003, 'reg_lambda': 2.2311038841268367e-05, 'min_child_weight': 6, 'gamma': 2.958268254002103, 'max_bin': 389}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [29:50<01:53, 14.19s/it, 1790.35/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  91: Precision=0.5359 | Recall=0.8112 | F1=0.6359 | F0.5=0.5701\n",
      "[I 2025-06-12 17:08:49,576] Trial 91 finished with value: 0.5701184082955211 and parameters: {'n_estimators': 105, 'max_depth': 9, 'learning_rate': 0.0052372729339851525, 'subsample': 0.7295474537448517, 'colsample_bytree': 0.7058523287236892, 'colsample_bylevel': 0.920129679865595, 'colsample_bynode': 0.6116007505987826, 'reg_alpha': 0.11131036575761469, 'reg_lambda': 0.000260701250270469, 'min_child_weight': 6, 'gamma': 3.2868843306832023, 'max_bin': 389}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [30:13<01:57, 16.76s/it, 1813.09/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  92: Precision=0.5481 | Recall=0.5923 | F1=0.5623 | F0.5=0.5518\n",
      "[I 2025-06-12 17:09:12,319] Trial 92 finished with value: 0.5518476627283169 and parameters: {'n_estimators': 205, 'max_depth': 9, 'learning_rate': 0.008027008222523993, 'subsample': 0.7374966966585877, 'colsample_bytree': 0.6914063153570438, 'colsample_bylevel': 0.9203814904249713, 'colsample_bynode': 0.6198615367831491, 'reg_alpha': 0.00862770960932679, 'reg_lambda': 0.0006856223470474292, 'min_child_weight': 6, 'gamma': 3.2684001323195178, 'max_bin': 389}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [30:26<01:34, 15.70s/it, 1826.32/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  93: Precision=0.5410 | Recall=0.7110 | F1=0.6043 | F0.5=0.5623\n",
      "[I 2025-06-12 17:09:25,548] Trial 93 finished with value: 0.5622837582646693 and parameters: {'n_estimators': 154, 'max_depth': 8, 'learning_rate': 0.006371932070778363, 'subsample': 0.7183410989572606, 'colsample_bytree': 0.7105956828079266, 'colsample_bylevel': 0.9438290642987534, 'colsample_bynode': 0.6466384047628094, 'reg_alpha': 0.7205148908187297, 'reg_lambda': 0.00017773384923185383, 'min_child_weight': 6, 'gamma': 3.6576064181322763, 'max_bin': 358}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [30:41<01:18, 15.63s/it, 1841.79/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  94: Precision=0.5465 | Recall=0.6502 | F1=0.5853 | F0.5=0.5593\n",
      "[I 2025-06-12 17:09:41,016] Trial 94 finished with value: 0.5592974821733915 and parameters: {'n_estimators': 220, 'max_depth': 7, 'learning_rate': 0.005691074170719727, 'subsample': 0.6980499450579158, 'colsample_bytree': 0.6696279654736272, 'colsample_bylevel': 0.9786085942143193, 'colsample_bynode': 0.633613741498104, 'reg_alpha': 0.26713534218162904, 'reg_lambda': 0.0004890801509238235, 'min_child_weight': 5, 'gamma': 3.942251292077893, 'max_bin': 344}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [30:50<00:54, 13.56s/it, 1850.52/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  95: Precision=0.5319 | Recall=0.8277 | F1=0.6399 | F0.5=0.5691\n",
      "[I 2025-06-12 17:09:49,742] Trial 95 finished with value: 0.5690759698656619 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.007291142246594324, 'subsample': 0.7758788067320281, 'colsample_bytree': 0.6782886057738403, 'colsample_bylevel': 0.7784144729037741, 'colsample_bynode': 0.6070766947124258, 'reg_alpha': 2.44997456833713, 'reg_lambda': 0.0013988695189970095, 'min_child_weight': 6, 'gamma': 3.4633213945843977, 'max_bin': 397}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [31:22<00:57, 19.01s/it, 1882.25/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  96: Precision=0.5463 | Recall=0.5769 | F1=0.5515 | F0.5=0.5456\n",
      "[I 2025-06-12 17:10:21,479] Trial 96 finished with value: 0.5456496563191162 and parameters: {'n_estimators': 290, 'max_depth': 10, 'learning_rate': 0.007198409937701742, 'subsample': 0.7759898558871092, 'colsample_bytree': 0.6991488388076217, 'colsample_bylevel': 0.9328786240516682, 'colsample_bynode': 0.6101570339212133, 'reg_alpha': 0.0756847903181957, 'reg_lambda': 0.0012151226041136754, 'min_child_weight': 6, 'gamma': 3.452916154371, 'max_bin': 417}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [31:33<00:33, 16.80s/it, 1893.88/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  97: Precision=0.5330 | Recall=0.8075 | F1=0.6354 | F0.5=0.5686\n",
      "[I 2025-06-12 17:10:33,109] Trial 97 finished with value: 0.56858117053593 and parameters: {'n_estimators': 102, 'max_depth': 10, 'learning_rate': 0.008346544467976764, 'subsample': 0.7988067642535095, 'colsample_bytree': 0.6559188037799868, 'colsample_bylevel': 0.8897470412091499, 'colsample_bynode': 0.602722670601585, 'reg_alpha': 2.736494576006764, 'reg_lambda': 0.009894033649195952, 'min_child_weight': 5, 'gamma': 2.8168556414134325, 'max_bin': 430}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [31:52<00:17, 17.48s/it, 1912.95/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  98: Precision=0.5334 | Recall=0.8285 | F1=0.6409 | F0.5=0.5704\n",
      "[I 2025-06-12 17:10:52,172] Trial 98 finished with value: 0.5703573703715623 and parameters: {'n_estimators': 153, 'max_depth': 10, 'learning_rate': 0.0050016463516870035, 'subsample': 0.7648437723083729, 'colsample_bytree': 0.6550043886733103, 'colsample_bylevel': 0.8978287244153174, 'colsample_bynode': 0.6006227499667893, 'reg_alpha': 2.5277019263753244, 'reg_lambda': 0.009024542068296396, 'min_child_weight': 5, 'gamma': 2.6021269907013367, 'max_bin': 430}. Best is trial 63 with value: 0.5721398499838035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 63. Best value: 0.57214: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [32:03<00:00, 19.24s/it, 1923.58/3600 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  99: Precision=0.5289 | Recall=0.8594 | F1=0.6506 | F0.5=0.5711\n",
      "[I 2025-06-12 17:11:02,802] Trial 99 finished with value: 0.571062277632939 and parameters: {'n_estimators': 152, 'max_depth': 10, 'learning_rate': 0.005240578329731185, 'subsample': 0.7651730607230356, 'colsample_bytree': 0.6318385953435955, 'colsample_bylevel': 0.916547265646687, 'colsample_bynode': 0.6225529059741628, 'reg_alpha': 6.128116326056999, 'reg_lambda': 0.019433498280224788, 'min_child_weight': 5, 'gamma': 2.424062851363187, 'max_bin': 410}. Best is trial 63 with value: 0.5721398499838035.\n",
      "\\nOptimization completed!\n",
      "Best F0.5 score: 0.572140\n",
      "Best parameters: {'n_estimators': 107, 'max_depth': 7, 'learning_rate': 0.007331979140441173, 'subsample': 0.6772174715021827, 'colsample_bytree': 0.8238805270933549, 'colsample_bylevel': 0.7730466620963483, 'colsample_bynode': 0.6682429822080043, 'reg_alpha': 5.409756188443174, 'reg_lambda': 0.0015524839266472987, 'min_child_weight': 6, 'gamma': 3.7995867106505936, 'max_bin': 365}\n",
      "\\nTraining final model with best F0.5 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n============================================================\n",
      "F0.5-OPTIMIZED MODEL EVALUATION\n",
      "============================================================\n",
      "F0.5-OPTIMIZED METRICS:\n",
      "----------------------------------------\n",
      "Metric       Training     Test         Difference  \n",
      "------------------------------------------------\n",
      "accuracy     0.583203     0.542712     0.040490    \n",
      "precision    0.570573     0.554183     0.016390    \n",
      "recall       0.805865     0.549223     0.256642    \n",
      "f1           0.668108     0.551692     0.116416    \n",
      "f0.5         0.605958     0.553183     0.052774    \n",
      "\\nüéØ KEY METRICS (Test Set):\n",
      "   ‚Ä¢ Precision: 0.554183\n",
      "   ‚Ä¢ F0.5:      0.553183 (precision-weighted)\n",
      "   ‚Ä¢ F1:        0.551692 (balanced)\n",
      "\\nClassification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.53      2021\n",
      "           1       0.55      0.55      0.55      2123\n",
      "\n",
      "    accuracy                           0.54      4144\n",
      "   macro avg       0.54      0.54      0.54      4144\n",
      "weighted avg       0.54      0.54      0.54      4144\n",
      "\n",
      "F0.5-optimized model saved to: xgboost_f05_results\\xgboost_f05_model_20250612_171104.joblib\n",
      "\\n============================================================\n",
      "F0.5 OPTIMIZATION COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "üéØ F0.5-optimized model saved to: xgboost_f05_results\\xgboost_f05_model_20250612_171104.joblib\n",
      "üìã Parameters saved to: xgboost_f05_results\\best_f05_parameters_20250612_171104.txt\n",
      "üèÜ Final Test F0.5: 0.553183\n"
     ]
    }
   ],
   "source": [
    "# Complete XGBoost GPU Optimizer with F0.5 Scoring (Fixed)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, fbeta_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class XGBoostGPUOptimizer:\n",
    "    def __init__(self, data_path, target_column='target', drop_columns=None, \n",
    "                 task_type='auto', test_size=0.2, random_state=42, \n",
    "                 optimization_metric='f0.5', use_gpu=True):\n",
    "        self.data_path = data_path\n",
    "        self.target_column = target_column\n",
    "        self.drop_columns = drop_columns or []\n",
    "        self.task_type = task_type\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.optimization_metric = optimization_metric\n",
    "        self.use_gpu = use_gpu\n",
    "        self.best_params = None\n",
    "        self.best_model = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = None\n",
    "        self._check_gpu_availability()\n",
    "\n",
    "    def _check_gpu_availability(self):\n",
    "        \"\"\"Check if GPU is available for XGBoost\"\"\"\n",
    "        if self.use_gpu:\n",
    "            try:\n",
    "                test_data = xgb.DMatrix(np.random.random((100, 10)), label=np.random.randint(0, 2, 100))\n",
    "                test_params = {'tree_method': 'hist', 'device': 'cuda'}\n",
    "                xgb.train(test_params, test_data, num_boost_round=1, verbose_eval=False)\n",
    "                print(\"‚úÖ GPU acceleration available and enabled!\")\n",
    "                print(f\"   XGBoost version: {xgb.__version__}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  GPU not available, falling back to CPU: {str(e)}\")\n",
    "                self.use_gpu = False\n",
    "        else:\n",
    "            print(\"üñ•Ô∏è  Using CPU-only mode\")\n",
    "\n",
    "    def load_and_preprocess_data(self):\n",
    "        \"\"\"Load and preprocess the dataset\"\"\"\n",
    "        print(\"Loading dataset...\")\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        \n",
    "        # Check if target column exists\n",
    "        if self.target_column not in df.columns:\n",
    "            raise ValueError(f\"Target column '{self.target_column}' not found in dataset\")\n",
    "        \n",
    "        # Separate features and target\n",
    "        y = df[self.target_column].copy()\n",
    "        columns_to_drop = self.drop_columns.copy()\n",
    "        if self.target_column not in columns_to_drop:\n",
    "            columns_to_drop.append(self.target_column)\n",
    "        X = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "        \n",
    "        print(f\"Features shape after dropping columns: {X.shape}\")\n",
    "        \n",
    "        # Handle missing values\n",
    "        for col in X.columns:\n",
    "            if X[col].dtype in ['object', 'category']:\n",
    "                X[col] = X[col].fillna(X[col].mode()[0] if not X[col].mode().empty else 'unknown')\n",
    "            else:\n",
    "                X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "        # Handle target missing values\n",
    "        if y.isnull().sum() > 0:\n",
    "            print(f\"Removing {y.isnull().sum()} rows with missing target values\")\n",
    "            mask = ~y.isnull()\n",
    "            X = X[mask]\n",
    "            y = y[mask]\n",
    "\n",
    "        # Auto-detect task type\n",
    "        if self.task_type == 'auto':\n",
    "            unique_values = len(y.unique())\n",
    "            if unique_values <= 20 and y.dtype in ['int64', 'int32', 'object', 'category']:\n",
    "                self.task_type = 'classification'\n",
    "                print(f\"Auto-detected: Classification ({unique_values} classes)\")\n",
    "            else:\n",
    "                self.task_type = 'regression'\n",
    "                print(f\"Auto-detected: Regression\")\n",
    "\n",
    "        # Encode categorical variables\n",
    "        categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "        if len(categorical_columns) > 0:\n",
    "            print(f\"Encoding categorical columns: {list(categorical_columns)}\")\n",
    "            for col in categorical_columns:\n",
    "                le = LabelEncoder()\n",
    "                X[col] = le.fit_transform(X[col].astype(str))\n",
    "                self.label_encoders[col] = le\n",
    "\n",
    "        # Encode target for classification\n",
    "        if self.task_type == 'classification' and y.dtype == 'object':\n",
    "            le_target = LabelEncoder()\n",
    "            y = le_target.fit_transform(y)\n",
    "            self.label_encoders['target'] = le_target\n",
    "\n",
    "        # Check class distribution\n",
    "        if self.task_type == 'classification':\n",
    "            class_counts = pd.Series(y).value_counts().sort_index()\n",
    "            print(f\"Class distribution: {dict(class_counts)}\")\n",
    "\n",
    "        # Chronological split for time series data\n",
    "        print(\"üïê Using chronological split for time series data...\")\n",
    "        split_idx = int(len(X) * (1 - self.test_size))\n",
    "        \n",
    "        self.X_train = X.iloc[:split_idx].copy()\n",
    "        self.X_test = X.iloc[split_idx:].copy()\n",
    "        self.y_train = y.iloc[:split_idx].copy()\n",
    "        self.y_test = y.iloc[split_idx:].copy()\n",
    "        \n",
    "        print(f\"Training set shape: {self.X_train.shape}\")\n",
    "        print(f\"Test set shape: {self.X_test.shape}\")\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "\n",
    "    def objective(self, trial):\n",
    "        \"\"\"Objective function for Optuna optimization with F0.5 scoring\"\"\"\n",
    "        try:\n",
    "            # Calculate class imbalance ratio (robust calculation)\n",
    "            neg_count = np.sum(self.y_train == 0)\n",
    "            pos_count = np.sum(self.y_train == 1)\n",
    "            pos_ratio = (neg_count + 1e-6) / (pos_count + 1e-6)  # Avoid divide-by-zero\n",
    "\n",
    "            # Binary classification parameters (hardcoded for 0/1 target)\n",
    "            params = {\n",
    "                'objective': 'binary:logistic',\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.5, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0),\n",
    "                'colsample_bynode': trial.suggest_float('colsample_bynode', 0.6, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "                'max_bin': trial.suggest_int('max_bin', 256, 512),\n",
    "                'tree_method': 'hist',\n",
    "                'device': 'cuda' if self.use_gpu else 'cpu',\n",
    "                'random_state': self.random_state,\n",
    "                'verbosity': 0,\n",
    "                'eval_metric': 'logloss'\n",
    "            }\n",
    "\n",
    "            # Add scale_pos_weight for imbalanced data\n",
    "            if pos_ratio > 1.5:\n",
    "                params['scale_pos_weight'] = trial.suggest_float('scale_pos_weight', 1.0, pos_ratio * 2)\n",
    "\n",
    "            # Time series cross-validation\n",
    "            tscv = TimeSeriesSplit(n_splits=5, gap=24)\n",
    "            \n",
    "            precision_scores = []\n",
    "            recall_scores = []\n",
    "            f1_scores = []\n",
    "            fbeta_scores = []\n",
    "            \n",
    "            for fold, (train_idx, val_idx) in enumerate(tscv.split(self.X_train)):\n",
    "                X_tr, X_val = self.X_train.iloc[train_idx], self.X_train.iloc[val_idx]\n",
    "                y_tr, y_val = self.y_train.iloc[train_idx], self.y_train.iloc[val_idx]\n",
    "\n",
    "                # Create and train model\n",
    "                model = xgb.XGBClassifier(**params)\n",
    "                model.fit(X_tr, y_tr, verbose=False)\n",
    "\n",
    "                # Make predictions\n",
    "                y_val_pred = model.predict(X_val)\n",
    "                \n",
    "                # Calculate metrics (binary classification)\n",
    "                fold_precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "                fold_recall = recall_score(y_val, y_val_pred, zero_division=0)\n",
    "                fold_f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
    "                fold_fbeta = fbeta_score(y_val, y_val_pred, beta=0.5, zero_division=0)\n",
    "                \n",
    "                precision_scores.append(fold_precision)\n",
    "                recall_scores.append(fold_recall)\n",
    "                f1_scores.append(fold_f1)\n",
    "                fbeta_scores.append(fold_fbeta)\n",
    "\n",
    "            # Calculate averages\n",
    "            avg_precision = np.mean(precision_scores)\n",
    "            avg_recall = np.mean(recall_scores)\n",
    "            avg_f1 = np.mean(f1_scores)\n",
    "            avg_fbeta = np.mean(fbeta_scores)\n",
    "            \n",
    "            # Print trial results\n",
    "            print(f\"Trial {trial.number:3d}: Precision={avg_precision:.4f} | Recall={avg_recall:.4f} | F1={avg_f1:.4f} | F0.5={avg_fbeta:.4f}\")\n",
    "\n",
    "            # Return optimization metric\n",
    "            if np.isnan(fbeta_scores).any():\n",
    "                return 0.0\n",
    "            return avg_fbeta\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Trial {trial.number} failed with error: {str(e)}\")\n",
    "            return 0.0\n",
    "\n",
    "    def optimize_hyperparameters(self, n_trials=100, timeout=3600):\n",
    "        \"\"\"Optimize hyperparameters using Optuna\"\"\"\n",
    "        print(f\"Starting F0.5-optimized hyperparameter search...\")\n",
    "        print(f\"F0.5 gives 2x weight to precision vs recall - perfect for trading!\")\n",
    "        print(f\"Number of trials: {n_trials}\")\n",
    "        print(f\"Timeout: {timeout} seconds\")\n",
    "        \n",
    "        direction = 'maximize'\n",
    "        study = optuna.create_study(\n",
    "            direction=direction, \n",
    "            sampler=TPESampler(seed=self.random_state),\n",
    "            study_name='xgboost_f05_optimization'\n",
    "        )\n",
    "        \n",
    "        study.optimize(self.objective, n_trials=n_trials, timeout=timeout, show_progress_bar=True)\n",
    "        \n",
    "        self.best_params = study.best_params\n",
    "        print(f\"\\\\nOptimization completed!\")\n",
    "        print(f\"Best F0.5 score: {study.best_value:.6f}\")\n",
    "        print(f\"Best parameters: {self.best_params}\")\n",
    "        \n",
    "        return study\n",
    "\n",
    "    def train_best_model(self):\n",
    "        \"\"\"Train the final model with best parameters\"\"\"\n",
    "        print(\"\\\\nTraining final model with best F0.5 parameters...\")\n",
    "        \n",
    "        # Prepare final parameters (binary classification)\n",
    "        final_params = self.best_params.copy()\n",
    "        final_params.update({\n",
    "            'objective': 'binary:logistic',\n",
    "            'tree_method': 'hist',\n",
    "            'device': 'cuda' if self.use_gpu else 'cpu',\n",
    "            'random_state': self.random_state,\n",
    "            'verbosity': 1\n",
    "        })\n",
    "            \n",
    "        self.best_model = xgb.XGBClassifier(**final_params)\n",
    "        self.best_model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        return self.best_model\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        \"\"\"Evaluate the trained model\"\"\"\n",
    "        if self.best_model is None:\n",
    "            raise ValueError(\"Model not trained yet. Call train_best_model() first.\")\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"F0.5-OPTIMIZED MODEL EVALUATION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = self.best_model.predict(self.X_train)\n",
    "        y_test_pred = self.best_model.predict(self.X_test)\n",
    "        \n",
    "        # Calculate metrics (binary classification - 0/1 only)\n",
    "        train_metrics = {\n",
    "            'accuracy': accuracy_score(self.y_train, y_train_pred),\n",
    "            'precision': precision_score(self.y_train, y_train_pred, zero_division=0),\n",
    "            'recall': recall_score(self.y_train, y_train_pred, zero_division=0),\n",
    "            'f1': f1_score(self.y_train, y_train_pred, zero_division=0),\n",
    "            'f0.5': fbeta_score(self.y_train, y_train_pred, beta=0.5, zero_division=0)\n",
    "        }\n",
    "        \n",
    "        test_metrics = {\n",
    "            'accuracy': accuracy_score(self.y_test, y_test_pred),\n",
    "            'precision': precision_score(self.y_test, y_test_pred, zero_division=0),\n",
    "            'recall': recall_score(self.y_test, y_test_pred, zero_division=0),\n",
    "            'f1': f1_score(self.y_test, y_test_pred, zero_division=0),\n",
    "            'f0.5': fbeta_score(self.y_test, y_test_pred, beta=0.5, zero_division=0)\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        print(\"F0.5-OPTIMIZED METRICS:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"{'Metric':<12} {'Training':<12} {'Test':<12} {'Difference':<12}\")\n",
    "        print(\"-\" * 48)\n",
    "        for metric in ['accuracy', 'precision', 'recall', 'f1', 'f0.5']:\n",
    "            train_val = train_metrics[metric]\n",
    "            test_val = test_metrics[metric]\n",
    "            diff = abs(train_val - test_val)\n",
    "            print(f\"{metric:<12} {train_val:<12.6f} {test_val:<12.6f} {diff:<12.6f}\")\n",
    "        \n",
    "        print(\"\\\\nüéØ KEY METRICS (Test Set):\")\n",
    "        print(f\"   ‚Ä¢ Precision: {test_metrics['precision']:.6f}\")\n",
    "        print(f\"   ‚Ä¢ F0.5:      {test_metrics['f0.5']:.6f} (precision-weighted)\")\n",
    "        print(f\"   ‚Ä¢ F1:        {test_metrics['f1']:.6f} (balanced)\")\n",
    "        \n",
    "        print(\"\\\\nClassification Report (Test Set):\")\n",
    "        print(classification_report(self.y_test, y_test_pred))\n",
    "        \n",
    "        return {'train_metrics': train_metrics, 'test_metrics': test_metrics}\n",
    "\n",
    "    def save_model_and_results(self, save_dir='xgboost_f05_results'):\n",
    "        \"\"\"Save the trained model and results\"\"\"\n",
    "        if self.best_model is None:\n",
    "            raise ValueError(\"Model not trained yet. Call train_best_model() first.\")\n",
    "        \n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save model\n",
    "        model_path = os.path.join(save_dir, f'xgboost_f05_model_{timestamp}.joblib')\n",
    "        joblib.dump(self.best_model, model_path)\n",
    "        print(f\"F0.5-optimized model saved to: {model_path}\")\n",
    "        \n",
    "        # Save parameters\n",
    "        params_path = os.path.join(save_dir, f'best_f05_parameters_{timestamp}.txt')\n",
    "        with open(params_path, 'w') as f:\n",
    "            f.write(f\"Optimization Metric: F0.5 (precision-weighted)\\\\n\")\n",
    "            f.write(f\"GPU Enabled: {self.use_gpu}\\\\n\")\n",
    "            f.write(f\"Best Parameters:\\\\n\")\n",
    "            for key, value in self.best_params.items():\n",
    "                f.write(f\"{key}: {value}\\\\n\")\n",
    "        \n",
    "        return model_path, params_path\n",
    "\n",
    "# Main execution function\n",
    "def main():\n",
    "    \"\"\"Main function to run F0.5 optimization\"\"\"\n",
    "    \n",
    "    DATA_PATH = r\"C:\\\\Users\\\\ADMIN\\\\Desktop\\\\Coding_projects\\\\stock_market_prediction\\\\Stock-Market-Prediction\\\\data\\\\processed\\\\gemini_btc_with_features_4h.csv\"\n",
    "    TARGET_COLUMN = \"target\"\n",
    "    DROP_COLUMNS = [\n",
    "    'open', 'high', 'low',\n",
    "    'high_low', 'high_close', 'low_close', 'typical_price',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3', \n",
    "    'bearish_scenario_6',\n",
    "    'volume_breakout', 'volume_breakdown', \n",
    "    'ema_cross_up', 'ema_cross_down', 'macd_cross_up', 'macd_cross_down',\n",
    "    'trending_market', 'trend_alignment', 'momentum_alignment',\n",
    "  \n",
    "]\n",
    "    \n",
    "    optimizer = XGBoostGPUOptimizer(\n",
    "        data_path=DATA_PATH,\n",
    "        target_column=TARGET_COLUMN,\n",
    "        drop_columns=DROP_COLUMNS,\n",
    "        optimization_metric=\"f0.5\",  # F0.5 gives 2x weight to precision\n",
    "        use_gpu=True\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Load and preprocess data\n",
    "        X_train, X_test, y_train, y_test = optimizer.load_and_preprocess_data()\n",
    "        \n",
    "        # Optimize hyperparameters for F0.5\n",
    "        study = optimizer.optimize_hyperparameters(n_trials=100, timeout=3600)\n",
    "        \n",
    "        # Train best model\n",
    "        best_model = optimizer.train_best_model()\n",
    "        \n",
    "        # Evaluate model\n",
    "        results = optimizer.evaluate_model()\n",
    "        \n",
    "        # Save results\n",
    "        model_path, params_path = optimizer.save_model_and_results()\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"F0.5 OPTIMIZATION COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üéØ F0.5-optimized model saved to: {model_path}\")\n",
    "        print(f\"üìã Parameters saved to: {params_path}\")\n",
    "        print(f\"üèÜ Final Test F0.5: {results['test_metrics']['f0.5']:.6f}\")\n",
    "        \n",
    "        return optimizer, study, results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimizer, study, results = main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41406da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  precision  recall      f1    f0.5     value  n_estimators  \\\n",
      "0      0     0.5372  0.5152  0.5193  0.5282  0.528217         812.0   \n",
      "1      1     0.5404  0.4245  0.4492  0.4907  0.490670        1682.0   \n",
      "2      2     0.5473  0.5291  0.5250  0.5339  0.533852         966.0   \n",
      "3      3     0.5393  0.4882  0.4959  0.5165  0.516514         679.0   \n",
      "4      4     0.5345  0.4684  0.4848  0.5090  0.508954        1139.0   \n",
      "5      5     0.5338  0.5485  0.5292  0.5285  0.528493         838.0   \n",
      "6      6     0.5380  0.4559  0.4752  0.5041  0.504087         110.0   \n",
      "7      7     0.5390  0.4863  0.5025  0.5214  0.521403         691.0   \n",
      "8      8     0.5438  0.4577  0.4754  0.5070  0.507038        1093.0   \n",
      "9      9     0.5524  0.4606  0.4804  0.5125  0.512546         534.0   \n",
      "\n",
      "   max_depth  learning_rate  subsample  colsample_bytree  colsample_bylevel  \\\n",
      "0       15.0       0.145532   0.839463          0.662407           0.662398   \n",
      "1        5.0       0.011551   0.673362          0.721697           0.809903   \n",
      "2       13.0       0.012541   0.805694          0.836966           0.618580   \n",
      "3        4.0       0.116798   0.776061          0.648815           0.798071   \n",
      "4        5.0       0.434650   0.910053          0.975800           0.957931   \n",
      "5        6.0       0.227219   0.742701          0.712374           0.817078   \n",
      "6       13.0       0.129624   0.891603          0.908508           0.629618   \n",
      "7        7.0       0.143940   0.855023          0.954885           0.788886   \n",
      "8        8.0       0.005621   0.643157          0.612572           0.854564   \n",
      "9        4.0       0.018988   0.664489          0.971879           0.923248   \n",
      "\n",
      "   colsample_bynode     reg_alpha    reg_lambda  min_child_weight     gamma  \\\n",
      "0          0.623233  6.245760e-01  2.570604e-03               8.0  0.102922   \n",
      "1          0.772778  4.178903e-06  3.211264e-03               2.0  1.460723   \n",
      "2          0.843018  3.425446e-07  3.850032e-08              10.0  4.828160   \n",
      "3          0.613755  1.527157e+00  2.133142e-06               7.0  1.558555   \n",
      "4          0.839160  1.980925e+00  6.257956e-08               2.0  0.226136   \n",
      "5          0.656370  1.658719e-01  4.687657e-08              10.0  3.861224   \n",
      "6          0.743386  1.103625e-07  5.860448e-01               7.0  1.654490   \n",
      "7          0.647838  2.625446e-02  7.031783e-02               6.0  3.854836   \n",
      "8          0.725742  3.776906e-04  1.472646e+00               3.0  2.051915   \n",
      "9          0.853362  6.968596e-01  1.710207e-01               2.0  4.462795   \n",
      "\n",
      "   max_bin  \n",
      "0    505.0  \n",
      "1    350.0  \n",
      "2    463.0  \n",
      "3    389.0  \n",
      "4    339.0  \n",
      "5    307.0  \n",
      "6    272.0  \n",
      "7    382.0  \n",
      "8    450.0  \n",
      "9    394.0  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def parse_xgboost_output_from_text(output_text):\n",
    "    \"\"\"\n",
    "    Parses Optuna XGBoost log output and returns a DataFrame of trials with metrics and parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Extract trial metrics\n",
    "    trial_pattern = r'Trial\\s+(\\d+):\\s+Precision=([0-9.]+)\\s+\\|\\s+Recall=([0-9.]+)\\s+\\|\\s+F1=([0-9.]+)\\s+\\|\\s+F0\\.5=([0-9.]+)'\n",
    "    trial_matches = re.findall(trial_pattern, output_text)\n",
    "\n",
    "    # Step 2: Extract trial parameters\n",
    "    param_pattern = r'Trial (\\d+) finished with value: ([0-9.]+) and parameters: ({.*?})\\.'\n",
    "    param_matches = re.findall(param_pattern, output_text)\n",
    "\n",
    "    # Step 3: Create DataFrame for metrics\n",
    "    metrics_df = pd.DataFrame(trial_matches, columns=['trial', 'precision', 'recall', 'f1', 'f0.5'])\n",
    "    metrics_df = metrics_df.astype({'trial': int, 'precision': float, 'recall': float, 'f1': float, 'f0.5': float})\n",
    "\n",
    "    # Step 4: Create DataFrame for parameters\n",
    "    param_df = pd.DataFrame(param_matches, columns=['trial', 'value', 'params'])\n",
    "    param_df['trial'] = param_df['trial'].astype(int)\n",
    "    param_df['value'] = param_df['value'].astype(float)\n",
    "    param_df['params'] = param_df['params'].apply(ast.literal_eval)\n",
    "    params_expanded = param_df['params'].apply(pd.Series)\n",
    "\n",
    "    # Step 5: Merge into final DataFrame\n",
    "    final_df = pd.concat([metrics_df.set_index('trial'), param_df.set_index('trial')[['value']], params_expanded], axis=1).reset_index()\n",
    "\n",
    "    return final_df\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Paste your Optuna output here ‚îÄ‚îÄ‚îÄ\n",
    "output_text = \"\"\"\n",
    "[I 2025-06-12 15:01:31,749] A new study created in memory with name: xgboost_f05_optimization\n",
    "‚úÖ GPU acceleration available and enabled!\n",
    "   XGBoost version: 3.0.2\n",
    "Loading dataset...\n",
    "Dataset shape: (20718, 67)\n",
    "Features shape after dropping columns: (20718, 65)\n",
    "Auto-detected: Classification (2 classes)\n",
    "Class distribution: {0: np.int64(9967), 1: np.int64(10751)}\n",
    "üïê Using chronological split for time series data...\n",
    "Training set shape: (16574, 65)\n",
    "Test set shape: (4144, 65)\n",
    "Starting F0.5-optimized hyperparameter search...\n",
    "F0.5 gives 2x weight to precision vs recall - perfect for trading!\n",
    "Number of trials: 100\n",
    "Timeout: 3600 seconds\n",
    "Best trial: 0. Best value: 0.528217:   1%|          | 1/100 [01:10<1:57:07, 70.98s/it, 70.98/3600 seconds]Trial   0: Precision=0.5372 | Recall=0.5152 | F1=0.5193 | F0.5=0.5282\n",
    "[I 2025-06-12 15:02:42,730] Trial 0 finished with value: 0.5282168764196205 and parameters: {'n_estimators': 812, 'max_depth': 15, 'learning_rate': 0.14553179565665345, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'colsample_bylevel': 0.662397808134481, 'colsample_bynode': 0.6232334448672797, 'reg_alpha': 0.6245760287469893, 'reg_lambda': 0.002570603566117598, 'min_child_weight': 8, 'gamma': 0.10292247147901223, 'max_bin': 505}. Best is trial 0 with value: 0.5282168764196205.\n",
    "Best trial: 0. Best value: 0.528217:   2%|‚ñè         | 2/100 [02:15<1:50:04, 67.39s/it, 135.85/3600 seconds]Trial   1: Precision=0.5404 | Recall=0.4245 | F1=0.4492 | F0.5=0.4907\n",
    "[I 2025-06-12 15:03:47,602] Trial 1 finished with value: 0.4906696167401158 and parameters: {'n_estimators': 1682, 'max_depth': 5, 'learning_rate': 0.011551009439226469, 'subsample': 0.6733618039413735, 'colsample_bytree': 0.7216968971838151, 'colsample_bylevel': 0.8099025726528951, 'colsample_bynode': 0.7727780074568463, 'reg_alpha': 4.17890272377219e-06, 'reg_lambda': 0.0032112643094417484, 'min_child_weight': 2, 'gamma': 1.4607232426760908, 'max_bin': 350}. Best is trial 0 with value: 0.5282168764196205.\n",
    "Best trial: 2. Best value: 0.533852:   3%|‚ñé         | 3/100 [02:34<1:12:47, 45.03s/it, 154.27/3600 seconds]Trial   2: Precision=0.5473 | Recall=0.5291 | F1=0.5250 | F0.5=0.5339\n",
    "[I 2025-06-12 15:04:06,022] Trial 2 finished with value: 0.5338518386236022 and parameters: {'n_estimators': 966, 'max_depth': 13, 'learning_rate': 0.01254057843022616, 'subsample': 0.8056937753654446, 'colsample_bytree': 0.836965827544817, 'colsample_bylevel': 0.6185801650879991, 'colsample_bynode': 0.8430179407605753, 'reg_alpha': 3.425445902633376e-07, 'reg_lambda': 3.850031979199519e-08, 'min_child_weight': 10, 'gamma': 4.828160165372797, 'max_bin': 463}. Best is trial 2 with value: 0.5338518386236022.\n",
    "Best trial: 2. Best value: 0.533852:   4%|‚ñç         | 4/100 [02:47<52:07, 32.58s/it, 167.78/3600 seconds]  Trial   3: Precision=0.5393 | Recall=0.4882 | F1=0.4959 | F0.5=0.5165\n",
    "[I 2025-06-12 15:04:19,526] Trial 3 finished with value: 0.5165136478899852 and parameters: {'n_estimators': 679, 'max_depth': 4, 'learning_rate': 0.11679817513130797, 'subsample': 0.7760609974958406, 'colsample_bytree': 0.6488152939379115, 'colsample_bylevel': 0.798070764044508, 'colsample_bynode': 0.6137554084460873, 'reg_alpha': 1.527156759251193, 'reg_lambda': 2.133142332373004e-06, 'min_child_weight': 7, 'gamma': 1.5585553804470549, 'max_bin': 389}. Best is trial 2 with value: 0.5338518386236022.\n",
    "Best trial: 2. Best value: 0.533852:   5%|‚ñå         | 5/100 [03:08<45:00, 28.42s/it, 188.83/3600 seconds]Trial   4: Precision=0.5345 | Recall=0.4684 | F1=0.4848 | F0.5=0.5090\n",
    "[I 2025-06-12 15:04:40,577] Trial 4 finished with value: 0.5089542030513506 and parameters: {'n_estimators': 1139, 'max_depth': 5, 'learning_rate': 0.43464957555697725, 'subsample': 0.9100531293444458, 'colsample_bytree': 0.9757995766256756, 'colsample_bylevel': 0.9579309401710595, 'colsample_bynode': 0.8391599915244341, 'reg_alpha': 1.9809253750493907, 'reg_lambda': 6.257956190096665e-08, 'min_child_weight': 2, 'gamma': 0.22613644455269033, 'max_bin': 339}. Best is trial 2 with value: 0.5338518386236022.\n",
    "Best trial: 2. Best value: 0.533852:   6%|‚ñå         | 6/100 [03:19<34:55, 22.30s/it, 199.23/3600 seconds]Trial   5: Precision=0.5338 | Recall=0.5485 | F1=0.5292 | F0.5=0.5285\n",
    "[I 2025-06-12 15:04:50,978] Trial 5 finished with value: 0.5284929006087904 and parameters: {'n_estimators': 838, 'max_depth': 6, 'learning_rate': 0.22721919801680068, 'subsample': 0.7427013306774357, 'colsample_bytree': 0.7123738038749523, 'colsample_bylevel': 0.8170784332632994, 'colsample_bynode': 0.6563696899899051, 'reg_alpha': 0.16587190283399655, 'reg_lambda': 4.6876566400928895e-08, 'min_child_weight': 10, 'gamma': 3.861223846483287, 'max_bin': 307}. Best is trial 2 with value: 0.5338518386236022.\n",
    "Best trial: 2. Best value: 0.533852:   7%|‚ñã         | 7/100 [03:28<27:48, 17.94s/it, 208.21/3600 seconds]Trial   6: Precision=0.5380 | Recall=0.4559 | F1=0.4752 | F0.5=0.5041\n",
    "[I 2025-06-12 15:04:59,962] Trial 6 finished with value: 0.5040869819365341 and parameters: {'n_estimators': 110, 'max_depth': 13, 'learning_rate': 0.12962378302375793, 'subsample': 0.8916028672163949, 'colsample_bytree': 0.9085081386743783, 'colsample_bylevel': 0.6296178606936361, 'colsample_bynode': 0.7433862914177091, 'reg_alpha': 1.1036250149900698e-07, 'reg_lambda': 0.5860448217200517, 'min_child_weight': 7, 'gamma': 1.654490124263246, 'max_bin': 272}. Best is trial 2 with value: 0.5338518386236022.\n",
    "Best trial: 2. Best value: 0.533852:   8%|‚ñä         | 8/100 [03:35<22:28, 14.66s/it, 215.85/3600 seconds]Trial   7: Precision=0.5390 | Recall=0.4863 | F1=0.5025 | F0.5=0.5214\n",
    "[I 2025-06-12 15:05:07,595] Trial 7 finished with value: 0.5214033346569088 and parameters: {'n_estimators': 691, 'max_depth': 7, 'learning_rate': 0.14394028591544616, 'subsample': 0.8550229885420852, 'colsample_bytree': 0.9548850970305306, 'colsample_bylevel': 0.7888859700647797, 'colsample_bynode': 0.6478376983753207, 'reg_alpha': 0.02625445968759339, 'reg_lambda': 0.0703178263660987, 'min_child_weight': 6, 'gamma': 3.854835899772805, 'max_bin': 382}. Best is trial 2 with value: 0.5338518386236022.\n",
    "Best trial: 2. Best value: 0.533852:   9%|‚ñâ         | 9/100 [05:02<56:21, 37.16s/it, 302.46/3600 seconds]Trial   8: Precision=0.5438 | Recall=0.4577 | F1=0.4754 | F0.5=0.5070\n",
    "[I 2025-06-12 15:06:34,213] Trial 8 finished with value: 0.5070378779378909 and parameters: {'n_estimators': 1093, 'max_depth': 8, 'learning_rate': 0.005620931047896532, 'subsample': 0.6431565707973218, 'colsample_bytree': 0.6125716742746937, 'colsample_bylevel': 0.8545641645055122, 'colsample_bynode': 0.7257423924305306, 'reg_alpha': 0.0003776906385115029, 'reg_lambda': 1.4726456718740824, 'min_child_weight': 3, 'gamma': 2.0519146151781484, 'max_bin': 450}. Best is trial 2 with value: 0.5338518386236022.\n",
    "Best trial: 2. Best value: 0.533852:  10%|‚ñà         | 10/100 [05:12<43:21, 28.91s/it, 312.91/3600 seconds]Trial   9: Precision=0.5524 | Recall=0.4606 | F1=0.4804 | F0.5=0.5125\n",
    "[I 2025-06-12 15:06:44,655] Trial 9 finished with value: 0.5125455497849721 and parameters: {'n_estimators': 534, 'max_depth': 4, 'learning_rate': 0.01898772399339208, 'subsample': 0.6644885149016018, 'colsample_bytree': 0.9718790609370292, 'colsample_bylevel': 0.9232481518257668, 'colsample_bynode': 0.8533615026041694, 'reg_alpha': 0.6968596391373533, 'reg_lambda': 0.1710207048797339, 'min_child_weight': 2, 'gamma': 4.462794992449889, 'max_bin': 394}. Best is trial 2 with value: 0.5338518386236022.\n",
    "Best trial: 10. Best value: 0.547337:  11%|‚ñà         | 11/100 [05:28<36:47, 24.81s/it, 328.42/3600 seconds]Trial  10: Precision=0.5403 | Recall=0.6024 | F1=0.5630 | F0.5=0.5473\n",
    "[I 2025-06-12 15:07:00,167] Trial 10 finished with value: 0.5473365544016147 and parameters: {'n_estimators': 1577, 'max_depth': 11, 'learning_rate': 0.03621799474202486, 'subsample': 0.9729161367647149, 'colsample_bytree': 0.8466707575873181, 'colsample_bylevel': 0.7151465108916805, 'colsample_bynode': 0.9768664324728544, 'reg_alpha': 1.2784194237583953e-08, 'reg_lambda': 1.030757695829262e-05, 'min_child_weight': 10, 'gamma': 4.96202058341917, 'max_bin': 499}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  12%|‚ñà‚ñè        | 12/100 [05:43<32:06, 21.89s/it, 343.63/3600 seconds]Trial  11: Precision=0.5437 | Recall=0.5924 | F1=0.5545 | F0.5=0.5446\n",
    "[I 2025-06-12 15:07:15,376] Trial 11 finished with value: 0.544581718896521 and parameters: {'n_estimators': 1617, 'max_depth': 11, 'learning_rate': 0.044095880367849595, 'subsample': 0.9782637392221827, 'colsample_bytree': 0.8410499373345498, 'colsample_bylevel': 0.6871414335345349, 'colsample_bynode': 0.9801940060533646, 'reg_alpha': 1.0769715790317198e-08, 'reg_lambda': 9.546702333605166e-06, 'min_child_weight': 10, 'gamma': 4.985825626172574, 'max_bin': 500}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  13%|‚ñà‚ñé        | 13/100 [06:03<30:39, 21.14s/it, 363.04/3600 seconds]Trial  12: Precision=0.5493 | Recall=0.5049 | F1=0.5101 | F0.5=0.5274\n",
    "[I 2025-06-12 15:07:34,790] Trial 12 finished with value: 0.5274343020362775 and parameters: {'n_estimators': 1909, 'max_depth': 10, 'learning_rate': 0.04465130455121415, 'subsample': 0.9984066126989742, 'colsample_bytree': 0.8288055772301383, 'colsample_bylevel': 0.708980611666942, 'colsample_bynode': 0.9997449754566204, 'reg_alpha': 1.0509212025163454e-08, 'reg_lambda': 9.658641762306647e-06, 'min_child_weight': 9, 'gamma': 3.210999781834424, 'max_bin': 512}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  14%|‚ñà‚ñç        | 14/100 [06:17<27:18, 19.06s/it, 377.28/3600 seconds]Trial  13: Precision=0.5444 | Recall=0.5470 | F1=0.5362 | F0.5=0.5389\n",
    "[I 2025-06-12 15:07:49,032] Trial 13 finished with value: 0.53892663365751 and parameters: {'n_estimators': 1479, 'max_depth': 10, 'learning_rate': 0.04288073747566629, 'subsample': 0.9984067957444853, 'colsample_bytree': 0.8688373577594762, 'colsample_bylevel': 0.7157541529215599, 'colsample_bynode': 0.992025551184718, 'reg_alpha': 2.0673298327150042e-05, 'reg_lambda': 2.7658555339141567e-05, 'min_child_weight': 4, 'gamma': 4.9863647064750936, 'max_bin': 460}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  15%|‚ñà‚ñå        | 15/100 [06:37<27:17, 19.26s/it, 397.02/3600 seconds]Trial  14: Precision=0.5485 | Recall=0.4860 | F1=0.4993 | F0.5=0.5230\n",
    "[I 2025-06-12 15:08:08,773] Trial 14 finished with value: 0.5230459319406981 and parameters: {'n_estimators': 1448, 'max_depth': 12, 'learning_rate': 0.027967202614255386, 'subsample': 0.9383919204108254, 'colsample_bytree': 0.758730254741415, 'colsample_bylevel': 0.7253702586686225, 'colsample_bynode': 0.9287300763833096, 'reg_alpha': 1.1995224485250402e-08, 'reg_lambda': 0.00013710128828236596, 'min_child_weight': 9, 'gamma': 3.1466433301490775, 'max_bin': 432}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  16%|‚ñà‚ñå        | 16/100 [06:52<25:22, 18.13s/it, 412.52/3600 seconds]Trial  15: Precision=0.5428 | Recall=0.5631 | F1=0.5422 | F0.5=0.5399\n",
    "[I 2025-06-12 15:08:24,264] Trial 15 finished with value: 0.5398786058986382 and parameters: {'n_estimators': 1981, 'max_depth': 11, 'learning_rate': 0.07359536390791321, 'subsample': 0.9438869784567316, 'colsample_bytree': 0.7753801906386225, 'colsample_bylevel': 0.6791639002034141, 'colsample_bynode': 0.9223912814117319, 'reg_alpha': 0.0007136002774640431, 'reg_lambda': 5.560213556234732e-07, 'min_child_weight': 10, 'gamma': 4.458116274002602, 'max_bin': 485}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  17%|‚ñà‚ñã        | 17/100 [07:08<24:11, 17.49s/it, 428.51/3600 seconds]Trial  16: Precision=0.5393 | Recall=0.5149 | F1=0.5156 | F0.5=0.5263\n",
    "[I 2025-06-12 15:08:40,262] Trial 16 finished with value: 0.526272376085853 and parameters: {'n_estimators': 1341, 'max_depth': 15, 'learning_rate': 0.06742959991035824, 'subsample': 0.9610628594861361, 'colsample_bytree': 0.8966022336767454, 'colsample_bylevel': 0.7481435303576582, 'colsample_bynode': 0.9323859666124772, 'reg_alpha': 1.0160476146493027e-06, 'reg_lambda': 0.0003337139522566804, 'min_child_weight': 5, 'gamma': 3.8971410115583933, 'max_bin': 428}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  18%|‚ñà‚ñä        | 18/100 [07:37<28:43, 21.02s/it, 457.75/3600 seconds]Trial  17: Precision=0.5452 | Recall=0.4523 | F1=0.4763 | F0.5=0.5096\n",
    "[I 2025-06-12 15:09:09,499] Trial 17 finished with value: 0.5095628261005162 and parameters: {'n_estimators': 1731, 'max_depth': 9, 'learning_rate': 0.025483359760344625, 'subsample': 0.8879073586015884, 'colsample_bytree': 0.8127450154361803, 'colsample_bylevel': 0.8842800445446883, 'colsample_bynode': 0.8873114092754438, 'reg_alpha': 3.017603616190815e-05, 'reg_lambda': 5.914748802363122e-07, 'min_child_weight': 8, 'gamma': 2.857576680313304, 'max_bin': 488}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  19%|‚ñà‚ñâ        | 19/100 [08:41<45:40, 33.84s/it, 521.46/3600 seconds]Trial  18: Precision=0.5448 | Recall=0.4863 | F1=0.4904 | F0.5=0.5124\n",
    "[I 2025-06-12 15:10:13,206] Trial 18 finished with value: 0.5124194924746497 and parameters: {'n_estimators': 1697, 'max_depth': 13, 'learning_rate': 0.007592065915538492, 'subsample': 0.6002600977282807, 'colsample_bytree': 0.9134822074638909, 'colsample_bylevel': 0.7557750626859493, 'colsample_bynode': 0.9496606563368475, 'reg_alpha': 6.707971818071522e-08, 'reg_lambda': 2.3621183256029898e-05, 'min_child_weight': 8, 'gamma': 4.341541203152221, 'max_bin': 423}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  20%|‚ñà‚ñà        | 20/100 [10:03<1:04:26, 48.33s/it, 603.57/3600 seconds]Trial  19: Precision=0.5442 | Recall=0.4628 | F1=0.4805 | F0.5=0.5097\n",
    "[I 2025-06-12 15:11:35,320] Trial 19 finished with value: 0.5096837499473906 and parameters: {'n_estimators': 1272, 'max_depth': 11, 'learning_rate': 0.030611261293365045, 'subsample': 0.8500867677135329, 'colsample_bytree': 0.7751560679816923, 'colsample_bylevel': 0.6668651828914425, 'colsample_bynode': 0.9720177690526055, 'reg_alpha': 0.003904933417253941, 'reg_lambda': 0.002080158956496785, 'min_child_weight': 9, 'gamma': 0.8217182626308466, 'max_bin': 482}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  21%|‚ñà‚ñà        | 21/100 [10:38<58:18, 44.28s/it, 638.41/3600 seconds]  Trial  20: Precision=0.5482 | Recall=0.4709 | F1=0.4885 | F0.5=0.5169\n",
    "[I 2025-06-12 15:12:10,158] Trial 20 finished with value: 0.5169018493210212 and parameters: {'n_estimators': 1596, 'max_depth': 8, 'learning_rate': 0.015820572538601353, 'subsample': 0.734793733388615, 'colsample_bytree': 0.8528438851069985, 'colsample_bylevel': 0.642926325310971, 'colsample_bynode': 0.8877775341309831, 'reg_alpha': 5.782407074939178e-06, 'reg_lambda': 2.090457364793104e-06, 'min_child_weight': 6, 'gamma': 3.5719975457308593, 'max_bin': 405}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  22%|‚ñà‚ñà‚ñè       | 22/100 [10:54<46:36, 35.85s/it, 654.61/3600 seconds]Trial  21: Precision=0.5386 | Recall=0.5667 | F1=0.5477 | F0.5=0.5411\n",
    "[I 2025-06-12 15:12:26,360] Trial 21 finished with value: 0.5411088709011148 and parameters: {'n_estimators': 1969, 'max_depth': 11, 'learning_rate': 0.0786670815913057, 'subsample': 0.9519969561033745, 'colsample_bytree': 0.78886288321171, 'colsample_bylevel': 0.6847908321350772, 'colsample_bynode': 0.906059436409382, 'reg_alpha': 0.000453074267228923, 'reg_lambda': 3.30815919363706e-07, 'min_child_weight': 10, 'gamma': 4.462139633305128, 'max_bin': 483}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  23%|‚ñà‚ñà‚ñé       | 23/100 [11:06<36:48, 28.68s/it, 666.56/3600 seconds]Trial  22: Precision=0.5498 | Recall=0.5588 | F1=0.5403 | F0.5=0.5421\n",
    "[I 2025-06-12 15:12:38,309] Trial 22 finished with value: 0.5421470924901236 and parameters: {'n_estimators': 1831, 'max_depth': 11, 'learning_rate': 0.07507866094735219, 'subsample': 0.9696966367938468, 'colsample_bytree': 0.7989907359530354, 'colsample_bylevel': 0.6853431737284235, 'colsample_bynode': 0.9611133759993724, 'reg_alpha': 7.245888910794863e-05, 'reg_lambda': 3.9301089101070274e-07, 'min_child_weight': 10, 'gamma': 4.868860945061802, 'max_bin': 509}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  24%|‚ñà‚ñà‚ñç       | 24/100 [11:20<30:50, 24.35s/it, 680.81/3600 seconds]Trial  23: Precision=0.5416 | Recall=0.5038 | F1=0.5111 | F0.5=0.5258\n",
    "[I 2025-06-12 15:12:52,554] Trial 23 finished with value: 0.5257871624629149 and parameters: {'n_estimators': 1808, 'max_depth': 12, 'learning_rate': 0.05225642525665542, 'subsample': 0.9713172883525554, 'colsample_bytree': 0.7293912040754702, 'colsample_bylevel': 0.6074439390815723, 'colsample_bynode': 0.9670859135474954, 'reg_alpha': 6.536351332688057e-08, 'reg_lambda': 1.0969787584030292e-08, 'min_child_weight': 9, 'gamma': 4.769037323746385, 'max_bin': 511}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  25%|‚ñà‚ñà‚ñå       | 25/100 [11:38<27:59, 22.39s/it, 698.62/3600 seconds]Trial  24: Precision=0.5459 | Recall=0.5022 | F1=0.5114 | F0.5=0.5280\n",
    "[I 2025-06-12 15:13:10,365] Trial 24 finished with value: 0.5280035946623445 and parameters: {'n_estimators': 1527, 'max_depth': 9, 'learning_rate': 0.03240688202945335, 'subsample': 0.9217274210810978, 'colsample_bytree': 0.873655217705636, 'colsample_bylevel': 0.7587693368692674, 'colsample_bynode': 0.9642249587628499, 'reg_alpha': 6.911766308732325e-07, 'reg_lambda': 7.51325578172344e-06, 'min_child_weight': 10, 'gamma': 4.130100765352471, 'max_bin': 459}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  26%|‚ñà‚ñà‚ñå       | 26/100 [11:53<24:42, 20.03s/it, 713.16/3600 seconds]Trial  25: Precision=0.5335 | Recall=0.5565 | F1=0.5408 | F0.5=0.5354\n",
    "[I 2025-06-12 15:13:24,910] Trial 25 finished with value: 0.5354094662995321 and parameters: {'n_estimators': 1809, 'max_depth': 14, 'learning_rate': 0.2487956625088385, 'subsample': 0.9799346657644713, 'colsample_bytree': 0.8135695386643549, 'colsample_bylevel': 0.7058226573957213, 'colsample_bynode': 0.8074879828556969, 'reg_alpha': 0.00758407576318697, 'reg_lambda': 0.0005529213350159316, 'min_child_weight': 7, 'gamma': 4.949306978309823, 'max_bin': 491}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  27%|‚ñà‚ñà‚ñã       | 27/100 [12:10<23:22, 19.21s/it, 730.45/3600 seconds]Trial  26: Precision=0.5436 | Recall=0.4473 | F1=0.4722 | F0.5=0.5062\n",
    "[I 2025-06-12 15:13:42,196] Trial 26 finished with value: 0.5062030473058672 and parameters: {'n_estimators': 1294, 'max_depth': 10, 'learning_rate': 0.09965994888932833, 'subsample': 0.8865939089993788, 'colsample_bytree': 0.9408593022802817, 'colsample_bylevel': 0.6448694721031036, 'colsample_bynode': 0.9986278773908163, 'reg_alpha': 4.053140892519333e-05, 'reg_lambda': 7.805636828283561e-05, 'min_child_weight': 8, 'gamma': 2.373136799007815, 'max_bin': 442}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  28%|‚ñà‚ñà‚ñä       | 28/100 [12:27<22:25, 18.69s/it, 747.91/3600 seconds]Trial  27: Precision=0.5502 | Recall=0.4737 | F1=0.4939 | F0.5=0.5210\n",
    "[I 2025-06-12 15:13:59,659] Trial 27 finished with value: 0.5209546763451132 and parameters: {'n_estimators': 1604, 'max_depth': 12, 'learning_rate': 0.05668266011117912, 'subsample': 0.9350736624069932, 'colsample_bytree': 0.7436618712234054, 'colsample_bylevel': 0.7491855852401944, 'colsample_bynode': 0.8767492006301629, 'reg_alpha': 3.442806528643752e-08, 'reg_lambda': 2.0136915328327024e-07, 'min_child_weight': 9, 'gamma': 3.469343482663943, 'max_bin': 471}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  29%|‚ñà‚ñà‚ñâ       | 29/100 [12:41<20:11, 17.07s/it, 761.21/3600 seconds]Trial  28: Precision=0.5461 | Recall=0.5682 | F1=0.5477 | F0.5=0.5439\n",
    "[I 2025-06-12 15:14:12,953] Trial 28 finished with value: 0.543888772853445 and parameters: {'n_estimators': 1350, 'max_depth': 9, 'learning_rate': 0.03788203546967142, 'subsample': 0.9774554920586199, 'colsample_bytree': 0.8773394984414489, 'colsample_bylevel': 0.9967825861452994, 'colsample_bynode': 0.950421444463226, 'reg_alpha': 3.539659322651877e-07, 'reg_lambda': 2.442929840236602e-06, 'min_child_weight': 10, 'gamma': 4.603738622883117, 'max_bin': 498}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  30%|‚ñà‚ñà‚ñà       | 30/100 [13:04<21:56, 18.81s/it, 784.07/3600 seconds]Trial  29: Precision=0.5543 | Recall=0.5116 | F1=0.5195 | F0.5=0.5361\n",
    "[I 2025-06-12 15:14:35,814] Trial 29 finished with value: 0.5361353641563273 and parameters: {'n_estimators': 1364, 'max_depth': 9, 'learning_rate': 0.02109450782917136, 'subsample': 0.826708231624751, 'colsample_bytree': 0.8833522446713408, 'colsample_bylevel': 0.975466640084087, 'colsample_bynode': 0.9292240818671718, 'reg_alpha': 3.11982695395809e-07, 'reg_lambda': 2.7256612087719455e-06, 'min_child_weight': 8, 'gamma': 4.1513711291412285, 'max_bin': 495}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 10. Best value: 0.547337:  31%|‚ñà‚ñà‚ñà       | 31/100 [13:17<19:40, 17.11s/it, 797.23/3600 seconds]Trial  30: Precision=0.5436 | Recall=0.4558 | F1=0.4769 | F0.5=0.5090\n",
    "[I 2025-06-12 15:14:48,984] Trial 30 finished with value: 0.5089636579245829 and parameters: {'n_estimators': 1193, 'max_depth': 8, 'learning_rate': 0.03750337014603532, 'subsample': 0.9124325426089073, 'colsample_bytree': 0.9385310758883566, 'colsample_bylevel': 0.9983673217562125, 'colsample_bynode': 0.8127492272052791, 'reg_alpha': 1.837949035927626e-06, 'reg_lambda': 0.014097942328666799, 'min_child_weight': 1, 'gamma': 4.646888307676538, 'max_bin': 363}. Best is trial 10 with value: 0.5473365544016147.\n",
    "Best trial: 31. Best value: 0.552707:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [13:28<17:34, 15.51s/it, 808.99/3600 seconds]Trial  31: Precision=0.5447 | Recall=0.6198 | F1=0.5712 | F0.5=0.5527\n",
    "[I 2025-06-12 15:15:00,741] Trial 31 finished with value: 0.5527067328903416 and parameters: {'n_estimators': 1816, 'max_depth': 11, 'learning_rate': 0.08318762169400208, 'subsample': 0.9747445700768947, 'colsample_bytree': 0.8482585848849901, 'colsample_bylevel': 0.6921613926016063, 'colsample_bynode': 0.9573872519911131, 'reg_alpha': 2.6597901572703125e-08, 'reg_lambda': 6.018239212121833e-06, 'min_child_weight': 10, 'gamma': 4.92976117882182, 'max_bin': 499}. Best is trial 31 with value: 0.5527067328903416.\n",
    "Best trial: 31. Best value: 0.552707:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [13:38<15:10, 13.60s/it, 818.13/3600 seconds]Trial  32: Precision=0.5449 | Recall=0.5855 | F1=0.5526 | F0.5=0.5446\n",
    "[I 2025-06-12 15:15:09,878] Trial 32 finished with value: 0.5445993469972631 and parameters: {'n_estimators': 1564, 'max_depth': 10, 'learning_rate': 0.21539942941903265, 'subsample': 0.9955538511011638, 'colsample_bytree': 0.8491048368875511, 'colsample_bylevel': 0.8486539439878545, 'colsample_bynode': 0.9779510389196041, 'reg_alpha': 1.756370572997982e-08, 'reg_lambda': 9.484492734942522, 'min_child_weight': 9, 'gamma': 4.206821317280739, 'max_bin': 473}. Best is trial 31 with value: 0.5527067328903416.\n",
    "Best trial: 31. Best value: 0.552707:  34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [13:48<13:52, 12.61s/it, 828.43/3600 seconds]Trial  33: Precision=0.5296 | Recall=0.5087 | F1=0.5111 | F0.5=0.5197\n",
    "[I 2025-06-12 15:15:20,182] Trial 33 finished with value: 0.5197000147396642 and parameters: {'n_estimators': 1629, 'max_depth': 10, 'learning_rate': 0.20438640839132063, 'subsample': 0.9956107313525514, 'colsample_bytree': 0.8449046947308698, 'colsample_bylevel': 0.8317004818792001, 'colsample_bynode': 0.9838788247270579, 'reg_alpha': 2.235553936097401e-08, 'reg_lambda': 5.009653871143045e-05, 'min_child_weight': 9, 'gamma': 4.0193048636901745, 'max_bin': 470}. Best is trial 31 with value: 0.5527067328903416.\n",
    "Best trial: 31. Best value: 0.552707:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [13:57<12:34, 11.61s/it, 837.70/3600 seconds]Trial  34: Precision=0.5367 | Recall=0.5767 | F1=0.5519 | F0.5=0.5417\n",
    "[I 2025-06-12 15:15:29,449] Trial 34 finished with value: 0.5417242206903994 and parameters: {'n_estimators': 1512, 'max_depth': 14, 'learning_rate': 0.4324345944660587, 'subsample': 0.9569206785091909, 'colsample_bytree': 0.8496792540711392, 'colsample_bylevel': 0.7745271327033333, 'colsample_bynode': 0.9062915711506379, 'reg_alpha': 1.6132270277097248e-07, 'reg_lambda': 5.828138061838733, 'min_child_weight': 9, 'gamma': 4.986134336038922, 'max_bin': 467}. Best is trial 31 with value: 0.5527067328903416.\n",
    "Best trial: 31. Best value: 0.552707:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [14:08<12:15, 11.49s/it, 848.93/3600 seconds]Trial  35: Precision=0.5404 | Recall=0.5275 | F1=0.5244 | F0.5=0.5307\n",
    "[I 2025-06-12 15:15:40,677] Trial 35 finished with value: 0.5306682650226393 and parameters: {'n_estimators': 1730, 'max_depth': 12, 'learning_rate': 0.30510248281005314, 'subsample': 0.925598187117271, 'colsample_bytree': 0.8273419933696505, 'colsample_bylevel': 0.8727708047827943, 'colsample_bynode': 0.9582453078299917, 'reg_alpha': 2.4996342977689448e-08, 'reg_lambda': 0.0014181387584406419, 'min_child_weight': 10, 'gamma': 4.345097614994303, 'max_bin': 445}. Best is trial 31 with value: 0.5527067328903416.\n",
    "Best trial: 31. Best value: 0.552707:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [14:16<10:46, 10.25s/it, 856.29/3600 seconds]Trial  36: Precision=0.5400 | Recall=0.5184 | F1=0.5218 | F0.5=0.5308\n",
    "[I 2025-06-12 15:15:48,042] Trial 36 finished with value: 0.5308424300140967 and parameters: {'n_estimators': 993, 'max_depth': 11, 'learning_rate': 0.10076980640753007, 'subsample': 0.8696729696537576, 'colsample_bytree': 0.6840654773930064, 'colsample_bylevel': 0.9100222982935362, 'colsample_bynode': 0.8632032478556128, 'reg_alpha': 7.073631877612704e-06, 'reg_lambda': 1.3506690295628998e-05, 'min_child_weight': 8, 'gamma': 4.687413492163072, 'max_bin': 499}. Best is trial 31 with value: 0.5527067328903416.\n",
    "Best trial: 31. Best value: 0.552707:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [14:30<11:58, 11.59s/it, 870.99/3600 seconds]Trial  37: Precision=0.5408 | Recall=0.4954 | F1=0.5036 | F0.5=0.5209\n",
    "[I 2025-06-12 15:16:02,739] Trial 37 finished with value: 0.5208870316739531 and parameters: {'n_estimators': 1883, 'max_depth': 14, 'learning_rate': 0.17885739375361678, 'subsample': 0.7723917796530066, 'colsample_bytree': 0.99859276180781, 'colsample_bylevel': 0.6601476369750394, 'colsample_bynode': 0.7716634527118463, 'reg_alpha': 9.984837371101858e-08, 'reg_lambda': 0.015972388264823594, 'min_child_weight': 10, 'gamma': 3.5909521249846827, 'max_bin': 476}. Best is trial 31 with value: 0.5527067328903416.\n",
    "Best trial: 31. Best value: 0.552707:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [14:59<17:01, 16.75s/it, 899.80/3600 seconds]Trial  38: Precision=0.5494 | Recall=0.5091 | F1=0.5137 | F0.5=0.5302\n",
    "[I 2025-06-12 15:16:31,545] Trial 38 finished with value: 0.5302432748852364 and parameters: {'n_estimators': 1457, 'max_depth': 13, 'learning_rate': 0.010717398857983153, 'subsample': 0.9004672217949161, 'colsample_bytree': 0.9167208936736448, 'colsample_bylevel': 0.8241193354060564, 'colsample_bynode': 0.9115577472259978, 'reg_alpha': 2.2727839333244235e-06, 'reg_lambda': 0.00014484609672855704, 'min_child_weight': 7, 'gamma': 4.185667811658899, 'max_bin': 334}. Best is trial 31 with value: 0.5527067328903416.\n",
    "Best trial: 31. Best value: 0.552707:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [15:09<14:30, 14.52s/it, 909.09/3600 seconds]Trial  39: Precision=0.5395 | Recall=0.4652 | F1=0.4826 | F0.5=0.5098\n",
    "[I 2025-06-12 15:16:40,841] Trial 39 finished with value: 0.5098054231526453 and parameters: {'n_estimators': 207, 'max_depth': 7, 'learning_rate': 0.09946006792980613, 'subsample': 0.8232008317712567, 'colsample_bytree': 0.8608025974186068, 'colsample_bylevel': 0.7926972808404957, 'colsample_bynode': 0.9420681344891177, 'reg_alpha': 3.2702008178588526e-08, 'reg_lambda': 5.280339766413153e-06, 'min_child_weight': 9, 'gamma': 0.7561010317095747, 'max_bin': 295}. Best is trial 31 with value: 0.5527067328903416.\n",
    "Best trial: 40. Best value: 0.565769:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [15:14<11:41, 11.88s/it, 914.84/3600 seconds]Trial  40: Precision=0.5394 | Recall=0.7433 | F1=0.6154 | F0.5=0.5658\n",
    "[I 2025-06-12 15:16:46,587] Trial 40 finished with value: 0.5657686140401919 and parameters: {'n_estimators': 840, 'max_depth': 10, 'learning_rate': 0.1622554136888379, 'subsample': 0.9473268865480898, 'colsample_bytree': 0.8173638013273287, 'colsample_bylevel': 0.7346008391077865, 'colsample_bynode': 0.9761007246217213, 'reg_alpha': 8.055925728983402, 'reg_lambda': 9.172233584927825e-08, 'min_child_weight': 10, 'gamma': 4.677404011585716, 'max_bin': 454}. Best is trial 40 with value: 0.5657686140401919.\n",
    "Best trial: 40. Best value: 0.565769:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [15:20<09:42, 10.05s/it, 920.60/3600 seconds]Trial  41: Precision=0.5408 | Recall=0.5778 | F1=0.5460 | F0.5=0.5395\n",
    "[I 2025-06-12 15:16:52,348] Trial 41 finished with value: 0.5395409417292515 and parameters: {'n_estimators': 852, 'max_depth': 10, 'learning_rate': 0.16546978833462303, 'subsample': 0.9843116279426305, 'colsample_bytree': 0.8240668898146918, 'colsample_bylevel': 0.7309416702703986, 'colsample_bynode': 0.9793463400898459, 'reg_alpha': 0.15497359707933334, 'reg_lambda': 1.4272202783968739e-08, 'min_child_weight': 10, 'gamma': 4.677569127454802, 'max_bin': 453}. Best is trial 40 with value: 0.5657686140401919.\n",
    "Best trial: 42. Best value: 0.56723:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [15:23<07:33,  7.96s/it, 923.70/3600 seconds] Trial  42: Precision=0.5376 | Recall=0.7619 | F1=0.6222 | F0.5=0.5672\n",
    "[I 2025-06-12 15:16:55,452] Trial 42 finished with value: 0.5672303869029487 and parameters: {'n_estimators': 544, 'max_depth': 10, 'learning_rate': 0.2938582603380786, 'subsample': 0.9552911410477546, 'colsample_bytree': 0.7991091655074166, 'colsample_bylevel': 0.7747986866913422, 'colsample_bynode': 0.6901392596118723, 'reg_alpha': 7.615371465435688, 'reg_lambda': 3.675517635889162e-08, 'min_child_weight': 10, 'gamma': 4.986366774672873, 'max_bin': 414}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [15:26<06:04,  6.51s/it, 926.81/3600 seconds]Trial  43: Precision=0.5439 | Recall=0.5473 | F1=0.5364 | F0.5=0.5377\n",
    "[I 2025-06-12 15:16:58,562] Trial 43 finished with value: 0.5377398722831043 and parameters: {'n_estimators': 448, 'max_depth': 10, 'learning_rate': 0.2926681128379413, 'subsample': 0.9518657738813817, 'colsample_bytree': 0.7931845298036111, 'colsample_bylevel': 0.7746493420757486, 'colsample_bynode': 0.7178476013510283, 'reg_alpha': 3.603227201603901, 'reg_lambda': 9.591274845698437e-08, 'min_child_weight': 9, 'gamma': 4.591640603122615, 'max_bin': 409}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [15:30<05:18,  5.79s/it, 930.94/3600 seconds]Trial  44: Precision=0.5468 | Recall=0.6201 | F1=0.5756 | F0.5=0.5567\n",
    "[I 2025-06-12 15:17:02,690] Trial 44 finished with value: 0.5567005613918015 and parameters: {'n_estimators': 696, 'max_depth': 8, 'learning_rate': 0.33010597254085583, 'subsample': 0.9262491655154511, 'colsample_bytree': 0.8917566000046583, 'colsample_bylevel': 0.733909258546673, 'colsample_bynode': 0.682895035796052, 'reg_alpha': 9.574576055143178, 'reg_lambda': 9.594424392618064e-08, 'min_child_weight': 10, 'gamma': 4.265817347555404, 'max_bin': 377}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [15:34<04:43,  5.25s/it, 934.92/3600 seconds]Trial  45: Precision=0.5375 | Recall=0.7127 | F1=0.6080 | F0.5=0.5629\n",
    "[I 2025-06-12 15:17:06,672] Trial 45 finished with value: 0.562937404049217 and parameters: {'n_estimators': 560, 'max_depth': 7, 'learning_rate': 0.35279038615947583, 'subsample': 0.9200292554553168, 'colsample_bytree': 0.8118712562580529, 'colsample_bylevel': 0.7301305299518506, 'colsample_bynode': 0.6841349510390149, 'reg_alpha': 9.445944973830327, 'reg_lambda': 5.789608807751393e-08, 'min_child_weight': 10, 'gamma': 3.715684095646795, 'max_bin': 371}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [15:39<04:32,  5.14s/it, 939.81/3600 seconds]Trial  46: Precision=0.5444 | Recall=0.4381 | F1=0.4770 | F0.5=0.5125\n",
    "[I 2025-06-12 15:17:11,561] Trial 46 finished with value: 0.5125286232083259 and parameters: {'n_estimators': 638, 'max_depth': 6, 'learning_rate': 0.47152627810536485, 'subsample': 0.9082315792591643, 'colsample_bytree': 0.894520124784577, 'colsample_bylevel': 0.7371893221446915, 'colsample_bynode': 0.6847139327777724, 'reg_alpha': 0.8511929903124492, 'reg_lambda': 4.246135459170971e-08, 'min_child_weight': 10, 'gamma': 3.753447232438254, 'max_bin': 371}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [15:42<03:54,  4.51s/it, 942.86/3600 seconds]Trial  47: Precision=0.5367 | Recall=0.6769 | F1=0.5900 | F0.5=0.5550\n",
    "[I 2025-06-12 15:17:14,608] Trial 47 finished with value: 0.5550462146626065 and parameters: {'n_estimators': 397, 'max_depth': 7, 'learning_rate': 0.3835832313890989, 'subsample': 0.8698614883700949, 'colsample_bytree': 0.7594161287459923, 'colsample_bylevel': 0.7769794342908466, 'colsample_bynode': 0.6291521008583488, 'reg_alpha': 8.97097101146731, 'reg_lambda': 1.1193711565081403e-07, 'min_child_weight': 4, 'gamma': 3.2761879065736563, 'max_bin': 338}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [15:45<03:25,  4.03s/it, 945.75/3600 seconds]Trial  48: Precision=0.5376 | Recall=0.6301 | F1=0.5605 | F0.5=0.5412\n",
    "[I 2025-06-12 15:17:17,494] Trial 48 finished with value: 0.5411880360287091 and parameters: {'n_estimators': 361, 'max_depth': 7, 'learning_rate': 0.3765605797705223, 'subsample': 0.8784224198276637, 'colsample_bytree': 0.6882680221161375, 'colsample_bylevel': 0.8084150039017949, 'colsample_bynode': 0.6289507652659951, 'reg_alpha': 7.975569774526406, 'reg_lambda': 9.068185296577855e-08, 'min_child_weight': 4, 'gamma': 2.952938886659701, 'max_bin': 337}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [15:51<03:48,  4.57s/it, 951.60/3600 seconds]Trial  49: Precision=0.5265 | Recall=0.5138 | F1=0.5087 | F0.5=0.5161\n",
    "[I 2025-06-12 15:17:23,350] Trial 49 finished with value: 0.5161056364919774 and parameters: {'n_estimators': 751, 'max_depth': 3, 'learning_rate': 0.33557275364803973, 'subsample': 0.8699738612508241, 'colsample_bytree': 0.7530917474938356, 'colsample_bylevel': 0.7767688906300976, 'colsample_bynode': 0.6033042870671139, 'reg_alpha': 0.20273854620931753, 'reg_lambda': 2.1112443079069013e-08, 'min_child_weight': 3, 'gamma': 3.218658106879926, 'max_bin': 317}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [15:56<03:43,  4.56s/it, 956.12/3600 seconds]Trial  50: Precision=0.5385 | Recall=0.5653 | F1=0.5447 | F0.5=0.5392\n",
    "[I 2025-06-12 15:17:27,866] Trial 50 finished with value: 0.5391953044786464 and parameters: {'n_estimators': 579, 'max_depth': 6, 'learning_rate': 0.3809549100792258, 'subsample': 0.7926477324599952, 'colsample_bytree': 0.7722180270609523, 'colsample_bylevel': 0.7997699479887511, 'colsample_bynode': 0.6809915376456998, 'reg_alpha': 7.108710255686432, 'reg_lambda': 1.2680926332142704e-07, 'min_child_weight': 5, 'gamma': 3.7976110896978064, 'max_bin': 353}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [16:02<04:05,  5.12s/it, 962.56/3600 seconds]Trial  51: Precision=0.5406 | Recall=0.5187 | F1=0.5182 | F0.5=0.5280\n",
    "[I 2025-06-12 15:17:34,306] Trial 51 finished with value: 0.5280208717463698 and parameters: {'n_estimators': 871, 'max_depth': 7, 'learning_rate': 0.25940108243562443, 'subsample': 0.9311369947846815, 'colsample_bytree': 0.8068672077998378, 'colsample_bylevel': 0.7099095194324501, 'colsample_bynode': 0.6601116122528707, 'reg_alpha': 2.524254653952177, 'reg_lambda': 8.729485642413214e-07, 'min_child_weight': 3, 'gamma': 2.4082120530165265, 'max_bin': 382}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [16:06<03:45,  4.80s/it, 966.61/3600 seconds]Trial  52: Precision=0.5403 | Recall=0.4081 | F1=0.4386 | F0.5=0.4847\n",
    "[I 2025-06-12 15:17:38,363] Trial 52 finished with value: 0.48468267218264066 and parameters: {'n_estimators': 422, 'max_depth': 5, 'learning_rate': 0.1252169766083488, 'subsample': 0.9125189667306356, 'colsample_bytree': 0.7224497019865433, 'colsample_bylevel': 0.76444848561412, 'colsample_bynode': 0.6984761943428841, 'reg_alpha': 0.33363598311290904, 'reg_lambda': 1.9404383059062544e-07, 'min_child_weight': 4, 'gamma': 3.3770684950251764, 'max_bin': 396}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [16:13<04:07,  5.38s/it, 973.36/3600 seconds]Trial  53: Precision=0.5498 | Recall=0.4334 | F1=0.4483 | F0.5=0.4816\n",
    "[I 2025-06-12 15:17:45,107] Trial 53 finished with value: 0.4815502222878437 and parameters: {'n_estimators': 752, 'max_depth': 8, 'learning_rate': 0.1766678428370133, 'subsample': 0.9495646806534406, 'colsample_bytree': 0.7819102939902971, 'colsample_bylevel': 0.738601480744785, 'colsample_bynode': 0.6352149563064649, 'reg_alpha': 0.07464744075638187, 'reg_lambda': 5.0170368669623673e-08, 'min_child_weight': 10, 'gamma': 2.6677489022075704, 'max_bin': 369}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [16:16<03:38,  4.86s/it, 976.98/3600 seconds]Trial  54: Precision=0.5426 | Recall=0.5057 | F1=0.5081 | F0.5=0.5239\n",
    "[I 2025-06-12 15:17:48,728] Trial 54 finished with value: 0.5239218591226606 and parameters: {'n_estimators': 522, 'max_depth': 8, 'learning_rate': 0.2762564614008492, 'subsample': 0.8598055628743251, 'colsample_bytree': 0.8304749504593194, 'colsample_bylevel': 0.7217159790733125, 'colsample_bynode': 0.7288633474138632, 'reg_alpha': 1.1949146122095802, 'reg_lambda': 2.4781183868467153e-08, 'min_child_weight': 6, 'gamma': 4.436170532432055, 'max_bin': 323}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [16:18<02:54,  3.96s/it, 978.86/3600 seconds]Trial  55: Precision=0.5371 | Recall=0.5712 | F1=0.5464 | F0.5=0.5386\n",
    "[I 2025-06-12 15:17:50,613] Trial 55 finished with value: 0.5386374258319301 and parameters: {'n_estimators': 233, 'max_depth': 6, 'learning_rate': 0.4854360429455281, 'subsample': 0.9207783716746454, 'colsample_bytree': 0.755694993636144, 'colsample_bylevel': 0.6994111992122172, 'colsample_bynode': 0.6685653833182013, 'reg_alpha': 3.6365902674819015, 'reg_lambda': 9.991363545182968e-07, 'min_child_weight': 5, 'gamma': 3.997271569061021, 'max_bin': 417}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [16:25<03:23,  4.73s/it, 985.38/3600 seconds]Trial  56: Precision=0.5381 | Recall=0.5220 | F1=0.5231 | F0.5=0.5302\n",
    "[I 2025-06-12 15:17:57,129] Trial 56 finished with value: 0.5302486180397857 and parameters: {'n_estimators': 918, 'max_depth': 9, 'learning_rate': 0.3442551849679718, 'subsample': 0.9027486048174467, 'colsample_bytree': 0.8097123985196139, 'colsample_bylevel': 0.7887100666501069, 'colsample_bynode': 0.6489658621964883, 'reg_alpha': 0.44859572158745464, 'reg_lambda': 3.2649366101547366e-08, 'min_child_weight': 10, 'gamma': 4.32826352652885, 'max_bin': 347}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [16:29<03:09,  4.50s/it, 989.35/3600 seconds]Trial  57: Precision=0.5415 | Recall=0.7033 | F1=0.6004 | F0.5=0.5613\n",
    "[I 2025-06-12 15:18:01,100] Trial 57 finished with value: 0.5613187863011683 and parameters: {'n_estimators': 665, 'max_depth': 7, 'learning_rate': 0.15090934276918974, 'subsample': 0.9341114085284519, 'colsample_bytree': 0.737367722480231, 'colsample_bylevel': 0.6978221650091054, 'colsample_bynode': 0.7550637721766501, 'reg_alpha': 7.779543925433442, 'reg_lambda': 3.2515309670862366e-07, 'min_child_weight': 9, 'gamma': 3.6743644729425684, 'max_bin': 390}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [16:33<03:03,  4.48s/it, 993.78/3600 seconds]Trial  58: Precision=0.5424 | Recall=0.6886 | F1=0.5992 | F0.5=0.5625\n",
    "[I 2025-06-12 15:18:05,527] Trial 58 finished with value: 0.562535297584065 and parameters: {'n_estimators': 633, 'max_depth': 7, 'learning_rate': 0.14233473448533315, 'subsample': 0.9355646972597608, 'colsample_bytree': 0.7001829143651069, 'colsample_bylevel': 0.7435240222651017, 'colsample_bynode': 0.7603883093365176, 'reg_alpha': 9.964976160192634, 'reg_lambda': 2.2832010902834984e-07, 'min_child_weight': 9, 'gamma': 3.6049860378960092, 'max_bin': 381}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [16:40<03:24,  5.12s/it, 1000.41/3600 seconds]Trial  59: Precision=0.5348 | Recall=0.4938 | F1=0.4963 | F0.5=0.5137\n",
    "[I 2025-06-12 15:18:12,155] Trial 59 finished with value: 0.5136577112581783 and parameters: {'n_estimators': 683, 'max_depth': 4, 'learning_rate': 0.1613069710982809, 'subsample': 0.723720478081262, 'colsample_bytree': 0.6131322858908977, 'colsample_bylevel': 0.6632043140093157, 'colsample_bynode': 0.764570283658172, 'reg_alpha': 1.6271540472063692, 'reg_lambda': 2.9493886595101855e-07, 'min_child_weight': 8, 'gamma': 3.60877502993062, 'max_bin': 393}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [16:46<03:26,  5.29s/it, 1006.09/3600 seconds]Trial  60: Precision=0.5433 | Recall=0.6621 | F1=0.5854 | F0.5=0.5568\n",
    "[I 2025-06-12 15:18:17,835] Trial 60 finished with value: 0.556767283942634 and parameters: {'n_estimators': 752, 'max_depth': 8, 'learning_rate': 0.13182437945974312, 'subsample': 0.9398820359354675, 'colsample_bytree': 0.6900795645672505, 'colsample_bylevel': 0.742667402513763, 'colsample_bynode': 0.7458565262852523, 'reg_alpha': 4.898881513011351, 'reg_lambda': 1.002594077741125e-08, 'min_child_weight': 9, 'gamma': 2.912585435622252, 'max_bin': 403}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [16:50<03:08,  4.95s/it, 1010.25/3600 seconds]Trial  61: Precision=0.5398 | Recall=0.6082 | F1=0.5693 | F0.5=0.5506\n",
    "[I 2025-06-12 15:18:22,003] Trial 61 finished with value: 0.5506429356766287 and parameters: {'n_estimators': 581, 'max_depth': 8, 'learning_rate': 0.1406678175419145, 'subsample': 0.9404525353969898, 'colsample_bytree': 0.7071901539716059, 'colsample_bylevel': 0.7442772053263754, 'colsample_bynode': 0.7561698030193705, 'reg_alpha': 4.157278900510569, 'reg_lambda': 1.1627434684920861e-08, 'min_child_weight': 9, 'gamma': 3.0482494112528675, 'max_bin': 403}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [16:55<03:07,  5.07s/it, 1015.60/3600 seconds]Trial  62: Precision=0.5389 | Recall=0.7007 | F1=0.6020 | F0.5=0.5612\n",
    "[I 2025-06-12 15:18:27,350] Trial 62 finished with value: 0.5612115252979184 and parameters: {'n_estimators': 771, 'max_depth': 7, 'learning_rate': 0.21389203779152252, 'subsample': 0.9610763460456629, 'colsample_bytree': 0.6540924237291258, 'colsample_bylevel': 0.7226565048594638, 'colsample_bynode': 0.7429147707694221, 'reg_alpha': 9.476557406893827, 'reg_lambda': 6.343224117427822e-08, 'min_child_weight': 9, 'gamma': 2.231415654732258, 'max_bin': 377}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [17:02<03:24,  5.69s/it, 1022.74/3600 seconds]Trial  63: Precision=0.5504 | Recall=0.4893 | F1=0.5088 | F0.5=0.5302\n",
    "[I 2025-06-12 15:18:34,486] Trial 63 finished with value: 0.5302111620249494 and parameters: {'n_estimators': 797, 'max_depth': 7, 'learning_rate': 0.21289515520387076, 'subsample': 0.9607927829277162, 'colsample_bytree': 0.6561087657506139, 'colsample_bylevel': 0.7568387590495396, 'colsample_bynode': 0.7426063758740388, 'reg_alpha': 1.7380018998851097, 'reg_lambda': 4.837895092625439e-08, 'min_child_weight': 9, 'gamma': 2.0149440182005756, 'max_bin': 357}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [17:11<03:47,  6.50s/it, 1031.11/3600 seconds]Trial  64: Precision=0.5389 | Recall=0.4784 | F1=0.5002 | F0.5=0.5209\n",
    "[I 2025-06-12 15:18:42,856] Trial 64 finished with value: 0.5209422546569485 and parameters: {'n_estimators': 1031, 'max_depth': 6, 'learning_rate': 0.1185810713984402, 'subsample': 0.9431095243806557, 'colsample_bytree': 0.6257372453457302, 'colsample_bylevel': 0.7211438493979149, 'colsample_bynode': 0.7913097342790076, 'reg_alpha': 0.7166699502192929, 'reg_lambda': 2.1157931829121715e-08, 'min_child_weight': 8, 'gamma': 2.146192877120734, 'max_bin': 434}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [17:15<03:16,  5.77s/it, 1035.18/3600 seconds]Trial  65: Precision=0.5489 | Recall=0.5565 | F1=0.5372 | F0.5=0.5383\n",
    "[I 2025-06-12 15:18:46,928] Trial 65 finished with value: 0.5382862539517533 and parameters: {'n_estimators': 511, 'max_depth': 5, 'learning_rate': 0.2389926863655854, 'subsample': 0.8948925937233445, 'colsample_bytree': 0.6744046953878168, 'colsample_bylevel': 0.7090844689002607, 'colsample_bynode': 0.7873317152603284, 'reg_alpha': 4.028368314176063, 'reg_lambda': 9.95325638648197e-07, 'min_child_weight': 8, 'gamma': 2.676598352165724, 'max_bin': 388}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [17:22<03:21,  6.10s/it, 1042.04/3600 seconds]Trial  66: Precision=0.5402 | Recall=0.4568 | F1=0.4800 | F0.5=0.5089\n",
    "[I 2025-06-12 15:18:53,793] Trial 66 finished with value: 0.5088975477899322 and parameters: {'n_estimators': 630, 'max_depth': 9, 'learning_rate': 0.14567423690693496, 'subsample': 0.9679817020393505, 'colsample_bytree': 0.6340736453856228, 'colsample_bylevel': 0.7637796313803028, 'colsample_bynode': 0.832783913644113, 'reg_alpha': 2.0321293464517134, 'reg_lambda': 2.079177904331061e-07, 'min_child_weight': 9, 'gamma': 1.4898673875389354, 'max_bin': 414}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [17:27<03:04,  5.76s/it, 1047.00/3600 seconds]Trial  67: Precision=0.5317 | Recall=0.6497 | F1=0.5769 | F0.5=0.5470\n",
    "[I 2025-06-12 15:18:58,754] Trial 67 finished with value: 0.5469682645376396 and parameters: {'n_estimators': 779, 'max_depth': 7, 'learning_rate': 0.20612249259007517, 'subsample': 0.9418789966337705, 'colsample_bytree': 0.7036181937579074, 'colsample_bylevel': 0.6751063252495746, 'colsample_bynode': 0.7121207532589455, 'reg_alpha': 5.255512381797356, 'reg_lambda': 5.970852717299491e-07, 'min_child_weight': 9, 'gamma': 2.824753569670697, 'max_bin': 401}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [17:34<03:12,  6.22s/it, 1054.29/3600 seconds]Trial  68: Precision=0.5400 | Recall=0.4937 | F1=0.5015 | F0.5=0.5188\n",
    "[I 2025-06-12 15:19:06,043] Trial 68 finished with value: 0.518766588699581 and parameters: {'n_estimators': 939, 'max_depth': 8, 'learning_rate': 0.19427300463430647, 'subsample': 0.9877335139329124, 'colsample_bytree': 0.7394840570485177, 'colsample_bylevel': 0.6979207050303272, 'colsample_bynode': 0.7504732292455413, 'reg_alpha': 0.06795642680327973, 'reg_lambda': 5.488810392831189e-08, 'min_child_weight': 8, 'gamma': 1.8064812897515168, 'max_bin': 423}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [17:42<03:27,  6.93s/it, 1062.88/3600 seconds]Trial  69: Precision=0.5494 | Recall=0.5264 | F1=0.5284 | F0.5=0.5385\n",
    "[I 2025-06-12 15:19:14,630] Trial 69 finished with value: 0.5384669768901491 and parameters: {'n_estimators': 1121, 'max_depth': 5, 'learning_rate': 0.10796486766269561, 'subsample': 0.9590583943061525, 'colsample_bytree': 0.6682368930617869, 'colsample_bylevel': 0.7254446337679731, 'colsample_bynode': 0.7265649830834799, 'reg_alpha': 1.0681039019372154, 'reg_lambda': 1.1456630797357442e-08, 'min_child_weight': 9, 'gamma': 2.210004787877786, 'max_bin': 381}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [17:52<03:45,  7.77s/it, 1072.63/3600 seconds]Trial  70: Precision=0.5465 | Recall=0.5427 | F1=0.5264 | F0.5=0.5323\n",
    "[I 2025-06-12 15:19:24,377] Trial 70 finished with value: 0.5322592900236144 and parameters: {'n_estimators': 335, 'max_depth': 6, 'learning_rate': 0.05970401306526717, 'subsample': 0.9156203240451252, 'colsample_bytree': 0.6945914485907692, 'colsample_bylevel': 0.7484975550687348, 'colsample_bynode': 0.7388492799903759, 'reg_alpha': 2.131127805426838, 'reg_lambda': 2.6595916984903582e-08, 'min_child_weight': 10, 'gamma': 1.2738536179071949, 'max_bin': 374}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [17:57<03:12,  6.87s/it, 1077.38/3600 seconds]Trial  71: Precision=0.5399 | Recall=0.7154 | F1=0.6086 | F0.5=0.5643\n",
    "[I 2025-06-12 15:19:29,130] Trial 71 finished with value: 0.5643147228567745 and parameters: {'n_estimators': 700, 'max_depth': 8, 'learning_rate': 0.15042617692527707, 'subsample': 0.9267515243832022, 'colsample_bytree': 0.6452651461782604, 'colsample_bylevel': 0.7344403402664156, 'colsample_bynode': 0.7041068475149477, 'reg_alpha': 9.92018995881969, 'reg_lambda': 1.0183526825789151e-07, 'min_child_weight': 10, 'gamma': 3.726291815525026, 'max_bin': 361}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [18:02<02:52,  6.39s/it, 1082.65/3600 seconds]Trial  72: Precision=0.5435 | Recall=0.6745 | F1=0.5889 | F0.5=0.5573\n",
    "[I 2025-06-12 15:19:34,400] Trial 72 finished with value: 0.5573451480700019 and parameters: {'n_estimators': 719, 'max_depth': 7, 'learning_rate': 0.1422832272180706, 'subsample': 0.9334771192052745, 'colsample_bytree': 0.656432617968631, 'colsample_bylevel': 0.7185936948203601, 'colsample_bynode': 0.7108750963469327, 'reg_alpha': 5.59135227955162, 'reg_lambda': 2.0586571252897087e-07, 'min_child_weight': 10, 'gamma': 3.7206994041041486, 'max_bin': 389}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [18:07<02:36,  6.02s/it, 1087.80/3600 seconds]Trial  73: Precision=0.5396 | Recall=0.7160 | F1=0.6076 | F0.5=0.5636\n",
    "[I 2025-06-12 15:19:39,552] Trial 73 finished with value: 0.5635927318291845 and parameters: {'n_estimators': 471, 'max_depth': 7, 'learning_rate': 0.09248652390485813, 'subsample': 0.9277440686405946, 'colsample_bytree': 0.6418730548234576, 'colsample_bylevel': 0.7153170949361594, 'colsample_bynode': 0.7023794708964379, 'reg_alpha': 8.762735300138617, 'reg_lambda': 3.7900219791324744e-07, 'min_child_weight': 10, 'gamma': 3.710966971885814, 'max_bin': 388}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [18:12<02:20,  5.64s/it, 1092.56/3600 seconds]Trial  74: Precision=0.5367 | Recall=0.7655 | F1=0.6225 | F0.5=0.5667\n",
    "[I 2025-06-12 15:19:44,305] Trial 74 finished with value: 0.5666896717282883 and parameters: {'n_estimators': 628, 'max_depth': 9, 'learning_rate': 0.09090884711890766, 'subsample': 0.9674261225545349, 'colsample_bytree': 0.6345810015758323, 'colsample_bylevel': 0.6945053798561943, 'colsample_bynode': 0.6939879381165214, 'reg_alpha': 9.71587685704779, 'reg_lambda': 1.8553487182522462e-06, 'min_child_weight': 10, 'gamma': 3.9559533491009664, 'max_bin': 360}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [18:18<02:17,  5.74s/it, 1098.54/3600 seconds]Trial  75: Precision=0.5545 | Recall=0.5643 | F1=0.5399 | F0.5=0.5413\n",
    "[I 2025-06-12 15:19:50,286] Trial 75 finished with value: 0.541281012712467 and parameters: {'n_estimators': 491, 'max_depth': 9, 'learning_rate': 0.07005345511204292, 'subsample': 0.708709913591598, 'colsample_bytree': 0.6389657376308308, 'colsample_bylevel': 0.6793059313938137, 'colsample_bynode': 0.6695452596067984, 'reg_alpha': 2.65650009419808, 'reg_lambda': 1.8551248147451623e-06, 'min_child_weight': 10, 'gamma': 4.025897044245642, 'max_bin': 361}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [18:24<02:16,  5.95s/it, 1104.96/3600 seconds]Trial  76: Precision=0.5497 | Recall=0.4809 | F1=0.4982 | F0.5=0.5234\n",
    "[I 2025-06-12 15:19:56,713] Trial 76 finished with value: 0.5233909209078785 and parameters: {'n_estimators': 586, 'max_depth': 10, 'learning_rate': 0.09361405208411805, 'subsample': 0.8900239009361034, 'colsample_bytree': 0.6065995396799174, 'colsample_bylevel': 0.6502275733953901, 'colsample_bynode': 0.6946839893417436, 'reg_alpha': 0.0018449558306787343, 'reg_lambda': 4.633223730095784e-07, 'min_child_weight': 10, 'gamma': 3.447876128646352, 'max_bin': 347}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [18:30<02:08,  5.83s/it, 1110.52/3600 seconds]Trial  77: Precision=0.5416 | Recall=0.5782 | F1=0.5539 | F0.5=0.5451\n",
    "[I 2025-06-12 15:20:02,268] Trial 77 finished with value: 0.545148367435148 and parameters: {'n_estimators': 635, 'max_depth': 9, 'learning_rate': 0.0872889426646259, 'subsample': 0.9228715122804264, 'colsample_bytree': 0.6404335782076407, 'colsample_bylevel': 0.6918829887545697, 'colsample_bynode': 0.6980027067128934, 'reg_alpha': 0.33046413267593705, 'reg_lambda': 1.4912762190578448e-06, 'min_child_weight': 10, 'gamma': 3.9103052082347167, 'max_bin': 367}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [18:34<01:48,  5.19s/it, 1114.21/3600 seconds]Trial  78: Precision=0.5496 | Recall=0.5737 | F1=0.5556 | F0.5=0.5505\n",
    "[I 2025-06-12 15:20:05,963] Trial 78 finished with value: 0.5505158234073997 and parameters: {'n_estimators': 466, 'max_depth': 8, 'learning_rate': 0.11493422745759783, 'subsample': 0.9662008532829057, 'colsample_bytree': 0.6242736047907912, 'colsample_bylevel': 0.6976059506386784, 'colsample_bynode': 0.7825931767927549, 'reg_alpha': 0.5210116187083742, 'reg_lambda': 3.501107559785428e-07, 'min_child_weight': 10, 'gamma': 3.6594356133365893, 'max_bin': 363}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [18:36<01:29,  4.45s/it, 1116.95/3600 seconds]Trial  79: Precision=0.5403 | Recall=0.6248 | F1=0.5711 | F0.5=0.5499\n",
    "[I 2025-06-12 15:20:08,704] Trial 79 finished with value: 0.5498967110254916 and parameters: {'n_estimators': 325, 'max_depth': 9, 'learning_rate': 0.06671983179375827, 'subsample': 0.9884646717297285, 'colsample_bytree': 0.6011493963829208, 'colsample_bylevel': 0.7837970773388053, 'colsample_bynode': 0.7008522105761563, 'reg_alpha': 1.1807445875629765, 'reg_lambda': 1.335827038274954e-07, 'min_child_weight': 10, 'gamma': 4.7979562081259965, 'max_bin': 395}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [18:40<01:20,  4.25s/it, 1120.74/3600 seconds]Trial  80: Precision=0.5409 | Recall=0.7296 | F1=0.6136 | F0.5=0.5666\n",
    "[I 2025-06-12 15:20:12,493] Trial 80 finished with value: 0.5665650577536075 and parameters: {'n_estimators': 564, 'max_depth': 6, 'learning_rate': 0.14900670128283602, 'subsample': 0.9516365846541924, 'colsample_bytree': 0.7319111406276745, 'colsample_bylevel': 0.6343671357779904, 'colsample_bynode': 0.8231422622509429, 'reg_alpha': 9.906449599594751, 'reg_lambda': 2.7615657713201837e-07, 'min_child_weight': 9, 'gamma': 3.3627998724833428, 'max_bin': 351}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [18:44<01:16,  4.25s/it, 1124.98/3600 seconds]Trial  81: Precision=0.5428 | Recall=0.6128 | F1=0.5669 | F0.5=0.5501\n",
    "[I 2025-06-12 15:20:16,724] Trial 81 finished with value: 0.5501121267465708 and parameters: {'n_estimators': 555, 'max_depth': 6, 'learning_rate': 0.16085832599370473, 'subsample': 0.9540297937918986, 'colsample_bytree': 0.7153647222721817, 'colsample_bylevel': 0.6321052473995208, 'colsample_bynode': 0.6757481457650518, 'reg_alpha': 3.2225132864794848, 'reg_lambda': 3.6129891630313387e-06, 'min_child_weight': 9, 'gamma': 3.479367611454905, 'max_bin': 353}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [18:49<01:13,  4.32s/it, 1129.45/3600 seconds]Trial  82: Precision=0.5439 | Recall=0.6925 | F1=0.5991 | F0.5=0.5628\n",
    "[I 2025-06-12 15:20:21,203] Trial 82 finished with value: 0.5627822788498229 and parameters: {'n_estimators': 625, 'max_depth': 7, 'learning_rate': 0.1847245188605124, 'subsample': 0.9760808448823027, 'colsample_bytree': 0.6766470467049517, 'colsample_bylevel': 0.6141190285101056, 'colsample_bynode': 0.6907633549522333, 'reg_alpha': 5.895954942576608, 'reg_lambda': 5.384767344934897e-07, 'min_child_weight': 10, 'gamma': 3.306819693716742, 'max_bin': 345}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [18:54<01:11,  4.48s/it, 1134.30/3600 seconds]Trial  83: Precision=0.5403 | Recall=0.4819 | F1=0.4986 | F0.5=0.5193\n",
    "[I 2025-06-12 15:20:26,052] Trial 83 finished with value: 0.5193259043825437 and parameters: {'n_estimators': 616, 'max_depth': 6, 'learning_rate': 0.1841673115717723, 'subsample': 0.9826442002618643, 'colsample_bytree': 0.6691889819070597, 'colsample_bylevel': 0.6202965068155406, 'colsample_bynode': 0.6890513218638574, 'reg_alpha': 0.00016652153176108424, 'reg_lambda': 7.688731955622763e-07, 'min_child_weight': 10, 'gamma': 3.310921683895967, 'max_bin': 322}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [19:00<01:13,  4.92s/it, 1140.24/3600 seconds]Trial  84: Precision=0.5435 | Recall=0.5111 | F1=0.5058 | F0.5=0.5204\n",
    "[I 2025-06-12 15:20:31,993] Trial 84 finished with value: 0.5204042283429335 and parameters: {'n_estimators': 833, 'max_depth': 5, 'learning_rate': 0.2665659676588889, 'subsample': 0.9730385345005627, 'colsample_bytree': 0.676038393297929, 'colsample_bylevel': 0.608680318582079, 'colsample_bynode': 0.6522304431604289, 'reg_alpha': 2.2815470566854144, 'reg_lambda': 1.8113834566025482e-07, 'min_child_weight': 10, 'gamma': 3.488920844220839, 'max_bin': 347}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [19:04<01:07,  4.80s/it, 1144.76/3600 seconds]Trial  85: Precision=0.5401 | Recall=0.7242 | F1=0.6087 | F0.5=0.5638\n",
    "[I 2025-06-12 15:20:36,506] Trial 85 finished with value: 0.5637957978302711 and parameters: {'n_estimators': 531, 'max_depth': 10, 'learning_rate': 0.11220793743930033, 'subsample': 0.9485163349469341, 'colsample_bytree': 0.6430287475084236, 'colsample_bylevel': 0.6295309397985598, 'colsample_bynode': 0.7189045536743576, 'reg_alpha': 6.127766451325177, 'reg_lambda': 7.536080963921503e-08, 'min_child_weight': 10, 'gamma': 3.122839846103602, 'max_bin': 331}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [19:07<00:54,  4.22s/it, 1147.62/3600 seconds]Trial  86: Precision=0.5409 | Recall=0.6738 | F1=0.5888 | F0.5=0.5566\n",
    "[I 2025-06-12 15:20:39,369] Trial 86 finished with value: 0.5565819867141195 and parameters: {'n_estimators': 259, 'max_depth': 10, 'learning_rate': 0.10699679660701084, 'subsample': 0.9463980142559242, 'colsample_bytree': 0.6472490704354784, 'colsample_bylevel': 0.6158441023483585, 'colsample_bynode': 0.7088624265630927, 'reg_alpha': 5.059974943861212, 'reg_lambda': 4.487713069292179e-07, 'min_child_weight': 10, 'gamma': 3.1112539303516336, 'max_bin': 328}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [19:11<00:48,  4.08s/it, 1151.37/3600 seconds]Trial  87: Precision=0.5465 | Recall=0.6058 | F1=0.5645 | F0.5=0.5505\n",
    "[I 2025-06-12 15:20:43,119] Trial 87 finished with value: 0.550477155349715 and parameters: {'n_estimators': 405, 'max_depth': 11, 'learning_rate': 0.09057760485397731, 'subsample': 0.992811491941112, 'colsample_bytree': 0.6189436179425665, 'colsample_bylevel': 0.6012025145690316, 'colsample_bynode': 0.6664052186751555, 'reg_alpha': 1.3657341512854375, 'reg_lambda': 6.978382630580399e-08, 'min_child_weight': 10, 'gamma': 4.08143796102492, 'max_bin': 302}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [19:14<00:41,  3.78s/it, 1154.46/3600 seconds]Trial  88: Precision=0.5359 | Recall=0.6856 | F1=0.5927 | F0.5=0.5555\n",
    "[I 2025-06-12 15:20:46,213] Trial 88 finished with value: 0.555491342632936 and parameters: {'n_estimators': 544, 'max_depth': 10, 'learning_rate': 0.23894576133669004, 'subsample': 0.9767196201743018, 'colsample_bytree': 0.6454298627728279, 'colsample_bylevel': 0.6321385578902005, 'colsample_bynode': 0.7207241206624618, 'reg_alpha': 5.198698650391352, 'reg_lambda': 3.422239493826272e-08, 'min_child_weight': 10, 'gamma': 3.847692795607733, 'max_bin': 344}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [19:18<00:37,  3.77s/it, 1158.21/3600 seconds]Trial  89: Precision=0.5456 | Recall=0.5794 | F1=0.5489 | F0.5=0.5426\n",
    "[I 2025-06-12 15:20:49,957] Trial 89 finished with value: 0.5425884226480184 and parameters: {'n_estimators': 478, 'max_depth': 10, 'learning_rate': 0.12967998463750788, 'subsample': 0.9545932349521901, 'colsample_bytree': 0.6279077548767724, 'colsample_bylevel': 0.6487128911286274, 'colsample_bynode': 0.7048465821353418, 'reg_alpha': 0.7525965436107802, 'reg_lambda': 1.2392010967236862e-06, 'min_child_weight': 10, 'gamma': 4.541452368225612, 'max_bin': 332}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [19:24<00:41,  4.62s/it, 1164.81/3600 seconds]Trial  90: Precision=0.5433 | Recall=0.5862 | F1=0.5540 | F0.5=0.5446\n",
    "[I 2025-06-12 15:20:56,563] Trial 90 finished with value: 0.5445646857594629 and parameters: {'n_estimators': 888, 'max_depth': 8, 'learning_rate': 0.08160977514254299, 'subsample': 0.9051217891996255, 'colsample_bytree': 0.8195815314969782, 'colsample_bylevel': 0.6402231824784484, 'colsample_bynode': 0.6384085313767873, 'reg_alpha': 2.6616305823856488, 'reg_lambda': 1.2308109381230847e-07, 'min_child_weight': 10, 'gamma': 3.359774169798674, 'max_bin': 313}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [19:29<00:37,  4.70s/it, 1169.68/3600 seconds]Trial  91: Precision=0.5436 | Recall=0.7037 | F1=0.6042 | F0.5=0.5645\n",
    "[I 2025-06-12 15:21:01,430] Trial 91 finished with value: 0.5644644769462357 and parameters: {'n_estimators': 711, 'max_depth': 7, 'learning_rate': 0.17670287851936947, 'subsample': 0.9159138512012986, 'colsample_bytree': 0.6608830413999812, 'colsample_bylevel': 0.6213227169698713, 'colsample_bynode': 0.7298064049552108, 'reg_alpha': 8.189662464921948, 'reg_lambda': 2.5937859612401417e-07, 'min_child_weight': 9, 'gamma': 3.901790871144497, 'max_bin': 256}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [19:35<00:34,  4.89s/it, 1175.03/3600 seconds]Trial  92: Precision=0.5431 | Recall=0.6745 | F1=0.5949 | F0.5=0.5613\n",
    "[I 2025-06-12 15:21:06,775] Trial 92 finished with value: 0.5612842179738967 and parameters: {'n_estimators': 714, 'max_depth': 8, 'learning_rate': 0.17333268902955115, 'subsample': 0.9173475121588792, 'colsample_bytree': 0.6621241438727542, 'colsample_bylevel': 0.6212096384391257, 'colsample_bynode': 0.734194603949288, 'reg_alpha': 6.105238288325974, 'reg_lambda': 6.761764610475351e-08, 'min_child_weight': 10, 'gamma': 3.1544239952024826, 'max_bin': 260}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [19:39<00:27,  4.64s/it, 1179.08/3600 seconds]Trial  93: Precision=0.5400 | Recall=0.5942 | F1=0.5606 | F0.5=0.5467\n",
    "[I 2025-06-12 15:21:10,831] Trial 93 finished with value: 0.5467217366432047 and parameters: {'n_estimators': 536, 'max_depth': 9, 'learning_rate': 0.3017464704600499, 'subsample': 0.9265547123531434, 'colsample_bytree': 0.837546089257487, 'colsample_bylevel': 0.669367581263933, 'colsample_bynode': 0.6904365971633635, 'reg_alpha': 3.3766102654349237, 'reg_lambda': 6.263548332611771e-07, 'min_child_weight': 9, 'gamma': 3.969875256456028, 'max_bin': 286}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [19:43<00:22,  4.59s/it, 1183.55/3600 seconds]Trial  94: Precision=0.5379 | Recall=0.7601 | F1=0.6211 | F0.5=0.5670\n",
    "[I 2025-06-12 15:21:15,297] Trial 94 finished with value: 0.566968506597713 and parameters: {'n_estimators': 608, 'max_depth': 6, 'learning_rate': 0.11173617179594919, 'subsample': 0.9645911793225247, 'colsample_bytree': 0.6819910234781379, 'colsample_bylevel': 0.6548357000765006, 'colsample_bynode': 0.6762872555624292, 'reg_alpha': 9.748702379111164, 'reg_lambda': 1.4540818565090677e-07, 'min_child_weight': 10, 'gamma': 3.822133878533465, 'max_bin': 283}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [19:47<00:17,  4.43s/it, 1187.62/3600 seconds]Trial  95: Precision=0.5437 | Recall=0.6890 | F1=0.5985 | F0.5=0.5623\n",
    "[I 2025-06-12 15:21:19,373] Trial 95 finished with value: 0.5622917417248257 and parameters: {'n_estimators': 435, 'max_depth': 6, 'learning_rate': 0.11396244935635029, 'subsample': 0.6071665438789435, 'colsample_bytree': 0.7972716256375797, 'colsample_bylevel': 0.6533940817693582, 'colsample_bynode': 0.6792638282387041, 'reg_alpha': 8.70709378025926, 'reg_lambda': 1.713300102548607e-08, 'min_child_weight': 10, 'gamma': 3.7445353598132836, 'max_bin': 279}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [19:52<00:13,  4.66s/it, 1192.82/3600 seconds]Trial  96: Precision=0.5431 | Recall=0.4950 | F1=0.5029 | F0.5=0.5212\n",
    "[I 2025-06-12 15:21:24,567] Trial 96 finished with value: 0.5211786224662751 and parameters: {'n_estimators': 585, 'max_depth': 11, 'learning_rate': 0.12740575851826347, 'subsample': 0.8817685807661472, 'colsample_bytree': 0.632725022904053, 'colsample_bylevel': 0.6578095925122986, 'colsample_bynode': 0.7234126819199523, 'reg_alpha': 1.56052559590487, 'reg_lambda': 8.39200754634072e-08, 'min_child_weight': 9, 'gamma': 4.214402094727458, 'max_bin': 265}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [19:57<00:09,  4.71s/it, 1197.63/3600 seconds]Trial  97: Precision=0.5415 | Recall=0.6685 | F1=0.5901 | F0.5=0.5584\n",
    "[I 2025-06-12 15:21:29,379] Trial 97 finished with value: 0.5584349793200943 and parameters: {'n_estimators': 678, 'max_depth': 5, 'learning_rate': 0.062426157492642666, 'subsample': 0.9469861373613607, 'colsample_bytree': 0.7851185773652151, 'colsample_bylevel': 0.6417654835359158, 'colsample_bynode': 0.6603487836123665, 'reg_alpha': 3.551646851404558, 'reg_lambda': 3.913598496966698e-08, 'min_child_weight': 10, 'gamma': 3.82444515807558, 'max_bin': 271}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [20:00<00:04,  4.30s/it, 1200.97/3600 seconds]Trial  98: Precision=0.5384 | Recall=0.7242 | F1=0.6081 | F0.5=0.5626\n",
    "[I 2025-06-12 15:21:32,721] Trial 98 finished with value: 0.56264223988349 and parameters: {'n_estimators': 387, 'max_depth': 6, 'learning_rate': 0.05274842051120016, 'subsample': 0.896539589307603, 'colsample_bytree': 0.6145279816072757, 'colsample_bylevel': 0.624053323079727, 'colsample_bynode': 0.8319486468526521, 'reg_alpha': 9.686518910883882, 'reg_lambda': 1.2681845716288595e-07, 'min_child_weight': 9, 'gamma': 3.8982557090126146, 'max_bin': 358}. Best is trial 42 with value: 0.5672303869029487.\n",
    "Best trial: 42. Best value: 0.56723: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [20:07<00:00, 12.08s/it, 1207.55/3600 seconds]Trial  99: Precision=0.5385 | Recall=0.5011 | F1=0.5061 | F0.5=0.5210\n",
    "[I 2025-06-12 15:21:39,303] Trial 99 finished with value: 0.5210426457300523 and parameters: {'n_estimators': 817, 'max_depth': 10, 'learning_rate': 0.07510770874962336, 'subsample': 0.9676230464300466, 'colsample_bytree': 0.7688464590489239, 'colsample_bylevel': 0.6380566223441241, 'colsample_bynode': 0.6731368198425041, 'reg_alpha': 0.021670317002119688, 'reg_lambda': 2.66504636593889e-07, 'min_child_weight': 1, 'gamma': 4.434956228306662, 'max_bin': 291}. Best is trial 42 with value: 0.5672303869029487.\n",
    "\\nOptimization completed!\n",
    "Best F0.5 score: 0.567230\n",
    "Best parameters: {'n_estimators': 544, 'max_depth': 10, 'learning_rate': 0.2938582603380786, 'subsample': 0.9552911410477546, 'colsample_bytree': 0.7991091655074166, 'colsample_bylevel': 0.7747986866913422, 'colsample_bynode': 0.6901392596118723, 'reg_alpha': 7.615371465435688, 'reg_lambda': 3.675517635889162e-08, 'min_child_weight': 10, 'gamma': 4.986366774672873, 'max_bin': 414}\n",
    "\\nTraining final model with best F0.5 parameters...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Run Parser ‚îÄ‚îÄ‚îÄ\n",
    "df_results = parse_xgboost_output_from_text(output_text)\n",
    "print(df_results.head(10))  # Show first 10 results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc15f5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\admin\\desktop\\coding_projects\\stock_market_prediction\\stock-market-prediction\\.venv\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\desktop\\coding_projects\\stock_market_prediction\\stock-market-prediction\\.venv\\lib\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\desktop\\coding_projects\\stock_market_prediction\\stock-market-prediction\\.venv\\lib\\site-packages (from xgboost) (1.15.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d5204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üöÄ Starting XGBoost training pipeline...\n",
      "INFO:__main__:üì• Loading data from: C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\n",
      "INFO:__main__:Loaded data shape: (20718, 67)\n",
      "INFO:__main__:Features shape: (20718, 66), Target shape: (20718,)\n",
      "INFO:__main__:Target value counts:\n",
      "target\n",
      "1    10751\n",
      "0     9967\n",
      "Name: count, dtype: int64\n",
      "INFO:__main__:Handling missing values...\n",
      "INFO:__main__:Encoding categorical columns: ['timestamp']\n",
      "INFO:__main__:Detected binary classification with 2 classes\n",
      "INFO:__main__:Train set: (16574, 66), Test set: (4144, 66)\n",
      "INFO:__main__:üöÄ Starting model training...\n",
      "INFO:__main__:Training split: train=13259, val=3315\n",
      "INFO:__main__:Training XGBoost model...\n",
      "INFO:__main__:XGBoost version: 3.0.2\n",
      "ERROR:__main__:Error during model fitting: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "INFO:__main__:Trying without early stopping...\n",
      "INFO:__main__:‚úì Training completed with 738 estimators\n",
      "INFO:__main__:üìä Evaluating model...\n",
      "INFO:__main__:üíæ Model saved to: xgb_final\\xgb_model_20250612_163054.joblib\n",
      "INFO:__main__:üíæ Encoders saved to: xgb_final\\encoders_20250612_163054.joblib\n",
      "INFO:__main__:üíæ Feature names saved to: xgb_final\\features_20250612_163054.joblib\n",
      "INFO:__main__:üèÅ Training pipeline completed successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "==================================================\n",
      "accuracy_train      : 0.6066\n",
      "accuracy_test       : 0.5198\n",
      "precision_test      : 0.5381\n",
      "recall_test         : 0.4423\n",
      "f1_test             : 0.4855\n",
      "roc_auc_test        : 0.5322\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "#  XGBoost Final Trainer  ‚Äî  v2-compatible, leakage-free (FIXED)\n",
    "# =============================================================\n",
    "import os, warnings, joblib\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost.callback import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, classification_report,\n",
    "                             confusion_matrix, roc_curve,\n",
    "                             precision_recall_curve, average_precision_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up logging for better debugging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  CONFIG  (update paths / params as needed)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "DATA_PATH     = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\"\n",
    "TARGET_COLUMN = \"target\"\n",
    "DROP_COLUMNS  = [\n",
    "    'open', 'high', 'low',\n",
    "    'high_low', 'high_close', 'low_close', 'typical_price',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3', \n",
    "    'bearish_scenario_6',\n",
    "    'volume_breakout', 'volume_breakdown', \n",
    "    'ema_cross_up', 'ema_cross_down', 'macd_cross_up', 'macd_cross_down',\n",
    "    'trending_market', 'trend_alignment', 'momentum_alignment',\n",
    "  \n",
    "]                 # e.g. [\"timestamp\"]\n",
    "TEST_FRAC     = 0.20\n",
    "RANDOM_SEED   = 42\n",
    "\n",
    "# Optimal hyper-parameters found in Optuna search\n",
    "BEST_PARAMS = {\n",
    "    \"n_estimators\":        738,\n",
    "    \"max_depth\":           3,\n",
    "    \"learning_rate\":       0.010742242818480038,\n",
    "    \"subsample\":           0.7288003215611947,\n",
    "    \"colsample_bytree\":    0.9716424763198493,\n",
    "    \"colsample_bylevel\":   0.9399534681398528,\n",
    "    \"reg_alpha\":           0.012276608615353355,\n",
    "    \"reg_lambda\":          0.0014806031253539519,\n",
    "    \"min_child_weight\":    1,\n",
    "    \"gamma\":               0.5640314445201723,\n",
    "}\n",
    "EARLY_STOP_ROUNDS = 100\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  TRAINER CLASS\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "class XGBoostFinalTrainer:\n",
    "    def __init__(self,\n",
    "                 data_path:      str,\n",
    "                 target_column:  str,\n",
    "                 drop_columns:   list = None,\n",
    "                 test_frac:      float = 0.2,\n",
    "                 random_state:   int   = 42):\n",
    "\n",
    "        self.data_path      = data_path\n",
    "        self.target_column  = target_column\n",
    "        self.drop_columns   = drop_columns or []\n",
    "        self.test_frac      = test_frac\n",
    "        self.random_state   = random_state\n",
    "\n",
    "        # populated later\n",
    "        self.is_binary      = False\n",
    "        self.label_encoders = {}\n",
    "        self.X_train = self.X_test = self.y_train = self.y_test = None\n",
    "        self.model   = None\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ DATA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def load_and_preprocess(self):\n",
    "        try:\n",
    "            logger.info(\"üì• Loading data from: %s\", self.data_path)\n",
    "            \n",
    "            # Check if file exists\n",
    "            if not os.path.exists(self.data_path):\n",
    "                raise FileNotFoundError(f\"Data file not found: {self.data_path}\")\n",
    "            \n",
    "            df = pd.read_csv(self.data_path)\n",
    "            logger.info(f\"Loaded data shape: {df.shape}\")\n",
    "            \n",
    "            if df.empty:\n",
    "                raise ValueError(\"Loaded dataframe is empty\")\n",
    "\n",
    "            if self.target_column not in df.columns:\n",
    "                available_cols = list(df.columns)\n",
    "                raise KeyError(f\"Target column '{self.target_column}' not found. Available columns: {available_cols}\")\n",
    "\n",
    "            # Check for sufficient data\n",
    "            if len(df) < 100:\n",
    "                raise ValueError(f\"Insufficient data: only {len(df)} rows. Need at least 100 rows for reliable training.\")\n",
    "\n",
    "            y = df[self.target_column].copy()\n",
    "            X = df.drop(columns=[col for col in self.drop_columns + [self.target_column] if col in df.columns])\n",
    "\n",
    "            logger.info(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "            logger.info(f\"Target value counts:\\n{y.value_counts()}\")\n",
    "\n",
    "            # Handle missing values more robustly\n",
    "            logger.info(\"Handling missing values...\")\n",
    "            for col in X.columns:\n",
    "                missing_count = X[col].isna().sum()\n",
    "                if missing_count > 0:\n",
    "                    logger.info(f\"Column '{col}' has {missing_count} missing values\")\n",
    "                    \n",
    "                if X[col].dtype in (\"object\", \"category\"):\n",
    "                    mode_val = X[col].mode()\n",
    "                    fill_val = mode_val.iloc[0] if len(mode_val) > 0 else \"unknown\"\n",
    "                    X[col] = X[col].fillna(fill_val)\n",
    "                else:\n",
    "                    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "            # Handle missing target values\n",
    "            if y.isna().any():\n",
    "                missing_targets = y.isna().sum()\n",
    "                logger.warning(f\"Removing {missing_targets} rows with missing target values\")\n",
    "                mask = ~y.isna()\n",
    "                X, y = X[mask].reset_index(drop=True), y[mask].reset_index(drop=True)\n",
    "\n",
    "            # Check if we still have enough data after cleaning\n",
    "            if len(X) < 50:\n",
    "                raise ValueError(f\"After cleaning, only {len(X)} rows remain. Need at least 50 rows.\")\n",
    "\n",
    "            # Encode categorical variables\n",
    "            categorical_cols = X.select_dtypes([\"object\", \"category\"]).columns\n",
    "            if len(categorical_cols) > 0:\n",
    "                logger.info(f\"Encoding categorical columns: {list(categorical_cols)}\")\n",
    "                for col in categorical_cols:\n",
    "                    le = LabelEncoder()\n",
    "                    X[col] = le.fit_transform(X[col].astype(str))\n",
    "                    self.label_encoders[col] = le\n",
    "\n",
    "            # Handle target encoding\n",
    "            if y.dtype == \"object\":\n",
    "                logger.info(\"Encoding target variable\")\n",
    "                le_t = LabelEncoder()\n",
    "                y = pd.Series(le_t.fit_transform(y), index=y.index)\n",
    "                self.label_encoders[\"target\"] = le_t\n",
    "\n",
    "            # Check target distribution\n",
    "            unique_targets = np.unique(y)\n",
    "            self.is_binary = len(unique_targets) == 2\n",
    "            logger.info(f\"Detected {'binary' if self.is_binary else 'multi-class'} classification with {len(unique_targets)} classes\")\n",
    "\n",
    "            # Check for class imbalance\n",
    "            target_counts = pd.Series(y).value_counts()\n",
    "            min_class_count = target_counts.min()\n",
    "            if min_class_count < 5:\n",
    "                logger.warning(f\"Warning: Minimum class has only {min_class_count} samples. This may cause training issues.\")\n",
    "\n",
    "            # Chronological split (prevents leakage)\n",
    "            split_idx = int(len(X) * (1 - self.test_frac))\n",
    "            \n",
    "            # Ensure we have enough data in both splits\n",
    "            if split_idx < 10 or (len(X) - split_idx) < 10:\n",
    "                raise ValueError(f\"Split results in insufficient data: train={split_idx}, test={len(X) - split_idx}\")\n",
    "            \n",
    "            self.X_train = X.iloc[:split_idx].reset_index(drop=True)\n",
    "            self.X_test = X.iloc[split_idx:].reset_index(drop=True)\n",
    "            self.y_train = y.iloc[:split_idx].reset_index(drop=True)\n",
    "            self.y_test = y.iloc[split_idx:].reset_index(drop=True)\n",
    "\n",
    "            logger.info(f\"Train set: {self.X_train.shape}, Test set: {self.X_test.shape}\")\n",
    "            \n",
    "            # Validate feature consistency\n",
    "            if self.X_train.shape[1] == 0:\n",
    "                raise ValueError(\"No features remaining after preprocessing\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in load_and_preprocess: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ TRAIN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def train(self, best_params: dict):\n",
    "        try:\n",
    "            if self.X_train is None:\n",
    "                raise RuntimeError(\"Data not loaded. Call load_and_preprocess() first.\")\n",
    "            \n",
    "            logger.info(\"üöÄ Starting model training...\")\n",
    "            \n",
    "            params = best_params.copy()\n",
    "            \n",
    "            # Set appropriate objective and eval_metric\n",
    "            if self.is_binary:\n",
    "                params.update({\n",
    "                    \"objective\": \"binary:logistic\",\n",
    "                    \"eval_metric\": \"logloss\",  # Changed from aucpr for better stability\n",
    "                })\n",
    "            else:\n",
    "                num_classes = len(np.unique(self.y_train))\n",
    "                params.update({\n",
    "                    \"objective\": \"multi:softprob\",\n",
    "                    \"eval_metric\": \"mlogloss\",\n",
    "                    \"num_class\": num_classes,\n",
    "                })\n",
    "            \n",
    "            params.update({\n",
    "                \"random_state\": self.random_state,\n",
    "                \"n_jobs\": -1,\n",
    "                \"verbosity\": 1,  # Enable some verbosity for debugging\n",
    "                \"tree_method\": \"hist\",  # More efficient and stable\n",
    "            })\n",
    "\n",
    "            # Create validation split from training data\n",
    "            val_frac = 0.2\n",
    "            val_idx = int(len(self.X_train) * (1 - val_frac))\n",
    "            \n",
    "            # Ensure minimum validation size\n",
    "            if (len(self.X_train) - val_idx) < 5:\n",
    "                val_idx = len(self.X_train) - 5\n",
    "                logger.warning(\"Adjusted validation split to ensure minimum validation size\")\n",
    "            \n",
    "            X_tr = self.X_train.iloc[:val_idx]\n",
    "            X_val = self.X_train.iloc[val_idx:]\n",
    "            y_tr = self.y_train.iloc[:val_idx]\n",
    "            y_val = self.y_train.iloc[val_idx:]\n",
    "\n",
    "            logger.info(f\"Training split: train={len(X_tr)}, val={len(X_val)}\")\n",
    "\n",
    "            # Initialize model\n",
    "            self.model = xgb.XGBClassifier(**params)\n",
    "\n",
    "            # Train model with error handling\n",
    "            logger.info(\"Training XGBoost model...\")\n",
    "            \n",
    "            # Check XGBoost version for callback compatibility\n",
    "            xgb_version = xgb.__version__\n",
    "            logger.info(f\"XGBoost version: {xgb_version}\")\n",
    "            \n",
    "            # Simple approach - just use early_stopping_rounds parameter\n",
    "            try:\n",
    "                self.model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    early_stopping_rounds=EARLY_STOP_ROUNDS,\n",
    "                    verbose=False\n",
    "                )\n",
    "            except Exception as fit_error:\n",
    "                logger.error(f\"Error during model fitting: {fit_error}\")\n",
    "                # Try without early stopping as last resort\n",
    "                logger.info(\"Trying without early stopping...\")\n",
    "                self.model.fit(X_tr, y_tr, verbose=False)\n",
    "\n",
    "            # Get best iteration info\n",
    "            if hasattr(self.model, 'best_iteration') and self.model.best_iteration is not None:\n",
    "                best_iter = self.model.best_iteration\n",
    "                logger.info(f\"‚úì Early stopping at iteration {best_iter}\")\n",
    "            else:\n",
    "                best_iter = params.get('n_estimators', 100)\n",
    "                logger.info(f\"‚úì Training completed with {best_iter} estimators\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in training: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ EVALUATE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def evaluate(self, plots: bool = False):\n",
    "        try:\n",
    "            if self.model is None:\n",
    "                raise RuntimeError(\"Model not trained. Call train() first!\")\n",
    "\n",
    "            logger.info(\"üìä Evaluating model...\")\n",
    "\n",
    "            # Make predictions\n",
    "            y_hat_tr = self.model.predict(self.X_train)\n",
    "            y_hat_te = self.model.predict(self.X_test)\n",
    "            \n",
    "            # Get prediction probabilities\n",
    "            y_proba_tr = self.model.predict_proba(self.X_train)\n",
    "            y_proba_te = self.model.predict_proba(self.X_test)\n",
    "\n",
    "            if self.is_binary:\n",
    "                y_proba_tr = y_proba_tr[:, 1]\n",
    "                y_proba_te = y_proba_te[:, 1]\n",
    "\n",
    "            # Calculate metrics\n",
    "            avg = \"binary\" if self.is_binary else \"weighted\"\n",
    "            \n",
    "            metrics = {\n",
    "                \"accuracy_train\": accuracy_score(self.y_train, y_hat_tr),\n",
    "                \"accuracy_test\": accuracy_score(self.y_test, y_hat_te),\n",
    "                \"precision_test\": precision_score(self.y_test, y_hat_te, average=avg, zero_division=0),\n",
    "                \"recall_test\": recall_score(self.y_test, y_hat_te, average=avg, zero_division=0),\n",
    "                \"f1_test\": f1_score(self.y_test, y_hat_te, average=avg, zero_division=0)\n",
    "            }\n",
    "\n",
    "            if self.is_binary:\n",
    "                try:\n",
    "                    metrics[\"roc_auc_test\"] = roc_auc_score(self.y_test, y_proba_te)\n",
    "                except ValueError as e:\n",
    "                    logger.warning(f\"Could not calculate ROC AUC: {e}\")\n",
    "                    metrics[\"roc_auc_test\"] = None\n",
    "\n",
    "            # Print results\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"MODEL EVALUATION RESULTS\")\n",
    "            print(\"=\"*50)\n",
    "            for metric_name, value in metrics.items():\n",
    "                if value is not None:\n",
    "                    print(f\"{metric_name:20}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{metric_name:20}: N/A\")\n",
    "            print(\"=\"*50)\n",
    "\n",
    "            return metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in evaluation: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ SAVE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def save(self, out_dir=\"xgb_final\"):\n",
    "        try:\n",
    "            if self.model is None:\n",
    "                raise RuntimeError(\"Model not trained. Call train() first!\")\n",
    "            \n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "            # Save model\n",
    "            model_path = os.path.join(out_dir, f\"xgb_model_{ts}.joblib\")\n",
    "            joblib.dump(self.model, model_path)\n",
    "            logger.info(f\"üíæ Model saved to: {model_path}\")\n",
    "\n",
    "            # Save encoders\n",
    "            if self.label_encoders:\n",
    "                encoder_path = os.path.join(out_dir, f\"encoders_{ts}.joblib\")\n",
    "                joblib.dump(self.label_encoders, encoder_path)\n",
    "                logger.info(f\"üíæ Encoders saved to: {encoder_path}\")\n",
    "\n",
    "            # Save feature names\n",
    "            if hasattr(self.X_train, \"columns\"):\n",
    "                features_path = os.path.join(out_dir, f\"features_{ts}.joblib\")\n",
    "                joblib.dump(list(self.X_train.columns), features_path)\n",
    "                logger.info(f\"üíæ Feature names saved to: {features_path}\")\n",
    "\n",
    "            return model_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in saving: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  MAIN\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def main():\n",
    "    try:\n",
    "        logger.info(\"üöÄ Starting XGBoost training pipeline...\")\n",
    "        \n",
    "        trainer = XGBoostFinalTrainer(\n",
    "            data_path=DATA_PATH,\n",
    "            target_column=TARGET_COLUMN,\n",
    "            drop_columns=DROP_COLUMNS,\n",
    "            test_frac=TEST_FRAC,\n",
    "            random_state=RANDOM_SEED\n",
    "        )\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        trainer.load_and_preprocess()\n",
    "        \n",
    "        # Train model\n",
    "        trainer.train(BEST_PARAMS)\n",
    "        \n",
    "        # Evaluate model\n",
    "        metrics = trainer.evaluate(plots=False)\n",
    "        \n",
    "        # Save model\n",
    "        model_path = trainer.save()\n",
    "\n",
    "        logger.info(\"üèÅ Training pipeline completed successfully!\")\n",
    "        return trainer, metrics, model_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainer, metrics, model_path = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2afaadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üîÑ Loading and preprocessing data once for all runs...\n",
      "INFO:__main__:üì• Loading data from: C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\n",
      "INFO:__main__:Loaded data shape: (20718, 67)\n",
      "INFO:__main__:Features shape: (20718, 66), Target shape: (20718,)\n",
      "INFO:__main__:Target value counts:\n",
      "target\n",
      "1    10751\n",
      "0     9967\n",
      "Name: count, dtype: int64\n",
      "INFO:__main__:Handling missing values...\n",
      "INFO:__main__:Encoding categorical columns: ['timestamp']\n",
      "INFO:__main__:Detected binary classification with 2 classes\n",
      "INFO:__main__:Train set: (16574, 66), Test set: (4144, 66)\n",
      "INFO:__main__:‚úÖ Data loaded successfully!\n",
      "INFO:__main__:üöÄ Starting parameter sweep with 10 configurations...\n",
      "INFO:__main__:\n",
      "‚öôÔ∏è  Run 1/10 (precision_opt_trial18)\n",
      "INFO:__main__:    Params: {'n_estimators': 1307, 'max_depth': 13, 'learning_rate': 0.024718249520416128, 'subsample': 0.9476077563455207, 'colsample_bytree': 0.8927667771131523, 'colsample_bylevel': 0.7500327051538141, 'colsample_bynode': 0.9496606563368475, 'reg_alpha': 0.002330119002013363, 'reg_lambda': 0.0006033236716118722, 'min_child_weight': 8, 'gamma': 2.664811828490935, 'max_bin': 481}\n",
      "INFO:__main__:üöÄ Starting model training...\n",
      "INFO:__main__:Training split: train=13259, val=3315\n",
      "INFO:__main__:Training XGBoost model...\n",
      "INFO:__main__:XGBoost version: 3.0.2\n",
      "ERROR:__main__:Error during model fitting: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "INFO:__main__:Trying without early stopping...\n",
      "INFO:__main__:‚úì Training completed with 1307 estimators\n",
      "INFO:__main__:üìä Evaluating model...\n",
      "INFO:__main__:‚úÖ Run 1 completed in 2.2s - F1: 0.4702\n",
      "INFO:__main__:\n",
      "‚öôÔ∏è  Run 2/10 (precision_opt_trial9)\n",
      "INFO:__main__:    Params: {'n_estimators': 534, 'max_depth': 4, 'learning_rate': 0.01898772399339208, 'subsample': 0.6644885149016018, 'colsample_bytree': 0.9718790609370292, 'colsample_bylevel': 0.9232481518257668, 'colsample_bynode': 0.8533615026041694, 'reg_alpha': 0.6968596391373533, 'reg_lambda': 0.1710207048797339, 'min_child_weight': 2, 'gamma': 4.462794992449889, 'max_bin': 394}\n",
      "INFO:__main__:üöÄ Starting model training...\n",
      "INFO:__main__:Training split: train=13259, val=3315\n",
      "INFO:__main__:Training XGBoost model...\n",
      "INFO:__main__:XGBoost version: 3.0.2\n",
      "ERROR:__main__:Error during model fitting: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "INFO:__main__:Trying without early stopping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "==================================================\n",
      "accuracy_train      : 0.8313\n",
      "accuracy_test       : 0.5133\n",
      "precision_test      : 0.5315\n",
      "recall_test         : 0.4216\n",
      "f1_test             : 0.4702\n",
      "roc_auc_test        : 0.5300\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úì Training completed with 534 estimators\n",
      "INFO:__main__:üìä Evaluating model...\n",
      "INFO:__main__:‚úÖ Run 2 completed in 0.7s - F1: 0.4748\n",
      "INFO:__main__:\n",
      "‚öôÔ∏è  Run 3/10 (precision_opt_trial2)\n",
      "INFO:__main__:    Params: {'n_estimators': 966, 'max_depth': 13, 'learning_rate': 0.01254057843022616, 'subsample': 0.8056937753654446, 'colsample_bytree': 0.836965827544817, 'colsample_bylevel': 0.6185801650879991, 'colsample_bynode': 0.8430179407605753, 'reg_alpha': 3.425445902633376e-07, 'reg_lambda': 3.850031979199519e-08, 'min_child_weight': 10, 'gamma': 4.828160165372797, 'max_bin': 463}\n",
      "INFO:__main__:üöÄ Starting model training...\n",
      "INFO:__main__:Training split: train=13259, val=3315\n",
      "INFO:__main__:Training XGBoost model...\n",
      "INFO:__main__:XGBoost version: 3.0.2\n",
      "ERROR:__main__:Error during model fitting: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "INFO:__main__:Trying without early stopping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "==================================================\n",
      "accuracy_train      : 0.6321\n",
      "accuracy_test       : 0.5270\n",
      "precision_test      : 0.5507\n",
      "recall_test         : 0.4173\n",
      "f1_test             : 0.4748\n",
      "roc_auc_test        : 0.5344\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úì Training completed with 966 estimators\n",
      "INFO:__main__:üìä Evaluating model...\n",
      "INFO:__main__:‚úÖ Run 3 completed in 1.5s - F1: 0.4982\n",
      "INFO:__main__:\n",
      "‚öôÔ∏è  Run 4/10 (precision_opt_trial25)\n",
      "INFO:__main__:    Params: {'n_estimators': 1297, 'max_depth': 14, 'learning_rate': 0.032677079513305216, 'subsample': 0.920158613666429, 'colsample_bytree': 0.8176021736804028, 'colsample_bylevel': 0.635663367103597, 'colsample_bynode': 0.8074879828556969, 'reg_alpha': 0.00422918163231331, 'reg_lambda': 2.6434085113630614e-07, 'min_child_weight': 7, 'gamma': 4.315961451395856, 'max_bin': 464}\n",
      "INFO:__main__:üöÄ Starting model training...\n",
      "INFO:__main__:Training split: train=13259, val=3315\n",
      "INFO:__main__:Training XGBoost model...\n",
      "INFO:__main__:XGBoost version: 3.0.2\n",
      "ERROR:__main__:Error during model fitting: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "INFO:__main__:Trying without early stopping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "==================================================\n",
      "accuracy_train      : 0.7026\n",
      "accuracy_test       : 0.5236\n",
      "precision_test      : 0.5411\n",
      "recall_test         : 0.4616\n",
      "f1_test             : 0.4982\n",
      "roc_auc_test        : 0.5303\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úì Training completed with 1297 estimators\n",
      "INFO:__main__:üìä Evaluating model...\n",
      "INFO:__main__:‚úÖ Run 4 completed in 1.3s - F1: 0.4924\n",
      "INFO:__main__:\n",
      "‚öôÔ∏è  Run 5/10 (precision_opt_trial22)\n",
      "INFO:__main__:    Params: {'n_estimators': 1869, 'max_depth': 11, 'learning_rate': 0.029785466048449057, 'subsample': 0.9600239834936011, 'colsample_bytree': 0.7984617451987015, 'colsample_bylevel': 0.7596781750650533, 'colsample_bynode': 0.9578920226477285, 'reg_alpha': 1.8469408002336966e-07, 'reg_lambda': 2.687788315138241e-06, 'min_child_weight': 10, 'gamma': 4.55767033074189, 'max_bin': 484}\n",
      "INFO:__main__:üöÄ Starting model training...\n",
      "INFO:__main__:Training split: train=13259, val=3315\n",
      "INFO:__main__:Training XGBoost model...\n",
      "INFO:__main__:XGBoost version: 3.0.2\n",
      "ERROR:__main__:Error during model fitting: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "INFO:__main__:Trying without early stopping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "==================================================\n",
      "accuracy_train      : 0.7456\n",
      "accuracy_test       : 0.5215\n",
      "precision_test      : 0.5392\n",
      "recall_test         : 0.4531\n",
      "f1_test             : 0.4924\n",
      "roc_auc_test        : 0.5267\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úì Training completed with 1869 estimators\n",
      "INFO:__main__:üìä Evaluating model...\n",
      "INFO:__main__:‚úÖ Run 5 completed in 1.5s - F1: 0.5265\n",
      "INFO:__main__:\n",
      "‚öôÔ∏è  Run 6/10 (f1_opt_trial76)\n",
      "INFO:__main__:    Params: {'n_estimators': 105, 'max_depth': 8, 'learning_rate': 0.005040041472632554, 'subsample': 0.7315045755029569, 'colsample_bytree': 0.6978876037786749, 'colsample_bylevel': 0.8270460042189236, 'colsample_bynode': 0.6107312168264377, 'reg_alpha': 2.2521102114594034, 'reg_lambda': 0.00038525640227419795, 'min_child_weight': 6, 'gamma': 3.194247833014993, 'max_bin': 391}\n",
      "INFO:__main__:üöÄ Starting model training...\n",
      "INFO:__main__:Training split: train=13259, val=3315\n",
      "INFO:__main__:Training XGBoost model...\n",
      "INFO:__main__:XGBoost version: 3.0.2\n",
      "ERROR:__main__:Error during model fitting: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "INFO:__main__:Trying without early stopping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "==================================================\n",
      "accuracy_train      : 0.7095\n",
      "accuracy_test       : 0.5234\n",
      "precision_test      : 0.5361\n",
      "recall_test         : 0.5172\n",
      "f1_test             : 0.5265\n",
      "roc_auc_test        : 0.5274\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úì Training completed with 105 estimators\n",
      "INFO:__main__:üìä Evaluating model...\n",
      "INFO:__main__:‚úÖ Run 6 completed in 0.5s - F1: 0.6430\n",
      "INFO:__main__:\n",
      "‚öôÔ∏è  Run 7/10 (f1_opt_trial63)\n",
      "INFO:__main__:    Params: {'n_estimators': 107, 'max_depth': 7, 'learning_rate': 0.007331979140441173, 'subsample': 0.6772174715021827, 'colsample_bytree': 0.8238805270933549, 'colsample_bylevel': 0.7730466620963483, 'colsample_bynode': 0.6682429822080043, 'reg_alpha': 5.409756188443174, 'reg_lambda': 0.0015524839266472987, 'min_child_weight': 6, 'gamma': 3.7995867106505936, 'max_bin': 365}\n",
      "INFO:__main__:üöÄ Starting model training...\n",
      "INFO:__main__:Training split: train=13259, val=3315\n",
      "INFO:__main__:Training XGBoost model...\n",
      "INFO:__main__:XGBoost version: 3.0.2\n",
      "ERROR:__main__:Error during model fitting: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "INFO:__main__:Trying without early stopping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "==================================================\n",
      "accuracy_train      : 0.5891\n",
      "accuracy_test       : 0.5220\n",
      "precision_test      : 0.5207\n",
      "recall_test         : 0.8403\n",
      "f1_test             : 0.6430\n",
      "roc_auc_test        : 0.5506\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úì Training completed with 107 estimators\n",
      "INFO:__main__:üìä Evaluating model...\n",
      "INFO:__main__:‚úÖ Run 7 completed in 0.3s - F1: 0.6481\n",
      "INFO:__main__:\n",
      "‚öôÔ∏è  Run 8/10 (f1_opt_trial99)\n",
      "INFO:__main__:    Params: {'n_estimators': 152, 'max_depth': 10, 'learning_rate': 0.005240578329731185, 'subsample': 0.7651730607230356, 'colsample_bytree': 0.6318385953435955, 'colsample_bylevel': 0.916547265646687, 'colsample_bynode': 0.6225529059741628, 'reg_alpha': 6.128116326056999, 'reg_lambda': 0.019433498280224788, 'min_child_weight': 5, 'gamma': 2.424062851363187, 'max_bin': 410}\n",
      "INFO:__main__:üöÄ Starting model training...\n",
      "INFO:__main__:Training split: train=13259, val=3315\n",
      "INFO:__main__:Training XGBoost model...\n",
      "INFO:__main__:XGBoost version: 3.0.2\n",
      "ERROR:__main__:Error during model fitting: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "INFO:__main__:Trying without early stopping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "==================================================\n",
      "accuracy_train      : 0.5726\n",
      "accuracy_test       : 0.5343\n",
      "precision_test      : 0.5287\n",
      "recall_test         : 0.8370\n",
      "f1_test             : 0.6481\n",
      "roc_auc_test        : 0.5538\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úì Training completed with 152 estimators\n",
      "INFO:__main__:üìä Evaluating model...\n",
      "INFO:__main__:‚úÖ Run 8 completed in 0.6s - F1: 0.6462\n",
      "INFO:__main__:\n",
      "‚öôÔ∏è  Run 9/10 (f1_opt_trial77)\n",
      "INFO:__main__:    Params: {'n_estimators': 103, 'max_depth': 9, 'learning_rate': 0.005217000368658448, 'subsample': 0.7308153424745538, 'colsample_bytree': 0.6964248488818299, 'colsample_bylevel': 0.8778333045131583, 'colsample_bynode': 0.6116428797860312, 'reg_alpha': 0.7200783783474446, 'reg_lambda': 0.0002441557634829753, 'min_child_weight': 6, 'gamma': 3.2496190417438267, 'max_bin': 408}\n",
      "INFO:__main__:üöÄ Starting model training...\n",
      "INFO:__main__:Training split: train=13259, val=3315\n",
      "INFO:__main__:Training XGBoost model...\n",
      "INFO:__main__:XGBoost version: 3.0.2\n",
      "ERROR:__main__:Error during model fitting: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "INFO:__main__:Trying without early stopping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "==================================================\n",
      "accuracy_train      : 0.5947\n",
      "accuracy_test       : 0.5244\n",
      "precision_test      : 0.5220\n",
      "recall_test         : 0.8479\n",
      "f1_test             : 0.6462\n",
      "roc_auc_test        : 0.5524\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úì Training completed with 103 estimators\n",
      "INFO:__main__:üìä Evaluating model...\n",
      "INFO:__main__:‚úÖ Run 9 completed in 0.7s - F1: 0.6241\n",
      "INFO:__main__:\n",
      "‚öôÔ∏è  Run 10/10 (f1_opt_trial98)\n",
      "INFO:__main__:    Params: {'n_estimators': 153, 'max_depth': 10, 'learning_rate': 0.0050016463516870035, 'subsample': 0.7648437723083729, 'colsample_bytree': 0.6550043886733103, 'colsample_bylevel': 0.8978287244153174, 'colsample_bynode': 0.6006227499667893, 'reg_alpha': 2.5277019263753244, 'reg_lambda': 0.009024542068296396, 'min_child_weight': 5, 'gamma': 2.6021269907013367, 'max_bin': 430}\n",
      "INFO:__main__:üöÄ Starting model training...\n",
      "INFO:__main__:Training split: train=13259, val=3315\n",
      "INFO:__main__:Training XGBoost model...\n",
      "INFO:__main__:XGBoost version: 3.0.2\n",
      "ERROR:__main__:Error during model fitting: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "INFO:__main__:Trying without early stopping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "==================================================\n",
      "accuracy_train      : 0.6274\n",
      "accuracy_test       : 0.5282\n",
      "precision_test      : 0.5273\n",
      "recall_test         : 0.7645\n",
      "f1_test             : 0.6241\n",
      "roc_auc_test        : 0.5428\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úì Training completed with 153 estimators\n",
      "INFO:__main__:üìä Evaluating model...\n",
      "INFO:__main__:‚úÖ Run 10 completed in 1.0s - F1: 0.6190\n",
      "INFO:__main__:\n",
      "üèÅ Parameter sweep completed in 10.6 seconds\n",
      "INFO:__main__:‚úÖ Successful runs: 10/10\n",
      "INFO:__main__:‚ùå Failed runs: 0/10\n",
      "INFO:__main__:üíæ Results saved to: parameter_sweep_results\\parameter_sweep_results_20250612_171847.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "==================================================\n",
      "accuracy_train      : 0.6575\n",
      "accuracy_test       : 0.5316\n",
      "precision_test      : 0.5306\n",
      "recall_test         : 0.7428\n",
      "f1_test             : 0.6190\n",
      "roc_auc_test        : 0.5437\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "üèÜ PARAMETER SWEEP RESULTS\n",
      "================================================================================\n",
      "\n",
      "üìà BEST MODELS:\n",
      "ü•á Best F1 Score:     0.6481 (Run 7)\n",
      "üéØ Best Precision:    0.5507 (Run 2)\n",
      "üîç Best Recall:       0.8479 (Run 8)\n",
      "‚öñÔ∏è  Best Accuracy:     0.5343 (Run 7)\n",
      "\n",
      "üìä TOP 5 MODELS BY F1 SCORE:\n",
      " run_id         source  f1_test  precision_test  recall_test  accuracy_test  training_time_sec\n",
      "      7 f1_opt_trial63   0.6481          0.5287       0.8370         0.5343             0.2900\n",
      "      8 f1_opt_trial99   0.6462          0.5220       0.8479         0.5244             0.6500\n",
      "      6 f1_opt_trial76   0.6430          0.5207       0.8403         0.5220             0.4500\n",
      "      9 f1_opt_trial77   0.6241          0.5273       0.7645         0.5282             0.6600\n",
      "     10 f1_opt_trial98   0.6190          0.5306       0.7428         0.5316             1.0400\n",
      "\n",
      "üìã ALL RESULTS (sorted by F1 score):\n",
      " run_id                source  f1_test  precision_test  recall_test  accuracy_test  overfitting  training_time_sec\n",
      "      7        f1_opt_trial63   0.6481          0.5287       0.8370         0.5343       0.0384             0.2900\n",
      "      8        f1_opt_trial99   0.6462          0.5220       0.8479         0.5244       0.0704             0.6500\n",
      "      6        f1_opt_trial76   0.6430          0.5207       0.8403         0.5220       0.0671             0.4500\n",
      "      9        f1_opt_trial77   0.6241          0.5273       0.7645         0.5282       0.0992             0.6600\n",
      "     10        f1_opt_trial98   0.6190          0.5306       0.7428         0.5316       0.1259             1.0400\n",
      "      5 precision_opt_trial22   0.5265          0.5361       0.5172         0.5234       0.1861             1.5500\n",
      "      3  precision_opt_trial2   0.4982          0.5411       0.4616         0.5236       0.1790             1.5300\n",
      "      4 precision_opt_trial25   0.4924          0.5392       0.4531         0.5215       0.2241             1.3000\n",
      "      2  precision_opt_trial9   0.4748          0.5507       0.4173         0.5270       0.1051             0.6800\n",
      "      1 precision_opt_trial18   0.4702          0.5315       0.4216         0.5133       0.3180             2.2100\n",
      "================================================================================\n",
      "\n",
      "üéØ BEST PARAMETERS (by f1_test):\n",
      "Score: 0.6481\n",
      "n_estimators: 107\n",
      "max_depth: 7\n",
      "learning_rate: 0.007331979140441173\n",
      "reg_alpha: 5.409756188443174\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def run_parameter_sweep():\n",
    "    \"\"\"\n",
    "    Enhanced parameter sweep with better efficiency and analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # üéØ PARAMETER COMBINATIONS TO TEST\n",
    "    all_param_sets = [\n",
    "        # TOP 5 BY PRECISION (from F0.5 optimization)\n",
    "        {\n",
    "            \"n_estimators\": 1307, \"max_depth\": 13, \"learning_rate\": 0.024718249520416128,\n",
    "            \"subsample\": 0.9476077563455207, \"colsample_bytree\": 0.8927667771131523,\n",
    "            \"colsample_bylevel\": 0.7500327051538141, \"colsample_bynode\": 0.9496606563368475,\n",
    "            \"reg_alpha\": 0.002330119002013363, \"reg_lambda\": 0.0006033236716118722,\n",
    "            \"min_child_weight\": 8, \"gamma\": 2.664811828490935, \"max_bin\": 481,\n",
    "            \"source\": \"precision_opt_trial18\"\n",
    "        },\n",
    "        {\n",
    "            \"n_estimators\": 534, \"max_depth\": 4, \"learning_rate\": 0.01898772399339208,\n",
    "            \"subsample\": 0.6644885149016018, \"colsample_bytree\": 0.9718790609370292,\n",
    "            \"colsample_bylevel\": 0.9232481518257668, \"colsample_bynode\": 0.8533615026041694,\n",
    "            \"reg_alpha\": 0.6968596391373533, \"reg_lambda\": 0.1710207048797339,\n",
    "            \"min_child_weight\": 2, \"gamma\": 4.462794992449889, \"max_bin\": 394,\n",
    "            \"source\": \"precision_opt_trial9\"\n",
    "        },\n",
    "        {\n",
    "            \"n_estimators\": 966, \"max_depth\": 13, \"learning_rate\": 0.01254057843022616,\n",
    "            \"subsample\": 0.8056937753654446, \"colsample_bytree\": 0.836965827544817,\n",
    "            \"colsample_bylevel\": 0.6185801650879991, \"colsample_bynode\": 0.8430179407605753,\n",
    "            \"reg_alpha\": 3.425445902633376e-07, \"reg_lambda\": 3.850031979199519e-08,\n",
    "            \"min_child_weight\": 10, \"gamma\": 4.828160165372797, \"max_bin\": 463,\n",
    "            \"source\": \"precision_opt_trial2\"\n",
    "        },\n",
    "        {\n",
    "            \"n_estimators\": 1297, \"max_depth\": 14, \"learning_rate\": 0.032677079513305216,\n",
    "            \"subsample\": 0.920158613666429, \"colsample_bytree\": 0.8176021736804028,\n",
    "            \"colsample_bylevel\": 0.635663367103597, \"colsample_bynode\": 0.8074879828556969,\n",
    "            \"reg_alpha\": 0.00422918163231331, \"reg_lambda\": 2.6434085113630614e-07,\n",
    "            \"min_child_weight\": 7, \"gamma\": 4.315961451395856, \"max_bin\": 464,\n",
    "            \"source\": \"precision_opt_trial25\"\n",
    "        },\n",
    "        {\n",
    "            \"n_estimators\": 1869, \"max_depth\": 11, \"learning_rate\": 0.029785466048449057,\n",
    "            \"subsample\": 0.9600239834936011, \"colsample_bytree\": 0.7984617451987015,\n",
    "            \"colsample_bylevel\": 0.7596781750650533, \"colsample_bynode\": 0.9578920226477285,\n",
    "            \"reg_alpha\": 1.8469408002336966e-07, \"reg_lambda\": 2.687788315138241e-06,\n",
    "            \"min_child_weight\": 10, \"gamma\": 4.55767033074189, \"max_bin\": 484,\n",
    "            \"source\": \"precision_opt_trial22\"\n",
    "        },\n",
    "        \n",
    "        # TOP 5 BY F1 SCORE (from F0.5 optimization)\n",
    "        {\n",
    "            \"n_estimators\": 105, \"max_depth\": 8, \"learning_rate\": 0.005040041472632554,\n",
    "            \"subsample\": 0.7315045755029569, \"colsample_bytree\": 0.6978876037786749,\n",
    "            \"colsample_bylevel\": 0.8270460042189236, \"colsample_bynode\": 0.6107312168264377,\n",
    "            \"reg_alpha\": 2.2521102114594034, \"reg_lambda\": 0.00038525640227419795,\n",
    "            \"min_child_weight\": 6, \"gamma\": 3.194247833014993, \"max_bin\": 391,\n",
    "            \"source\": \"f1_opt_trial76\"\n",
    "        },\n",
    "        {\n",
    "            \"n_estimators\": 107, \"max_depth\": 7, \"learning_rate\": 0.007331979140441173,\n",
    "            \"subsample\": 0.6772174715021827, \"colsample_bytree\": 0.8238805270933549,\n",
    "            \"colsample_bylevel\": 0.7730466620963483, \"colsample_bynode\": 0.6682429822080043,\n",
    "            \"reg_alpha\": 5.409756188443174, \"reg_lambda\": 0.0015524839266472987,\n",
    "            \"min_child_weight\": 6, \"gamma\": 3.7995867106505936, \"max_bin\": 365,\n",
    "            \"source\": \"f1_opt_trial63\"\n",
    "        },\n",
    "        {\n",
    "            \"n_estimators\": 152, \"max_depth\": 10, \"learning_rate\": 0.005240578329731185,\n",
    "            \"subsample\": 0.7651730607230356, \"colsample_bytree\": 0.6318385953435955,\n",
    "            \"colsample_bylevel\": 0.916547265646687, \"colsample_bynode\": 0.6225529059741628,\n",
    "            \"reg_alpha\": 6.128116326056999, \"reg_lambda\": 0.019433498280224788,\n",
    "            \"min_child_weight\": 5, \"gamma\": 2.424062851363187, \"max_bin\": 410,\n",
    "            \"source\": \"f1_opt_trial99\"\n",
    "        },\n",
    "        {\n",
    "            \"n_estimators\": 103, \"max_depth\": 9, \"learning_rate\": 0.005217000368658448,\n",
    "            \"subsample\": 0.7308153424745538, \"colsample_bytree\": 0.6964248488818299,\n",
    "            \"colsample_bylevel\": 0.8778333045131583, \"colsample_bynode\": 0.6116428797860312,\n",
    "            \"reg_alpha\": 0.7200783783474446, \"reg_lambda\": 0.0002441557634829753,\n",
    "            \"min_child_weight\": 6, \"gamma\": 3.2496190417438267, \"max_bin\": 408,\n",
    "            \"source\": \"f1_opt_trial77\"\n",
    "        },\n",
    "        {\n",
    "            \"n_estimators\": 153, \"max_depth\": 10, \"learning_rate\": 0.0050016463516870035,\n",
    "            \"subsample\": 0.7648437723083729, \"colsample_bytree\": 0.6550043886733103,\n",
    "            \"colsample_bylevel\": 0.8978287244153174, \"colsample_bynode\": 0.6006227499667893,\n",
    "            \"reg_alpha\": 2.5277019263753244, \"reg_lambda\": 0.009024542068296396,\n",
    "            \"min_child_weight\": 5, \"gamma\": 2.6021269907013367, \"max_bin\": 430,\n",
    "            \"source\": \"f1_opt_trial98\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # üìä RESULTS STORAGE\n",
    "    results = []\n",
    "    failed_runs = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # üîÑ LOAD DATA ONCE (efficiency improvement)\n",
    "    logger.info(\"üîÑ Loading and preprocessing data once for all runs...\")\n",
    "    try:\n",
    "        base_trainer = XGBoostFinalTrainer(\n",
    "            data_path=DATA_PATH,\n",
    "            target_column=TARGET_COLUMN,\n",
    "            drop_columns=DROP_COLUMNS,\n",
    "            test_frac=TEST_FRAC,\n",
    "            random_state=RANDOM_SEED\n",
    "        )\n",
    "        base_trainer.load_and_preprocess()\n",
    "        logger.info(\"‚úÖ Data loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to load data: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # üèÉ‚Äç‚ôÇÔ∏è RUN PARAMETER SWEEP\n",
    "    total_runs = len(all_param_sets)\n",
    "    logger.info(f\"üöÄ Starting parameter sweep with {total_runs} configurations...\")\n",
    "    \n",
    "    for i, param_set in enumerate(all_param_sets, 1):\n",
    "        run_start = time.time()\n",
    "        params = param_set.copy()\n",
    "        source = params.pop(\"source\", \"unknown\")\n",
    "        \n",
    "        logger.info(f\"\\n‚öôÔ∏è  Run {i}/{total_runs} ({source})\")\n",
    "        logger.info(f\"    Params: {params}\")\n",
    "        \n",
    "        try:\n",
    "            # Create new trainer instance with same preprocessed data\n",
    "            trainer = XGBoostFinalTrainer(\n",
    "                data_path=DATA_PATH,\n",
    "                target_column=TARGET_COLUMN,\n",
    "                drop_columns=DROP_COLUMNS,\n",
    "                test_frac=TEST_FRAC,\n",
    "                random_state=RANDOM_SEED\n",
    "            )\n",
    "            \n",
    "            # Copy preprocessed data instead of reloading\n",
    "            trainer.X_train = base_trainer.X_train.copy()\n",
    "            trainer.X_test = base_trainer.X_test.copy()\n",
    "            trainer.y_train = base_trainer.y_train.copy()\n",
    "            trainer.y_test = base_trainer.y_test.copy()\n",
    "            trainer.is_binary = base_trainer.is_binary\n",
    "            trainer.label_encoders = base_trainer.label_encoders.copy()\n",
    "            \n",
    "            # Train with current parameters\n",
    "            trainer.train(params)\n",
    "            metrics = trainer.evaluate(plots=False)\n",
    "            \n",
    "            run_time = time.time() - run_start\n",
    "            \n",
    "            # Store results\n",
    "            result = {\n",
    "                \"run_id\": i,\n",
    "                \"source\": source,\n",
    "                \"training_time_sec\": round(run_time, 2),\n",
    "                \n",
    "                # Parameters\n",
    "                \"n_estimators\": params.get(\"n_estimators\"),\n",
    "                \"max_depth\": params.get(\"max_depth\"),\n",
    "                \"learning_rate\": params.get(\"learning_rate\"),\n",
    "                \"reg_alpha\": params.get(\"reg_alpha\"),\n",
    "                \n",
    "                # Metrics\n",
    "                \"accuracy_train\": metrics.get(\"accuracy_train\", 0),\n",
    "                \"accuracy_test\": metrics.get(\"accuracy_test\", 0),\n",
    "                \"precision_test\": metrics.get(\"precision_test\", 0),\n",
    "                \"recall_test\": metrics.get(\"recall_test\", 0),\n",
    "                \"f1_test\": metrics.get(\"f1_test\", 0),\n",
    "                \"roc_auc_test\": metrics.get(\"roc_auc_test\", 0),\n",
    "                \n",
    "                # Overfitting indicator\n",
    "                \"overfitting\": metrics.get(\"accuracy_train\", 0) - metrics.get(\"accuracy_test\", 0)\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            logger.info(f\"‚úÖ Run {i} completed in {run_time:.1f}s - F1: {result['f1_test']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            run_time = time.time() - run_start\n",
    "            logger.error(f\"‚ùå Run {i} failed after {run_time:.1f}s: {str(e)[:100]}...\")\n",
    "            failed_runs.append({\n",
    "                \"run_id\": i,\n",
    "                \"source\": source,\n",
    "                \"params\": params,\n",
    "                \"error\": str(e)[:200]\n",
    "            })\n",
    "    \n",
    "    # üìà ANALYSIS AND RESULTS\n",
    "    total_time = time.time() - start_time\n",
    "    logger.info(f\"\\nüèÅ Parameter sweep completed in {total_time:.1f} seconds\")\n",
    "    logger.info(f\"‚úÖ Successful runs: {len(results)}/{total_runs}\")\n",
    "    logger.info(f\"‚ùå Failed runs: {len(failed_runs)}/{total_runs}\")\n",
    "    \n",
    "    if not results:\n",
    "        logger.error(\"No successful runs - cannot proceed with analysis\")\n",
    "        return None, pd.DataFrame(failed_runs) if failed_runs else None\n",
    "    \n",
    "    # Convert to DataFrame and analyze\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # üèÜ FIND BEST MODELS\n",
    "    best_f1 = df_results.loc[df_results['f1_test'].idxmax()]\n",
    "    best_precision = df_results.loc[df_results['precision_test'].idxmax()]\n",
    "    best_recall = df_results.loc[df_results['recall_test'].idxmax()]\n",
    "    best_balanced = df_results.loc[df_results['accuracy_test'].idxmax()]\n",
    "    \n",
    "    # Sort by F1 score (or change to your preferred metric)\n",
    "    df_results = df_results.sort_values(by=\"f1_test\", ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # üìä SUMMARY REPORT\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üèÜ PARAMETER SWEEP RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nüìà BEST MODELS:\")\n",
    "    print(f\"ü•á Best F1 Score:     {best_f1['f1_test']:.4f} (Run {best_f1['run_id']})\")\n",
    "    print(f\"üéØ Best Precision:    {best_precision['precision_test']:.4f} (Run {best_precision['run_id']})\")\n",
    "    print(f\"üîç Best Recall:       {best_recall['recall_test']:.4f} (Run {best_recall['run_id']})\")\n",
    "    print(f\"‚öñÔ∏è  Best Accuracy:     {best_balanced['accuracy_test']:.4f} (Run {best_balanced['run_id']})\")\n",
    "    \n",
    "    print(f\"\\nüìä TOP 5 MODELS BY F1 SCORE:\")\n",
    "    top_5 = df_results.head(5)[['run_id', 'source', 'f1_test', 'precision_test', 'recall_test', 'accuracy_test', 'training_time_sec']]\n",
    "    print(top_5.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    if len(failed_runs) > 0:\n",
    "        print(f\"\\n‚ùå FAILED RUNS:\")\n",
    "        df_failed = pd.DataFrame(failed_runs)\n",
    "        print(df_failed[['run_id', 'source', 'error']].to_string(index=False))\n",
    "    \n",
    "    # üìã DETAILED RESULTS\n",
    "    print(f\"\\nüìã ALL RESULTS (sorted by F1 score):\")\n",
    "    display_cols = ['run_id', 'source', 'f1_test', 'precision_test', 'recall_test', \n",
    "                   'accuracy_test', 'overfitting', 'training_time_sec']\n",
    "    print(df_results[display_cols].to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return df_results, df_failed if failed_runs else None\n",
    "\n",
    "\n",
    "def get_best_params(df_results, metric='f1_test'):\n",
    "    \"\"\"\n",
    "    Extract the best parameter set based on specified metric\n",
    "    \"\"\"\n",
    "    if df_results is None or df_results.empty:\n",
    "        return None\n",
    "    \n",
    "    best_row = df_results.loc[df_results[metric].idxmax()]\n",
    "    \n",
    "    best_params = {\n",
    "        \"n_estimators\": int(best_row[\"n_estimators\"]),\n",
    "        \"max_depth\": int(best_row[\"max_depth\"]),\n",
    "        \"learning_rate\": float(best_row[\"learning_rate\"]),\n",
    "        \"reg_alpha\": float(best_row[\"reg_alpha\"])\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüéØ BEST PARAMETERS (by {metric}):\")\n",
    "    print(f\"Score: {best_row[metric]:.4f}\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "\n",
    "def save_results(df_results, df_failed=None, output_dir=\"parameter_sweep_results\"):\n",
    "    \"\"\"\n",
    "    Save results to CSV files with timestamp\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    if df_results is not None:\n",
    "        results_file = os.path.join(output_dir, f\"parameter_sweep_results_{timestamp}.csv\")\n",
    "        df_results.to_csv(results_file, index=False)\n",
    "        logger.info(f\"üíæ Results saved to: {results_file}\")\n",
    "    \n",
    "    if df_failed is not None and not df_failed.empty:\n",
    "        failed_file = os.path.join(output_dir, f\"parameter_sweep_failed_{timestamp}.csv\")\n",
    "        df_failed.to_csv(failed_file, index=False)\n",
    "        logger.info(f\"üíæ Failed runs saved to: {failed_file}\")\n",
    "\n",
    "\n",
    "# üöÄ UPDATED MAIN FUNCTION\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run parameter sweep\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run parameter sweep\n",
    "        df_results, df_failed = run_parameter_sweep()\n",
    "        \n",
    "        if df_results is not None:\n",
    "            # Get best parameters\n",
    "            best_params = get_best_params(df_results, metric='f1_test')\n",
    "            \n",
    "            # Save results\n",
    "            save_results(df_results, df_failed)\n",
    "            \n",
    "            return df_results, df_failed, best_params\n",
    "        else:\n",
    "            logger.error(\"Parameter sweep failed completely\")\n",
    "            return None, df_failed, None\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main function failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_results, df_failed, best_params = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc985e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üöÄ Starting Trial 9 (Best Precision) training pipeline...\n",
      "INFO:__main__:üì• Loading data for Trial 9 training...\n",
      "INFO:__main__:Loaded data shape: (20718, 67)\n",
      "INFO:__main__:Target distribution:\n",
      "target\n",
      "1    10751\n",
      "0     9967\n",
      "Name: count, dtype: int64\n",
      "INFO:__main__:Detected binary classification with classes: [0 1]\n",
      "INFO:__main__:Train set: (16574, 65), Test set: (4144, 65)\n",
      "INFO:__main__:Features: 65\n",
      "INFO:__main__:üöÄ Training Trial 9 (Best Precision) model...\n",
      "INFO:__main__:‚úì Training completed!\n",
      "INFO:__main__:üìä Evaluating Trial 9 model...\n",
      "INFO:__main__:üìä Generating predictions CSV...\n",
      "INFO:__main__:üíæ Predictions saved to: trial9_predictions.csv\n",
      "INFO:__main__:üìä Total predictions: 4144\n",
      "INFO:__main__:üíæ Trial 9 model saved to: trial9_model\\trial9_best_precision_20250612_172752.joblib\n",
      "INFO:__main__:üèÅ Trial 9 training and prediction generation completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ TRIAL 9 (BEST PRECISION) MODEL RESULTS\n",
      "============================================================\n",
      "Training Accuracy:   0.6476\n",
      "Test Accuracy:       0.5263\n",
      "Test Precision:      0.5567 üéØ\n",
      "Test Recall:         0.3702\n",
      "Test F1:             0.4447\n",
      "Test AUC:            0.5396\n",
      "Overfitting Gap:     0.1213\n",
      "============================================================\n",
      "\n",
      "üîç SAMPLE PREDICTIONS:\n",
      "          timestamp  prob_down  prob_up  winning_prob  prediction  actual\n",
      "2023-05-07 12:00:00   0.523782 0.476218      0.523782           0       0\n",
      "2023-05-07 16:00:00   0.591859 0.408141      0.591859           0       0\n",
      "2023-05-07 20:00:00   0.520758 0.479242      0.520758           0       0\n",
      "2023-05-08 00:00:00   0.447865 0.552135      0.552135           1       0\n",
      "2023-05-08 04:00:00   0.375828 0.624172      0.624172           1       0\n",
      "2023-05-08 08:00:00   0.428110 0.571890      0.571890           1       1\n",
      "2023-05-08 12:00:00   0.450084 0.549916      0.549916           1       1\n",
      "2023-05-08 16:00:00   0.522540 0.477460      0.522540           0       0\n",
      "2023-05-08 20:00:00   0.450983 0.549017      0.549017           1       1\n",
      "2023-05-09 00:00:00   0.470585 0.529415      0.529415           1       1\n",
      "\n",
      "üìà PREDICTION SUMMARY:\n",
      "Accuracy: 0.5263\n",
      "Precision: 0.5567\n",
      "Correct predictions: 2181/4144\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "#  Trial 9 (Best Precision) Model Trainer & Predictor\n",
    "# =============================================================\n",
    "import os, warnings, joblib\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, classification_report)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  CONFIG - TRIAL 9 BEST PRECISION PARAMETERS\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "DATA_PATH = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\"\n",
    "TARGET_COLUMN = \"target\"\n",
    "DROP_COLUMNS = [\"timestamp\"]  # We'll keep timestamp for predictions\n",
    "TEST_FRAC = 0.20\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# TRIAL 9 BEST PRECISION PARAMETERS\n",
    "TRIAL9_PARAMS = {\n",
    "    \"n_estimators\": 534,\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.01898772399339208,\n",
    "    \"subsample\": 0.6644885149016018,\n",
    "    \"colsample_bytree\": 0.9718790609370292,\n",
    "    \"colsample_bylevel\": 0.9232481518257668,\n",
    "    \"colsample_bynode\": 0.8533615026041694,\n",
    "    \"reg_alpha\": 0.6968596391373533,\n",
    "    \"reg_lambda\": 0.1710207048797339,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"gamma\": 4.462794992449889,\n",
    "    \"max_bin\": 394,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"random_state\": RANDOM_SEED,\n",
    "    \"verbosity\": 1,\n",
    "    \"tree_method\": \"hist\",\n",
    "}\n",
    "\n",
    "\n",
    "class Trial9Trainer:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.label_encoders = {}\n",
    "        self.feature_columns = None\n",
    "        self.X_train = self.X_test = self.y_train = self.y_test = None\n",
    "        self.test_timestamps = None\n",
    "        \n",
    "    def load_and_preprocess(self):\n",
    "        \"\"\"Load and preprocess data, keeping timestamps for predictions\"\"\"\n",
    "        logger.info(\"üì• Loading data for Trial 9 training...\")\n",
    "        \n",
    "        if not os.path.exists(DATA_PATH):\n",
    "            raise FileNotFoundError(f\"Data file not found: {DATA_PATH}\")\n",
    "        \n",
    "        df = pd.read_csv(DATA_PATH)\n",
    "        logger.info(f\"Loaded data shape: {df.shape}\")\n",
    "        \n",
    "        if TARGET_COLUMN not in df.columns:\n",
    "            raise KeyError(f\"Target column '{TARGET_COLUMN}' not found\")\n",
    "\n",
    "        # Keep timestamps for later use\n",
    "        timestamps = df['timestamp'].copy()\n",
    "        \n",
    "        # Separate target and features\n",
    "        y = df[TARGET_COLUMN].copy()\n",
    "        X = df.drop(columns=[TARGET_COLUMN])  # Keep timestamp initially\n",
    "        \n",
    "        logger.info(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "\n",
    "        # Handle missing values in features (excluding timestamp)\n",
    "        feature_cols = [col for col in X.columns if col != 'timestamp']\n",
    "        for col in feature_cols:\n",
    "            if X[col].dtype in (\"object\", \"category\"):\n",
    "                mode_val = X[col].mode()\n",
    "                fill_val = mode_val.iloc[0] if len(mode_val) > 0 else \"unknown\"\n",
    "                X[col] = X[col].fillna(fill_val)\n",
    "            else:\n",
    "                X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "        # Handle missing targets\n",
    "        if y.isna().any():\n",
    "            mask = ~y.isna()\n",
    "            X, y, timestamps = X[mask].reset_index(drop=True), y[mask].reset_index(drop=True), timestamps[mask].reset_index(drop=True)\n",
    "\n",
    "        # Encode categorical variables (timestamp)\n",
    "        le_timestamp = LabelEncoder()\n",
    "        X['timestamp'] = le_timestamp.fit_transform(X['timestamp'].astype(str))\n",
    "        self.label_encoders['timestamp'] = le_timestamp\n",
    "\n",
    "        # Handle target encoding if needed\n",
    "        if y.dtype == \"object\":\n",
    "            le_target = LabelEncoder()\n",
    "            y = pd.Series(le_target.fit_transform(y), index=y.index)\n",
    "            self.label_encoders[\"target\"] = le_target\n",
    "\n",
    "        logger.info(f\"Detected binary classification with classes: {np.unique(y)}\")\n",
    "\n",
    "        # CHRONOLOGICAL SPLIT (keeping timestamps)\n",
    "        split_idx = int(len(X) * (1 - TEST_FRAC))\n",
    "        \n",
    "        self.X_train = X.iloc[:split_idx].reset_index(drop=True)\n",
    "        self.X_test = X.iloc[split_idx:].reset_index(drop=True)\n",
    "        self.y_train = y.iloc[:split_idx].reset_index(drop=True)\n",
    "        self.y_test = y.iloc[split_idx:].reset_index(drop=True)\n",
    "        \n",
    "        # Store test timestamps for predictions (before dropping timestamp column)\n",
    "        self.test_timestamps = timestamps.iloc[split_idx:].reset_index(drop=True)\n",
    "        \n",
    "        # Now drop timestamp from features for training\n",
    "        self.X_train = self.X_train.drop(columns=['timestamp'])\n",
    "        self.X_test = self.X_test.drop(columns=['timestamp'])\n",
    "        \n",
    "        # Store feature column names\n",
    "        self.feature_columns = list(self.X_train.columns)\n",
    "        \n",
    "        logger.info(f\"Train set: {self.X_train.shape}, Test set: {self.X_test.shape}\")\n",
    "        logger.info(f\"Features: {len(self.feature_columns)}\")\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the Trial 9 model\"\"\"\n",
    "        logger.info(\"üöÄ Training Trial 9 (Best Precision) model...\")\n",
    "        \n",
    "        self.model = xgb.XGBClassifier(**TRIAL9_PARAMS)\n",
    "        \n",
    "        # Train model\n",
    "        self.model.fit(self.X_train, self.y_train, verbose=False)\n",
    "        \n",
    "        logger.info(\"‚úì Training completed!\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate the trained model\"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not trained!\")\n",
    "\n",
    "        logger.info(\"üìä Evaluating Trial 9 model...\")\n",
    "\n",
    "        # Predictions\n",
    "        y_train_pred = self.model.predict(self.X_train)\n",
    "        y_test_pred = self.model.predict(self.X_test)\n",
    "        y_test_proba = self.model.predict_proba(self.X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_acc = accuracy_score(self.y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(self.y_test, y_test_pred)\n",
    "        test_precision = precision_score(self.y_test, y_test_pred, zero_division=0)\n",
    "        test_recall = recall_score(self.y_test, y_test_pred, zero_division=0)\n",
    "        test_f1 = f1_score(self.y_test, y_test_pred, zero_division=0)\n",
    "        test_auc = roc_auc_score(self.y_test, y_test_proba[:, 1])\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üéØ TRIAL 9 (BEST PRECISION) MODEL RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Training Accuracy:   {train_acc:.4f}\")\n",
    "        print(f\"Test Accuracy:       {test_acc:.4f}\")\n",
    "        print(f\"Test Precision:      {test_precision:.4f} üéØ\")\n",
    "        print(f\"Test Recall:         {test_recall:.4f}\")\n",
    "        print(f\"Test F1:             {test_f1:.4f}\")\n",
    "        print(f\"Test AUC:            {test_auc:.4f}\")\n",
    "        print(f\"Overfitting Gap:     {train_acc - test_acc:.4f}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return {\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"test_accuracy\": test_acc,\n",
    "            \"test_precision\": test_precision,\n",
    "            \"test_recall\": test_recall,\n",
    "            \"test_f1\": test_f1,\n",
    "            \"test_auc\": test_auc\n",
    "        }\n",
    "\n",
    "    def generate_predictions_csv(self, output_file=\"trial9_predictions.csv\"):\n",
    "        \"\"\"Generate predictions CSV in the requested format\"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not trained!\")\n",
    "\n",
    "        logger.info(\"üìä Generating predictions CSV...\")\n",
    "        \n",
    "        # Get probabilities for test set\n",
    "        y_test_proba = self.model.predict_proba(self.X_test)\n",
    "        y_test_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "        # Create predictions DataFrame\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'timestamp': self.test_timestamps,\n",
    "            'prob_down': y_test_proba[:, 0],  # Probability of class 0\n",
    "            'prob_up': y_test_proba[:, 1],    # Probability of class 1\n",
    "            'winning_prob': np.maximum(y_test_proba[:, 0], y_test_proba[:, 1]),  # Higher probability\n",
    "            'prediction': y_test_pred,\n",
    "            'actual': self.y_test\n",
    "        })\n",
    "        \n",
    "        # Round probabilities to 6 decimal places to match your format\n",
    "        predictions_df['prob_down'] = predictions_df['prob_down'].round(6)\n",
    "        predictions_df['prob_up'] = predictions_df['prob_up'].round(6)\n",
    "        predictions_df['winning_prob'] = predictions_df['winning_prob'].round(6)\n",
    "        \n",
    "        # Save to CSV\n",
    "        predictions_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        logger.info(f\"üíæ Predictions saved to: {output_file}\")\n",
    "        logger.info(f\"üìä Total predictions: {len(predictions_df)}\")\n",
    "        \n",
    "        # Show sample of predictions\n",
    "        print(\"\\nüîç SAMPLE PREDICTIONS:\")\n",
    "        print(predictions_df.head(10).to_string(index=False))\n",
    "        \n",
    "        # Calculate accuracy on predictions\n",
    "        accuracy = accuracy_score(predictions_df['actual'], predictions_df['prediction'])\n",
    "        precision = precision_score(predictions_df['actual'], predictions_df['prediction'], zero_division=0)\n",
    "        \n",
    "        print(f\"\\nüìà PREDICTION SUMMARY:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Correct predictions: {(predictions_df['prediction'] == predictions_df['actual']).sum()}/{len(predictions_df)}\")\n",
    "        \n",
    "        return predictions_df\n",
    "\n",
    "    def save_model(self, output_dir=\"trial9_model\"):\n",
    "        \"\"\"Save the trained model\"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not trained!\")\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save model\n",
    "        model_path = os.path.join(output_dir, f\"trial9_best_precision_{ts}.joblib\")\n",
    "        joblib.dump(self.model, model_path)\n",
    "        \n",
    "        # Save encoders and feature names\n",
    "        if self.label_encoders:\n",
    "            joblib.dump(self.label_encoders, os.path.join(output_dir, f\"trial9_encoders_{ts}.joblib\"))\n",
    "        \n",
    "        joblib.dump(self.feature_columns, os.path.join(output_dir, f\"trial9_features_{ts}.joblib\"))\n",
    "        \n",
    "        logger.info(f\"üíæ Trial 9 model saved to: {model_path}\")\n",
    "        return model_path\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to train Trial 9 model and generate predictions\"\"\"\n",
    "    logger.info(\"üöÄ Starting Trial 9 (Best Precision) training pipeline...\")\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Trial9Trainer()\n",
    "    \n",
    "    try:\n",
    "        # Load and preprocess data\n",
    "        trainer.load_and_preprocess()\n",
    "        \n",
    "        # Train model with Trial 9 parameters\n",
    "        trainer.train()\n",
    "        \n",
    "        # Evaluate model\n",
    "        metrics = trainer.evaluate()\n",
    "        \n",
    "        # Generate predictions CSV\n",
    "        predictions_df = trainer.generate_predictions_csv(\"trial9_predictions.csv\")\n",
    "        \n",
    "        # Save model\n",
    "        model_path = trainer.save_model()\n",
    "        \n",
    "        logger.info(\"üèÅ Trial 9 training and prediction generation completed!\")\n",
    "        \n",
    "        return trainer, metrics, predictions_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainer, metrics, predictions_df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a38d85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üöÄ Starting XGBoost training pipeline...\n",
      "INFO:__main__:üì• Loading data for XGBoost training...\n",
      "INFO:__main__:Loaded data shape: (20718, 67)\n",
      "INFO:__main__:üïê Parsing timestamps...\n",
      "INFO:__main__:Target distribution:\n",
      "target\n",
      "1    10751\n",
      "0     9967\n",
      "Name: count, dtype: int64\n",
      "INFO:__main__:Detected binary classification with classes: [0 1]\n",
      "INFO:__main__:Train set: (16574, 65), Test set: (4144, 65)\n",
      "INFO:__main__:Features: 65\n",
      "INFO:__main__:Test date range: 2023-05-07 12:00:00 to 2025-03-28 00:00:00\n",
      "INFO:__main__:üöÄ Training XGBoost model...\n",
      "INFO:__main__:‚úì Training completed!\n",
      "INFO:__main__:üìä Evaluating XGBoost model...\n",
      "INFO:__main__:üìä Generating predictions CSV...\n",
      "INFO:__main__:üíæ Predictions saved to: C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\Final_runs_csv\\xgboost_predictions_fixed.csv\n",
      "INFO:__main__:üìä Total predictions: 4144\n",
      "INFO:__main__:üìÖ Date range: 2023-05-07 12:00:00 to 2025-03-28 00:00:00\n",
      "INFO:__main__:üíæ XGBoost model saved to: C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\Final_runs_csv\\xgboost_model\\xgboost_model_20250614_120239.joblib\n",
      "INFO:__main__:üèÅ XGBoost training and prediction generation completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ XGBOOST MODEL RESULTS\n",
      "============================================================\n",
      "Training Accuracy:   0.7544\n",
      "Test Accuracy:       0.5309\n",
      "Test Precision:      0.5571\n",
      "Test Recall:         0.4112\n",
      "Test F1:             0.4732\n",
      "Test AUC:            0.5434\n",
      "Overfitting Gap:     0.2235\n",
      "============================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.66      0.58      2021\n",
      "           1       0.56      0.41      0.47      2123\n",
      "\n",
      "    accuracy                           0.53      4144\n",
      "   macro avg       0.54      0.53      0.53      4144\n",
      "weighted avg       0.54      0.53      0.52      4144\n",
      "\n",
      "\n",
      "üîç SAMPLE PREDICTIONS:\n",
      "          timestamp  prob_up  prob_down  winning_prob  prediction  actual\n",
      "2023-05-07 12:00:00 0.483700   0.516300      0.516300           0       0\n",
      "2023-05-07 16:00:00 0.444156   0.555844      0.555844           0       0\n",
      "2023-05-07 20:00:00 0.493198   0.506802      0.506802           0       0\n",
      "2023-05-08 00:00:00 0.582110   0.417890      0.582110           1       0\n",
      "2023-05-08 04:00:00 0.650563   0.349437      0.650563           1       0\n",
      "2023-05-08 08:00:00 0.628384   0.371616      0.628384           1       1\n",
      "2023-05-08 12:00:00 0.590084   0.409916      0.590084           1       1\n",
      "2023-05-08 16:00:00 0.484231   0.515769      0.515769           0       0\n",
      "2023-05-08 20:00:00 0.589556   0.410444      0.589556           1       1\n",
      "2023-05-09 00:00:00 0.530505   0.469495      0.530505           1       1\n",
      "\n",
      "üìà PREDICTION SUMMARY:\n",
      "Accuracy: 0.5309\n",
      "Precision: 0.5571\n",
      "Correct predictions: 2200/4144\n",
      "\n",
      "‚úÖ Timestamp format check:\n",
      "First timestamp: 2023-05-07 12:00:00\n",
      "Last timestamp: 2025-03-28 00:00:00\n",
      "Timestamp dtype: datetime64[ns]\n",
      "\n",
      "============================================================\n",
      "‚úì Original backed up to: xgboost_predictions_backup.csv\n",
      "‚úì Original file replaced with fixed version\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "#  XGBoost Model Trainer & Predictor (Fixed Timestamps)\n",
    "# =============================================================\n",
    "import os, warnings, joblib\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, classification_report)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  CONFIG - XGBOOST PARAMETERS\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "DATA_PATH = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\"\n",
    "OUTPUT_PATH = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\Final_runs_csv\"\n",
    "TARGET_COLUMN = \"target\"\n",
    "DROP_COLUMNS = [\"timestamp\"]  # We'll keep timestamp for predictions\n",
    "TEST_FRAC = 0.20\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# You can adjust these XGBoost parameters as needed\n",
    "XGBOOST_PARAMS = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"gamma\": 0.1,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"random_state\": RANDOM_SEED,\n",
    "    \"verbosity\": 1,\n",
    "    \"tree_method\": \"hist\",\n",
    "}\n",
    "\n",
    "\n",
    "class XGBoostTrainer:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.label_encoders = {}\n",
    "        self.feature_columns = None\n",
    "        self.X_train = self.X_test = self.y_train = self.y_test = None\n",
    "        self.test_timestamps = None\n",
    "        \n",
    "    def load_and_preprocess(self):\n",
    "        \"\"\"Load and preprocess data, keeping timestamps for predictions\"\"\"\n",
    "        logger.info(\"üì• Loading data for XGBoost training...\")\n",
    "        \n",
    "        if not os.path.exists(DATA_PATH):\n",
    "            raise FileNotFoundError(f\"Data file not found: {DATA_PATH}\")\n",
    "        \n",
    "        df = pd.read_csv(DATA_PATH)\n",
    "        logger.info(f\"Loaded data shape: {df.shape}\")\n",
    "        \n",
    "        if TARGET_COLUMN not in df.columns:\n",
    "            raise KeyError(f\"Target column '{TARGET_COLUMN}' not found\")\n",
    "\n",
    "        # Parse timestamps properly to ensure consistent format\n",
    "        logger.info(\"üïê Parsing timestamps...\")\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        \n",
    "        # Keep timestamps for later use\n",
    "        timestamps = df['timestamp'].copy()\n",
    "        \n",
    "        # Separate target and features\n",
    "        y = df[TARGET_COLUMN].copy()\n",
    "        X = df.drop(columns=[TARGET_COLUMN])  # Keep timestamp initially\n",
    "        \n",
    "        logger.info(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "\n",
    "        # Handle missing values in features (excluding timestamp)\n",
    "        feature_cols = [col for col in X.columns if col != 'timestamp']\n",
    "        for col in feature_cols:\n",
    "            if X[col].dtype in (\"object\", \"category\"):\n",
    "                mode_val = X[col].mode()\n",
    "                fill_val = mode_val.iloc[0] if len(mode_val) > 0 else \"unknown\"\n",
    "                X[col] = X[col].fillna(fill_val)\n",
    "            else:\n",
    "                X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "        # Handle missing targets\n",
    "        if y.isna().any():\n",
    "            mask = ~y.isna()\n",
    "            X, y, timestamps = X[mask].reset_index(drop=True), y[mask].reset_index(drop=True), timestamps[mask].reset_index(drop=True)\n",
    "\n",
    "        # Don't encode timestamp - we'll drop it for training but keep original\n",
    "        # This avoids any timestamp format issues\n",
    "        \n",
    "        # Handle target encoding if needed\n",
    "        if y.dtype == \"object\":\n",
    "            le_target = LabelEncoder()\n",
    "            y = pd.Series(le_target.fit_transform(y), index=y.index)\n",
    "            self.label_encoders[\"target\"] = le_target\n",
    "\n",
    "        logger.info(f\"Detected binary classification with classes: {np.unique(y)}\")\n",
    "\n",
    "        # CHRONOLOGICAL SPLIT (keeping timestamps)\n",
    "        split_idx = int(len(X) * (1 - TEST_FRAC))\n",
    "        \n",
    "        self.X_train = X.iloc[:split_idx].reset_index(drop=True)\n",
    "        self.X_test = X.iloc[split_idx:].reset_index(drop=True)\n",
    "        self.y_train = y.iloc[:split_idx].reset_index(drop=True)\n",
    "        self.y_test = y.iloc[split_idx:].reset_index(drop=True)\n",
    "        \n",
    "        # Store test timestamps for predictions (before dropping timestamp column)\n",
    "        self.test_timestamps = timestamps.iloc[split_idx:].reset_index(drop=True)\n",
    "        \n",
    "        # Now drop timestamp from features for training\n",
    "        self.X_train = self.X_train.drop(columns=['timestamp'])\n",
    "        self.X_test = self.X_test.drop(columns=['timestamp'])\n",
    "        \n",
    "        # Store feature column names\n",
    "        self.feature_columns = list(self.X_train.columns)\n",
    "        \n",
    "        logger.info(f\"Train set: {self.X_train.shape}, Test set: {self.X_test.shape}\")\n",
    "        logger.info(f\"Features: {len(self.feature_columns)}\")\n",
    "        logger.info(f\"Test date range: {self.test_timestamps.min()} to {self.test_timestamps.max()}\")\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the XGBoost model\"\"\"\n",
    "        logger.info(\"üöÄ Training XGBoost model...\")\n",
    "        \n",
    "        self.model = xgb.XGBClassifier(**XGBOOST_PARAMS)\n",
    "        \n",
    "        # Train model\n",
    "        self.model.fit(self.X_train, self.y_train, verbose=False)\n",
    "        \n",
    "        logger.info(\"‚úì Training completed!\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate the trained model\"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not trained!\")\n",
    "\n",
    "        logger.info(\"üìä Evaluating XGBoost model...\")\n",
    "\n",
    "        # Predictions\n",
    "        y_train_pred = self.model.predict(self.X_train)\n",
    "        y_test_pred = self.model.predict(self.X_test)\n",
    "        y_test_proba = self.model.predict_proba(self.X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_acc = accuracy_score(self.y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(self.y_test, y_test_pred)\n",
    "        test_precision = precision_score(self.y_test, y_test_pred, zero_division=0)\n",
    "        test_recall = recall_score(self.y_test, y_test_pred, zero_division=0)\n",
    "        test_f1 = f1_score(self.y_test, y_test_pred, zero_division=0)\n",
    "        test_auc = roc_auc_score(self.y_test, y_test_proba[:, 1])\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üéØ XGBOOST MODEL RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Training Accuracy:   {train_acc:.4f}\")\n",
    "        print(f\"Test Accuracy:       {test_acc:.4f}\")\n",
    "        print(f\"Test Precision:      {test_precision:.4f}\")\n",
    "        print(f\"Test Recall:         {test_recall:.4f}\")\n",
    "        print(f\"Test F1:             {test_f1:.4f}\")\n",
    "        print(f\"Test AUC:            {test_auc:.4f}\")\n",
    "        print(f\"Overfitting Gap:     {train_acc - test_acc:.4f}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Show classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(self.y_test, y_test_pred))\n",
    "        \n",
    "        return {\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"test_accuracy\": test_acc,\n",
    "            \"test_precision\": test_precision,\n",
    "            \"test_recall\": test_recall,\n",
    "            \"test_f1\": test_f1,\n",
    "            \"test_auc\": test_auc\n",
    "        }\n",
    "\n",
    "    def generate_predictions_csv(self, output_file=\"xgboost_predictions_new.csv\"):\n",
    "        \"\"\"Generate predictions CSV with properly formatted timestamps\"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not trained!\")\n",
    "\n",
    "        logger.info(\"üìä Generating predictions CSV...\")\n",
    "        \n",
    "        # Get probabilities for test set\n",
    "        y_test_proba = self.model.predict_proba(self.X_test)\n",
    "        y_test_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "        # Create predictions DataFrame\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'timestamp': self.test_timestamps,\n",
    "            'prob_up': y_test_proba[:, 1],    # Probability of class 1\n",
    "            'prob_down': y_test_proba[:, 0],  # Probability of class 0\n",
    "            'winning_prob': np.maximum(y_test_proba[:, 0], y_test_proba[:, 1]),  # Higher probability\n",
    "            'prediction': y_test_pred,\n",
    "            'actual': self.y_test\n",
    "        })\n",
    "        \n",
    "        # Ensure timestamp is in datetime format\n",
    "        predictions_df['timestamp'] = pd.to_datetime(predictions_df['timestamp'])\n",
    "        \n",
    "        # Round probabilities to 6 decimal places to match your format\n",
    "        predictions_df['prob_down'] = predictions_df['prob_down'].round(6)\n",
    "        predictions_df['prob_up'] = predictions_df['prob_up'].round(6)\n",
    "        predictions_df['winning_prob'] = predictions_df['winning_prob'].round(6)\n",
    "        \n",
    "        # Sort by timestamp to ensure chronological order\n",
    "        predictions_df = predictions_df.sort_values('timestamp').reset_index(drop=True)\n",
    "        \n",
    "        # Save to CSV with proper path\n",
    "        output_path = os.path.join(OUTPUT_PATH, output_file)\n",
    "        predictions_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        logger.info(f\"üíæ Predictions saved to: {output_path}\")\n",
    "        logger.info(f\"üìä Total predictions: {len(predictions_df)}\")\n",
    "        logger.info(f\"üìÖ Date range: {predictions_df['timestamp'].min()} to {predictions_df['timestamp'].max()}\")\n",
    "        \n",
    "        # Show sample of predictions\n",
    "        print(\"\\nüîç SAMPLE PREDICTIONS:\")\n",
    "        print(predictions_df.head(10).to_string(index=False))\n",
    "        \n",
    "        # Calculate accuracy on predictions\n",
    "        accuracy = accuracy_score(predictions_df['actual'], predictions_df['prediction'])\n",
    "        precision = precision_score(predictions_df['actual'], predictions_df['prediction'], zero_division=0)\n",
    "        \n",
    "        print(f\"\\nüìà PREDICTION SUMMARY:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Correct predictions: {(predictions_df['prediction'] == predictions_df['actual']).sum()}/{len(predictions_df)}\")\n",
    "        \n",
    "        # Verify timestamp format\n",
    "        print(f\"\\n‚úÖ Timestamp format check:\")\n",
    "        print(f\"First timestamp: {predictions_df['timestamp'].iloc[0]}\")\n",
    "        print(f\"Last timestamp: {predictions_df['timestamp'].iloc[-1]}\")\n",
    "        print(f\"Timestamp dtype: {predictions_df['timestamp'].dtype}\")\n",
    "        \n",
    "        return predictions_df\n",
    "\n",
    "    def save_model(self, output_dir=\"xgboost_model\"):\n",
    "        \"\"\"Save the trained model\"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not trained!\")\n",
    "        \n",
    "        model_dir = os.path.join(OUTPUT_PATH, output_dir)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save model\n",
    "        model_path = os.path.join(model_dir, f\"xgboost_model_{ts}.joblib\")\n",
    "        joblib.dump(self.model, model_path)\n",
    "        \n",
    "        # Save encoders and feature names\n",
    "        if self.label_encoders:\n",
    "            joblib.dump(self.label_encoders, os.path.join(model_dir, f\"xgboost_encoders_{ts}.joblib\"))\n",
    "        \n",
    "        joblib.dump(self.feature_columns, os.path.join(model_dir, f\"xgboost_features_{ts}.joblib\"))\n",
    "        \n",
    "        logger.info(f\"üíæ XGBoost model saved to: {model_path}\")\n",
    "        return model_path\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to train XGBoost model and generate predictions\"\"\"\n",
    "    logger.info(\"üöÄ Starting XGBoost training pipeline...\")\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = XGBoostTrainer()\n",
    "    \n",
    "    try:\n",
    "        # Load and preprocess data\n",
    "        trainer.load_and_preprocess()\n",
    "        \n",
    "        # Train model\n",
    "        trainer.train()\n",
    "        \n",
    "        # Evaluate model\n",
    "        metrics = trainer.evaluate()\n",
    "        \n",
    "        # Generate predictions CSV\n",
    "        predictions_df = trainer.generate_predictions_csv(\"xgboost_predictions_fixed.csv\")\n",
    "        \n",
    "        # Save model\n",
    "        model_path = trainer.save_model()\n",
    "        \n",
    "        logger.info(\"üèÅ XGBoost training and prediction generation completed!\")\n",
    "        \n",
    "        # Ask if user wants to replace the original file\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        replace = input(\"Replace the original xgboost_predictions.csv with the new file? (y/n): \").lower()\n",
    "        if replace == 'y':\n",
    "            original_path = os.path.join(OUTPUT_PATH, \"xgboost_predictions.csv\")\n",
    "            new_path = os.path.join(OUTPUT_PATH, \"xgboost_predictions_fixed.csv\")\n",
    "            \n",
    "            # Backup original\n",
    "            backup_path = os.path.join(OUTPUT_PATH, \"xgboost_predictions_backup.csv\")\n",
    "            if os.path.exists(original_path):\n",
    "                import shutil\n",
    "                shutil.copy2(original_path, backup_path)\n",
    "                print(f\"‚úì Original backed up to: xgboost_predictions_backup.csv\")\n",
    "            \n",
    "            # Replace with new file\n",
    "            predictions_df.to_csv(original_path, index=False)\n",
    "            print(f\"‚úì Original file replaced with fixed version\")\n",
    "        \n",
    "        return trainer, metrics, predictions_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainer, metrics, predictions_df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c555a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation at threshold 0.5:\n",
      "Precision: 0.557\n",
      "Recall   : 0.411\n",
      "F1 Score : 0.473\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the predictions CSV\n",
    "csv_path = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\Final_runs_csv\\xgboost_predictions_fixed.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Ensure column names are correct and lowercase\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Extract actual and predicted values\n",
    "y_true = df['actual']\n",
    "y_pred = df['prediction']  # prediction at threshold 0.5\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "# Print results\n",
    "print(\"üìä Evaluation at threshold 0.5:\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall   : {recall:.3f}\")\n",
    "print(f\"F1 Score : {f1:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep \n",
    "atr_14  , OBV\n",
    "\n",
    "drop\n",
    "\n",
    "'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'trending_market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b25d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_tcn = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6','ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Loading data â€¦\n",
      "Shape  : (15855, 59)\n",
      "Classes:\n",
      " target\n",
      "1    8097\n",
      "0    7758\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Class-weights 0 / 1 â†’ 1.00 / 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 18:52:10,220] A new study created in memory with name: no-name-5d78d030-0093-439e-a2ba-35523e4ee0ab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Optimising  40 trials  |  80 min wall-time â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  0  FÎ±2=0.1605  P=0.509 R=0.120  cfg={'window': 30, 'filters': 32, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.23033450352296264, 'dense': 128, 'act': 'relu', 'lr': 0.00017376356936978755, 'batch': 32, 'norm': 'batch'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [01:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 18:53:20,599] Trial 0 finished with value: -0.1605241605241605 and parameters: {'window': 30, 'filters': 32, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.23033450352296264, 'dense': 128, 'act': 'relu', 'lr': 0.00017376356936978755, 'batch': 32, 'norm': 'batch'}. Best is trial 0 with value: -0.1605241605241605.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   2%|â–Ž         | 1/40 [01:11<46:34, 71.66s/it, 71.66/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  1  FÎ±2=0.0000  P=0.000 R=0.000  cfg={'window': 24, 'filters': 64, 'kernel': 4, 'nb_stacks': 2, 'blocks_per_stack': 1, 'dropout': 0.2322634555704315, 'dense': 128, 'act': 'relu', 'lr': 0.0008234548958371457, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   2%|â–Ž         | 1/40 [02:52<46:34, 71.66s/it, 71.66/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 18:55:02,851] Trial 1 finished with value: -0.0 and parameters: {'window': 24, 'filters': 64, 'kernel': 4, 'nb_stacks': 2, 'blocks_per_stack': 1, 'dropout': 0.2322634555704315, 'dense': 128, 'act': 'relu', 'lr': 0.0008234548958371457, 'batch': 32, 'norm': 'layer'}. Best is trial 0 with value: -0.1605241605241605.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   5%|â–Œ         | 2/40 [02:53<56:47, 89.67s/it, 173.94/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  2  FÎ±2=0.4784  P=0.532 R=0.456  cfg={'window': 24, 'filters': 32, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3318496824692567, 'dense': 128, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.0002455257311459749, 'batch': 64, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   5%|â–Œ         | 2/40 [13:54<56:47, 89.67s/it, 173.94/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:06:04,741] Trial 2 finished with value: -0.4783904619970194 and parameters: {'window': 24, 'filters': 32, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3318496824692567, 'dense': 128, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.0002455257311459749, 'batch': 64, 'norm': 'layer'}. Best is trial 2 with value: -0.4783904619970194.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:   8%|â–Š         | 3/40 [13:56<3:36:29, 351.07s/it, 836.07/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  3  FÎ±2=0.3502  P=0.527 R=0.300  cfg={'window': 18, 'filters': 64, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.26205720315428516, 'dense': 64, 'act': 'selu', 'lr': 0.00019380132456492117, 'batch': 64, 'norm': 'batch'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:   8%|â–Š         | 3/40 [14:42<3:36:29, 351.07s/it, 836.07/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:06:52,361] Trial 3 finished with value: -0.3501890359168242 and parameters: {'window': 18, 'filters': 64, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.26205720315428516, 'dense': 64, 'act': 'selu', 'lr': 0.00019380132456492117, 'batch': 64, 'norm': 'batch'}. Best is trial 2 with value: -0.4783904619970194.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:  10%|â–ˆ         | 4/40 [14:43<2:18:44, 231.23s/it, 883.60/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  4  FÎ±2=0.7657  P=0.521 R=1.000  cfg={'window': 54, 'filters': 96, 'kernel': 4, 'nb_stacks': 3, 'blocks_per_stack': 1, 'dropout': 0.2068198488145982, 'dense': 32, 'act': 'elu', 'lr': 0.0020547569815878254, 'batch': 64, 'norm': 'none'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:  10%|â–ˆ         | 4/40 [33:13<2:18:44, 231.23s/it, 883.60/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:25:23,788] Trial 4 finished with value: -0.7656667190199467 and parameters: {'window': 54, 'filters': 96, 'kernel': 4, 'nb_stacks': 3, 'blocks_per_stack': 1, 'dropout': 0.2068198488145982, 'dense': 32, 'act': 'elu', 'lr': 0.0020547569815878254, 'batch': 64, 'norm': 'none'}. Best is trial 4 with value: -0.7656667190199467.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  12%|â–ˆâ–Ž        | 5/40 [33:35<5:20:04, 548.71s/it, 1995.21/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:25:45,368] Trial 5 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  15%|â–ˆâ–Œ        | 6/40 [33:50<3:29:22, 369.48s/it, 2016.78/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:26:01,051] Trial 6 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  18%|â–ˆâ–Š        | 7/40 [34:14<2:19:36, 253.83s/it, 2032.52/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:26:24,480] Trial 7 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  20%|â–ˆâ–ˆ        | 8/40 [34:16<1:36:15, 180.50s/it, 2056.00/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  8  FÎ±2=0.0000  P=0.000 R=0.000  cfg={'window': 48, 'filters': 48, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.12738248831454668, 'dense': 64, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.001995489737195091, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  20%|â–ˆâ–ˆ        | 8/40 [38:46<1:36:15, 180.50s/it, 2056.00/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:30:56,774] Trial 8 finished with value: -0.0 and parameters: {'window': 48, 'filters': 48, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.12738248831454668, 'dense': 64, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.001995489737195091, 'batch': 32, 'norm': 'layer'}. Best is trial 4 with value: -0.7656667190199467.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [38:58<1:48:05, 209.22s/it, 2328.39/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:31:08,443] Trial 9 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [47:12<1:14:07, 148.23s/it, 2340.05/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:39:22,883] Trial 10 pruned. Trial was pruned at epoch 22.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  28%|â–ˆâ–ˆâ–Š       | 11/40 [47:47<2:02:50, 254.17s/it, 2834.41/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:39:57,582] Trial 11 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [48:21<1:27:29, 187.49s/it, 2869.41/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:40:31,286] Trial 12 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [48:51<1:03:22, 140.84s/it, 2902.88/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:41:01,988] Trial 13 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [49:38<46:37, 107.58s/it, 2933.62/4800 seconds]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:41:48,536] Trial 14 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [50:02<37:10, 89.21s/it, 2980.27/4800 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:42:12,653] Trial 15 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [50:22<27:51, 69.63s/it, 3004.41/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:42:33,114] Trial 16 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [50:54<21:01, 54.83s/it, 3024.84/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:43:04,270] Trial 17 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [51:31<17:29, 47.71s/it, 3055.98/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:43:41,819] Trial 18 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [51:58<15:38, 44.69s/it, 3093.63/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:44:08,636] Trial 19 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [52:32<13:06, 39.33s/it, 3120.48/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:44:42,949] Trial 20 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [52:44<11:58, 37.83s/it, 3154.80/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:44:54,758] Trial 21 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [52:56<09:00, 30.02s/it, 3166.61/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:45:06,538] Trial 22 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [53:08<06:57, 24.54s/it, 3178.37/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:45:18,786] Trial 23 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [53:32<05:33, 20.86s/it, 3190.65/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:45:42,569] Trial 24 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [54:32<05:26, 21.76s/it, 3214.49/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:46:43,083] Trial 25 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [54:44<07:48, 33.48s/it, 3275.34/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:46:54,500] Trial 26 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [55:07<05:49, 26.85s/it, 3286.70/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:47:17,998] Trial 27 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [55:51<05:10, 25.85s/it, 3310.21/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:02,045] Trial 28 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [56:05<05:44, 31.33s/it, 3354.33/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:16,155] Trial 29 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [56:20<04:21, 26.16s/it, 3368.45/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:31,058] Trial 30 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [56:34<03:24, 22.77s/it, 3383.30/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:44,848] Trial 31 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [56:51<02:40, 20.08s/it, 3397.11/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:49:01,379] Trial 32 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [57:06<02:12, 18.97s/it, 3413.50/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:49:16,742] Trial 33 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [57:08<01:47, 17.89s/it, 3428.87/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34  FÎ±2=0.3297  P=0.497 R=0.282  cfg={'window': 24, 'filters': 48, 'kernel': 2, 'nb_stacks': 2, 'blocks_per_stack': 2, 'dropout': 0.31901512444749536, 'dense': 128, 'act': 'relu', 'lr': 0.0006474141743156096, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [1:01:16<01:47, 17.89s/it, 3428.87/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:53:27,074] Trial 34 finished with value: -0.3297015632401705 and parameters: {'window': 24, 'filters': 48, 'kernel': 2, 'nb_stacks': 2, 'blocks_per_stack': 2, 'dropout': 0.31901512444749536, 'dense': 128, 'act': 'relu', 'lr': 0.0006474141743156096, 'batch': 32, 'norm': 'layer'}. Best is trial 4 with value: -0.7656667190199467.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [1:01:48<07:18, 87.63s/it, 3679.21/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:53:59,012] Trial 35 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [1:01:51<04:43, 70.99s/it, 3711.39/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36  FÎ±2=0.7666  P=0.523 R=1.000  cfg={'window': 12, 'filters': 48, 'kernel': 5, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3118914406542517, 'dense': 128, 'act': 'relu', 'lr': 0.0005947328436650964, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [1:21:31<04:43, 70.99s/it, 3711.39/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 20:13:41,748] Trial 36 finished with value: -0.766599597585513 and parameters: {'window': 12, 'filters': 48, 'kernel': 5, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3118914406542517, 'dense': 128, 'act': 'relu', 'lr': 0.0005947328436650964, 'batch': 32, 'norm': 'layer'}. Best is trial 36 with value: -0.766599597585513.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: -0.7666:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [1:21:34<06:36, 132.27s/it, 4894.06/4800 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â• BEST RESULT â•â•â•â•â•â•â•â•â•â•â•\n",
      "weighted-F1 (Î±=2) : 0.7666\n",
      "precision         : 0.5226\n",
      "recall            : 1.0000\n",
      "best epoch        : 35\n",
      "hyper-parameters  :\n",
      "  window            : 12\n",
      "  filters           : 48\n",
      "  kernel            : 5\n",
      "  nb_stacks         : 3\n",
      "  blocks_per_stack  : 2\n",
      "  dropout           : 0.3118914406542517\n",
      "  dense             : 128\n",
      "  act               : relu\n",
      "  lr                : 0.0005947328436650964\n",
      "  batch             : 32\n",
      "  norm              : layer\n",
      "\n",
      "ðŸ“ Artefacts saved (timestamp 20250609_171344).  Scaler â†’ tcn_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tcn_optuna_search.py  â€”  Robust TCN hyper-parameter optimisation\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ Objective  : weighted-F1 with Î± = 2  (precision has double weight)\n",
    "â€¢ Output     : scaler, best-params (.json), all trials (.csv), history plot\n",
    "â€¢ Tested on  : TensorFlow 2.16 Â· tcn 3.5 Â· Optuna 3.x  (CPU & single GPU)\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os, json, gc, warnings, optuna\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN                       #  pip install tcn==3.*\n",
    "from optuna_integration.tfkeras import TFKerasPruningCallback\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ runtime hygiene â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED, VAL_FRAC, ALPHA = 42, 0.20, 2.0\n",
    "N_TRIALS, TIMEOUT = 40, 80 * 60  #â€‰seconds\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ paths, drops â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "SCALER_PKL = \"tcn_scaler.pkl\"\n",
    "\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6','ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal',\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ data load â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ðŸ“Š Loading data â€¦\")\n",
    "df = (\n",
    "    pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "      .loc[\"2018-01-01\":]\n",
    "      .drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "      .dropna(subset=[\"target\"])\n",
    "      .dropna()\n",
    ")\n",
    "print(f\"Shape  : {df.shape}\")\n",
    "print(\"Classes:\\n\", df[\"target\"].value_counts(), \"\\n\")\n",
    "\n",
    "X_raw, y_raw = df.drop(columns=\"target\").values, df[\"target\"].astype(int).values\n",
    "n_features   = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = np.float32((1 - pos_rate) / pos_rate if pos_rate else 1.0)\n",
    "print(f\"Class-weights 0 / 1 â†’ {CLASS_W0:.2f} / {CLASS_W1:.2f}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ window cache helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "_CACHE: Dict[Tuple[int, int, int], Tuple[np.ndarray, np.ndarray]] = {}\n",
    "\n",
    "def make_windows(arr: np.ndarray, labels: np.ndarray, win: int):\n",
    "    k = (id(arr), len(labels), win)\n",
    "    if k in _CACHE:\n",
    "        return _CACHE[k]\n",
    "\n",
    "    Xs, ys = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        Xs.append(arr[i - win:i])\n",
    "        ys.append(labels[i])\n",
    "    Xw, yw = np.asarray(Xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "    if Xw.nbytes + yw.nbytes < 1_000_000_000:\n",
    "        _CACHE[k] = (Xw, yw)\n",
    "    return Xw, yw\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ metric: weighted-F1 (Î±=2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def f1_alpha2(y_true, y_prob) -> float:\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    p, r   = precision_score(y_true, y_pred, zero_division=0), \\\n",
    "             recall_score   (y_true, y_pred, zero_division=0)\n",
    "    return 0. if p+r == 0 else (1+ALPHA)*p*r / (ALPHA*p + r)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TCN model factory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def build_tcn(cfg: dict) -> keras.Model:\n",
    "    dilations = [2 ** i for i in range(cfg[\"nb_stacks\"] * cfg[\"blocks_per_stack\"])]\n",
    "\n",
    "    inp = keras.layers.Input(shape=(cfg[\"window\"], n_features))\n",
    "    x   = TCN(\n",
    "            nb_filters       = cfg[\"filters\"],\n",
    "            kernel_size      = cfg[\"kernel\"],\n",
    "            nb_stacks        = cfg[\"nb_stacks\"],\n",
    "            dilations        = dilations,\n",
    "            padding          = \"causal\",\n",
    "            dropout_rate     = cfg[\"dropout\"],\n",
    "            activation       = cfg[\"act\"],\n",
    "            use_skip_connections = True,\n",
    "            use_batch_norm   = cfg[\"norm\"] == \"batch\",\n",
    "            use_layer_norm   = cfg[\"norm\"] == \"layer\",\n",
    "            return_sequences = False\n",
    "         )(inp)\n",
    "\n",
    "    x   = keras.layers.Dense(cfg[\"dense\"], activation=cfg[\"act\"])(x)\n",
    "    x   = keras.layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    out = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    # balanced BCE\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), CLASS_W1, CLASS_W0)\n",
    "        w   = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(keras.optimizers.Adam(cfg[\"lr\"]), loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Optuna objective â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    cfg = dict(\n",
    "        window           = trial.suggest_int(\"window\", 12, 60, step=6),\n",
    "        filters          = trial.suggest_categorical(\"filters\", [32, 48, 64, 96]),\n",
    "        kernel           = trial.suggest_int(\"kernel\", 2, 6),\n",
    "        nb_stacks        = trial.suggest_int(\"nb_stacks\", 1, 3),\n",
    "        blocks_per_stack = trial.suggest_int(\"blocks_per_stack\", 1, 2),\n",
    "        dropout          = trial.suggest_float(\"dropout\", 0.05, 0.35),\n",
    "        dense            = trial.suggest_categorical(\"dense\", [32, 64, 128]),\n",
    "        act              = trial.suggest_categorical(\"act\", [\"relu\", \"elu\", \"selu\", tf.nn.swish]),\n",
    "        lr               = trial.suggest_float(\"lr\", 5e-5, 3e-3, log=True),\n",
    "        batch            = trial.suggest_categorical(\"batch\", [32, 64]),\n",
    "        norm             = trial.suggest_categorical(\"norm\", [\"none\", \"batch\", \"layer\"]),\n",
    "    )\n",
    "\n",
    "    X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, cfg[\"window\"])\n",
    "    X_va, y_va = make_windows(X_va_raw, y_va_raw, cfg[\"window\"])\n",
    "\n",
    "    if len(X_tr) < cfg[\"batch\"] * 10:      # too small â†’ prune\n",
    "        return float(\"inf\")\n",
    "\n",
    "    tf.keras.backend.clear_session(); gc.collect()\n",
    "    model = build_tcn(cfg)\n",
    "\n",
    "    cb = [\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=0),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, min_lr=1e-6, verbose=0),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\")\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(X_tr, y_tr,\n",
    "                     validation_data=(X_va, y_va),\n",
    "                     epochs=100,\n",
    "                     batch_size=cfg[\"batch\"],\n",
    "                     shuffle=False,\n",
    "                     callbacks=cb,\n",
    "                     verbose=0)\n",
    "\n",
    "    y_prob = model.predict(X_va, batch_size=cfg[\"batch\"], verbose=0).ravel()\n",
    "    score  = f1_alpha2(y_va, y_prob)\n",
    "\n",
    "    # store metrics to inspect later\n",
    "    trial.set_user_attr(\"precision\", precision_score(y_va, y_prob >= 0.5, zero_division=0))\n",
    "    trial.set_user_attr(\"recall\",    recall_score   (y_va, y_prob >= 0.5, zero_division=0))\n",
    "    trial.set_user_attr(\"best_epoch\", int(np.argmin(hist.history[\"val_loss\"]) + 1))\n",
    "\n",
    "    # print live metrics\n",
    "    print(f\"Trial {trial.number:2d}  \"\n",
    "          f\"FÎ±2={score:.4f}  P={trial.user_attrs['precision']:.3f} \"\n",
    "          f\"R={trial.user_attrs['recall']:.3f}  cfg={trial.params}\")\n",
    "\n",
    "    del model; tf.keras.backend.clear_session(); gc.collect()\n",
    "    return -score   # minimise\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def main():\n",
    "    study = optuna.create_study(direction=\"minimize\",\n",
    "                                sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "                                pruner =optuna.pruners.MedianPruner(n_startup_trials=5))\n",
    "\n",
    "    print(f\"\\nðŸš€ Optimising  {N_TRIALS} trials  |  {TIMEOUT//60} min wall-time â€¦\")\n",
    "    study.optimize(objective,\n",
    "                   n_trials=N_TRIALS,\n",
    "                   timeout=TIMEOUT,\n",
    "                   show_progress_bar=True,\n",
    "                   gc_after_trial=True)\n",
    "\n",
    "    best, ts = study.best_trial, datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    print(\"\\nâ•â•â•â•â•â•â•â•â•â•â• BEST RESULT â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "    print(f\"weighted-F1 (Î±=2) : {-best.value:.4f}\")\n",
    "    print(f\"precision         : {best.user_attrs['precision']:.4f}\")\n",
    "    print(f\"recall            : {best.user_attrs['recall']:.4f}\")\n",
    "    print(f\"best epoch        : {best.user_attrs['best_epoch']}\")\n",
    "    print(\"hyper-parameters  :\")\n",
    "    for k, v in best.params.items():\n",
    "        print(f\"  {k:18s}: {v}\")\n",
    "\n",
    "    json.dump(best.params, open(f\"best_params_tcn_{ts}.json\", \"w\"), indent=2)\n",
    "    study.trials_dataframe().to_csv(f\"trials_tcn_{ts}.csv\", index=False)\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"optuna_tcn_history_{ts}.png\", dpi=300)\n",
    "        plt.close()\n",
    "    except Exception:\n",
    "        print(\"âš ï¸ matplotlib unavailable â€“ history plot skipped.\")\n",
    "\n",
    "    print(f\"\\nðŸ“ Artefacts saved (timestamp {ts}).  \"\n",
    "          f\"Scaler â†’ {SCALER_PKL}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0994880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Loading & preprocessing data...\n",
      "Before dropna: (20718, 66)\n",
      "After dropna: (15855, 34)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'conv_blocks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 134\u001b[0m\n\u001b[0;32m    131\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m make_windows(X_val_s, y_val, win)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 2. Model Building â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(OPTIMAL_PARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m    136\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    137\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 3. Training â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 81\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(win, n_features)\u001b[0m\n\u001b[0;32m     78\u001b[0m inp \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(win, n_features))\n\u001b[0;32m     79\u001b[0m x \u001b[38;5;241m=\u001b[39m inp\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconv_blocks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[0;32m     82\u001b[0m     f \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilters\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m b)\n\u001b[0;32m     83\u001b[0m     y \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv1D(f, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     84\u001b[0m                       activation\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mact\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     85\u001b[0m                       kernel_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39ml2(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m]))(x)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'conv_blocks'"
     ]
    }
   ],
   "source": [
    "import os, json, joblib, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Setup â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Configuration â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "CSV_PATH = Path(r\"C:/Users/ADMIN/Desktop/Coding_projects/stock_market_prediction/\"\n",
    "                r\"Stock-Market-Prediction/data/processed/\"\n",
    "                r\"gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "# Output files\n",
    "MODEL_OUT = \"cnn_optimal_final.h5\"\n",
    "SCALER_OUT = \"cnn_scaler_final.pkl\"\n",
    "PREDICTIONS_OUT = \"cnn_predictions.csv\"\n",
    "SUMMARY_JSON = \"cnn_final_training_summary.json\"\n",
    "\n",
    "# Optimal hyperparameters\n",
    "OPTIMAL_PARAMS =    {\n",
    "        'name': 'Trial_2_HighestPrecision',\n",
    "        'window': 24, 'filters': 32, 'kernel': 2,\n",
    "        'nb_stacks': 3, 'blocks_per_stack': 2,\n",
    "        'dropout': 0.3318, 'dense': 128, 'act': 'swish',\n",
    "        'lr': 0.0002455, 'batch': 64, 'norm': 'layer'\n",
    "    }\n",
    "\n",
    "VAL_FRAC = 0.20\n",
    "EARLY_STOP = 15\n",
    "ALPHA = 2.0\n",
    "\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6','ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal',\n",
    "]\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Helper Functions â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def weighted_f1(y_true, y_pred, alpha=ALPHA):\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score(y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def make_windows(arr, labels, win):\n",
    "    xs, ys = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        xs.append(arr[i-win:i])\n",
    "        ys.append(labels[i])\n",
    "    return np.asarray(xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "def build_model(win, n_features):\n",
    "    params = OPTIMAL_PARAMS\n",
    "    inp = layers.Input(shape=(win, n_features))\n",
    "    x = inp\n",
    "\n",
    "    for b in range(params['conv_blocks']):\n",
    "        f = params['filters'] * (2 ** b)\n",
    "        y = layers.Conv1D(f, params['kernel'], padding=\"causal\",\n",
    "                          activation=params['act'],\n",
    "                          kernel_regularizer=regularizers.l2(params['l2']))(x)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "        if params['conv_blocks'] > 1:\n",
    "            if x.shape[-1] != y.shape[-1]:\n",
    "                x = layers.Conv1D(f, 1, padding=\"same\")(x)\n",
    "            x = layers.add([x, y])\n",
    "        else:\n",
    "            x = y\n",
    "\n",
    "    if params['pool'] == 'gmp':\n",
    "        x = layers.GlobalMaxPooling1D()(x)\n",
    "    else:\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(params['dropout'])(x)\n",
    "\n",
    "    if params['extra_dense']:\n",
    "        x = layers.Dense(params['dense'], activation=params['act'],\n",
    "                         kernel_regularizer=regularizers.l2(params['l2']))(x)\n",
    "        x = layers.Dropout(params['dropout'])(x)\n",
    "\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inp, out)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 1. Data Loading â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"ðŸ“Š Loading & preprocessing data...\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "print(\"Before dropna:\", df.shape)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"]).dropna()\n",
    "print(\"After dropna:\", df.shape)\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split_idx])\n",
    "\n",
    "X_train_s = scaler.transform(X_raw[:split_idx]).astype(np.float32)\n",
    "X_val_s = scaler.transform(X_raw[split_idx:]).astype(np.float32)\n",
    "y_train = y_raw[:split_idx]\n",
    "y_val = y_raw[split_idx:]\n",
    "\n",
    "win = OPTIMAL_PARAMS['window']\n",
    "X_train, y_train = make_windows(X_train_s, y_train, win)\n",
    "X_val, y_val = make_windows(X_val_s, y_val, win)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 2. Model Building â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "model = build_model(win, n_features)\n",
    "model.compile(optimizer=keras.optimizers.Adam(OPTIMAL_PARAMS['lr']),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 3. Training â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=EARLY_STOP,\n",
    "                                  restore_best_weights=True,\n",
    "                                  verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.5,\n",
    "                                      patience=5,\n",
    "                                      verbose=1,\n",
    "                                      min_lr=1e-7)\n",
    "]\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=OPTIMAL_PARAMS['epochs'],\n",
    "                    batch_size=OPTIMAL_PARAMS['batch'],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 4. Evaluation â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "prob_up = model.predict(X_val, verbose=0).ravel()\n",
    "prob_down = 1 - prob_up\n",
    "pred = (prob_up >= 0.5).astype(int)\n",
    "\n",
    "precision = precision_score(y_val, pred, zero_division=0)\n",
    "recall = recall_score(y_val, pred, zero_division=0)\n",
    "wf1 = weighted_f1(y_val, pred)\n",
    "accuracy = accuracy_score(y_val, pred)\n",
    "auc = roc_auc_score(y_val, prob_up)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Trial Metrics â€” Precision: {precision:.4f}, Recall: {recall:.4f}, F1(Î±={ALPHA}): {wf1:.4f}\")\n",
    "\n",
    "# Remaining steps unchanged: saving predictions, model, summary JSON...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b703651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¬ Trial_2_HighestPrecision | Window=24, Filters=32 | act=swish, norm=layer\n",
      "   Precision: 0.531 | Recall: 0.709 | F1: 0.607 | F1Î±=2: 0.638 | AUC: 0.510\n",
      "\n",
      "ðŸ”¬ Trial_3_SecondPrecision | Window=18, Filters=64 | act=selu, norm=batch\n",
      "   Precision: 0.541 | Recall: 0.147 | F1: 0.231 | F1Î±=2: 0.194 | AUC: 0.512\n",
      "\n",
      "ðŸ”¬ Trial_36_BestOverall | Window=12, Filters=48 | act=relu, norm=layer\n",
      "   Precision: 0.523 | Recall: 1.000 | F1: 0.686 | F1Î±=2: 0.767 | AUC: 0.511\n",
      "\n",
      "ðŸ FINAL RANKING BY PRECISION:\n",
      "1. Trial_3_SecondPrecision   â†’ P=0.541, R=0.147, F1=0.194, AUC=0.512\n",
      "2. Trial_2_HighestPrecision  â†’ P=0.531, R=0.709, F1=0.638, AUC=0.510\n",
      "3. Trial_36_BestOverall      â†’ P=0.523, R=1.000, F1=0.767, AUC=0.511\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tcn_precision_comparison.py\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Trains and compares the top 3 TCN configurations that achieved\n",
    "the highest precision scores during optimization.\n",
    "\"\"\"\n",
    "\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, accuracy_score, roc_auc_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC = 0.20\n",
    "ALPHA = 2.0\n",
    "EPOCHS = 100\n",
    "EARLY_STOP = 15\n",
    "\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6', 'ema_cross_up', 'macd_cross_up', \n",
    "    'oversold_reversal', 'overbought_reversal'\n",
    "]\n",
    "\n",
    "PRECISION_CONFIGS = [\n",
    "    {\n",
    "        'name': 'Trial_2_HighestPrecision',\n",
    "        'window': 24, 'filters': 32, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2,\n",
    "        'dropout': 0.3318, 'dense': 128, 'act': 'swish', \n",
    "        'lr': 0.0002455, 'batch': 64, 'norm': 'layer',\n",
    "        'expected_precision': 0.532, 'expected_recall': 0.456, 'expected_f1': 0.478\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "def weighted_f1(y_true, y_pred, alpha=ALPHA):\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score(y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def make_windows(arr, labels, win):\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i-win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.asarray(X, np.float32), np.asarray(y, np.int8)\n",
    "\n",
    "def build_tcn_model(cfg, n_features, class_w0, class_w1):\n",
    "    act_map = {'relu': 'relu', 'elu': 'elu', 'selu': 'selu', 'swish': tf.nn.swish, 'tanh': 'tanh'}\n",
    "    act = act_map.get(cfg['act'], cfg['act'])\n",
    "    dilations = [2 ** i for i in range(cfg['nb_stacks'] * cfg['blocks_per_stack'])]\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(cfg['window'], n_features))\n",
    "    x = TCN(nb_filters=cfg['filters'], kernel_size=cfg['kernel'], nb_stacks=cfg['nb_stacks'],\n",
    "            dilations=dilations, padding=\"causal\", dropout_rate=cfg['dropout'],\n",
    "            activation=act, use_skip_connections=True, use_batch_norm=cfg['norm'] == 'batch',\n",
    "            use_layer_norm=cfg['norm'] == 'layer', return_sequences=False)(inputs)\n",
    "    x = keras.layers.Dense(cfg['dense'], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg['dropout'])(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w = tf.where(tf.equal(y_t, 1), class_w1, class_w0)\n",
    "        w = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(cfg['lr']), loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Load Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"]).dropna()\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split_idx])\n",
    "\n",
    "X_train = scaler.transform(X_raw[:split_idx]).astype(np.float32)\n",
    "X_val = scaler.transform(X_raw[split_idx:]).astype(np.float32)\n",
    "y_train, y_val = y_raw[:split_idx], y_raw[split_idx:]\n",
    "\n",
    "pos_rate = y_train.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = np.float32((1 - pos_rate) / pos_rate if pos_rate else 1.0)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Training Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "results = []\n",
    "\n",
    "for cfg in PRECISION_CONFIGS:\n",
    "    print(f\"\\nðŸ”¬ {cfg['name']} | Window={cfg['window']}, Filters={cfg['filters']} | act={cfg['act']}, norm={cfg['norm']}\")\n",
    "\n",
    "    X_tr, y_tr = make_windows(X_train, y_train, cfg['window'])\n",
    "    X_va, y_va = make_windows(X_val, y_val, cfg['window'])\n",
    "\n",
    "    tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "    model = build_tcn_model(cfg, n_features, CLASS_W0, CLASS_W1)\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=EARLY_STOP, restore_best_weights=True, verbose=0),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=7, factor=0.5, min_lr=1e-7, verbose=0)\n",
    "    ]\n",
    "\n",
    "    model.fit(X_tr, y_tr, validation_data=(X_va, y_va), epochs=EPOCHS,\n",
    "              batch_size=cfg['batch'], shuffle=False, callbacks=callbacks, verbose=0)\n",
    "\n",
    "    prob = model.predict(X_va, verbose=0).ravel()\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "    precision = precision_score(y_va, pred, zero_division=0)\n",
    "    recall = recall_score(y_va, pred, zero_division=0)\n",
    "    f1_std = f1_score(y_va, pred, zero_division=0)\n",
    "    f1_wgt = weighted_f1(y_va, pred)\n",
    "    acc = accuracy_score(y_va, pred)\n",
    "    auc = roc_auc_score(y_va, prob)\n",
    "\n",
    "    print(f\"   Precision: {precision:.3f} | Recall: {recall:.3f} | F1: {f1_std:.3f} | F1Î±=2: {f1_wgt:.3f} | AUC: {auc:.3f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"name\": cfg[\"name\"],\n",
    "        \"actual_precision\": precision,\n",
    "        \"actual_recall\": recall,\n",
    "        \"actual_f1\": f1_std,\n",
    "        \"actual_f1_weighted\": f1_wgt,\n",
    "        \"actual_accuracy\": acc,\n",
    "        \"actual_auc\": auc\n",
    "    })\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nðŸ FINAL RANKING BY PRECISION:\")\n",
    "for i, res in enumerate(sorted(results, key=lambda r: r['actual_precision'], reverse=True), 1):\n",
    "    print(f\"{i}. {res['name']:<25s} â†’ P={res['actual_precision']:.3f}, R={res['actual_recall']:.3f}, F1={res['actual_f1_weighted']:.3f}, AUC={res['actual_auc']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4990f",
   "metadata": {},
   "outputs": [],
   "source": [
    " [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6','ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0572bb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š loading & scaling data â€¦\n",
      "\n",
      "Trial_2_HighestPrecision | win=24, filters=32, act=swish\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 160\u001b[0m\n\u001b[0;32m    151\u001b[0m model \u001b[38;5;241m=\u001b[39m build_tcn(cfg, n_features, CW0, CW1)\n\u001b[0;32m    153\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    154\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39mEARLY_STOP,\n\u001b[0;32m    155\u001b[0m                                   restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    156\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.5\u001b[39m,\n\u001b[0;32m    157\u001b[0m                                       min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    158\u001b[0m ]\n\u001b[1;32m--> 160\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_va\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m          \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_va, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m    169\u001b[0m pred \u001b[38;5;241m=\u001b[39m (prob \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tcn_precision_comparison.py\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Compares hand-picked TCN configs on BTC-4 h data and\n",
    "saves *per-bar* validation predictions in the format:\n",
    "\n",
    "timestamp,prob_up,prob_down,winning_prob,prediction,actual\n",
    "20/10/2023 16:00,0.520832,0.479168,0.520832,1,1\n",
    "â€¦\n",
    "\"\"\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             f1_score, accuracy_score, roc_auc_score)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ runtime hygiene â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC   = 0.20          # last 20 % is hold-out\n",
    "ALPHA      = 2.0           # precision weight for weighted-F1\n",
    "EPOCHS     = 100\n",
    "EARLY_STOP = 15\n",
    "\n",
    "DROP_COLS =  [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6','ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal',\n",
    "]          # â† paste the long list you already had\n",
    "\n",
    "PRECISION_CONFIGS = [\n",
    "    {\n",
    "        'name': 'Trial_2_HighestPrecision',\n",
    "        'window': 24, 'filters': 32, 'kernel': 2,\n",
    "        'nb_stacks': 3, 'blocks_per_stack': 2,\n",
    "        'dropout': 0.3318, 'dense': 128, 'act': 'swish',\n",
    "        'lr': 0.0002455, 'batch': 64, 'norm': 'layer'\n",
    "    },\n",
    "    # add more configs if you like â€¦\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def weighted_f1(y_t, y_p, a=ALPHA):\n",
    "    p = precision_score(y_t, y_p, zero_division=0)\n",
    "    r = recall_score   (y_t, y_p, zero_division=0)\n",
    "    return 0.0 if p+r == 0 else (1+a)*p*r/(a*p+r)\n",
    "\n",
    "def make_windows(x, y, win):\n",
    "    xs, ys = [], []\n",
    "    for i in range(win, len(x)):\n",
    "        xs.append(x[i-win:i])\n",
    "        ys.append(y[i])\n",
    "    return np.asarray(xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "def build_tcn(cfg, n_feat, cw0, cw1):\n",
    "    act_map = {'relu':'relu','elu':'elu','selu':'selu','swish':tf.nn.swish,\n",
    "               'tanh':'tanh'}\n",
    "    act = act_map[cfg['act']]\n",
    "    dilations = [2**i for i in range(cfg['nb_stacks']*cfg['blocks_per_stack'])]\n",
    "\n",
    "    inp = keras.Input((cfg['window'], n_feat))\n",
    "    x   = TCN(nb_filters=cfg['filters'],\n",
    "              kernel_size=cfg['kernel'],\n",
    "              nb_stacks=cfg['nb_stacks'],\n",
    "              dilations=dilations,\n",
    "              padding='causal',\n",
    "              dropout_rate=cfg['dropout'],\n",
    "              activation=act,\n",
    "              use_skip_connections=True,\n",
    "              use_batch_norm = cfg['norm']=='batch',\n",
    "              use_layer_norm = cfg['norm']=='layer',\n",
    "              return_sequences=False)(inp)\n",
    "\n",
    "    x   = keras.layers.Dense(cfg['dense'], activation=act)(x)\n",
    "    x   = keras.layers.Dropout(cfg['dropout'])(x)\n",
    "    out = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    # class-balanced BCE\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), cw1, cw0)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(keras.optimizers.Adam(cfg['lr']), loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ load data once â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ðŸ“Š loading & scaling data â€¦\")\n",
    "df = (pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "        .loc[\"2018-01-01\":]\n",
    "        .drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "        .dropna(subset=['target']).dropna())\n",
    "\n",
    "X, y = df.drop(columns='target').values, df['target'].astype(int).values\n",
    "n_features = X.shape[1]\n",
    "split = int(len(df)*(1-VAL_FRAC))\n",
    "\n",
    "scaler = StandardScaler().fit(X[:split])\n",
    "X_tr_raw = scaler.transform(X[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y[:split], y[split:]\n",
    "\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CW0 = np.float32(1.0)\n",
    "CW1 = np.float32((1-pos_rate)/pos_rate if pos_rate else 1.0)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ compare configs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "results = []\n",
    "\n",
    "for cfg in PRECISION_CONFIGS:\n",
    "    tag = (f\"{cfg['name']} | win={cfg['window']}, \"\n",
    "           f\"filters={cfg['filters']}, act={cfg['act']}\")\n",
    "    print(\"\\n\"+tag+\"\\n\"+\"â”€\"*len(tag))\n",
    "\n",
    "    # build windows\n",
    "    X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, cfg['window'])\n",
    "\n",
    "    # leak-free: prepend last â€˜windowâ€™ rows of train to val before windowing\n",
    "    X_val_stack = np.concatenate([X_tr_raw[-cfg['window']:], X_va_raw])\n",
    "    y_val_stack = np.concatenate([y_tr_raw[-cfg['window']:], y_va_raw])\n",
    "    X_va, y_va = make_windows(X_val_stack, y_val_stack, cfg['window'])\n",
    "\n",
    "    tf.keras.backend.clear_session(); gc.collect()\n",
    "    model = build_tcn(cfg, n_features, CW0, CW1)\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=EARLY_STOP,\n",
    "                                      restore_best_weights=True, verbose=0),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=7, factor=.5,\n",
    "                                          min_lr=1e-7, verbose=0)\n",
    "    ]\n",
    "\n",
    "    model.fit(X_tr, y_tr,\n",
    "              validation_data=(X_va, y_va),\n",
    "              epochs=EPOCHS,\n",
    "              batch_size=cfg['batch'],\n",
    "              shuffle=False,\n",
    "              callbacks=callbacks,\n",
    "              verbose=0)\n",
    "\n",
    "    prob = model.predict(X_va, verbose=0).ravel()\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "    prec = precision_score(y_va, pred, zero_division=0)\n",
    "    rec  = recall_score   (y_va, pred, zero_division=0)\n",
    "    f1   = f1_score       (y_va, pred, zero_division=0)\n",
    "    f1_w = weighted_f1    (y_va, pred)\n",
    "    auc  = roc_auc_score  (y_va, prob)\n",
    "    acc  = accuracy_score (y_va, pred)\n",
    "\n",
    "    print(f\"P={prec:.3f}  R={rec:.3f}  F1={f1:.3f} \"\n",
    "          f\"FÎ±2={f1_w:.3f}  AUC={auc:.3f}\")\n",
    "\n",
    "    # â”€â”€â”€ save per-bar predictions in required format â”€â”€\n",
    "    val_start = split + cfg['window']\n",
    "    ts_index  = df.index[val_start : val_start + len(prob)]\n",
    "\n",
    "    # â”€â”€â”€ save per-bar predictions in required format â”€â”€\n",
    "    val_start = split                          # â† FIXED\n",
    "    ts_index  = df.index[val_start : val_start + len(prob)]\n",
    "\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"timestamp\"   : ts_index.strftime(\"%d/%m/%Y %H:%M\"),\n",
    "        \"prob_up\"     : prob,\n",
    "        \"prob_down\"   : 1.0 - prob,\n",
    "        \"winning_prob\": np.where(prob >= 0.5, prob, 1.0 - prob),\n",
    "        \"prediction\"  : pred,\n",
    "        \"actual\"      : y_va\n",
    "    })\n",
    "\n",
    "    csv_name = f\"{cfg['name']}_win{cfg['window']}_predictions.csv\"\n",
    "    pred_df.to_csv(csv_name, index=False, float_format=\"%.6f\")\n",
    "    print(f\"ðŸ“„ saved predictions â†’ {csv_name}\")\n",
    "\n",
    "\n",
    "    csv_name = f\"{cfg['name']}_win{cfg['window']}_predictions.csv\"\n",
    "    pred_df.to_csv(csv_name, index=False, float_format=\"%.6f\")\n",
    "    print(f\"ðŸ“„ saved predictions â†’ {csv_name}\")\n",
    "\n",
    "    # keep run-level metrics\n",
    "    results.append(dict(name=cfg['name'], precision=prec,\n",
    "                        recall=rec, f1=f1_w, auc=auc))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ leaderboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nðŸ† Leaderboard (by Precision)\")\n",
    "for rk, res in enumerate(sorted(results, key=lambda x: x['precision'],\n",
    "                                reverse=True), 1):\n",
    "    print(f\"{rk}. {res['name']:<25s} | \"\n",
    "          f\"P={res['precision']:.3f} R={res['recall']:.3f} \"\n",
    "          f\"FÎ±2={res['f1']:.3f} AUC={res['auc']:.3f}\")\n",
    "\n",
    "# optional: JSON summary\n",
    "with open(\"tcn_comparison_summary.json\", \"w\") as fp:\n",
    "    json.dump({\"timestamp\":datetime.utcnow().isoformat(timespec='seconds')+'Z',\n",
    "               \"metrics\":results}, fp, indent=2)\n",
    "print(\"\\nðŸ“‘ Summary saved â†’ tcn_comparison_summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ–¥ï¸ GPU Status:\n",
      "   GPUs available: 0\n",
      "ðŸŽ¯ Training: Trial_2_HighestPrecision\n",
      "   Expected: P=0.527, R=0.300, F1=0.350\n",
      "   Window: 24, Filters: 32, Act: swish\n",
      "\n",
      "ðŸ“Š Loading data...\n",
      "   Data shape: (15855, 34)\n",
      "   Features: 33\n",
      "   Train/Val split: 12684/3171\n",
      "   Class weights: 1.00 / 0.97\n",
      "\n",
      "ðŸš€ Training Trial_2_HighestPrecision...\n",
      "   Train windows: 12,660\n",
      "   Val windows: 3,147\n",
      "WARNING:tensorflow:From c:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/60\n",
      "198/198 - 31s - 155ms/step - loss: 0.9185 - val_loss: 0.6997 - learning_rate: 2.4550e-04\n",
      "Epoch 2/60\n",
      "198/198 - 17s - 87ms/step - loss: 0.7636 - val_loss: 0.6991 - learning_rate: 2.4550e-04\n",
      "Epoch 3/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.7231 - val_loss: 0.6958 - learning_rate: 2.4550e-04\n",
      "Epoch 4/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.7087 - val_loss: 0.6943 - learning_rate: 2.4550e-04\n",
      "Epoch 5/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6985 - val_loss: 0.6932 - learning_rate: 2.4550e-04\n",
      "Epoch 6/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6951 - val_loss: 0.6955 - learning_rate: 2.4550e-04\n",
      "Epoch 7/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6893 - val_loss: 0.6903 - learning_rate: 2.4550e-04\n",
      "Epoch 8/60\n",
      "198/198 - 17s - 84ms/step - loss: 0.6878 - val_loss: 0.6912 - learning_rate: 2.4550e-04\n",
      "Epoch 9/60\n",
      "198/198 - 14s - 70ms/step - loss: 0.6871 - val_loss: 0.6894 - learning_rate: 2.4550e-04\n",
      "Epoch 10/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6895 - val_loss: 0.6903 - learning_rate: 2.4550e-04\n",
      "Epoch 11/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6851 - val_loss: 0.6873 - learning_rate: 2.4550e-04\n",
      "Epoch 12/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6854 - val_loss: 0.6891 - learning_rate: 2.4550e-04\n",
      "Epoch 13/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6854 - val_loss: 0.6888 - learning_rate: 2.4550e-04\n",
      "Epoch 14/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6845 - val_loss: 0.6862 - learning_rate: 2.4550e-04\n",
      "Epoch 15/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6846 - val_loss: 0.6864 - learning_rate: 2.4550e-04\n",
      "Epoch 16/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6837 - val_loss: 0.6864 - learning_rate: 2.4550e-04\n",
      "Epoch 17/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6841 - val_loss: 0.6861 - learning_rate: 2.4550e-04\n",
      "Epoch 18/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6833 - val_loss: 0.6849 - learning_rate: 2.4550e-04\n",
      "Epoch 19/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6836 - val_loss: 0.6847 - learning_rate: 2.4550e-04\n",
      "Epoch 20/60\n",
      "198/198 - 17s - 87ms/step - loss: 0.6837 - val_loss: 0.6862 - learning_rate: 2.4550e-04\n",
      "Epoch 21/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6828 - val_loss: 0.6849 - learning_rate: 2.4550e-04\n",
      "Epoch 22/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6829 - val_loss: 0.6869 - learning_rate: 2.4550e-04\n",
      "Epoch 23/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6831 - val_loss: 0.6866 - learning_rate: 2.4550e-04\n",
      "Epoch 24/60\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00012275000335648656.\n",
      "198/198 - 17s - 86ms/step - loss: 0.6828 - val_loss: 0.6868 - learning_rate: 2.4550e-04\n",
      "Epoch 25/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6835 - val_loss: 0.6840 - learning_rate: 1.2275e-04\n",
      "Epoch 26/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6824 - val_loss: 0.6840 - learning_rate: 1.2275e-04\n",
      "Epoch 27/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6824 - val_loss: 0.6838 - learning_rate: 1.2275e-04\n",
      "Epoch 28/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6835 - val_loss: 0.6840 - learning_rate: 1.2275e-04\n",
      "Epoch 29/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6821 - val_loss: 0.6834 - learning_rate: 1.2275e-04\n",
      "Epoch 30/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6828 - val_loss: 0.6834 - learning_rate: 1.2275e-04\n",
      "Epoch 31/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6824 - val_loss: 0.6837 - learning_rate: 1.2275e-04\n",
      "Epoch 32/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6824 - val_loss: 0.6833 - learning_rate: 1.2275e-04\n",
      "Epoch 33/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6823 - val_loss: 0.6839 - learning_rate: 1.2275e-04\n",
      "Epoch 34/60\n",
      "198/198 - 17s - 87ms/step - loss: 0.6821 - val_loss: 0.6840 - learning_rate: 1.2275e-04\n",
      "Epoch 35/60\n",
      "198/198 - 17s - 87ms/step - loss: 0.6816 - val_loss: 0.6848 - learning_rate: 1.2275e-04\n",
      "Epoch 36/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6821 - val_loss: 0.6853 - learning_rate: 1.2275e-04\n",
      "Epoch 37/60\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.137500167824328e-05.\n",
      "198/198 - 9s - 44ms/step - loss: 0.6816 - val_loss: 0.6859 - learning_rate: 1.2275e-04\n",
      "Epoch 38/60\n",
      "198/198 - 16s - 83ms/step - loss: 0.6822 - val_loss: 0.6855 - learning_rate: 6.1375e-05\n",
      "Epoch 39/60\n",
      "198/198 - 17s - 87ms/step - loss: 0.6814 - val_loss: 0.6847 - learning_rate: 6.1375e-05\n",
      "Epoch 40/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6816 - val_loss: 0.6848 - learning_rate: 6.1375e-05\n",
      "Epoch 41/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6808 - val_loss: 0.6854 - learning_rate: 6.1375e-05\n",
      "Epoch 42/60\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 3.068750083912164e-05.\n",
      "198/198 - 17s - 87ms/step - loss: 0.6817 - val_loss: 0.6854 - learning_rate: 6.1375e-05\n",
      "Epoch 43/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6809 - val_loss: 0.6854 - learning_rate: 3.0688e-05\n",
      "Epoch 44/60\n",
      "198/198 - 17s - 85ms/step - loss: 0.6816 - val_loss: 0.6850 - learning_rate: 3.0688e-05\n",
      "Epoch 45/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6811 - val_loss: 0.6850 - learning_rate: 3.0688e-05\n",
      "Epoch 46/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6813 - val_loss: 0.6849 - learning_rate: 3.0688e-05\n",
      "Epoch 47/60\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.534375041956082e-05.\n",
      "198/198 - 17s - 86ms/step - loss: 0.6814 - val_loss: 0.6850 - learning_rate: 3.0688e-05\n",
      "Epoch 48/60\n",
      "198/198 - 21s - 108ms/step - loss: 0.6817 - val_loss: 0.6849 - learning_rate: 1.5344e-05\n",
      "Epoch 49/60\n",
      "198/198 - 17s - 87ms/step - loss: 0.6806 - val_loss: 0.6850 - learning_rate: 1.5344e-05\n",
      "Epoch 50/60\n",
      "198/198 - 17s - 87ms/step - loss: 0.6809 - val_loss: 0.6851 - learning_rate: 1.5344e-05\n",
      "Epoch 51/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6818 - val_loss: 0.6850 - learning_rate: 1.5344e-05\n",
      "Epoch 52/60\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 7.67187520978041e-06.\n",
      "198/198 - 17s - 86ms/step - loss: 0.6821 - val_loss: 0.6849 - learning_rate: 1.5344e-05\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "\n",
      "â±ï¸ Training completed in: 0:14:40.394667\n",
      "\n",
      "ðŸ“Š Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Results vs Expected:\n",
      "   Precision: 0.534 (expected: 0.527) âœ…\n",
      "   Recall:    0.269 (expected: 0.300) âŒ\n",
      "   F1 Std:    0.358 (expected: 0.350)\n",
      "   F1 Weighted (Î±=2): 0.322\n",
      "   Accuracy:  0.495\n",
      "   AUC:       0.512\n",
      "\n",
      "ðŸ’¾ Saving results...\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "\nObject ResidualBlock was created by passing\nnon-serializable argument values in `__init__()`,\nand therefore the object must override `get_config()` in\norder to be serializable. Please implement `get_config()`.\n\nExample:\n\nclass CustomLayer(keras.layers.Layer):\n    def __init__(self, arg1, arg2, **kwargs):\n        super().__init__(**kwargs)\n        self.arg1 = arg1\n        self.arg2 = arg2\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"arg1\": self.arg1,\n            \"arg2\": self.arg2,\n        })\n        return config",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 202\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ’¾ Saving results...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# Save model and scaler\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtcn_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCFG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m    204\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(scaler, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCFG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [deepcopy(a, memo) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:161\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    159\u001b[0m reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce_ex__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reductor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mreductor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: \nObject ResidualBlock was created by passing\nnon-serializable argument values in `__init__()`,\nand therefore the object must override `get_config()` in\norder to be serializable. Please implement `get_config()`.\n\nExample:\n\nclass CustomLayer(keras.layers.Layer):\n    def __init__(self, arg1, arg2, **kwargs):\n        super().__init__(**kwargs)\n        self.arg1 = arg1\n        self.arg2 = arg2\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"arg1\": self.arg1,\n            \"arg2\": self.arg2,\n        })\n        return config"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tcn_trial3_only.py - TRIAL 3 SECOND PRECISION\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Quick training of Trial 3 configuration only.\n",
    "Expected: Precision=0.527, Recall=0.300, F1=0.350\n",
    "\"\"\"\n",
    "\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             f1_score, accuracy_score, roc_auc_score)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "print(\"ðŸ–¥ï¸ GPU Status:\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"   GPUs available: {len(gpus)}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC = 0.20\n",
    "ALPHA = 2.0\n",
    "EPOCHS = 60  # Quick training\n",
    "EARLY_STOP = 20\n",
    "\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6', 'ema_cross_up', 'macd_cross_up', \n",
    "    'oversold_reversal', 'overbought_reversal'\n",
    "]\n",
    "\n",
    "# TRIAL 3 CONFIG ONLY\n",
    "CFG =    {\n",
    "        'name': 'Trial_2_HighestPrecision',\n",
    "        'window': 24, 'filters': 32, 'kernel': 2,\n",
    "        'nb_stacks': 3, 'blocks_per_stack': 2,\n",
    "        'dropout': 0.3318, 'dense': 128, 'act': 'swish',\n",
    "        'lr': 0.0002455, 'batch': 64, 'norm': 'layer'\n",
    "    }\n",
    "\n",
    "print(f\"ðŸŽ¯ Training: {CFG['name']}\")\n",
    "print(f\"   Expected: P=0.527, R=0.300, F1=0.350\")\n",
    "print(f\"   Window: {CFG['window']}, Filters: {CFG['filters']}, Act: {CFG['act']}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def weighted_f1(y_t, y_p, a=ALPHA):\n",
    "    p = precision_score(y_t, y_p, zero_division=0)\n",
    "    r = recall_score(y_t, y_p, zero_division=0)\n",
    "    return 0.0 if p+r == 0 else (1+a)*p*r/(a*p+r)\n",
    "\n",
    "def make_windows(x, y, win):\n",
    "    xs, ys = [], []\n",
    "    for i in range(win, len(x)):\n",
    "        xs.append(x[i-win:i])\n",
    "        ys.append(y[i])\n",
    "    return np.asarray(xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "def build_tcn(cfg, n_feat, cw0, cw1):\n",
    "    act_map = {'relu':'relu', 'elu':'elu', 'selu':'selu', 'swish':tf.nn.swish, 'tanh':'tanh'}\n",
    "    act = act_map[cfg['act']]\n",
    "    dilations = [2**i for i in range(cfg['nb_stacks'] * cfg['blocks_per_stack'])]\n",
    "\n",
    "    inp = keras.Input((cfg['window'], n_feat))\n",
    "    x = TCN(nb_filters=cfg['filters'],\n",
    "            kernel_size=cfg['kernel'],\n",
    "            nb_stacks=cfg['nb_stacks'],\n",
    "            dilations=dilations,\n",
    "            padding='causal',\n",
    "            dropout_rate=cfg['dropout'],\n",
    "            activation=act,\n",
    "            use_skip_connections=True,\n",
    "            use_batch_norm=cfg['norm']=='batch',\n",
    "            use_layer_norm=cfg['norm']=='layer',\n",
    "            return_sequences=False)(inp)\n",
    "\n",
    "    x = keras.layers.Dense(cfg['dense'], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg['dropout'])(x)\n",
    "    out = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    # Weighted BCE\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w = tf.where(tf.equal(y_t, 1), cw1, cw0)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(keras.optimizers.Adam(cfg['lr']), loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Load Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nðŸ“Š Loading data...\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"]).dropna()\n",
    "\n",
    "\n",
    "X, y = df.drop(columns='target').values, df['target'].astype(int).values\n",
    "n_features = X.shape[1]\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "\n",
    "print(f\"   Data shape: {df.shape}\")\n",
    "print(f\"   Features: {n_features}\")\n",
    "print(f\"   Train/Val split: {split}/{len(df)-split}\")\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler().fit(X[:split])\n",
    "X_tr_raw = scaler.transform(X[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y[:split], y[split:]\n",
    "\n",
    "# Class weights\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CW0 = np.float32(1.0)\n",
    "CW1 = np.float32((1-pos_rate)/pos_rate if pos_rate else 1.0)\n",
    "print(f\"   Class weights: {CW0:.2f} / {CW1:.2f}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Train Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nðŸš€ Training {CFG['name']}...\")\n",
    "\n",
    "# Create windows\n",
    "X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, CFG['window'])\n",
    "X_va, y_va = make_windows(X_va_raw, y_va_raw, CFG['window'])\n",
    "\n",
    "print(f\"   Train windows: {len(X_tr):,}\")\n",
    "print(f\"   Val windows: {len(X_va):,}\")\n",
    "\n",
    "# Build model\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "model = build_tcn(CFG, n_features, CW0, CW1)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=EARLY_STOP, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-7, verbose=1)\n",
    "]\n",
    "\n",
    "# Train\n",
    "start_time = datetime.now()\n",
    "history = model.fit(X_tr, y_tr,\n",
    "                    validation_data=(X_va, y_va),\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=CFG['batch'],\n",
    "                    shuffle=False,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "train_time = datetime.now() - start_time\n",
    "print(f\"\\nâ±ï¸ Training completed in: {train_time}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Evaluate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nðŸ“Š Evaluating...\")\n",
    "prob = model.predict(X_va, verbose=0).ravel()\n",
    "pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "prec = precision_score(y_va, pred, zero_division=0)\n",
    "rec = recall_score(y_va, pred, zero_division=0)\n",
    "f1 = f1_score(y_va, pred, zero_division=0)\n",
    "f1_w = weighted_f1(y_va, pred)\n",
    "auc = roc_auc_score(y_va, prob)\n",
    "acc = accuracy_score(y_va, pred)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Results vs Expected:\")\n",
    "print(f\"   Precision: {prec:.3f} (expected: 0.527) {'âœ…' if prec >= 0.520 else 'âŒ'}\")\n",
    "print(f\"   Recall:    {rec:.3f} (expected: 0.300) {'âœ…' if rec >= 0.290 else 'âŒ'}\")\n",
    "print(f\"   F1 Std:    {f1:.3f} (expected: 0.350)\")\n",
    "print(f\"   F1 Weighted (Î±=2): {f1_w:.3f}\")\n",
    "print(f\"   Accuracy:  {acc:.3f}\")\n",
    "print(f\"   AUC:       {auc:.3f}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Save Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nðŸ’¾ Saving results...\")\n",
    "\n",
    "# Save model and scaler\n",
    "model.save(f\"tcn_{CFG['name'].lower()}.h5\")\n",
    "import joblib\n",
    "joblib.dump(scaler, f\"scaler_{CFG['name'].lower()}.pkl\")\n",
    "\n",
    "# Generate predictions CSV\n",
    "val_start_idx = split + CFG['window']\n",
    "timestamps = df.index[val_start_idx:val_start_idx + len(prob)]\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"timestamp\": timestamps.strftime(\"%d/%m/%Y %H:%M\"),\n",
    "    \"prob_up\": prob,\n",
    "    \"prob_down\": 1.0 - prob,\n",
    "    \"winning_prob\": np.maximum(prob, 1.0 - prob),\n",
    "    \"prediction\": pred,\n",
    "    \"actual\": y_va\n",
    "})\n",
    "\n",
    "csv_name = f\"{CFG['name']}_predictions.csv\"\n",
    "pred_df.to_csv(csv_name, index=False, float_format=\"%.6f\")\n",
    "\n",
    "print(f\"âœ… Model saved: tcn_{CFG['name'].lower()}.h5\")\n",
    "print(f\"âœ… Scaler saved: scaler_{CFG['name'].lower()}.pkl\") \n",
    "print(f\"âœ… Predictions saved: {csv_name} ({len(pred_df):,} rows)\")\n",
    "\n",
    "# Save summary\n",
    "summary = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"config\": CFG,\n",
    "    \"training_time_seconds\": train_time.total_seconds(),\n",
    "    \"epochs_trained\": len(history.history['loss']),\n",
    "    \"metrics\": {\n",
    "        \"precision\": float(prec),\n",
    "        \"recall\": float(rec),\n",
    "        \"f1_standard\": float(f1),\n",
    "        \"f1_weighted\": float(f1_w),\n",
    "        \"accuracy\": float(acc),\n",
    "        \"auc\": float(auc)\n",
    "    },\n",
    "    \"expected_vs_actual\": {\n",
    "        \"precision_diff\": float(prec - 0.527),\n",
    "        \"recall_diff\": float(rec - 0.300),\n",
    "        \"f1_diff\": float(f1 - 0.350)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"{CFG['name']}_summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Summary saved: {CFG['name']}_summary.json\")\n",
    "print(f\"\\nðŸŽ‰ Training complete! Time: {train_time}\")\n",
    "\n",
    "# Quick sample of predictions\n",
    "print(f\"\\nðŸ“‹ Sample predictions:\")\n",
    "print(pred_df.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a27332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ–¥ï¸ GPU Status:\n",
      "   GPUs available: 0\n",
      "\n",
      "ðŸ“Š Loading data...\n",
      "Epoch 1/60\n",
      "198/198 - 26s - 130ms/step - loss: 0.9407 - val_loss: 0.6833 - learning_rate: 2.4550e-04\n",
      "Epoch 2/60\n",
      "198/198 - 9s - 46ms/step - loss: 0.7668 - val_loss: 0.6830 - learning_rate: 2.4550e-04\n",
      "Epoch 3/60\n",
      "198/198 - 9s - 46ms/step - loss: 0.7286 - val_loss: 0.6820 - learning_rate: 2.4550e-04\n",
      "Epoch 4/60\n",
      "198/198 - 9s - 45ms/step - loss: 0.7065 - val_loss: 0.6822 - learning_rate: 2.4550e-04\n",
      "Epoch 5/60\n",
      "198/198 - 9s - 45ms/step - loss: 0.6947 - val_loss: 0.6826 - learning_rate: 2.4550e-04\n",
      "Epoch 6/60\n",
      "198/198 - 9s - 46ms/step - loss: 0.6913 - val_loss: 0.6841 - learning_rate: 2.4550e-04\n",
      "Epoch 7/60\n",
      "198/198 - 9s - 46ms/step - loss: 0.6907 - val_loss: 0.6838 - learning_rate: 2.4550e-04\n",
      "Epoch 8/60\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00012275000335648656.\n",
      "198/198 - 12s - 62ms/step - loss: 0.6903 - val_loss: 0.6832 - learning_rate: 2.4550e-04\n",
      "Epoch 9/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6880 - val_loss: 0.6819 - learning_rate: 1.2275e-04\n",
      "Epoch 10/60\n",
      "198/198 - 16s - 82ms/step - loss: 0.6890 - val_loss: 0.6827 - learning_rate: 1.2275e-04\n",
      "Epoch 11/60\n",
      "198/198 - 9s - 47ms/step - loss: 0.6865 - val_loss: 0.6827 - learning_rate: 1.2275e-04\n",
      "Epoch 12/60\n",
      "198/198 - 9s - 46ms/step - loss: 0.6863 - val_loss: 0.6830 - learning_rate: 1.2275e-04\n",
      "Epoch 13/60\n",
      "198/198 - 9s - 45ms/step - loss: 0.6855 - val_loss: 0.6841 - learning_rate: 1.2275e-04\n",
      "Epoch 14/60\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 6.137500167824328e-05.\n",
      "198/198 - 9s - 44ms/step - loss: 0.6862 - val_loss: 0.6832 - learning_rate: 1.2275e-04\n",
      "Epoch 15/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6866 - val_loss: 0.6823 - learning_rate: 6.1375e-05\n",
      "Epoch 16/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6863 - val_loss: 0.6819 - learning_rate: 6.1375e-05\n",
      "Epoch 17/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6856 - val_loss: 0.6821 - learning_rate: 6.1375e-05\n",
      "Epoch 18/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6851 - val_loss: 0.6820 - learning_rate: 6.1375e-05\n",
      "Epoch 19/60\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.068750083912164e-05.\n",
      "198/198 - 9s - 44ms/step - loss: 0.6859 - val_loss: 0.6819 - learning_rate: 6.1375e-05\n",
      "Epoch 20/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6848 - val_loss: 0.6817 - learning_rate: 3.0688e-05\n",
      "Epoch 21/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6845 - val_loss: 0.6818 - learning_rate: 3.0688e-05\n",
      "Epoch 22/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6851 - val_loss: 0.6819 - learning_rate: 3.0688e-05\n",
      "Epoch 23/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6855 - val_loss: 0.6820 - learning_rate: 3.0688e-05\n",
      "Epoch 24/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6851 - val_loss: 0.6819 - learning_rate: 3.0688e-05\n",
      "Epoch 25/60\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.534375041956082e-05.\n",
      "198/198 - 9s - 43ms/step - loss: 0.6837 - val_loss: 0.6818 - learning_rate: 3.0688e-05\n",
      "Epoch 26/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6835 - val_loss: 0.6817 - learning_rate: 1.5344e-05\n",
      "Epoch 27/60\n",
      "198/198 - 9s - 43ms/step - loss: 0.6844 - val_loss: 0.6816 - learning_rate: 1.5344e-05\n",
      "Epoch 28/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6848 - val_loss: 0.6816 - learning_rate: 1.5344e-05\n",
      "Epoch 29/60\n",
      "198/198 - 9s - 43ms/step - loss: 0.6843 - val_loss: 0.6816 - learning_rate: 1.5344e-05\n",
      "Epoch 30/60\n",
      "198/198 - 9s - 43ms/step - loss: 0.6846 - val_loss: 0.6815 - learning_rate: 1.5344e-05\n",
      "Epoch 31/60\n",
      "198/198 - 9s - 43ms/step - loss: 0.6847 - val_loss: 0.6816 - learning_rate: 1.5344e-05\n",
      "Epoch 32/60\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 7.67187520978041e-06.\n",
      "198/198 - 9s - 44ms/step - loss: 0.6846 - val_loss: 0.6816 - learning_rate: 1.5344e-05\n",
      "Epoch 33/60\n",
      "198/198 - 9s - 43ms/step - loss: 0.6830 - val_loss: 0.6816 - learning_rate: 7.6719e-06\n",
      "Epoch 34/60\n",
      "198/198 - 9s - 43ms/step - loss: 0.6841 - val_loss: 0.6816 - learning_rate: 7.6719e-06\n",
      "Epoch 35/60\n",
      "198/198 - 9s - 43ms/step - loss: 0.6835 - val_loss: 0.6816 - learning_rate: 7.6719e-06\n",
      "Epoch 36/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6848 - val_loss: 0.6817 - learning_rate: 7.6719e-06\n",
      "Epoch 37/60\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.835937604890205e-06.\n",
      "198/198 - 9s - 43ms/step - loss: 0.6843 - val_loss: 0.6817 - learning_rate: 7.6719e-06\n",
      "Epoch 38/60\n",
      "198/198 - 9s - 44ms/step - loss: 0.6844 - val_loss: 0.6817 - learning_rate: 3.8359e-06\n",
      "Epoch 39/60\n",
      "198/198 - 9s - 45ms/step - loss: 0.6835 - val_loss: 0.6817 - learning_rate: 3.8359e-06\n",
      "Epoch 40/60\n",
      "198/198 - 9s - 45ms/step - loss: 0.6843 - val_loss: 0.6817 - learning_rate: 3.8359e-06\n",
      "Epoch 41/60\n",
      "198/198 - 13s - 64ms/step - loss: 0.6825 - val_loss: 0.6817 - learning_rate: 3.8359e-06\n",
      "Epoch 42/60\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.9179688024451025e-06.\n",
      "198/198 - 18s - 89ms/step - loss: 0.6836 - val_loss: 0.6816 - learning_rate: 3.8359e-06\n",
      "Epoch 43/60\n",
      "198/198 - 18s - 88ms/step - loss: 0.6844 - val_loss: 0.6816 - learning_rate: 1.9180e-06\n",
      "Epoch 44/60\n",
      "198/198 - 18s - 88ms/step - loss: 0.6840 - val_loss: 0.6816 - learning_rate: 1.9180e-06\n",
      "Epoch 45/60\n",
      "198/198 - 21s - 104ms/step - loss: 0.6836 - val_loss: 0.6816 - learning_rate: 1.9180e-06\n",
      "Epoch 46/60\n",
      "198/198 - 17s - 87ms/step - loss: 0.6842 - val_loss: 0.6816 - learning_rate: 1.9180e-06\n",
      "Epoch 47/60\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 9.589844012225512e-07.\n",
      "198/198 - 9s - 46ms/step - loss: 0.6844 - val_loss: 0.6816 - learning_rate: 1.9180e-06\n",
      "Epoch 48/60\n",
      "198/198 - 17s - 86ms/step - loss: 0.6847 - val_loss: 0.6816 - learning_rate: 9.5898e-07\n",
      "Epoch 49/60\n",
      "198/198 - 17s - 84ms/step - loss: 0.6842 - val_loss: 0.6816 - learning_rate: 9.5898e-07\n",
      "Epoch 50/60\n",
      "198/198 - 17s - 84ms/step - loss: 0.6839 - val_loss: 0.6816 - learning_rate: 9.5898e-07\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "ðŸ“ˆ Results:\n",
      "   Precision:  0.525\n",
      "   Recall:     0.705\n",
      "   F1 Score:   0.602\n",
      "   F1 (Î±=2):   0.633\n",
      "   Accuracy:   0.513\n",
      "   AUC:        0.513\n",
      "âœ… Predictions saved: Trial_2_HighestPrecision_predictions.csv (3,147 rows)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tcn_trial3_only.py - TRIAL 3 SECOND PRECISION\n",
    "Quick training of Trial 3 configuration only.\n",
    "Expected: Precision=0.527, Recall=0.300, F1=0.350\n",
    "\"\"\"\n",
    "\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             f1_score, accuracy_score, roc_auc_score)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "print(\"ðŸ–¥ï¸ GPU Status:\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"   GPUs available: {len(gpus)}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC = 0.20\n",
    "ALPHA = 2.0\n",
    "EPOCHS = 60\n",
    "EARLY_STOP = 20\n",
    "\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6', 'ema_cross_up', 'macd_cross_up', \n",
    "    'oversold_reversal', 'overbought_reversal'\n",
    "]\n",
    "\n",
    "CFG = {\n",
    "    'name': 'Trial_2_HighestPrecision',\n",
    "    'window': 24, 'filters': 32, 'kernel': 2,\n",
    "    'nb_stacks': 3, 'blocks_per_stack': 2,\n",
    "    'dropout': 0.3318, 'dense': 128, 'act': 'swish',\n",
    "    'lr': 0.0002455, 'batch': 64, 'norm': 'layer'\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def weighted_f1(y_t, y_p, a=ALPHA):\n",
    "    p = precision_score(y_t, y_p, zero_division=0)\n",
    "    r = recall_score(y_t, y_p, zero_division=0)\n",
    "    return 0.0 if p+r == 0 else (1+a)*p*r/(a*p+r)\n",
    "\n",
    "def make_windows(x, y, win):\n",
    "    xs, ys = [], []\n",
    "    for i in range(win, len(x)):\n",
    "        xs.append(x[i-win:i])\n",
    "        ys.append(y[i])\n",
    "    return np.asarray(xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "def build_tcn(cfg, n_feat, cw0, cw1):\n",
    "    act_map = {'relu':'relu', 'elu':'elu', 'selu':'selu', 'swish':tf.nn.swish, 'tanh':'tanh'}\n",
    "    act = act_map[cfg['act']]\n",
    "    dilations = [2**i for i in range(cfg['nb_stacks'] * cfg['blocks_per_stack'])]\n",
    "\n",
    "    inp = keras.Input((cfg['window'], n_feat))\n",
    "    x = TCN(nb_filters=cfg['filters'], kernel_size=cfg['kernel'], nb_stacks=cfg['nb_stacks'],\n",
    "            dilations=dilations, padding='causal', dropout_rate=cfg['dropout'], activation=act,\n",
    "            use_skip_connections=True, use_batch_norm=cfg['norm']=='batch', use_layer_norm=cfg['norm']=='layer',\n",
    "            return_sequences=False)(inp)\n",
    "    x = keras.layers.Dense(cfg['dense'], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg['dropout'])(x)\n",
    "    out = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w = tf.where(tf.equal(y_t, 1), cw1, cw0)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(keras.optimizers.Adam(cfg['lr']), loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Load Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nðŸ“Š Loading data...\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"]).dropna()\n",
    "\n",
    "X, y = df.drop(columns='target').values, df['target'].astype(int).values\n",
    "n_features = X.shape[1]\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "\n",
    "scaler = StandardScaler().fit(X[:split])\n",
    "X_tr_raw = scaler.transform(X[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y[:split], y[split:]\n",
    "\n",
    "# Class weights\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CW0 = np.float32(1.0)\n",
    "CW1 = np.float32((1-pos_rate)/pos_rate if pos_rate else 1.0)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Train â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, CFG['window'])\n",
    "X_va, y_va = make_windows(X_va_raw, y_va_raw, CFG['window'])\n",
    "\n",
    "model = build_tcn(CFG, n_features, CW0, CW1)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=EARLY_STOP, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-7, verbose=1)\n",
    "]\n",
    "\n",
    "start_time = datetime.now()\n",
    "model.fit(X_tr, y_tr, validation_data=(X_va, y_va),\n",
    "          epochs=EPOCHS, batch_size=CFG['batch'], shuffle=False,\n",
    "          callbacks=callbacks, verbose=2)\n",
    "train_time = datetime.now() - start_time\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Evaluate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "prob = model.predict(X_va, verbose=0).ravel()\n",
    "pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "prec = precision_score(y_va, pred, zero_division=0)\n",
    "rec = recall_score(y_va, pred, zero_division=0)\n",
    "f1 = f1_score(y_va, pred, zero_division=0)\n",
    "f1_w = weighted_f1(y_va, pred)\n",
    "auc = roc_auc_score(y_va, prob)\n",
    "acc = accuracy_score(y_va, pred)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Results:\")\n",
    "print(f\"   Precision:  {prec:.3f}\")\n",
    "print(f\"   Recall:     {rec:.3f}\")\n",
    "print(f\"   F1 Score:   {f1:.3f}\")\n",
    "print(f\"   F1 (Î±=2):   {f1_w:.3f}\")\n",
    "print(f\"   Accuracy:   {acc:.3f}\")\n",
    "print(f\"   AUC:        {auc:.3f}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Save Predictions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "val_start_idx = split + CFG['window']\n",
    "timestamps = df.index[val_start_idx:val_start_idx + len(prob)]\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"timestamp\": timestamps.strftime(\"%d/%m/%Y %H:%M\"),\n",
    "    \"prob_up\": prob,\n",
    "    \"prob_down\": 1.0 - prob,\n",
    "    \"winning_prob\": np.maximum(prob, 1.0 - prob),\n",
    "    \"prediction\": pred,\n",
    "    \"actual\": y_va\n",
    "})\n",
    "\n",
    "csv_name = f\"{CFG['name']}_predictions.csv\"\n",
    "pred_df.to_csv(csv_name, index=False, float_format=\"%.6f\")\n",
    "print(f\"âœ… Predictions saved: {csv_name} ({len(pred_df):,} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3a0a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Evaluation at threshold 0.5:\n",
      "Precision: 0.525\n",
      "Recall   : 0.705\n",
      "F1 Score : 0.602\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the predictions CSV\n",
    "csv_path = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\src\\Models\\models\\models\\Trial_2_HighestPrecision_predictions.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Ensure column names are correct and lowercase\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Extract actual and predicted values\n",
    "y_true = df['actual']\n",
    "y_pred = df['prediction']  # prediction at threshold 0.5\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "# Print results\n",
    "print(\"ðŸ“Š Evaluation at threshold 0.5:\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall   : {recall:.3f}\")\n",
    "print(f\"F1 Score : {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4888667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ–¥ï¸ GPU Status:\n",
      "   GPUs available: 0\n",
      "\n",
      "ðŸ“Š Loading data...\n",
      "Epoch 1/60\n",
      "396/396 - 44s - 111ms/step - loss: 0.8539 - val_loss: 0.6847 - learning_rate: 5.9500e-04\n",
      "Epoch 2/60\n",
      "396/396 - 39s - 98ms/step - loss: 0.6871 - val_loss: 0.6841 - learning_rate: 5.9500e-04\n",
      "Epoch 3/60\n",
      "396/396 - 28s - 71ms/step - loss: 0.6837 - val_loss: 0.6837 - learning_rate: 5.9500e-04\n",
      "Epoch 4/60\n",
      "396/396 - 28s - 72ms/step - loss: 0.6828 - val_loss: 0.6824 - learning_rate: 5.9500e-04\n",
      "Epoch 5/60\n",
      "396/396 - 28s - 72ms/step - loss: 0.6826 - val_loss: 0.6822 - learning_rate: 5.9500e-04\n",
      "Epoch 6/60\n",
      "396/396 - 29s - 72ms/step - loss: 0.6826 - val_loss: 0.6833 - learning_rate: 5.9500e-04\n",
      "Epoch 7/60\n",
      "396/396 - 41s - 103ms/step - loss: 0.6826 - val_loss: 0.6820 - learning_rate: 5.9500e-04\n",
      "Epoch 8/60\n",
      "396/396 - 28s - 72ms/step - loss: 0.6823 - val_loss: 0.6834 - learning_rate: 5.9500e-04\n",
      "Epoch 9/60\n",
      "396/396 - 28s - 71ms/step - loss: 0.6825 - val_loss: 0.6819 - learning_rate: 5.9500e-04\n",
      "Epoch 10/60\n",
      "396/396 - 28s - 72ms/step - loss: 0.6822 - val_loss: 0.6820 - learning_rate: 5.9500e-04\n",
      "Epoch 11/60\n",
      "396/396 - 28s - 72ms/step - loss: 0.6823 - val_loss: 0.6820 - learning_rate: 5.9500e-04\n",
      "Epoch 12/60\n",
      "396/396 - 17s - 44ms/step - loss: 0.6824 - val_loss: 0.6820 - learning_rate: 5.9500e-04\n",
      "Epoch 13/60\n",
      "396/396 - 29s - 72ms/step - loss: 0.6822 - val_loss: 0.6841 - learning_rate: 5.9500e-04\n",
      "Epoch 14/60\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00029749999521300197.\n",
      "396/396 - 28s - 71ms/step - loss: 0.6819 - val_loss: 0.6891 - learning_rate: 5.9500e-04\n",
      "Epoch 15/60\n",
      "396/396 - 41s - 104ms/step - loss: 0.6821 - val_loss: 0.6831 - learning_rate: 2.9750e-04\n",
      "Epoch 16/60\n",
      "396/396 - 29s - 73ms/step - loss: 0.6820 - val_loss: 0.6823 - learning_rate: 2.9750e-04\n",
      "Epoch 17/60\n",
      "396/396 - 30s - 75ms/step - loss: 0.6814 - val_loss: 0.6845 - learning_rate: 2.9750e-04\n",
      "Epoch 18/60\n",
      "396/396 - 29s - 74ms/step - loss: 0.6818 - val_loss: 0.6836 - learning_rate: 2.9750e-04\n",
      "Epoch 19/60\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00014874999760650098.\n",
      "396/396 - 19s - 48ms/step - loss: 0.6805 - val_loss: 0.6874 - learning_rate: 2.9750e-04\n",
      "Epoch 20/60\n",
      "396/396 - 21s - 54ms/step - loss: 0.6793 - val_loss: 0.6870 - learning_rate: 1.4875e-04\n",
      "Epoch 21/60\n",
      "396/396 - 22s - 55ms/step - loss: 0.6797 - val_loss: 0.6851 - learning_rate: 1.4875e-04\n",
      "Epoch 22/60\n",
      "396/396 - 27s - 68ms/step - loss: 0.6784 - val_loss: 0.6879 - learning_rate: 1.4875e-04\n",
      "Epoch 23/60\n",
      "396/396 - 27s - 68ms/step - loss: 0.6787 - val_loss: 0.6882 - learning_rate: 1.4875e-04\n",
      "Epoch 24/60\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.437499880325049e-05.\n",
      "396/396 - 27s - 68ms/step - loss: 0.6780 - val_loss: 0.6912 - learning_rate: 1.4875e-04\n",
      "Epoch 25/60\n",
      "396/396 - 27s - 68ms/step - loss: 0.6766 - val_loss: 0.6965 - learning_rate: 7.4375e-05\n",
      "Epoch 26/60\n",
      "396/396 - 27s - 68ms/step - loss: 0.6769 - val_loss: 0.6881 - learning_rate: 7.4375e-05\n",
      "Epoch 27/60\n",
      "396/396 - 27s - 67ms/step - loss: 0.6761 - val_loss: 0.6896 - learning_rate: 7.4375e-05\n",
      "Epoch 28/60\n",
      "396/396 - 27s - 68ms/step - loss: 0.6763 - val_loss: 0.6885 - learning_rate: 7.4375e-05\n",
      "Epoch 29/60\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.7187499401625246e-05.\n",
      "396/396 - 27s - 68ms/step - loss: 0.6758 - val_loss: 0.6883 - learning_rate: 7.4375e-05\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\n",
      "ðŸ“ˆ Results:\n",
      "   Precision:  0.523\n",
      "   Recall:     1.000\n",
      "   F1 Score:   0.686\n",
      "   F1 (Î±=2):   0.767\n",
      "   Accuracy:   0.523\n",
      "   AUC:        0.502\n",
      "âœ… Predictions saved: Trial_36_BestOverall_predictions.csv (3,159 rows)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tcn_trial3_only.py - TRIAL 3 SECOND PRECISION\n",
    "Quick training of Trial 3 configuration only.\n",
    "Expected: Precision=0.527, Recall=0.300, F1=0.350\n",
    "\"\"\"\n",
    "\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             f1_score, accuracy_score, roc_auc_score)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "print(\"ðŸ–¥ï¸ GPU Status:\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"   GPUs available: {len(gpus)}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC = 0.20\n",
    "ALPHA = 2.0\n",
    "EPOCHS = 60\n",
    "EARLY_STOP = 20\n",
    "\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6', 'ema_cross_up', 'macd_cross_up', \n",
    "    'oversold_reversal', 'overbought_reversal'\n",
    "]\n",
    "\n",
    "CFG =     {\n",
    "        'name': 'Trial_36_BestOverall',\n",
    "        'window': 12, 'filters': 48, 'kernel': 5,\n",
    "        'nb_stacks': 3, 'blocks_per_stack': 2,\n",
    "        'dropout': 0.312, 'dense': 128, 'act': 'relu',\n",
    "        'lr': 0.000595, 'batch': 32, 'norm': 'layer'\n",
    "    }\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def weighted_f1(y_t, y_p, a=ALPHA):\n",
    "    p = precision_score(y_t, y_p, zero_division=0)\n",
    "    r = recall_score(y_t, y_p, zero_division=0)\n",
    "    return 0.0 if p+r == 0 else (1+a)*p*r/(a*p+r)\n",
    "\n",
    "def make_windows(x, y, win):\n",
    "    xs, ys = [], []\n",
    "    for i in range(win, len(x)):\n",
    "        xs.append(x[i-win:i])\n",
    "        ys.append(y[i])\n",
    "    return np.asarray(xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "def build_tcn(cfg, n_feat, cw0, cw1):\n",
    "    act_map = {'relu':'relu', 'elu':'elu', 'selu':'selu', 'swish':tf.nn.swish, 'tanh':'tanh'}\n",
    "    act = act_map[cfg['act']]\n",
    "    dilations = [2**i for i in range(cfg['nb_stacks'] * cfg['blocks_per_stack'])]\n",
    "\n",
    "    inp = keras.Input((cfg['window'], n_feat))\n",
    "    x = TCN(nb_filters=cfg['filters'], kernel_size=cfg['kernel'], nb_stacks=cfg['nb_stacks'],\n",
    "            dilations=dilations, padding='causal', dropout_rate=cfg['dropout'], activation=act,\n",
    "            use_skip_connections=True, use_batch_norm=cfg['norm']=='batch', use_layer_norm=cfg['norm']=='layer',\n",
    "            return_sequences=False)(inp)\n",
    "    x = keras.layers.Dense(cfg['dense'], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg['dropout'])(x)\n",
    "    out = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w = tf.where(tf.equal(y_t, 1), cw1, cw0)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(keras.optimizers.Adam(cfg['lr']), loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Load Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nðŸ“Š Loading data...\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"]).dropna()\n",
    "\n",
    "X, y = df.drop(columns='target').values, df['target'].astype(int).values\n",
    "n_features = X.shape[1]\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "\n",
    "scaler = StandardScaler().fit(X[:split])\n",
    "X_tr_raw = scaler.transform(X[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y[:split], y[split:]\n",
    "\n",
    "# Class weights\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CW0 = np.float32(1.0)\n",
    "CW1 = np.float32((1-pos_rate)/pos_rate if pos_rate else 1.0)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Train â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, CFG['window'])\n",
    "X_va, y_va = make_windows(X_va_raw, y_va_raw, CFG['window'])\n",
    "\n",
    "model = build_tcn(CFG, n_features, CW0, CW1)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=EARLY_STOP, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-7, verbose=1)\n",
    "]\n",
    "\n",
    "start_time = datetime.now()\n",
    "model.fit(X_tr, y_tr, validation_data=(X_va, y_va),\n",
    "          epochs=EPOCHS, batch_size=CFG['batch'], shuffle=False,\n",
    "          callbacks=callbacks, verbose=2)\n",
    "train_time = datetime.now() - start_time\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Evaluate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "prob = model.predict(X_va, verbose=0).ravel()\n",
    "pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "prec = precision_score(y_va, pred, zero_division=0)\n",
    "rec = recall_score(y_va, pred, zero_division=0)\n",
    "f1 = f1_score(y_va, pred, zero_division=0)\n",
    "f1_w = weighted_f1(y_va, pred)\n",
    "auc = roc_auc_score(y_va, prob)\n",
    "acc = accuracy_score(y_va, pred)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Results:\")\n",
    "print(f\"   Precision:  {prec:.3f}\")\n",
    "print(f\"   Recall:     {rec:.3f}\")\n",
    "print(f\"   F1 Score:   {f1:.3f}\")\n",
    "print(f\"   F1 (Î±=2):   {f1_w:.3f}\")\n",
    "print(f\"   Accuracy:   {acc:.3f}\")\n",
    "print(f\"   AUC:        {auc:.3f}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Save Predictions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "val_start_idx = split + CFG['window']\n",
    "timestamps = df.index[val_start_idx:val_start_idx + len(prob)]\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"timestamp\": timestamps.strftime(\"%d/%m/%Y %H:%M\"),\n",
    "    \"prob_up\": prob,\n",
    "    \"prob_down\": 1.0 - prob,\n",
    "    \"winning_prob\": np.maximum(prob, 1.0 - prob),\n",
    "    \"prediction\": pred,\n",
    "    \"actual\": y_va\n",
    "})\n",
    "\n",
    "csv_name = f\"{CFG['name']}_predictions.csv\"\n",
    "pred_df.to_csv(csv_name, index=False, float_format=\"%.6f\")\n",
    "print(f\"âœ… Predictions saved: {csv_name} ({len(pred_df):,} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8fd075",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\src\\Models\\models\\models\\TCN_HighestPrecision_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984072c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Evaluation at threshold 0.5:\n",
      "Precision: 0.523\n",
      "Recall   : 1.000\n",
      "F1 Score : 0.686\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the predictions CSV\n",
    "csv_path = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\src\\Models\\models\\models\\Trial_36_BestOverall_predictions.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Ensure column names are correct and lowercase\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Extract actual and predicted values\n",
    "y_true = df['actual']\n",
    "y_pred = df['prediction']  # prediction at threshold 0.5\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "# Print results\n",
    "print(\"ðŸ“Š Evaluation at threshold 0.5:\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall   : {recall:.3f}\")\n",
    "print(f\"F1 Score : {f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

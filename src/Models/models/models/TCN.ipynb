{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep \n",
    "atr_14  , OBV\n",
    "\n",
    "drop\n",
    "\n",
    "'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'trending_market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b25d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_tcn = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6','ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85e8b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading data â€¦\n",
      "Shape  : (15855, 59)\n",
      "Classes:\n",
      " target\n",
      "1    8097\n",
      "0    7758\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Class-weights 0 / 1 â†’ 1.00 / 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 18:52:10,220] A new study created in memory with name: no-name-5d78d030-0093-439e-a2ba-35523e4ee0ab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Optimising  40 trials  |  80 min wall-time â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  0  FÎ±2=0.1605  P=0.509 R=0.120  cfg={'window': 30, 'filters': 32, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.23033450352296264, 'dense': 128, 'act': 'relu', 'lr': 0.00017376356936978755, 'batch': 32, 'norm': 'batch'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [01:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 18:53:20,599] Trial 0 finished with value: -0.1605241605241605 and parameters: {'window': 30, 'filters': 32, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.23033450352296264, 'dense': 128, 'act': 'relu', 'lr': 0.00017376356936978755, 'batch': 32, 'norm': 'batch'}. Best is trial 0 with value: -0.1605241605241605.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   2%|â–         | 1/40 [01:11<46:34, 71.66s/it, 71.66/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  1  FÎ±2=0.0000  P=0.000 R=0.000  cfg={'window': 24, 'filters': 64, 'kernel': 4, 'nb_stacks': 2, 'blocks_per_stack': 1, 'dropout': 0.2322634555704315, 'dense': 128, 'act': 'relu', 'lr': 0.0008234548958371457, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   2%|â–         | 1/40 [02:52<46:34, 71.66s/it, 71.66/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 18:55:02,851] Trial 1 finished with value: -0.0 and parameters: {'window': 24, 'filters': 64, 'kernel': 4, 'nb_stacks': 2, 'blocks_per_stack': 1, 'dropout': 0.2322634555704315, 'dense': 128, 'act': 'relu', 'lr': 0.0008234548958371457, 'batch': 32, 'norm': 'layer'}. Best is trial 0 with value: -0.1605241605241605.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   5%|â–Œ         | 2/40 [02:53<56:47, 89.67s/it, 173.94/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  2  FÎ±2=0.4784  P=0.532 R=0.456  cfg={'window': 24, 'filters': 32, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3318496824692567, 'dense': 128, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.0002455257311459749, 'batch': 64, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   5%|â–Œ         | 2/40 [13:54<56:47, 89.67s/it, 173.94/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:06:04,741] Trial 2 finished with value: -0.4783904619970194 and parameters: {'window': 24, 'filters': 32, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3318496824692567, 'dense': 128, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.0002455257311459749, 'batch': 64, 'norm': 'layer'}. Best is trial 2 with value: -0.4783904619970194.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:   8%|â–Š         | 3/40 [13:56<3:36:29, 351.07s/it, 836.07/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  3  FÎ±2=0.3502  P=0.527 R=0.300  cfg={'window': 18, 'filters': 64, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.26205720315428516, 'dense': 64, 'act': 'selu', 'lr': 0.00019380132456492117, 'batch': 64, 'norm': 'batch'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:   8%|â–Š         | 3/40 [14:42<3:36:29, 351.07s/it, 836.07/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:06:52,361] Trial 3 finished with value: -0.3501890359168242 and parameters: {'window': 18, 'filters': 64, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.26205720315428516, 'dense': 64, 'act': 'selu', 'lr': 0.00019380132456492117, 'batch': 64, 'norm': 'batch'}. Best is trial 2 with value: -0.4783904619970194.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:  10%|â–ˆ         | 4/40 [14:43<2:18:44, 231.23s/it, 883.60/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  4  FÎ±2=0.7657  P=0.521 R=1.000  cfg={'window': 54, 'filters': 96, 'kernel': 4, 'nb_stacks': 3, 'blocks_per_stack': 1, 'dropout': 0.2068198488145982, 'dense': 32, 'act': 'elu', 'lr': 0.0020547569815878254, 'batch': 64, 'norm': 'none'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:  10%|â–ˆ         | 4/40 [33:13<2:18:44, 231.23s/it, 883.60/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:25:23,788] Trial 4 finished with value: -0.7656667190199467 and parameters: {'window': 54, 'filters': 96, 'kernel': 4, 'nb_stacks': 3, 'blocks_per_stack': 1, 'dropout': 0.2068198488145982, 'dense': 32, 'act': 'elu', 'lr': 0.0020547569815878254, 'batch': 64, 'norm': 'none'}. Best is trial 4 with value: -0.7656667190199467.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  12%|â–ˆâ–        | 5/40 [33:35<5:20:04, 548.71s/it, 1995.21/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:25:45,368] Trial 5 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  15%|â–ˆâ–Œ        | 6/40 [33:50<3:29:22, 369.48s/it, 2016.78/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:26:01,051] Trial 6 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  18%|â–ˆâ–Š        | 7/40 [34:14<2:19:36, 253.83s/it, 2032.52/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:26:24,480] Trial 7 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  20%|â–ˆâ–ˆ        | 8/40 [34:16<1:36:15, 180.50s/it, 2056.00/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  8  FÎ±2=0.0000  P=0.000 R=0.000  cfg={'window': 48, 'filters': 48, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.12738248831454668, 'dense': 64, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.001995489737195091, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  20%|â–ˆâ–ˆ        | 8/40 [38:46<1:36:15, 180.50s/it, 2056.00/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:30:56,774] Trial 8 finished with value: -0.0 and parameters: {'window': 48, 'filters': 48, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.12738248831454668, 'dense': 64, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.001995489737195091, 'batch': 32, 'norm': 'layer'}. Best is trial 4 with value: -0.7656667190199467.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  22%|â–ˆâ–ˆâ–       | 9/40 [38:58<1:48:05, 209.22s/it, 2328.39/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:31:08,443] Trial 9 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [47:12<1:14:07, 148.23s/it, 2340.05/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:39:22,883] Trial 10 pruned. Trial was pruned at epoch 22.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  28%|â–ˆâ–ˆâ–Š       | 11/40 [47:47<2:02:50, 254.17s/it, 2834.41/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:39:57,582] Trial 11 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [48:21<1:27:29, 187.49s/it, 2869.41/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:40:31,286] Trial 12 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  32%|â–ˆâ–ˆâ–ˆâ–      | 13/40 [48:51<1:03:22, 140.84s/it, 2902.88/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:41:01,988] Trial 13 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [49:38<46:37, 107.58s/it, 2933.62/4800 seconds]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:41:48,536] Trial 14 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [50:02<37:10, 89.21s/it, 2980.27/4800 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:42:12,653] Trial 15 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [50:22<27:51, 69.63s/it, 3004.41/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:42:33,114] Trial 16 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 17/40 [50:54<21:01, 54.83s/it, 3024.84/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:43:04,270] Trial 17 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [51:31<17:29, 47.71s/it, 3055.98/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:43:41,819] Trial 18 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [51:58<15:38, 44.69s/it, 3093.63/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:44:08,636] Trial 19 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [52:32<13:06, 39.33s/it, 3120.48/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:44:42,949] Trial 20 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 21/40 [52:44<11:58, 37.83s/it, 3154.80/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:44:54,758] Trial 21 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [52:56<09:00, 30.02s/it, 3166.61/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:45:06,538] Trial 22 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [53:08<06:57, 24.54s/it, 3178.37/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:45:18,786] Trial 23 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [53:32<05:33, 20.86s/it, 3190.65/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:45:42,569] Trial 24 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 25/40 [54:32<05:26, 21.76s/it, 3214.49/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:46:43,083] Trial 25 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [54:44<07:48, 33.48s/it, 3275.34/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:46:54,500] Trial 26 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [55:07<05:49, 26.85s/it, 3286.70/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:47:17,998] Trial 27 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [55:51<05:10, 25.85s/it, 3310.21/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:02,045] Trial 28 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 29/40 [56:05<05:44, 31.33s/it, 3354.33/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:16,155] Trial 29 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [56:20<04:21, 26.16s/it, 3368.45/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:31,058] Trial 30 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [56:34<03:24, 22.77s/it, 3383.30/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:44,848] Trial 31 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [56:51<02:40, 20.08s/it, 3397.11/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:49:01,379] Trial 32 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 33/40 [57:06<02:12, 18.97s/it, 3413.50/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:49:16,742] Trial 33 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [57:08<01:47, 17.89s/it, 3428.87/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34  FÎ±2=0.3297  P=0.497 R=0.282  cfg={'window': 24, 'filters': 48, 'kernel': 2, 'nb_stacks': 2, 'blocks_per_stack': 2, 'dropout': 0.31901512444749536, 'dense': 128, 'act': 'relu', 'lr': 0.0006474141743156096, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [1:01:16<01:47, 17.89s/it, 3428.87/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:53:27,074] Trial 34 finished with value: -0.3297015632401705 and parameters: {'window': 24, 'filters': 48, 'kernel': 2, 'nb_stacks': 2, 'blocks_per_stack': 2, 'dropout': 0.31901512444749536, 'dense': 128, 'act': 'relu', 'lr': 0.0006474141743156096, 'batch': 32, 'norm': 'layer'}. Best is trial 4 with value: -0.7656667190199467.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [1:01:48<07:18, 87.63s/it, 3679.21/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:53:59,012] Trial 35 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [1:01:51<04:43, 70.99s/it, 3711.39/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36  FÎ±2=0.7666  P=0.523 R=1.000  cfg={'window': 12, 'filters': 48, 'kernel': 5, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3118914406542517, 'dense': 128, 'act': 'relu', 'lr': 0.0005947328436650964, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [1:21:31<04:43, 70.99s/it, 3711.39/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 20:13:41,748] Trial 36 finished with value: -0.766599597585513 and parameters: {'window': 12, 'filters': 48, 'kernel': 5, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3118914406542517, 'dense': 128, 'act': 'relu', 'lr': 0.0005947328436650964, 'batch': 32, 'norm': 'layer'}. Best is trial 36 with value: -0.766599597585513.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: -0.7666:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 37/40 [1:21:34<06:36, 132.27s/it, 4894.06/4800 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â• BEST RESULT â•â•â•â•â•â•â•â•â•â•â•\n",
      "weighted-F1 (Î±=2) : 0.7666\n",
      "precision         : 0.5226\n",
      "recall            : 1.0000\n",
      "best epoch        : 35\n",
      "hyper-parameters  :\n",
      "  window            : 12\n",
      "  filters           : 48\n",
      "  kernel            : 5\n",
      "  nb_stacks         : 3\n",
      "  blocks_per_stack  : 2\n",
      "  dropout           : 0.3118914406542517\n",
      "  dense             : 128\n",
      "  act               : relu\n",
      "  lr                : 0.0005947328436650964\n",
      "  batch             : 32\n",
      "  norm              : layer\n",
      "\n",
      "ğŸ“ Artefacts saved (timestamp 20250609_171344).  Scaler â†’ tcn_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tcn_optuna_search.py  â€”  Robust TCN hyper-parameter optimisation\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ Objective  : weighted-F1 with Î± = 2  (precision has double weight)\n",
    "â€¢ Output     : scaler, best-params (.json), all trials (.csv), history plot\n",
    "â€¢ Tested on  : TensorFlow 2.16 Â· tcn 3.5 Â· Optuna 3.x  (CPU & single GPU)\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os, json, gc, warnings, optuna\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN                       #  pip install tcn==3.*\n",
    "from optuna_integration.tfkeras import TFKerasPruningCallback\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ runtime hygiene â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED, VAL_FRAC, ALPHA = 42, 0.20, 2.0\n",
    "N_TRIALS, TIMEOUT = 40, 80 * 60  #â€‰seconds\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ paths, drops â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "SCALER_PKL = \"tcn_scaler.pkl\"\n",
    "\n",
    "DROP_COLS = [  # (shortened â€“ add the rest of your leakage columns here)\n",
    "    \"close\", \"open\", \"high\", \"low\", \"typical_price\", \"high_low\",\n",
    "    \"high_close\", \"low_close\", \"EMA_21\", \"SMA_20\", \"vwap_24h\", \"close_4h\"\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ data load â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ“Š Loading data â€¦\")\n",
    "df = (\n",
    "    pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "      .loc[\"2018-01-01\":]\n",
    "      .drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "      .dropna(subset=[\"target\"])\n",
    "      .dropna()\n",
    ")\n",
    "print(f\"Shape  : {df.shape}\")\n",
    "print(\"Classes:\\n\", df[\"target\"].value_counts(), \"\\n\")\n",
    "\n",
    "X_raw, y_raw = df.drop(columns=\"target\").values, df[\"target\"].astype(int).values\n",
    "n_features   = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = np.float32((1 - pos_rate) / pos_rate if pos_rate else 1.0)\n",
    "print(f\"Class-weights 0 / 1 â†’ {CLASS_W0:.2f} / {CLASS_W1:.2f}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ window cache helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "_CACHE: Dict[Tuple[int, int, int], Tuple[np.ndarray, np.ndarray]] = {}\n",
    "\n",
    "def make_windows(arr: np.ndarray, labels: np.ndarray, win: int):\n",
    "    k = (id(arr), len(labels), win)\n",
    "    if k in _CACHE:\n",
    "        return _CACHE[k]\n",
    "\n",
    "    Xs, ys = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        Xs.append(arr[i - win:i])\n",
    "        ys.append(labels[i])\n",
    "    Xw, yw = np.asarray(Xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "    if Xw.nbytes + yw.nbytes < 1_000_000_000:\n",
    "        _CACHE[k] = (Xw, yw)\n",
    "    return Xw, yw\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ metric: weighted-F1 (Î±=2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def f1_alpha2(y_true, y_prob) -> float:\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    p, r   = precision_score(y_true, y_pred, zero_division=0), \\\n",
    "             recall_score   (y_true, y_pred, zero_division=0)\n",
    "    return 0. if p+r == 0 else (1+ALPHA)*p*r / (ALPHA*p + r)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TCN model factory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def build_tcn(cfg: dict) -> keras.Model:\n",
    "    dilations = [2 ** i for i in range(cfg[\"nb_stacks\"] * cfg[\"blocks_per_stack\"])]\n",
    "\n",
    "    inp = keras.layers.Input(shape=(cfg[\"window\"], n_features))\n",
    "    x   = TCN(\n",
    "            nb_filters       = cfg[\"filters\"],\n",
    "            kernel_size      = cfg[\"kernel\"],\n",
    "            nb_stacks        = cfg[\"nb_stacks\"],\n",
    "            dilations        = dilations,\n",
    "            padding          = \"causal\",\n",
    "            dropout_rate     = cfg[\"dropout\"],\n",
    "            activation       = cfg[\"act\"],\n",
    "            use_skip_connections = True,\n",
    "            use_batch_norm   = cfg[\"norm\"] == \"batch\",\n",
    "            use_layer_norm   = cfg[\"norm\"] == \"layer\",\n",
    "            return_sequences = False\n",
    "         )(inp)\n",
    "\n",
    "    x   = keras.layers.Dense(cfg[\"dense\"], activation=cfg[\"act\"])(x)\n",
    "    x   = keras.layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    out = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    # balanced BCE\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), CLASS_W1, CLASS_W0)\n",
    "        w   = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(keras.optimizers.Adam(cfg[\"lr\"]), loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Optuna objective â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    cfg = dict(\n",
    "        window           = trial.suggest_int(\"window\", 12, 60, step=6),\n",
    "        filters          = trial.suggest_categorical(\"filters\", [32, 48, 64, 96]),\n",
    "        kernel           = trial.suggest_int(\"kernel\", 2, 6),\n",
    "        nb_stacks        = trial.suggest_int(\"nb_stacks\", 1, 3),\n",
    "        blocks_per_stack = trial.suggest_int(\"blocks_per_stack\", 1, 2),\n",
    "        dropout          = trial.suggest_float(\"dropout\", 0.05, 0.35),\n",
    "        dense            = trial.suggest_categorical(\"dense\", [32, 64, 128]),\n",
    "        act              = trial.suggest_categorical(\"act\", [\"relu\", \"elu\", \"selu\", tf.nn.swish]),\n",
    "        lr               = trial.suggest_float(\"lr\", 5e-5, 3e-3, log=True),\n",
    "        batch            = trial.suggest_categorical(\"batch\", [32, 64]),\n",
    "        norm             = trial.suggest_categorical(\"norm\", [\"none\", \"batch\", \"layer\"]),\n",
    "    )\n",
    "\n",
    "    X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, cfg[\"window\"])\n",
    "    X_va, y_va = make_windows(X_va_raw, y_va_raw, cfg[\"window\"])\n",
    "\n",
    "    if len(X_tr) < cfg[\"batch\"] * 10:      # too small â†’ prune\n",
    "        return float(\"inf\")\n",
    "\n",
    "    tf.keras.backend.clear_session(); gc.collect()\n",
    "    model = build_tcn(cfg)\n",
    "\n",
    "    cb = [\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=0),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, min_lr=1e-6, verbose=0),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\")\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(X_tr, y_tr,\n",
    "                     validation_data=(X_va, y_va),\n",
    "                     epochs=100,\n",
    "                     batch_size=cfg[\"batch\"],\n",
    "                     shuffle=False,\n",
    "                     callbacks=cb,\n",
    "                     verbose=0)\n",
    "\n",
    "    y_prob = model.predict(X_va, batch_size=cfg[\"batch\"], verbose=0).ravel()\n",
    "    score  = f1_alpha2(y_va, y_prob)\n",
    "\n",
    "    # store metrics to inspect later\n",
    "    trial.set_user_attr(\"precision\", precision_score(y_va, y_prob >= 0.5, zero_division=0))\n",
    "    trial.set_user_attr(\"recall\",    recall_score   (y_va, y_prob >= 0.5, zero_division=0))\n",
    "    trial.set_user_attr(\"best_epoch\", int(np.argmin(hist.history[\"val_loss\"]) + 1))\n",
    "\n",
    "    # print live metrics\n",
    "    print(f\"Trial {trial.number:2d}  \"\n",
    "          f\"FÎ±2={score:.4f}  P={trial.user_attrs['precision']:.3f} \"\n",
    "          f\"R={trial.user_attrs['recall']:.3f}  cfg={trial.params}\")\n",
    "\n",
    "    del model; tf.keras.backend.clear_session(); gc.collect()\n",
    "    return -score   # minimise\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def main():\n",
    "    study = optuna.create_study(direction=\"minimize\",\n",
    "                                sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "                                pruner =optuna.pruners.MedianPruner(n_startup_trials=5))\n",
    "\n",
    "    print(f\"\\nğŸš€ Optimising  {N_TRIALS} trials  |  {TIMEOUT//60} min wall-time â€¦\")\n",
    "    study.optimize(objective,\n",
    "                   n_trials=N_TRIALS,\n",
    "                   timeout=TIMEOUT,\n",
    "                   show_progress_bar=True,\n",
    "                   gc_after_trial=True)\n",
    "\n",
    "    best, ts = study.best_trial, datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    print(\"\\nâ•â•â•â•â•â•â•â•â•â•â• BEST RESULT â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "    print(f\"weighted-F1 (Î±=2) : {-best.value:.4f}\")\n",
    "    print(f\"precision         : {best.user_attrs['precision']:.4f}\")\n",
    "    print(f\"recall            : {best.user_attrs['recall']:.4f}\")\n",
    "    print(f\"best epoch        : {best.user_attrs['best_epoch']}\")\n",
    "    print(\"hyper-parameters  :\")\n",
    "    for k, v in best.params.items():\n",
    "        print(f\"  {k:18s}: {v}\")\n",
    "\n",
    "    json.dump(best.params, open(f\"best_params_tcn_{ts}.json\", \"w\"), indent=2)\n",
    "    study.trials_dataframe().to_csv(f\"trials_tcn_{ts}.csv\", index=False)\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"optuna_tcn_history_{ts}.png\", dpi=300)\n",
    "        plt.close()\n",
    "    except Exception:\n",
    "        print(\"âš ï¸ matplotlib unavailable â€“ history plot skipped.\")\n",
    "\n",
    "    print(f\"\\nğŸ“ Artefacts saved (timestamp {ts}).  \"\n",
    "          f\"Scaler â†’ {SCALER_PKL}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[I 2025-06-09 18:05:11,711] A new study created in memory with name: no-name-0933098c-6339-4e53-ace1-0af2750e397a\n",
    "ğŸ“Š Loading data â€¦\n",
    "Shape  : (15855, 66)\n",
    "Classes:\n",
    " target\n",
    "1    8097\n",
    "0    7758\n",
    "Name: count, dtype: int64 \n",
    "\n",
    "Class-weights 0 / 1 â†’ 1.00 / 0.97\n",
    "\n",
    "ğŸš€ Optimising  40 trials  |  30 min wall-time â€¦\n",
    "  0%|          | 0/40 [00:00<?, ?it/s]Trial  0  FÎ±2=0.4618  P=0.529 R=0.434  cfg={'window': 30, 'filters': 32, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.23033450352296264, 'dense': 128, 'act': 'relu', 'lr': 0.00017376356936978755, 'batch': 32, 'norm': 'batch'}\n",
    "  0%|          | 0/40 [00:44<?, ?it/s][I 2025-06-09 18:05:56,603] Trial 0 finished with value: -0.46183783783783783 and parameters: {'window': 30, 'filters': 32, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.23033450352296264, 'dense': 128, 'act': 'relu', 'lr': 0.00017376356936978755, 'batch': 32, 'norm': 'batch'}. Best is trial 0 with value: -0.46183783783783783.\n",
    "Best trial: 0. Best value: -0.461838:   2%|â–         | 1/40 [00:45<29:26, 45.29s/it, 45.29/1800 seconds]Trial  1  FÎ±2=0.2813  P=0.515 R=0.229  cfg={'window': 24, 'filters': 64, 'kernel': 4, 'nb_stacks': 2, 'blocks_per_stack': 1, 'dropout': 0.2322634555704315, 'dense': 128, 'act': 'relu', 'lr': 0.0008234548958371457, 'batch': 32, 'norm': 'layer'}\n",
    "Best trial: 0. Best value: -0.461838:   2%|â–         | 1/40 [02:14<29:26, 45.29s/it, 45.29/1800 seconds][I 2025-06-09 18:07:26,384] Trial 1 finished with value: -0.28134328358208954 and parameters: {'window': 24, 'filters': 64, 'kernel': 4, 'nb_stacks': 2, 'blocks_per_stack': 1, 'dropout': 0.2322634555704315, 'dense': 128, 'act': 'relu', 'lr': 0.0008234548958371457, 'batch': 32, 'norm': 'layer'}. Best is trial 0 with value: -0.46183783783783783.\n",
    "Best trial: 0. Best value: -0.461838:   5%|â–Œ         | 2/40 [02:15<45:16, 71.48s/it, 135.10/1800 seconds]Trial  2  FÎ±2=0.5694  P=0.519 R=0.599  cfg={'window': 24, 'filters': 32, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3318496824692567, 'dense': 128, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.0002455257311459749, 'batch': 64, 'norm': 'layer'}\n",
    "Best trial: 0. Best value: -0.461838:   5%|â–Œ         | 2/40 [13:03<45:16, 71.48s/it, 135.10/1800 seconds][I 2025-06-09 18:18:15,273] Trial 2 finished with value: -0.5694444444444443 and parameters: {'window': 24, 'filters': 32, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3318496824692567, 'dense': 128, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.0002455257311459749, 'batch': 64, 'norm': 'layer'}. Best is trial 2 with value: -0.5694444444444443.\n",
    "Best trial: 2. Best value: -0.569444:   8%|â–Š         | 3/40 [13:04<3:26:43, 335.23s/it, 784.19/1800 seconds]Trial  3  FÎ±2=0.4582  P=0.528 R=0.430  cfg={'window': 18, 'filters': 64, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.26205720315428516, 'dense': 64, 'act': 'selu', 'lr': 0.00019380132456492117, 'batch': 64, 'norm': 'batch'}\n",
    "Best trial: 2. Best value: -0.569444:   8%|â–Š         | 3/40 [13:50<3:26:43, 335.23s/it, 784.19/1800 seconds][I 2025-06-09 18:19:01,809] Trial 3 finished with value: -0.45815358067299394 and parameters: {'window': 18, 'filters': 64, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.26205720315428516, 'dense': 64, 'act': 'selu', 'lr': 0.00019380132456492117, 'batch': 64, 'norm': 'batch'}. Best is trial 2 with value: -0.5694444444444443.\n",
    "Best trial: 2. Best value: -0.569444:  10%|â–ˆ         | 4/40 [13:50<2:12:44, 221.23s/it, 830.66/1800 seconds]Trial  4  FÎ±2=0.0734  P=0.464 R=0.052  cfg={'window': 54, 'filters': 96, 'kernel': 4, 'nb_stacks': 3, 'blocks_per_stack': 1, 'dropout': 0.2068198488145982, 'dense': 32, 'act': 'elu', 'lr': 0.0020547569815878254, 'batch': 64, 'norm': 'none'}\n",
    "Best trial: 2. Best value: -0.569444:  10%|â–ˆ         | 4/40 [20:56<2:12:44, 221.23s/it, 830.66/1800 seconds][I 2025-06-09 18:26:07,757] Trial 4 finished with value: -0.07344797435150102 and parameters: {'window': 54, 'filters': 96, 'kernel': 4, 'nb_stacks': 3, 'blocks_per_stack': 1, 'dropout': 0.2068198488145982, 'dense': 32, 'act': 'elu', 'lr': 0.0020547569815878254, 'batch': 64, 'norm': 'none'}. Best is trial 2 with value: -0.5694444444444443.\n",
    "Best trial: 2. Best value: -0.569444:  12%|â–ˆâ–        | 5/40 [21:44<2:52:07, 295.06s/it, 1256.64/1800 seconds][I 2025-06-09 18:26:56,640] Trial 5 pruned. Trial was pruned at epoch 2.\n",
    "Best trial: 2. Best value: -0.569444:  15%|â–ˆâ–Œ        | 6/40 [22:07<1:59:46, 211.37s/it, 1305.56/1800 seconds][I 2025-06-09 18:27:19,541] Trial 6 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  18%|â–ˆâ–Š        | 7/40 [22:51<1:22:22, 149.77s/it, 1328.51/1800 seconds][I 2025-06-09 18:28:03,649] Trial 7 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  20%|â–ˆâ–ˆ        | 8/40 [25:29<1:01:56, 116.16s/it, 1372.68/1800 seconds][I 2025-06-09 18:30:41,459] Trial 8 pruned. Trial was pruned at epoch 2.\n",
    "Best trial: 2. Best value: -0.569444:  22%|â–ˆâ–ˆâ–       | 9/40 [25:45<1:06:46, 129.23s/it, 1530.66/1800 seconds][I 2025-06-09 18:30:57,079] Trial 9 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [26:39<47:04, 94.15s/it, 1546.25/1800 seconds]  [I 2025-06-09 18:31:51,377] Trial 10 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  28%|â–ˆâ–ˆâ–Š       | 11/40 [26:48<39:37, 82.00s/it, 1600.71/1800 seconds][I 2025-06-09 18:32:00,674] Trial 11 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [26:57<27:56, 59.86s/it, 1609.93/1800 seconds][I 2025-06-09 18:32:09,118] Trial 12 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  32%|â–ˆâ–ˆâ–ˆâ–      | 13/40 [27:06<19:56, 44.30s/it, 1618.42/1800 seconds][I 2025-06-09 18:32:18,590] Trial 13 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [27:38<14:38, 33.78s/it, 1627.88/1800 seconds][I 2025-06-09 18:32:50,659] Trial 14 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [27:39<13:51, 33.27s/it, 1659.99/1800 seconds]Trial 15  FÎ±2=0.5717  P=0.532 R=0.594  cfg={'window': 30, 'filters': 32, 'kernel': 3, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.19135781227800264, 'dense': 32, 'act': 'relu', 'lr': 5.35786547006468e-05, 'batch': 32, 'norm': 'layer'}\n",
    "Best trial: 2. Best value: -0.569444:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [28:35<13:51, 33.27s/it, 1659.99/1800 seconds][I 2025-06-09 18:33:47,413] Trial 15 finished with value: -0.5716803760282021 and parameters: {'window': 30, 'filters': 32, 'kernel': 3, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.19135781227800264, 'dense': 32, 'act': 'relu', 'lr': 5.35786547006468e-05, 'batch': 32, 'norm': 'layer'}. Best is trial 15 with value: -0.5716803760282021.\n",
    "Best trial: 15. Best value: -0.57168:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [29:14<16:08, 40.33s/it, 1716.72/1800 seconds][I 2025-06-09 18:34:26,236] Trial 16 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 15. Best value: -0.57168:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 17/40 [29:29<15:18, 39.93s/it, 1755.72/1800 seconds][I 2025-06-09 18:34:41,644] Trial 17 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 15. Best value: -0.57168:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [32:38<11:56, 32.56s/it, 1771.12/1800 seconds][I 2025-06-09 18:37:50,265] Trial 18 pruned. Trial was pruned at epoch 1.\n",
    "Best trial: 15. Best value: -0.57168:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [32:39<36:06, 103.15s/it, 1959.93/1800 seconds]\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â• BEST RESULT â•â•â•â•â•â•â•â•â•â•â•\n",
    "weighted-F1 (Î±=2) : 0.5717\n",
    "precision         : 0.5323\n",
    "recall            : 0.5937\n",
    "best epoch        : 7\n",
    "hyper-parameters  :\n",
    "  window            : 30\n",
    "  filters           : 32\n",
    "  kernel            : 3\n",
    "  nb_stacks         : 1\n",
    "  blocks_per_stack  : 2\n",
    "  dropout           : 0.19135781227800264\n",
    "  dense             : 32\n",
    "  act               : relu\n",
    "  lr                : 5.35786547006468e-05\n",
    "  batch             : 32\n",
    "  norm              : layer\n",
    "\n",
    "ğŸ“ Artefacts saved (timestamp 20250609_153751).  Scaler â†’ tcn_scaler.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813c7b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading data â€¦\n",
      "Data after cleaning : (15855, 59)\n",
      "Class weights 0 / 1 â†’ 1.00 / 0.97\n",
      "Train windows : (12660, 24, 58) â€¢ Val windows : (3147, 24, 58)\n",
      "WARNING:tensorflow:From c:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                                        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                           </span>â”ƒ<span style=\"font-weight: bold\">               Para</span>\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                         â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                                           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                             â”‚                <span style=\"color: #00af00; text-decoration-color: #00af00\">80,</span>\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            â”‚                 <span style=\"color: #00af00; text-decoration-color: #00af00\">4,</span>\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              â”‚                   \n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)                            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m58\u001b[0m)                         â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ tcn (\u001b[38;5;33mTCN\u001b[0m)                                           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                             â”‚                \u001b[38;5;34m80,\u001b[0m\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                                       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            â”‚                 \u001b[38;5;34m4,\u001b[0m\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              â”‚                   \n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,089</span> (332.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m85,089\u001b[0m (332.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,089</span> (332.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m85,089\u001b[0m (332.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training â€¦\n",
      "Epoch 1/100\n",
      "198/198 - 38s - 192ms/step - loss: 1.0617 - val_loss: 0.7057 - learning_rate: 2.4553e-04\n",
      "Epoch 2/100\n",
      "198/198 - 18s - 92ms/step - loss: 0.8069 - val_loss: 0.7041 - learning_rate: 2.4553e-04\n",
      "Epoch 3/100\n",
      "198/198 - 18s - 91ms/step - loss: 0.7418 - val_loss: 0.7051 - learning_rate: 2.4553e-04\n",
      "Epoch 4/100\n",
      "198/198 - 17s - 85ms/step - loss: 0.7195 - val_loss: 0.6986 - learning_rate: 2.4553e-04\n",
      "Epoch 5/100\n",
      "198/198 - 17s - 85ms/step - loss: 0.7059 - val_loss: 0.7019 - learning_rate: 2.4553e-04\n",
      "Epoch 6/100\n",
      "198/198 - 17s - 84ms/step - loss: 0.7013 - val_loss: 0.6982 - learning_rate: 2.4553e-04\n",
      "Epoch 7/100\n",
      "198/198 - 17s - 83ms/step - loss: 0.6954 - val_loss: 0.7003 - learning_rate: 2.4553e-04\n",
      "Epoch 8/100\n",
      "198/198 - 17s - 84ms/step - loss: 0.6917 - val_loss: 0.6960 - learning_rate: 2.4553e-04\n",
      "Epoch 9/100\n",
      "198/198 - 12s - 61ms/step - loss: 0.6906 - val_loss: 0.6921 - learning_rate: 2.4553e-04\n",
      "Epoch 10/100\n",
      "198/198 - 12s - 61ms/step - loss: 0.6914 - val_loss: 0.6894 - learning_rate: 2.4553e-04\n",
      "Epoch 11/100\n",
      "198/198 - 12s - 62ms/step - loss: 0.6876 - val_loss: 0.6890 - learning_rate: 2.4553e-04\n",
      "Epoch 12/100\n",
      "198/198 - 9s - 43ms/step - loss: 0.6880 - val_loss: 0.6883 - learning_rate: 2.4553e-04\n",
      "Epoch 13/100\n",
      "198/198 - 8s - 41ms/step - loss: 0.6867 - val_loss: 0.6871 - learning_rate: 2.4553e-04\n",
      "Epoch 14/100\n",
      "198/198 - 8s - 41ms/step - loss: 0.6869 - val_loss: 0.6867 - learning_rate: 2.4553e-04\n",
      "Epoch 15/100\n",
      "198/198 - 8s - 41ms/step - loss: 0.6863 - val_loss: 0.6869 - learning_rate: 2.4553e-04\n",
      "Epoch 16/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6861 - val_loss: 0.6880 - learning_rate: 2.4553e-04\n",
      "Epoch 17/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6848 - val_loss: 0.6866 - learning_rate: 2.4553e-04\n",
      "Epoch 18/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6847 - val_loss: 0.6863 - learning_rate: 2.4553e-04\n",
      "Epoch 19/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6833 - val_loss: 0.6871 - learning_rate: 2.4553e-04\n",
      "Epoch 20/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6847 - val_loss: 0.6868 - learning_rate: 2.4553e-04\n",
      "Epoch 21/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6834 - val_loss: 0.6856 - learning_rate: 2.4553e-04\n",
      "Epoch 22/100\n",
      "198/198 - 8s - 40ms/step - loss: 0.6831 - val_loss: 0.6868 - learning_rate: 2.4553e-04\n",
      "Epoch 23/100\n",
      "198/198 - 8s - 40ms/step - loss: 0.6836 - val_loss: 0.6863 - learning_rate: 2.4553e-04\n",
      "Epoch 24/100\n",
      "198/198 - 10s - 50ms/step - loss: 0.6834 - val_loss: 0.6868 - learning_rate: 2.4553e-04\n",
      "Epoch 25/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6831 - val_loss: 0.6872 - learning_rate: 2.4553e-04\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00012276286724954844.\n",
      "198/198 - 16s - 83ms/step - loss: 0.6840 - val_loss: 0.6863 - learning_rate: 2.4553e-04\n",
      "Epoch 27/100\n",
      "198/198 - 16s - 83ms/step - loss: 0.6826 - val_loss: 0.6854 - learning_rate: 1.2276e-04\n",
      "Epoch 28/100\n",
      "198/198 - 16s - 81ms/step - loss: 0.6835 - val_loss: 0.6847 - learning_rate: 1.2276e-04\n",
      "Epoch 29/100\n",
      "198/198 - 13s - 64ms/step - loss: 0.6823 - val_loss: 0.6842 - learning_rate: 1.2276e-04\n",
      "Epoch 30/100\n",
      "198/198 - 9s - 43ms/step - loss: 0.6820 - val_loss: 0.6843 - learning_rate: 1.2276e-04\n",
      "Epoch 31/100\n",
      "198/198 - 8s - 43ms/step - loss: 0.6815 - val_loss: 0.6844 - learning_rate: 1.2276e-04\n",
      "Epoch 32/100\n",
      "198/198 - 12s - 61ms/step - loss: 0.6824 - val_loss: 0.6844 - learning_rate: 1.2276e-04\n",
      "Epoch 33/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6829 - val_loss: 0.6846 - learning_rate: 1.2276e-04\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.138143362477422e-05.\n",
      "198/198 - 16s - 81ms/step - loss: 0.6823 - val_loss: 0.6848 - learning_rate: 1.2276e-04\n",
      "Epoch 35/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6830 - val_loss: 0.6840 - learning_rate: 6.1381e-05\n",
      "Epoch 36/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6819 - val_loss: 0.6841 - learning_rate: 6.1381e-05\n",
      "Epoch 37/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6824 - val_loss: 0.6837 - learning_rate: 6.1381e-05\n",
      "Epoch 38/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6821 - val_loss: 0.6842 - learning_rate: 6.1381e-05\n",
      "Epoch 39/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6819 - val_loss: 0.6841 - learning_rate: 6.1381e-05\n",
      "Epoch 40/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6818 - val_loss: 0.6844 - learning_rate: 6.1381e-05\n",
      "Epoch 41/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6822 - val_loss: 0.6843 - learning_rate: 6.1381e-05\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 3.069071681238711e-05.\n",
      "198/198 - 21s - 104ms/step - loss: 0.6821 - val_loss: 0.6846 - learning_rate: 6.1381e-05\n",
      "Epoch 43/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6819 - val_loss: 0.6843 - learning_rate: 3.0691e-05\n",
      "Epoch 44/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6818 - val_loss: 0.6843 - learning_rate: 3.0691e-05\n",
      "Epoch 45/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6826 - val_loss: 0.6843 - learning_rate: 3.0691e-05\n",
      "Epoch 46/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6812 - val_loss: 0.6843 - learning_rate: 3.0691e-05\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.5345358406193554e-05.\n",
      "198/198 - 16s - 82ms/step - loss: 0.6819 - val_loss: 0.6842 - learning_rate: 3.0691e-05\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "\n",
      "ğŸ“ˆ Final evaluation â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€ VALIDATION METRICS â”€â”€â”€â”€â”€\n",
      "Accuracy            :  0.493\n",
      "Precision           :  0.565\n",
      "Recall              :  0.127\n",
      "Weighted-F1 (Î±=2)   :  0.171\n",
      "Confusion matrix    : [1343, 160, 1436, 208]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 32, 'kernel_size': 2, 'padding': 'causal', 'activation': 'swish', 'dropout_rate': 0.3318496824692567, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 24, 58]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 211\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. save artefacts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39;00m\n\u001b[0;32m    210\u001b[0m ts \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mutcnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 211\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_H5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m summary \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m      : ts \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: CFG,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m: cm\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    226\u001b[0m }\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(SUMMARY_JS, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [deepcopy(a, memo) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:265\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[0;32m    264\u001b[0m     args \u001b[38;5;241m=\u001b[39m (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[1;32m--> 265\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m    267\u001b[0m     memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 32, 'kernel_size': 2, 'padding': 'causal', 'activation': 'swish', 'dropout_rate': 0.3318496824692567, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 24, 58]}}"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_tcn_final.py  Â·  2025-06-09\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "One-shot training of a Temporal Convolutional Network\n",
    "for 4-hour BTC direction, using the fixed hyper-params\n",
    "supplied by the user (see CFG below).\n",
    "\n",
    "Outputs\n",
    "â€¢ tcn_btc_direction.h5\n",
    "â€¢ tcn_scaler.pkl\n",
    "â€¢ tcn_training_summary.json\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ imports & hygiene â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             confusion_matrix, accuracy_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN                     # pip install tcn==3.*\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ paths & constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "SCALER_PKL = \"tcn_scaler.pkl\"\n",
    "MODEL_H5   = \"tcn_btc_direction.h5\"\n",
    "SUMMARY_JS = \"tcn_training_summary.json\"\n",
    "\n",
    "VAL_FRAC = 0.20         # last 20 % for validation\n",
    "ALPHA    = 2.0          # precision weight in FÎ² (Î²=âˆšÎ±)\n",
    "\n",
    "DROP_COLS = [           # minimal leakage list â€“ extend as needed\n",
    "    \"open\", \"high\", \"low\", \"close\", \"typical_price\",\n",
    "    \"high_low\", \"high_close\", \"low_close\", \"EMA_21\", \"SMA_20\",\n",
    "    \"vwap_24h\", \"close_4h\"\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ hyper-parameters (fixed) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CFG: Dict = {\n",
    "    'window'          : 24,\n",
    "    'filters'         : 32,\n",
    "    'kernel'          : 2,\n",
    "    'nb_stacks'       : 3,\n",
    "    'blocks_per_stack': 2,\n",
    "    'dropout'         : 0.3318496824692567,\n",
    "    'dense'           : 128,\n",
    "    'act'             : 'swish',\n",
    "    'lr'              : 0.0002455257311459749,\n",
    "    'batch'           : 64,\n",
    "    'norm'            : 'layer'            # \"none\" | \"batch\" | \"layer\"\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helper functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_windows(arr: np.ndarray,\n",
    "                 labels: np.ndarray,\n",
    "                 win: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Turn a 2-D feature matrix into sliding 3-D windows.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i - win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.asarray(X, np.float32), np.asarray(y, np.int8)\n",
    "\n",
    "def f1_alpha2(y_true, y_prob, alpha: float) -> float:\n",
    "    \"\"\"Weighted F1 where precision gets Î±-times the weight of recall.\"\"\"\n",
    "    y_pred = (y_prob >= .5).astype(int)\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score   (y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def build_model(cfg: Dict,\n",
    "                n_feat: int,\n",
    "                class_w0: float,\n",
    "                class_w1: float) -> keras.Model:\n",
    "    \"\"\"Create & compile a single-output TCN binary classifier.\"\"\"\n",
    "    # -- validation of activation string (fix #1) --\n",
    "    act = cfg[\"act\"].lower()\n",
    "    assert act in {\"relu\", \"elu\", \"selu\", \"swish\", \"tanh\"}, \\\n",
    "        f\"Unsupported activation: {cfg['act']}\"\n",
    "\n",
    "    # dilations: 1 â†’ â€¦, 2**k\n",
    "    dilations = [2 ** i\n",
    "                 for i in range(cfg[\"nb_stacks\"] * cfg[\"blocks_per_stack\"])]\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    x = TCN(\n",
    "            nb_filters        = cfg[\"filters\"],\n",
    "            kernel_size       = cfg[\"kernel\"],\n",
    "            nb_stacks         = cfg[\"nb_stacks\"],\n",
    "            dilations         = dilations,\n",
    "            padding           = \"causal\",\n",
    "            dropout_rate      = cfg[\"dropout\"],\n",
    "            activation        = act,\n",
    "            use_skip_connections=True,\n",
    "            use_batch_norm    = cfg[\"norm\"] == \"batch\",\n",
    "            use_layer_norm    = cfg[\"norm\"] == \"layer\",\n",
    "            return_sequences  = False\n",
    "        )(inputs)\n",
    "\n",
    "    x = keras.layers.Dense(cfg[\"dense\"], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # custom weighted BCE (float32 safe)\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), class_w1, class_w0)\n",
    "        w   = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(cfg[\"lr\"]),\n",
    "                  loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. load dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ“Š Loading data â€¦\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Data after cleaning : {df.shape}\")\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "# class weights (fix #2 clarity)\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = (np.float32((1 - pos_rate) / pos_rate)\n",
    "            if pos_rate != 0 else np.float32(1.0))\n",
    "print(f\"Class weights 0 / 1 â†’ {CLASS_W0:.2f} / {CLASS_W1:.2f}\")\n",
    "\n",
    "# slide into windows\n",
    "X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, CFG[\"window\"])\n",
    "X_va, y_va = make_windows(X_va_raw, y_va_raw, CFG[\"window\"])\n",
    "print(f\"Train windows : {X_tr.shape} â€¢ Val windows : {X_va.shape}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. train model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "model = build_model(CFG, n_features, CLASS_W0, CLASS_W1)\n",
    "model.summary(line_length=120)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\nğŸš€ Training â€¦\")\n",
    "history = model.fit(X_tr, y_tr,\n",
    "                    validation_data=(X_va, y_va),\n",
    "                    epochs=100,\n",
    "                    batch_size=CFG[\"batch\"],\n",
    "                    shuffle=False,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. evaluation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ“ˆ Final evaluation â€¦\")\n",
    "prob = model.predict(X_va, batch_size=CFG[\"batch\"], verbose=0).ravel()\n",
    "pred = (prob >= .5).astype(int)\n",
    "\n",
    "precision = precision_score(y_va, pred, zero_division=0)\n",
    "recall    = recall_score   (y_va, pred, zero_division=0)\n",
    "f1a2      = f1_alpha2(y_va, prob, ALPHA)   # fix #3\n",
    "acc       = accuracy_score(y_va, pred)\n",
    "cm        = confusion_matrix(y_va, pred)\n",
    "\n",
    "print(\"\\nâ”€â”€â”€â”€â”€ VALIDATION METRICS â”€â”€â”€â”€â”€\")\n",
    "print(f\"Accuracy            : {acc:6.3f}\")\n",
    "print(f\"Precision           : {precision:6.3f}\")\n",
    "print(f\"Recall              : {recall:6.3f}\")\n",
    "print(f\"Weighted-F1 (Î±=2)   : {f1a2:6.3f}\")\n",
    "print(f\"Confusion matrix    : {cm.ravel().tolist()}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. save artefacts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model.save(MODEL_H5)\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\"      : ts + \"Z\",\n",
    "    \"hyperparameters\": CFG,\n",
    "    \"alpha\"          : ALPHA,\n",
    "    \"n_features\"     : n_features,\n",
    "    \"train_windows\"  : int(len(X_tr)),\n",
    "    \"val_windows\"    : int(len(X_va)),\n",
    "    \"class_weights\"  : [float(CLASS_W0), float(CLASS_W1)],\n",
    "    \"metrics\"        : dict(accuracy=float(acc),\n",
    "                            precision=float(precision),\n",
    "                            recall=float(recall),\n",
    "                            f1_alpha2=float(f1a2)),\n",
    "    \"confusion_matrix\": cm.ravel().tolist()\n",
    "}\n",
    "with open(SUMMARY_JS, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Model   saved â†’ {MODEL_H5}\")\n",
    "print(f\"âœ… Scaler  saved â†’ {SCALER_PKL}\")\n",
    "print(f\"âœ… Summary saved â†’ {SUMMARY_JS}\")\n",
    "print(\"ğŸ‰ Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "702b4076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading data â€¦\n",
      "Data after cleaning : (15855, 59)\n",
      "Class weights 0 / 1 â†’ 1.00 / 0.97\n",
      "Train windows : (12672, 12, 58) â€¢ Val windows : (3159, 12, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                                        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                           </span>â”ƒ<span style=\"font-weight: bold\">               Para</span>\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                         â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                                           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                             â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">425,</span>\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            â”‚                 <span style=\"color: #00af00; text-decoration-color: #00af00\">6,</span>\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              â”‚                   \n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)                            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m58\u001b[0m)                         â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ tcn (\u001b[38;5;33mTCN\u001b[0m)                                           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                             â”‚               \u001b[38;5;34m425,\u001b[0m\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                                       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            â”‚                 \u001b[38;5;34m6,\u001b[0m\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              â”‚                   \n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,537</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m431,537\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,537</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m431,537\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training â€¦\n",
      "Epoch 1/100\n",
      "396/396 - 25s - 63ms/step - loss: 0.8768 - val_loss: 0.6852 - learning_rate: 5.9473e-04\n",
      "Epoch 2/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6861 - val_loss: 0.6837 - learning_rate: 5.9473e-04\n",
      "Epoch 3/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6846 - val_loss: 0.6823 - learning_rate: 5.9473e-04\n",
      "Epoch 4/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6830 - val_loss: 0.6821 - learning_rate: 5.9473e-04\n",
      "Epoch 5/100\n",
      "396/396 - 13s - 34ms/step - loss: 0.6823 - val_loss: 0.6829 - learning_rate: 5.9473e-04\n",
      "Epoch 6/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6825 - val_loss: 0.6817 - learning_rate: 5.9473e-04\n",
      "Epoch 7/100\n",
      "396/396 - 16s - 40ms/step - loss: 0.6827 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 8/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6832 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 9/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 5.9473e-04\n",
      "Epoch 10/100\n",
      "396/396 - 13s - 34ms/step - loss: 0.6824 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 11/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6824 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 12/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6823 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00029736640863120556.\n",
      "396/396 - 13s - 33ms/step - loss: 0.6823 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 14/100\n",
      "396/396 - 13s - 34ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 2.9737e-04\n",
      "Epoch 15/100\n",
      "396/396 - 13s - 34ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 2.9737e-04\n",
      "Epoch 16/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 2.9737e-04\n",
      "Epoch 17/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6823 - val_loss: 0.6832 - learning_rate: 2.9737e-04\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00014868320431560278.\n",
      "396/396 - 13s - 34ms/step - loss: 0.6824 - val_loss: 0.6815 - learning_rate: 2.9737e-04\n",
      "Epoch 19/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 1.4868e-04\n",
      "Epoch 20/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 1.4868e-04\n",
      "Epoch 21/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 1.4868e-04\n",
      "Epoch 22/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 1.4868e-04\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 7.434160215780139e-05.\n",
      "396/396 - 13s - 32ms/step - loss: 0.6820 - val_loss: 0.6829 - learning_rate: 1.4868e-04\n",
      "Epoch 24/100\n",
      "396/396 - 12s - 32ms/step - loss: 0.6825 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 25/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6824 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 26/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 27/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 28/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.7170801078900695e-05.\n",
      "396/396 - 12s - 31ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 30/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 3.7171e-05\n",
      "Epoch 31/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 3.7171e-05\n",
      "Epoch 32/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 3.7171e-05\n",
      "Epoch 33/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 3.7171e-05\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.8585400539450347e-05.\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 3.7171e-05\n",
      "Epoch 35/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 1.8585e-05\n",
      "Epoch 36/100\n",
      "396/396 - 27s - 69ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 1.8585e-05\n",
      "Epoch 37/100\n",
      "396/396 - 29s - 72ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 1.8585e-05\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\n",
      "ğŸ“ˆ Final evaluation â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€ VALIDATION METRICS â”€â”€â”€â”€â”€\n",
      "Accuracy            :  0.523\n",
      "Precision           :  0.523\n",
      "Recall              :  1.000\n",
      "Weighted-F1 (Î±=2)   :  0.767\n",
      "Confusion matrix    : [0, 1508, 0, 1651]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 48, 'kernel_size': 5, 'padding': 'causal', 'activation': 'relu', 'dropout_rate': 0.3118914406542517, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 12, 58]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 210\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. save artefacts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39;00m\n\u001b[0;32m    209\u001b[0m ts \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mutcnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 210\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_H5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m summary \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m      : ts \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: CFG,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m: cm\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    225\u001b[0m }\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(SUMMARY_JS, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [deepcopy(a, memo) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:265\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[0;32m    264\u001b[0m     args \u001b[38;5;241m=\u001b[39m (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[1;32m--> 265\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m    267\u001b[0m     memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 48, 'kernel_size': 5, 'padding': 'causal', 'activation': 'relu', 'dropout_rate': 0.3118914406542517, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 12, 58]}}"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_tcn_final.py  Â·  2025-06-09\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "One-shot training of a Temporal Convolutional Network\n",
    "for 4-hour BTC direction, using the fixed hyper-params\n",
    "supplied by the user (see CFG below).\n",
    "\n",
    "Outputs\n",
    "â€¢ tcn_btc_direction.h5\n",
    "â€¢ tcn_scaler.pkl\n",
    "â€¢ tcn_training_summary.json\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ imports & hygiene â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             confusion_matrix, accuracy_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN                     # pip install tcn==3.*\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ paths & constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "SCALER_PKL = \"tcn_scaler.pkl\"\n",
    "MODEL_H5   = \"tcn_btc_direction.h5\"\n",
    "SUMMARY_JS = \"tcn_training_summary.json\"\n",
    "\n",
    "VAL_FRAC = 0.20         # last 20 % for validation\n",
    "ALPHA    = 2.0          # precision weight in FÎ² (Î²=âˆšÎ±)\n",
    "\n",
    "DROP_COLS = [           # minimal leakage list â€“ extend as needed\n",
    "    \"open\", \"high\", \"low\", \"close\", \"typical_price\",\n",
    "    \"high_low\", \"high_close\", \"low_close\", \"EMA_21\", \"SMA_20\",\n",
    "    \"vwap_24h\", \"close_4h\"\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ hyper-parameters (fixed) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CFG: Dict = {\n",
    "    'window'          : 12,\n",
    "    'filters'         : 48,\n",
    "    'kernel'          : 5,\n",
    "    'nb_stacks'       : 3,\n",
    "    'blocks_per_stack': 2,\n",
    "    'dropout'         : 0.3118914406542517,\n",
    "    'dense'           : 128,\n",
    "    'act'             : 'relu',\n",
    "    'lr'              : 5.947328436650964e-4,\n",
    "    'batch'           : 32,\n",
    "    'norm'            : 'layer'            # \"none\" | \"batch\" | \"layer\"\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helper functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_windows(arr: np.ndarray,\n",
    "                 labels: np.ndarray,\n",
    "                 win: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Turn a 2-D feature matrix into sliding 3-D windows.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i - win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.asarray(X, np.float32), np.asarray(y, np.int8)\n",
    "\n",
    "def f1_alpha2(y_true, y_prob, alpha: float) -> float:\n",
    "    \"\"\"Weighted F1 where precision gets Î±-times the weight of recall.\"\"\"\n",
    "    y_pred = (y_prob >= .5).astype(int)\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score   (y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def build_model(cfg: Dict,\n",
    "                n_feat: int,\n",
    "                class_w0: float,\n",
    "                class_w1: float) -> keras.Model:\n",
    "    \"\"\"Create & compile a single-output TCN binary classifier.\"\"\"\n",
    "    # -- validation of activation string (fix #1) --\n",
    "    act = cfg[\"act\"].lower()\n",
    "    assert act in {\"relu\", \"elu\", \"selu\", \"swish\", \"tanh\"}, \\\n",
    "        f\"Unsupported activation: {cfg['act']}\"\n",
    "\n",
    "    # dilations: 1 â†’ â€¦, 2**k\n",
    "    dilations = [2 ** i\n",
    "                 for i in range(cfg[\"nb_stacks\"] * cfg[\"blocks_per_stack\"])]\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    x = TCN(\n",
    "            nb_filters        = cfg[\"filters\"],\n",
    "            kernel_size       = cfg[\"kernel\"],\n",
    "            nb_stacks         = cfg[\"nb_stacks\"],\n",
    "            dilations         = dilations,\n",
    "            padding           = \"causal\",\n",
    "            dropout_rate      = cfg[\"dropout\"],\n",
    "            activation        = act,\n",
    "            use_skip_connections=True,\n",
    "            use_batch_norm    = cfg[\"norm\"] == \"batch\",\n",
    "            use_layer_norm    = cfg[\"norm\"] == \"layer\",\n",
    "            return_sequences  = False\n",
    "        )(inputs)\n",
    "\n",
    "    x = keras.layers.Dense(cfg[\"dense\"], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # custom weighted BCE (float32 safe)\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), class_w1, class_w0)\n",
    "        w   = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(cfg[\"lr\"]),\n",
    "                  loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. load dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ“Š Loading data â€¦\")\n",
    "df = (pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "        .loc[\"2018-01-01\":]\n",
    "        .drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "        .dropna(subset=[\"target\"])\n",
    "        .dropna())\n",
    "print(f\"Data after cleaning : {df.shape}\")\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "# class weights (fix #2 clarity)\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = (np.float32((1 - pos_rate) / pos_rate)\n",
    "            if pos_rate != 0 else np.float32(1.0))\n",
    "print(f\"Class weights 0 / 1 â†’ {CLASS_W0:.2f} / {CLASS_W1:.2f}\")\n",
    "\n",
    "# slide into windows\n",
    "X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, CFG[\"window\"])\n",
    "X_va, y_va = make_windows(X_va_raw, y_va_raw, CFG[\"window\"])\n",
    "print(f\"Train windows : {X_tr.shape} â€¢ Val windows : {X_va.shape}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. train model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "model = build_model(CFG, n_features, CLASS_W0, CLASS_W1)\n",
    "model.summary(line_length=120)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\nğŸš€ Training â€¦\")\n",
    "history = model.fit(X_tr, y_tr,\n",
    "                    validation_data=(X_va, y_va),\n",
    "                    epochs=100,\n",
    "                    batch_size=CFG[\"batch\"],\n",
    "                    shuffle=False,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. evaluation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ“ˆ Final evaluation â€¦\")\n",
    "prob = model.predict(X_va, batch_size=CFG[\"batch\"], verbose=0).ravel()\n",
    "pred = (prob >= .5).astype(int)\n",
    "\n",
    "precision = precision_score(y_va, pred, zero_division=0)\n",
    "recall    = recall_score   (y_va, pred, zero_division=0)\n",
    "f1a2      = f1_alpha2(y_va, prob, ALPHA)   # fix #3\n",
    "acc       = accuracy_score(y_va, pred)\n",
    "cm        = confusion_matrix(y_va, pred)\n",
    "\n",
    "print(\"\\nâ”€â”€â”€â”€â”€ VALIDATION METRICS â”€â”€â”€â”€â”€\")\n",
    "print(f\"Accuracy            : {acc:6.3f}\")\n",
    "print(f\"Precision           : {precision:6.3f}\")\n",
    "print(f\"Recall              : {recall:6.3f}\")\n",
    "print(f\"Weighted-F1 (Î±=2)   : {f1a2:6.3f}\")\n",
    "print(f\"Confusion matrix    : {cm.ravel().tolist()}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. save artefacts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model.save(MODEL_H5)\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\"      : ts + \"Z\",\n",
    "    \"hyperparameters\": CFG,\n",
    "    \"alpha\"          : ALPHA,\n",
    "    \"n_features\"     : n_features,\n",
    "    \"train_windows\"  : int(len(X_tr)),\n",
    "    \"val_windows\"    : int(len(X_va)),\n",
    "    \"class_weights\"  : [float(CLASS_W0), float(CLASS_W1)],\n",
    "    \"metrics\"        : dict(accuracy=float(acc),\n",
    "                            precision=float(precision),\n",
    "                            recall=float(recall),\n",
    "                            f1_alpha2=float(f1a2)),\n",
    "    \"confusion_matrix\": cm.ravel().tolist()\n",
    "}\n",
    "with open(SUMMARY_JS, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Model   saved â†’ {MODEL_H5}\")\n",
    "print(f\"âœ… Scaler  saved â†’ {SCALER_PKL}\")\n",
    "print(f\"âœ… Summary saved â†’ {SUMMARY_JS}\")\n",
    "print(\"ğŸ‰ Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8050c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading data â€¦\n",
      "Data after cleaning : (15855, 59)\n",
      "Class weights 0 / 1 â†’ 1.00 / 0.97\n",
      "Train windows : (12660, 24, 58) â€¢ Val windows : (3147, 24, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                                        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                           </span>â”ƒ<span style=\"font-weight: bold\">               Para</span>\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                         â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                                           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                             â”‚                <span style=\"color: #00af00; text-decoration-color: #00af00\">80,</span>\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            â”‚                 <span style=\"color: #00af00; text-decoration-color: #00af00\">4,</span>\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              â”‚                   \n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)                            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m58\u001b[0m)                         â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ tcn (\u001b[38;5;33mTCN\u001b[0m)                                           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                             â”‚                \u001b[38;5;34m80,\u001b[0m\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                                       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            â”‚                 \u001b[38;5;34m4,\u001b[0m\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              â”‚                   \n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,089</span> (332.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m85,089\u001b[0m (332.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,089</span> (332.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m85,089\u001b[0m (332.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training â€¦\n",
      "Epoch 1/100\n",
      "198/198 - 44s - 220ms/step - loss: 0.9470 - val_loss: 0.6877 - learning_rate: 2.4553e-04\n",
      "Epoch 2/100\n",
      "198/198 - 19s - 94ms/step - loss: 0.7569 - val_loss: 0.6850 - learning_rate: 2.4553e-04\n",
      "Epoch 3/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.7161 - val_loss: 0.6851 - learning_rate: 2.4553e-04\n",
      "Epoch 4/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.7040 - val_loss: 0.6845 - learning_rate: 2.4553e-04\n",
      "Epoch 5/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.6982 - val_loss: 0.6844 - learning_rate: 2.4553e-04\n",
      "Epoch 6/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.6934 - val_loss: 0.6832 - learning_rate: 2.4553e-04\n",
      "Epoch 7/100\n",
      "198/198 - 19s - 94ms/step - loss: 0.6906 - val_loss: 0.6834 - learning_rate: 2.4553e-04\n",
      "Epoch 8/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.6896 - val_loss: 0.6822 - learning_rate: 2.4553e-04\n",
      "Epoch 9/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.6896 - val_loss: 0.6830 - learning_rate: 2.4553e-04\n",
      "Epoch 10/100\n",
      "198/198 - 18s - 93ms/step - loss: 0.6879 - val_loss: 0.6828 - learning_rate: 2.4553e-04\n",
      "Epoch 11/100\n",
      "198/198 - 19s - 94ms/step - loss: 0.6869 - val_loss: 0.6826 - learning_rate: 2.4553e-04\n",
      "Epoch 12/100\n",
      "198/198 - 18s - 93ms/step - loss: 0.6856 - val_loss: 0.6829 - learning_rate: 2.4553e-04\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00012276286724954844.\n",
      "198/198 - 18s - 93ms/step - loss: 0.6862 - val_loss: 0.6825 - learning_rate: 2.4553e-04\n",
      "Epoch 14/100\n",
      "198/198 - 19s - 94ms/step - loss: 0.6848 - val_loss: 0.6819 - learning_rate: 1.2276e-04\n",
      "Epoch 15/100\n",
      "198/198 - 15s - 76ms/step - loss: 0.6846 - val_loss: 0.6816 - learning_rate: 1.2276e-04\n",
      "Epoch 16/100\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_tcn_final.py  Â·  2025-06-09\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "One-shot training of a Temporal Convolutional Network\n",
    "for 4-hour BTC direction, using the fixed hyper-params\n",
    "supplied by the user (see CFG below).\n",
    "\n",
    "Outputs\n",
    "â€¢ tcn_btc_direction.h5\n",
    "â€¢ tcn_scaler.pkl\n",
    "â€¢ tcn_training_summary.json\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ imports & hygiene â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             confusion_matrix, accuracy_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN                     # pip install tcn==3.*\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ paths & constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "SCALER_PKL = \"tcn_scaler.pkl\"\n",
    "MODEL_H5   = \"tcn_btc_direction.h5\"\n",
    "SUMMARY_JS = \"tcn_training_summary.json\"\n",
    "\n",
    "VAL_FRAC = 0.20         # last 20 % for validation\n",
    "ALPHA    = 2.0          # precision weight in FÎ² (Î²=âˆšÎ±)\n",
    "\n",
    "DROP_COLS = [           # minimal leakage list â€“ extend as needed\n",
    "    \"open\", \"high\", \"low\", \"close\", \"typical_price\",\n",
    "    \"high_low\", \"high_close\", \"low_close\", \"EMA_21\", \"SMA_20\",\n",
    "    \"vwap_24h\", \"close_4h\"\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ hyper-parameters (fixed) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CFG: Dict = {\n",
    "  'window': 24,\n",
    "  'filters': 32,\n",
    "  'kernel': 2,\n",
    "  'nb_stacks': 3,\n",
    "  'blocks_per_stack': 2,\n",
    "  'dropout': 0.3318496824692567,\n",
    "  'dense': 128,\n",
    "  'act': 'swish',\n",
    "  'lr': 0.0002455257311459749,\n",
    "  'batch': 64,\n",
    "  'norm': 'layer'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helper functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_windows(arr: np.ndarray,\n",
    "                 labels: np.ndarray,\n",
    "                 win: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Turn a 2-D feature matrix into sliding 3-D windows.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i - win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.asarray(X, np.float32), np.asarray(y, np.int8)\n",
    "\n",
    "def f1_alpha2(y_true, y_prob, alpha: float) -> float:\n",
    "    \"\"\"Weighted F1 where precision gets Î±-times the weight of recall.\"\"\"\n",
    "    y_pred = (y_prob >= .5).astype(int)\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score   (y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def build_model(cfg: Dict,\n",
    "                n_feat: int,\n",
    "                class_w0: float,\n",
    "                class_w1: float) -> keras.Model:\n",
    "    \"\"\"Create & compile a single-output TCN binary classifier.\"\"\"\n",
    "    # -- validation of activation string (fix #1) --\n",
    "    act = cfg[\"act\"].lower()\n",
    "    assert act in {\"relu\", \"elu\", \"selu\", \"swish\", \"tanh\"}, \\\n",
    "        f\"Unsupported activation: {cfg['act']}\"\n",
    "\n",
    "    # dilations: 1 â†’ â€¦, 2**k\n",
    "    dilations = [2 ** i\n",
    "                 for i in range(cfg[\"nb_stacks\"] * cfg[\"blocks_per_stack\"])]\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    x = TCN(\n",
    "            nb_filters        = cfg[\"filters\"],\n",
    "            kernel_size       = cfg[\"kernel\"],\n",
    "            nb_stacks         = cfg[\"nb_stacks\"],\n",
    "            dilations         = dilations,\n",
    "            padding           = \"causal\",\n",
    "            dropout_rate      = cfg[\"dropout\"],\n",
    "            activation        = act,\n",
    "            use_skip_connections=True,\n",
    "            use_batch_norm    = cfg[\"norm\"] == \"batch\",\n",
    "            use_layer_norm    = cfg[\"norm\"] == \"layer\",\n",
    "            return_sequences  = False\n",
    "        )(inputs)\n",
    "\n",
    "    x = keras.layers.Dense(cfg[\"dense\"], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # custom weighted BCE (float32 safe)\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), class_w1, class_w0)\n",
    "        w   = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(cfg[\"lr\"]),\n",
    "                  loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. load dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ“Š Loading data â€¦\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Data after cleaning : {df.shape}\")\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "# class weights (fix #2 clarity)\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = (np.float32((1 - pos_rate) / pos_rate)\n",
    "            if pos_rate != 0 else np.float32(1.0))\n",
    "print(f\"Class weights 0 / 1 â†’ {CLASS_W0:.2f} / {CLASS_W1:.2f}\")\n",
    "\n",
    "# slide into windows\n",
    "X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, CFG[\"window\"])\n",
    "X_va, y_va = make_windows(X_va_raw, y_va_raw, CFG[\"window\"])\n",
    "print(f\"Train windows : {X_tr.shape} â€¢ Val windows : {X_va.shape}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. train model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "model = build_model(CFG, n_features, CLASS_W0, CLASS_W1)\n",
    "model.summary(line_length=120)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\nğŸš€ Training â€¦\")\n",
    "history = model.fit(X_tr, y_tr,\n",
    "                    validation_data=(X_va, y_va),\n",
    "                    epochs=100,\n",
    "                    batch_size=CFG[\"batch\"],\n",
    "                    shuffle=False,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. evaluation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ“ˆ Final evaluation â€¦\")\n",
    "prob = model.predict(X_va, batch_size=CFG[\"batch\"], verbose=0).ravel()\n",
    "pred = (prob >= .5).astype(int)\n",
    "\n",
    "precision = precision_score(y_va, pred, zero_division=0)\n",
    "recall    = recall_score   (y_va, pred, zero_division=0)\n",
    "f1a2      = f1_alpha2(y_va, prob, ALPHA)   # fix #3\n",
    "acc       = accuracy_score(y_va, pred)\n",
    "cm        = confusion_matrix(y_va, pred)\n",
    "\n",
    "print(\"\\nâ”€â”€â”€â”€â”€ VALIDATION METRICS â”€â”€â”€â”€â”€\")\n",
    "print(f\"Accuracy            : {acc:6.3f}\")\n",
    "print(f\"Precision           : {precision:6.3f}\")\n",
    "print(f\"Recall              : {recall:6.3f}\")\n",
    "print(f\"Weighted-F1 (Î±=2)   : {f1a2:6.3f}\")\n",
    "print(f\"Confusion matrix    : {cm.ravel().tolist()}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. save artefacts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model.save(MODEL_H5)\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\"      : ts + \"Z\",\n",
    "    \"hyperparameters\": CFG,\n",
    "    \"alpha\"          : ALPHA,\n",
    "    \"n_features\"     : n_features,\n",
    "    \"train_windows\"  : int(len(X_tr)),\n",
    "    \"val_windows\"    : int(len(X_va)),\n",
    "    \"class_weights\"  : [float(CLASS_W0), float(CLASS_W1)],\n",
    "    \"metrics\"        : dict(accuracy=float(acc),\n",
    "                            precision=float(precision),\n",
    "                            recall=float(recall),\n",
    "                            f1_alpha2=float(f1a2)),\n",
    "    \"confusion_matrix\": cm.ravel().tolist()\n",
    "}\n",
    "with open(SUMMARY_JS, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Model   saved â†’ {MODEL_H5}\")\n",
    "print(f\"âœ… Scaler  saved â†’ {SCALER_PKL}\")\n",
    "print(f\"âœ… Summary saved â†’ {SUMMARY_JS}\")\n",
    "print(\"ğŸ‰ Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b703651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading data â€¦\n",
      "Data after cleaning : (15855, 59)\n",
      "Class weights 0 / 1 â†’ 1.00 / 0.97\n",
      "Train windows : (12672, 12, 58) â€¢ Val windows : (3159, 12, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                                        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                           </span>â”ƒ<span style=\"font-weight: bold\">               Para</span>\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                         â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                                           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                             â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">425,</span>\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            â”‚                 <span style=\"color: #00af00; text-decoration-color: #00af00\">6,</span>\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              â”‚                   \n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)                            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m58\u001b[0m)                         â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ tcn (\u001b[38;5;33mTCN\u001b[0m)                                           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                             â”‚               \u001b[38;5;34m425,\u001b[0m\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                                       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            â”‚                 \u001b[38;5;34m6,\u001b[0m\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            â”‚                   \n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              â”‚                   \n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,537</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m431,537\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,537</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m431,537\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training â€¦\n",
      "Epoch 1/100\n",
      "396/396 - 24s - 60ms/step - loss: 0.8478 - val_loss: 0.6884 - learning_rate: 5.9473e-04\n",
      "Epoch 2/100\n",
      "396/396 - 11s - 28ms/step - loss: 0.6874 - val_loss: 0.6842 - learning_rate: 5.9473e-04\n",
      "Epoch 3/100\n",
      "396/396 - 24s - 60ms/step - loss: 0.6846 - val_loss: 0.6839 - learning_rate: 5.9473e-04\n",
      "Epoch 4/100\n",
      "396/396 - 21s - 52ms/step - loss: 0.6832 - val_loss: 0.6831 - learning_rate: 5.9473e-04\n",
      "Epoch 5/100\n",
      "396/396 - 17s - 42ms/step - loss: 0.6826 - val_loss: 0.6830 - learning_rate: 5.9473e-04\n",
      "Epoch 6/100\n",
      "396/396 - 27s - 67ms/step - loss: 0.6829 - val_loss: 0.6839 - learning_rate: 5.9473e-04\n",
      "Epoch 7/100\n",
      "396/396 - 27s - 69ms/step - loss: 0.6823 - val_loss: 0.6822 - learning_rate: 5.9473e-04\n",
      "Epoch 8/100\n",
      "396/396 - 27s - 68ms/step - loss: 0.6820 - val_loss: 0.6874 - learning_rate: 5.9473e-04\n",
      "Epoch 9/100\n",
      "396/396 - 28s - 70ms/step - loss: 0.6824 - val_loss: 0.6822 - learning_rate: 5.9473e-04\n",
      "Epoch 10/100\n",
      "396/396 - 28s - 71ms/step - loss: 0.6821 - val_loss: 0.6872 - learning_rate: 5.9473e-04\n",
      "Epoch 11/100\n",
      "396/396 - 28s - 70ms/step - loss: 0.6826 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 12/100\n",
      "396/396 - 26s - 66ms/step - loss: 0.6822 - val_loss: 0.6859 - learning_rate: 5.9473e-04\n",
      "Epoch 13/100\n",
      "396/396 - 26s - 66ms/step - loss: 0.6823 - val_loss: 0.6843 - learning_rate: 5.9473e-04\n",
      "Epoch 14/100\n",
      "396/396 - 27s - 69ms/step - loss: 0.6823 - val_loss: 0.6831 - learning_rate: 5.9473e-04\n",
      "Epoch 15/100\n",
      "396/396 - 27s - 69ms/step - loss: 0.6830 - val_loss: 0.6823 - learning_rate: 5.9473e-04\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00029736640863120556.\n",
      "396/396 - 27s - 69ms/step - loss: 0.6823 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 17/100\n",
      "396/396 - 27s - 69ms/step - loss: 0.6820 - val_loss: 0.6837 - learning_rate: 2.9737e-04\n",
      "Epoch 18/100\n",
      "396/396 - 27s - 68ms/step - loss: 0.6820 - val_loss: 0.6836 - learning_rate: 2.9737e-04\n",
      "Epoch 19/100\n",
      "396/396 - 27s - 68ms/step - loss: 0.6812 - val_loss: 0.6878 - learning_rate: 2.9737e-04\n",
      "Epoch 20/100\n",
      "396/396 - 27s - 68ms/step - loss: 0.6814 - val_loss: 0.6863 - learning_rate: 2.9737e-04\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00014868320431560278.\n",
      "396/396 - 27s - 68ms/step - loss: 0.6805 - val_loss: 0.6879 - learning_rate: 2.9737e-04\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\n",
      "ğŸ“ˆ Final evaluation â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”€â”€â”€â”€â”€ VALIDATION METRICS â”€â”€â”€â”€â”€\n",
      "Accuracy            :  0.523\n",
      "Precision           :  0.523\n",
      "Recall              :  1.000\n",
      "Weighted-F1 (Î±=2)   :  0.767\n",
      "Confusion matrix    : [0, 1508, 0, 1651]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 48, 'kernel_size': 5, 'padding': 'causal', 'activation': 'relu', 'dropout_rate': 0.3118914406542517, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 12, 58]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 212\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. save artefacts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39;00m\n\u001b[0;32m    211\u001b[0m ts \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mutcnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 212\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_H5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m summary \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m      : ts \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: CFG,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m: cm\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    227\u001b[0m }\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(SUMMARY_JS, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [deepcopy(a, memo) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:265\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[0;32m    264\u001b[0m     args \u001b[38;5;241m=\u001b[39m (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[1;32m--> 265\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m    267\u001b[0m     memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 48, 'kernel_size': 5, 'padding': 'causal', 'activation': 'relu', 'dropout_rate': 0.3118914406542517, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 12, 58]}}"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_tcn_final.py  Â·  2025-06-09\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "One-shot training of a Temporal Convolutional Network\n",
    "for 4-hour BTC direction, using the fixed hyper-params\n",
    "supplied by the user (see CFG below).\n",
    "\n",
    "Outputs\n",
    "â€¢ tcn_btc_direction.h5\n",
    "â€¢ tcn_scaler.pkl\n",
    "â€¢ tcn_training_summary.json\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ imports & hygiene â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             confusion_matrix, accuracy_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN                     # pip install tcn==3.*\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ paths & constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "SCALER_PKL = \"tcn_scaler.pkl\"\n",
    "MODEL_H5   = \"tcn_btc_direction.h5\"\n",
    "SUMMARY_JS = \"tcn_training_summary.json\"\n",
    "\n",
    "VAL_FRAC = 0.20         # last 20 % for validation\n",
    "ALPHA    = 2.0          # precision weight in FÎ² (Î²=âˆšÎ±)\n",
    "\n",
    "DROP_COLS = [           # minimal leakage list â€“ extend as needed\n",
    "    \"open\", \"high\", \"low\", \"close\", \"typical_price\",\n",
    "    \"high_low\", \"high_close\", \"low_close\", \"EMA_21\", \"SMA_20\",\n",
    "    \"vwap_24h\", \"close_4h\"\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ hyper-parameters (fixed) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CFG: Dict = {\n",
    "  'window': 12,\n",
    "  'filters': 48,\n",
    "  'kernel': 5,\n",
    "  'nb_stacks': 3,\n",
    "  'blocks_per_stack': 2,\n",
    "  'dropout': 0.3118914406542517,\n",
    "  'dense': 128,\n",
    "  'act': 'relu',\n",
    "  'lr': 0.0005947328436650964,\n",
    "  'batch': 32,\n",
    "  'norm': 'layer'\n",
    "}\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helper functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_windows(arr: np.ndarray,\n",
    "                 labels: np.ndarray,\n",
    "                 win: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Turn a 2-D feature matrix into sliding 3-D windows.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i - win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.asarray(X, np.float32), np.asarray(y, np.int8)\n",
    "\n",
    "def f1_alpha2(y_true, y_prob, alpha: float) -> float:\n",
    "    \"\"\"Weighted F1 where precision gets Î±-times the weight of recall.\"\"\"\n",
    "    y_pred = (y_prob >= .5).astype(int)\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score   (y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def build_model(cfg: Dict,\n",
    "                n_feat: int,\n",
    "                class_w0: float,\n",
    "                class_w1: float) -> keras.Model:\n",
    "    \"\"\"Create & compile a single-output TCN binary classifier.\"\"\"\n",
    "    # -- validation of activation string (fix #1) --\n",
    "    act = cfg[\"act\"].lower()\n",
    "    assert act in {\"relu\", \"elu\", \"selu\", \"swish\", \"tanh\"}, \\\n",
    "        f\"Unsupported activation: {cfg['act']}\"\n",
    "\n",
    "    # dilations: 1 â†’ â€¦, 2**k\n",
    "    dilations = [2 ** i\n",
    "                 for i in range(cfg[\"nb_stacks\"] * cfg[\"blocks_per_stack\"])]\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    x = TCN(\n",
    "            nb_filters        = cfg[\"filters\"],\n",
    "            kernel_size       = cfg[\"kernel\"],\n",
    "            nb_stacks         = cfg[\"nb_stacks\"],\n",
    "            dilations         = dilations,\n",
    "            padding           = \"causal\",\n",
    "            dropout_rate      = cfg[\"dropout\"],\n",
    "            activation        = act,\n",
    "            use_skip_connections=True,\n",
    "            use_batch_norm    = cfg[\"norm\"] == \"batch\",\n",
    "            use_layer_norm    = cfg[\"norm\"] == \"layer\",\n",
    "            return_sequences  = False\n",
    "        )(inputs)\n",
    "\n",
    "    x = keras.layers.Dense(cfg[\"dense\"], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # custom weighted BCE (float32 safe)\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), class_w1, class_w0)\n",
    "        w   = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(cfg[\"lr\"]),\n",
    "                  loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. load dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ“Š Loading data â€¦\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Data after cleaning : {df.shape}\")\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "# class weights (fix #2 clarity)\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = (np.float32((1 - pos_rate) / pos_rate)\n",
    "            if pos_rate != 0 else np.float32(1.0))\n",
    "print(f\"Class weights 0 / 1 â†’ {CLASS_W0:.2f} / {CLASS_W1:.2f}\")\n",
    "\n",
    "# slide into windows\n",
    "X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, CFG[\"window\"])\n",
    "X_va, y_va = make_windows(X_va_raw, y_va_raw, CFG[\"window\"])\n",
    "print(f\"Train windows : {X_tr.shape} â€¢ Val windows : {X_va.shape}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. train model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "model = build_model(CFG, n_features, CLASS_W0, CLASS_W1)\n",
    "model.summary(line_length=120)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\nğŸš€ Training â€¦\")\n",
    "history = model.fit(X_tr, y_tr,\n",
    "                    validation_data=(X_va, y_va),\n",
    "                    epochs=100,\n",
    "                    batch_size=CFG[\"batch\"],\n",
    "                    shuffle=False,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. evaluation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ“ˆ Final evaluation â€¦\")\n",
    "prob = model.predict(X_va, batch_size=CFG[\"batch\"], verbose=0).ravel()\n",
    "pred = (prob >= .5).astype(int)\n",
    "\n",
    "precision = precision_score(y_va, pred, zero_division=0)\n",
    "recall    = recall_score   (y_va, pred, zero_division=0)\n",
    "f1a2      = f1_alpha2(y_va, prob, ALPHA)   # fix #3\n",
    "acc       = accuracy_score(y_va, pred)\n",
    "cm        = confusion_matrix(y_va, pred)\n",
    "\n",
    "print(\"\\nâ”€â”€â”€â”€â”€ VALIDATION METRICS â”€â”€â”€â”€â”€\")\n",
    "print(f\"Accuracy            : {acc:6.3f}\")\n",
    "print(f\"Precision           : {precision:6.3f}\")\n",
    "print(f\"Recall              : {recall:6.3f}\")\n",
    "print(f\"Weighted-F1 (Î±=2)   : {f1a2:6.3f}\")\n",
    "print(f\"Confusion matrix    : {cm.ravel().tolist()}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. save artefacts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model.save(MODEL_H5)\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\"      : ts + \"Z\",\n",
    "    \"hyperparameters\": CFG,\n",
    "    \"alpha\"          : ALPHA,\n",
    "    \"n_features\"     : n_features,\n",
    "    \"train_windows\"  : int(len(X_tr)),\n",
    "    \"val_windows\"    : int(len(X_va)),\n",
    "    \"class_weights\"  : [float(CLASS_W0), float(CLASS_W1)],\n",
    "    \"metrics\"        : dict(accuracy=float(acc),\n",
    "                            precision=float(precision),\n",
    "                            recall=float(recall),\n",
    "                            f1_alpha2=float(f1a2)),\n",
    "    \"confusion_matrix\": cm.ravel().tolist()\n",
    "}\n",
    "with open(SUMMARY_JS, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Model   saved â†’ {MODEL_H5}\")\n",
    "print(f\"âœ… Scaler  saved â†’ {SCALER_PKL}\")\n",
    "print(f\"âœ… Summary saved â†’ {SUMMARY_JS}\")\n",
    "print(\"ğŸ‰ Training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep \n",
    "atr_14  , OBV\n",
    "\n",
    "drop\n",
    "\n",
    "'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'trending_market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b25d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_tcn = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_21', 'SMA_20',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'trending_market', 'above_sma50', 'ema7_above_ema21',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold',\n",
    "    'above_sma20', 'macd_positive', 'volume_breakout', 'volume_breakdown',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6','ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85e8b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loading data …\n",
      "Shape  : (15855, 59)\n",
      "Classes:\n",
      " target\n",
      "1    8097\n",
      "0    7758\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Class-weights 0 / 1 → 1.00 / 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 18:52:10,220] A new study created in memory with name: no-name-5d78d030-0093-439e-a2ba-35523e4ee0ab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Optimising  40 trials  |  80 min wall-time …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  0  Fα2=0.1605  P=0.509 R=0.120  cfg={'window': 30, 'filters': 32, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.23033450352296264, 'dense': 128, 'act': 'relu', 'lr': 0.00017376356936978755, 'batch': 32, 'norm': 'batch'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [01:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 18:53:20,599] Trial 0 finished with value: -0.1605241605241605 and parameters: {'window': 30, 'filters': 32, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.23033450352296264, 'dense': 128, 'act': 'relu', 'lr': 0.00017376356936978755, 'batch': 32, 'norm': 'batch'}. Best is trial 0 with value: -0.1605241605241605.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   2%|▎         | 1/40 [01:11<46:34, 71.66s/it, 71.66/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  1  Fα2=0.0000  P=0.000 R=0.000  cfg={'window': 24, 'filters': 64, 'kernel': 4, 'nb_stacks': 2, 'blocks_per_stack': 1, 'dropout': 0.2322634555704315, 'dense': 128, 'act': 'relu', 'lr': 0.0008234548958371457, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   2%|▎         | 1/40 [02:52<46:34, 71.66s/it, 71.66/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 18:55:02,851] Trial 1 finished with value: -0.0 and parameters: {'window': 24, 'filters': 64, 'kernel': 4, 'nb_stacks': 2, 'blocks_per_stack': 1, 'dropout': 0.2322634555704315, 'dense': 128, 'act': 'relu', 'lr': 0.0008234548958371457, 'batch': 32, 'norm': 'layer'}. Best is trial 0 with value: -0.1605241605241605.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   5%|▌         | 2/40 [02:53<56:47, 89.67s/it, 173.94/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  2  Fα2=0.4784  P=0.532 R=0.456  cfg={'window': 24, 'filters': 32, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3318496824692567, 'dense': 128, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.0002455257311459749, 'batch': 64, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: -0.160524:   5%|▌         | 2/40 [13:54<56:47, 89.67s/it, 173.94/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:06:04,741] Trial 2 finished with value: -0.4783904619970194 and parameters: {'window': 24, 'filters': 32, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3318496824692567, 'dense': 128, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.0002455257311459749, 'batch': 64, 'norm': 'layer'}. Best is trial 2 with value: -0.4783904619970194.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:   8%|▊         | 3/40 [13:56<3:36:29, 351.07s/it, 836.07/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  3  Fα2=0.3502  P=0.527 R=0.300  cfg={'window': 18, 'filters': 64, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.26205720315428516, 'dense': 64, 'act': 'selu', 'lr': 0.00019380132456492117, 'batch': 64, 'norm': 'batch'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:   8%|▊         | 3/40 [14:42<3:36:29, 351.07s/it, 836.07/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:06:52,361] Trial 3 finished with value: -0.3501890359168242 and parameters: {'window': 18, 'filters': 64, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.26205720315428516, 'dense': 64, 'act': 'selu', 'lr': 0.00019380132456492117, 'batch': 64, 'norm': 'batch'}. Best is trial 2 with value: -0.4783904619970194.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:  10%|█         | 4/40 [14:43<2:18:44, 231.23s/it, 883.60/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  4  Fα2=0.7657  P=0.521 R=1.000  cfg={'window': 54, 'filters': 96, 'kernel': 4, 'nb_stacks': 3, 'blocks_per_stack': 1, 'dropout': 0.2068198488145982, 'dense': 32, 'act': 'elu', 'lr': 0.0020547569815878254, 'batch': 64, 'norm': 'none'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.47839:  10%|█         | 4/40 [33:13<2:18:44, 231.23s/it, 883.60/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:25:23,788] Trial 4 finished with value: -0.7656667190199467 and parameters: {'window': 54, 'filters': 96, 'kernel': 4, 'nb_stacks': 3, 'blocks_per_stack': 1, 'dropout': 0.2068198488145982, 'dense': 32, 'act': 'elu', 'lr': 0.0020547569815878254, 'batch': 64, 'norm': 'none'}. Best is trial 4 with value: -0.7656667190199467.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  12%|█▎        | 5/40 [33:35<5:20:04, 548.71s/it, 1995.21/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:25:45,368] Trial 5 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  15%|█▌        | 6/40 [33:50<3:29:22, 369.48s/it, 2016.78/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:26:01,051] Trial 6 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  18%|█▊        | 7/40 [34:14<2:19:36, 253.83s/it, 2032.52/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:26:24,480] Trial 7 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  20%|██        | 8/40 [34:16<1:36:15, 180.50s/it, 2056.00/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial  8  Fα2=0.0000  P=0.000 R=0.000  cfg={'window': 48, 'filters': 48, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.12738248831454668, 'dense': 64, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.001995489737195091, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  20%|██        | 8/40 [38:46<1:36:15, 180.50s/it, 2056.00/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:30:56,774] Trial 8 finished with value: -0.0 and parameters: {'window': 48, 'filters': 48, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.12738248831454668, 'dense': 64, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.001995489737195091, 'batch': 32, 'norm': 'layer'}. Best is trial 4 with value: -0.7656667190199467.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  22%|██▎       | 9/40 [38:58<1:48:05, 209.22s/it, 2328.39/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:31:08,443] Trial 9 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  25%|██▌       | 10/40 [47:12<1:14:07, 148.23s/it, 2340.05/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:39:22,883] Trial 10 pruned. Trial was pruned at epoch 22.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  28%|██▊       | 11/40 [47:47<2:02:50, 254.17s/it, 2834.41/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:39:57,582] Trial 11 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  30%|███       | 12/40 [48:21<1:27:29, 187.49s/it, 2869.41/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:40:31,286] Trial 12 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  32%|███▎      | 13/40 [48:51<1:03:22, 140.84s/it, 2902.88/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:41:01,988] Trial 13 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  35%|███▌      | 14/40 [49:38<46:37, 107.58s/it, 2933.62/4800 seconds]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:41:48,536] Trial 14 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  38%|███▊      | 15/40 [50:02<37:10, 89.21s/it, 2980.27/4800 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:42:12,653] Trial 15 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  40%|████      | 16/40 [50:22<27:51, 69.63s/it, 3004.41/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:42:33,114] Trial 16 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  42%|████▎     | 17/40 [50:54<21:01, 54.83s/it, 3024.84/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:43:04,270] Trial 17 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  45%|████▌     | 18/40 [51:31<17:29, 47.71s/it, 3055.98/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:43:41,819] Trial 18 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  48%|████▊     | 19/40 [51:58<15:38, 44.69s/it, 3093.63/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:44:08,636] Trial 19 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  50%|█████     | 20/40 [52:32<13:06, 39.33s/it, 3120.48/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:44:42,949] Trial 20 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  52%|█████▎    | 21/40 [52:44<11:58, 37.83s/it, 3154.80/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:44:54,758] Trial 21 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  55%|█████▌    | 22/40 [52:56<09:00, 30.02s/it, 3166.61/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:45:06,538] Trial 22 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  57%|█████▊    | 23/40 [53:08<06:57, 24.54s/it, 3178.37/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:45:18,786] Trial 23 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  60%|██████    | 24/40 [53:32<05:33, 20.86s/it, 3190.65/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:45:42,569] Trial 24 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  62%|██████▎   | 25/40 [54:32<05:26, 21.76s/it, 3214.49/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:46:43,083] Trial 25 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  65%|██████▌   | 26/40 [54:44<07:48, 33.48s/it, 3275.34/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:46:54,500] Trial 26 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  68%|██████▊   | 27/40 [55:07<05:49, 26.85s/it, 3286.70/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:47:17,998] Trial 27 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  70%|███████   | 28/40 [55:51<05:10, 25.85s/it, 3310.21/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:02,045] Trial 28 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  72%|███████▎  | 29/40 [56:05<05:44, 31.33s/it, 3354.33/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:16,155] Trial 29 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  75%|███████▌  | 30/40 [56:20<04:21, 26.16s/it, 3368.45/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:31,058] Trial 30 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  78%|███████▊  | 31/40 [56:34<03:24, 22.77s/it, 3383.30/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:48:44,848] Trial 31 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  80%|████████  | 32/40 [56:51<02:40, 20.08s/it, 3397.11/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:49:01,379] Trial 32 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  82%|████████▎ | 33/40 [57:06<02:12, 18.97s/it, 3413.50/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:49:16,742] Trial 33 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  85%|████████▌ | 34/40 [57:08<01:47, 17.89s/it, 3428.87/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34  Fα2=0.3297  P=0.497 R=0.282  cfg={'window': 24, 'filters': 48, 'kernel': 2, 'nb_stacks': 2, 'blocks_per_stack': 2, 'dropout': 0.31901512444749536, 'dense': 128, 'act': 'relu', 'lr': 0.0006474141743156096, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  85%|████████▌ | 34/40 [1:01:16<01:47, 17.89s/it, 3428.87/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:53:27,074] Trial 34 finished with value: -0.3297015632401705 and parameters: {'window': 24, 'filters': 48, 'kernel': 2, 'nb_stacks': 2, 'blocks_per_stack': 2, 'dropout': 0.31901512444749536, 'dense': 128, 'act': 'relu', 'lr': 0.0006474141743156096, 'batch': 32, 'norm': 'layer'}. Best is trial 4 with value: -0.7656667190199467.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  88%|████████▊ | 35/40 [1:01:48<07:18, 87.63s/it, 3679.21/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 19:53:59,012] Trial 35 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  90%|█████████ | 36/40 [1:01:51<04:43, 70.99s/it, 3711.39/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36  Fα2=0.7666  P=0.523 R=1.000  cfg={'window': 12, 'filters': 48, 'kernel': 5, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3118914406542517, 'dense': 128, 'act': 'relu', 'lr': 0.0005947328436650964, 'batch': 32, 'norm': 'layer'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.765667:  90%|█████████ | 36/40 [1:21:31<04:43, 70.99s/it, 3711.39/4800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 20:13:41,748] Trial 36 finished with value: -0.766599597585513 and parameters: {'window': 12, 'filters': 48, 'kernel': 5, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3118914406542517, 'dense': 128, 'act': 'relu', 'lr': 0.0005947328436650964, 'batch': 32, 'norm': 'layer'}. Best is trial 36 with value: -0.766599597585513.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: -0.7666:  92%|█████████▎| 37/40 [1:21:34<06:36, 132.27s/it, 4894.06/4800 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "═══════════ BEST RESULT ═══════════\n",
      "weighted-F1 (α=2) : 0.7666\n",
      "precision         : 0.5226\n",
      "recall            : 1.0000\n",
      "best epoch        : 35\n",
      "hyper-parameters  :\n",
      "  window            : 12\n",
      "  filters           : 48\n",
      "  kernel            : 5\n",
      "  nb_stacks         : 3\n",
      "  blocks_per_stack  : 2\n",
      "  dropout           : 0.3118914406542517\n",
      "  dense             : 128\n",
      "  act               : relu\n",
      "  lr                : 0.0005947328436650964\n",
      "  batch             : 32\n",
      "  norm              : layer\n",
      "\n",
      "📝 Artefacts saved (timestamp 20250609_171344).  Scaler → tcn_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tcn_optuna_search.py  —  Robust TCN hyper-parameter optimisation\n",
    "─────────────────────────────────────────────────────────────────\n",
    "• Objective  : weighted-F1 with α = 2  (precision has double weight)\n",
    "• Output     : scaler, best-params (.json), all trials (.csv), history plot\n",
    "• Tested on  : TensorFlow 2.16 · tcn 3.5 · Optuna 3.x  (CPU & single GPU)\n",
    "\"\"\"\n",
    "\n",
    "# ───────────────────────── imports ──────────────────────────\n",
    "import os, json, gc, warnings, optuna\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN                       #  pip install tcn==3.*\n",
    "from optuna_integration.tfkeras import TFKerasPruningCallback\n",
    "\n",
    "# ───────────────────── runtime hygiene ──────────────────────\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED, VAL_FRAC, ALPHA = 42, 0.20, 2.0\n",
    "N_TRIALS, TIMEOUT = 40, 80 * 60  # seconds\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ──────────────────────── paths, drops ─────────────────────\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "SCALER_PKL = \"tcn_scaler.pkl\"\n",
    "\n",
    "DROP_COLS = [  # (shortened – add the rest of your leakage columns here)\n",
    "    \"close\", \"open\", \"high\", \"low\", \"typical_price\", \"high_low\",\n",
    "    \"high_close\", \"low_close\", \"EMA_21\", \"SMA_20\", \"vwap_24h\", \"close_4h\"\n",
    "]\n",
    "\n",
    "# ───────────────────────── data load ───────────────────────\n",
    "print(\"📊 Loading data …\")\n",
    "df = (\n",
    "    pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "      .loc[\"2018-01-01\":]\n",
    "      .drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "      .dropna(subset=[\"target\"])\n",
    "      .dropna()\n",
    ")\n",
    "print(f\"Shape  : {df.shape}\")\n",
    "print(\"Classes:\\n\", df[\"target\"].value_counts(), \"\\n\")\n",
    "\n",
    "X_raw, y_raw = df.drop(columns=\"target\").values, df[\"target\"].astype(int).values\n",
    "n_features   = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = np.float32((1 - pos_rate) / pos_rate if pos_rate else 1.0)\n",
    "print(f\"Class-weights 0 / 1 → {CLASS_W0:.2f} / {CLASS_W1:.2f}\")\n",
    "\n",
    "# ─────────────────── window cache helper ───────────────────\n",
    "_CACHE: Dict[Tuple[int, int, int], Tuple[np.ndarray, np.ndarray]] = {}\n",
    "\n",
    "def make_windows(arr: np.ndarray, labels: np.ndarray, win: int):\n",
    "    k = (id(arr), len(labels), win)\n",
    "    if k in _CACHE:\n",
    "        return _CACHE[k]\n",
    "\n",
    "    Xs, ys = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        Xs.append(arr[i - win:i])\n",
    "        ys.append(labels[i])\n",
    "    Xw, yw = np.asarray(Xs, np.float32), np.asarray(ys, np.int8)\n",
    "\n",
    "    if Xw.nbytes + yw.nbytes < 1_000_000_000:\n",
    "        _CACHE[k] = (Xw, yw)\n",
    "    return Xw, yw\n",
    "\n",
    "# ─────────────── metric: weighted-F1 (α=2) ────────────────\n",
    "def f1_alpha2(y_true, y_prob) -> float:\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    p, r   = precision_score(y_true, y_pred, zero_division=0), \\\n",
    "             recall_score   (y_true, y_pred, zero_division=0)\n",
    "    return 0. if p+r == 0 else (1+ALPHA)*p*r / (ALPHA*p + r)\n",
    "\n",
    "# ──────────────── TCN model factory ───────────────────────\n",
    "def build_tcn(cfg: dict) -> keras.Model:\n",
    "    dilations = [2 ** i for i in range(cfg[\"nb_stacks\"] * cfg[\"blocks_per_stack\"])]\n",
    "\n",
    "    inp = keras.layers.Input(shape=(cfg[\"window\"], n_features))\n",
    "    x   = TCN(\n",
    "            nb_filters       = cfg[\"filters\"],\n",
    "            kernel_size      = cfg[\"kernel\"],\n",
    "            nb_stacks        = cfg[\"nb_stacks\"],\n",
    "            dilations        = dilations,\n",
    "            padding          = \"causal\",\n",
    "            dropout_rate     = cfg[\"dropout\"],\n",
    "            activation       = cfg[\"act\"],\n",
    "            use_skip_connections = True,\n",
    "            use_batch_norm   = cfg[\"norm\"] == \"batch\",\n",
    "            use_layer_norm   = cfg[\"norm\"] == \"layer\",\n",
    "            return_sequences = False\n",
    "         )(inp)\n",
    "\n",
    "    x   = keras.layers.Dense(cfg[\"dense\"], activation=cfg[\"act\"])(x)\n",
    "    x   = keras.layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    out = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inp, out)\n",
    "\n",
    "    # balanced BCE\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), CLASS_W1, CLASS_W0)\n",
    "        w   = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(keras.optimizers.Adam(cfg[\"lr\"]), loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# ──────────────────── Optuna objective ────────────────────\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    cfg = dict(\n",
    "        window           = trial.suggest_int(\"window\", 12, 60, step=6),\n",
    "        filters          = trial.suggest_categorical(\"filters\", [32, 48, 64, 96]),\n",
    "        kernel           = trial.suggest_int(\"kernel\", 2, 6),\n",
    "        nb_stacks        = trial.suggest_int(\"nb_stacks\", 1, 3),\n",
    "        blocks_per_stack = trial.suggest_int(\"blocks_per_stack\", 1, 2),\n",
    "        dropout          = trial.suggest_float(\"dropout\", 0.05, 0.35),\n",
    "        dense            = trial.suggest_categorical(\"dense\", [32, 64, 128]),\n",
    "        act              = trial.suggest_categorical(\"act\", [\"relu\", \"elu\", \"selu\", tf.nn.swish]),\n",
    "        lr               = trial.suggest_float(\"lr\", 5e-5, 3e-3, log=True),\n",
    "        batch            = trial.suggest_categorical(\"batch\", [32, 64]),\n",
    "        norm             = trial.suggest_categorical(\"norm\", [\"none\", \"batch\", \"layer\"]),\n",
    "    )\n",
    "\n",
    "    X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, cfg[\"window\"])\n",
    "    X_va, y_va = make_windows(X_va_raw, y_va_raw, cfg[\"window\"])\n",
    "\n",
    "    if len(X_tr) < cfg[\"batch\"] * 10:      # too small → prune\n",
    "        return float(\"inf\")\n",
    "\n",
    "    tf.keras.backend.clear_session(); gc.collect()\n",
    "    model = build_tcn(cfg)\n",
    "\n",
    "    cb = [\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=0),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, min_lr=1e-6, verbose=0),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\")\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(X_tr, y_tr,\n",
    "                     validation_data=(X_va, y_va),\n",
    "                     epochs=100,\n",
    "                     batch_size=cfg[\"batch\"],\n",
    "                     shuffle=False,\n",
    "                     callbacks=cb,\n",
    "                     verbose=0)\n",
    "\n",
    "    y_prob = model.predict(X_va, batch_size=cfg[\"batch\"], verbose=0).ravel()\n",
    "    score  = f1_alpha2(y_va, y_prob)\n",
    "\n",
    "    # store metrics to inspect later\n",
    "    trial.set_user_attr(\"precision\", precision_score(y_va, y_prob >= 0.5, zero_division=0))\n",
    "    trial.set_user_attr(\"recall\",    recall_score   (y_va, y_prob >= 0.5, zero_division=0))\n",
    "    trial.set_user_attr(\"best_epoch\", int(np.argmin(hist.history[\"val_loss\"]) + 1))\n",
    "\n",
    "    # print live metrics\n",
    "    print(f\"Trial {trial.number:2d}  \"\n",
    "          f\"Fα2={score:.4f}  P={trial.user_attrs['precision']:.3f} \"\n",
    "          f\"R={trial.user_attrs['recall']:.3f}  cfg={trial.params}\")\n",
    "\n",
    "    del model; tf.keras.backend.clear_session(); gc.collect()\n",
    "    return -score   # minimise\n",
    "\n",
    "# ─────────────────────────── main ──────────────────────────\n",
    "def main():\n",
    "    study = optuna.create_study(direction=\"minimize\",\n",
    "                                sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "                                pruner =optuna.pruners.MedianPruner(n_startup_trials=5))\n",
    "\n",
    "    print(f\"\\n🚀 Optimising  {N_TRIALS} trials  |  {TIMEOUT//60} min wall-time …\")\n",
    "    study.optimize(objective,\n",
    "                   n_trials=N_TRIALS,\n",
    "                   timeout=TIMEOUT,\n",
    "                   show_progress_bar=True,\n",
    "                   gc_after_trial=True)\n",
    "\n",
    "    best, ts = study.best_trial, datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    print(\"\\n═══════════ BEST RESULT ═══════════\")\n",
    "    print(f\"weighted-F1 (α=2) : {-best.value:.4f}\")\n",
    "    print(f\"precision         : {best.user_attrs['precision']:.4f}\")\n",
    "    print(f\"recall            : {best.user_attrs['recall']:.4f}\")\n",
    "    print(f\"best epoch        : {best.user_attrs['best_epoch']}\")\n",
    "    print(\"hyper-parameters  :\")\n",
    "    for k, v in best.params.items():\n",
    "        print(f\"  {k:18s}: {v}\")\n",
    "\n",
    "    json.dump(best.params, open(f\"best_params_tcn_{ts}.json\", \"w\"), indent=2)\n",
    "    study.trials_dataframe().to_csv(f\"trials_tcn_{ts}.csv\", index=False)\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"optuna_tcn_history_{ts}.png\", dpi=300)\n",
    "        plt.close()\n",
    "    except Exception:\n",
    "        print(\"⚠️ matplotlib unavailable – history plot skipped.\")\n",
    "\n",
    "    print(f\"\\n📝 Artefacts saved (timestamp {ts}).  \"\n",
    "          f\"Scaler → {SCALER_PKL}\")\n",
    "\n",
    "# ───────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[I 2025-06-09 18:05:11,711] A new study created in memory with name: no-name-0933098c-6339-4e53-ace1-0af2750e397a\n",
    "📊 Loading data …\n",
    "Shape  : (15855, 66)\n",
    "Classes:\n",
    " target\n",
    "1    8097\n",
    "0    7758\n",
    "Name: count, dtype: int64 \n",
    "\n",
    "Class-weights 0 / 1 → 1.00 / 0.97\n",
    "\n",
    "🚀 Optimising  40 trials  |  30 min wall-time …\n",
    "  0%|          | 0/40 [00:00<?, ?it/s]Trial  0  Fα2=0.4618  P=0.529 R=0.434  cfg={'window': 30, 'filters': 32, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.23033450352296264, 'dense': 128, 'act': 'relu', 'lr': 0.00017376356936978755, 'batch': 32, 'norm': 'batch'}\n",
    "  0%|          | 0/40 [00:44<?, ?it/s][I 2025-06-09 18:05:56,603] Trial 0 finished with value: -0.46183783783783783 and parameters: {'window': 30, 'filters': 32, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.23033450352296264, 'dense': 128, 'act': 'relu', 'lr': 0.00017376356936978755, 'batch': 32, 'norm': 'batch'}. Best is trial 0 with value: -0.46183783783783783.\n",
    "Best trial: 0. Best value: -0.461838:   2%|▎         | 1/40 [00:45<29:26, 45.29s/it, 45.29/1800 seconds]Trial  1  Fα2=0.2813  P=0.515 R=0.229  cfg={'window': 24, 'filters': 64, 'kernel': 4, 'nb_stacks': 2, 'blocks_per_stack': 1, 'dropout': 0.2322634555704315, 'dense': 128, 'act': 'relu', 'lr': 0.0008234548958371457, 'batch': 32, 'norm': 'layer'}\n",
    "Best trial: 0. Best value: -0.461838:   2%|▎         | 1/40 [02:14<29:26, 45.29s/it, 45.29/1800 seconds][I 2025-06-09 18:07:26,384] Trial 1 finished with value: -0.28134328358208954 and parameters: {'window': 24, 'filters': 64, 'kernel': 4, 'nb_stacks': 2, 'blocks_per_stack': 1, 'dropout': 0.2322634555704315, 'dense': 128, 'act': 'relu', 'lr': 0.0008234548958371457, 'batch': 32, 'norm': 'layer'}. Best is trial 0 with value: -0.46183783783783783.\n",
    "Best trial: 0. Best value: -0.461838:   5%|▌         | 2/40 [02:15<45:16, 71.48s/it, 135.10/1800 seconds]Trial  2  Fα2=0.5694  P=0.519 R=0.599  cfg={'window': 24, 'filters': 32, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3318496824692567, 'dense': 128, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.0002455257311459749, 'batch': 64, 'norm': 'layer'}\n",
    "Best trial: 0. Best value: -0.461838:   5%|▌         | 2/40 [13:03<45:16, 71.48s/it, 135.10/1800 seconds][I 2025-06-09 18:18:15,273] Trial 2 finished with value: -0.5694444444444443 and parameters: {'window': 24, 'filters': 32, 'kernel': 2, 'nb_stacks': 3, 'blocks_per_stack': 2, 'dropout': 0.3318496824692567, 'dense': 128, 'act': <function swish at 0x0000025F5ECDAF80>, 'lr': 0.0002455257311459749, 'batch': 64, 'norm': 'layer'}. Best is trial 2 with value: -0.5694444444444443.\n",
    "Best trial: 2. Best value: -0.569444:   8%|▊         | 3/40 [13:04<3:26:43, 335.23s/it, 784.19/1800 seconds]Trial  3  Fα2=0.4582  P=0.528 R=0.430  cfg={'window': 18, 'filters': 64, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.26205720315428516, 'dense': 64, 'act': 'selu', 'lr': 0.00019380132456492117, 'batch': 64, 'norm': 'batch'}\n",
    "Best trial: 2. Best value: -0.569444:   8%|▊         | 3/40 [13:50<3:26:43, 335.23s/it, 784.19/1800 seconds][I 2025-06-09 18:19:01,809] Trial 3 finished with value: -0.45815358067299394 and parameters: {'window': 18, 'filters': 64, 'kernel': 2, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.26205720315428516, 'dense': 64, 'act': 'selu', 'lr': 0.00019380132456492117, 'batch': 64, 'norm': 'batch'}. Best is trial 2 with value: -0.5694444444444443.\n",
    "Best trial: 2. Best value: -0.569444:  10%|█         | 4/40 [13:50<2:12:44, 221.23s/it, 830.66/1800 seconds]Trial  4  Fα2=0.0734  P=0.464 R=0.052  cfg={'window': 54, 'filters': 96, 'kernel': 4, 'nb_stacks': 3, 'blocks_per_stack': 1, 'dropout': 0.2068198488145982, 'dense': 32, 'act': 'elu', 'lr': 0.0020547569815878254, 'batch': 64, 'norm': 'none'}\n",
    "Best trial: 2. Best value: -0.569444:  10%|█         | 4/40 [20:56<2:12:44, 221.23s/it, 830.66/1800 seconds][I 2025-06-09 18:26:07,757] Trial 4 finished with value: -0.07344797435150102 and parameters: {'window': 54, 'filters': 96, 'kernel': 4, 'nb_stacks': 3, 'blocks_per_stack': 1, 'dropout': 0.2068198488145982, 'dense': 32, 'act': 'elu', 'lr': 0.0020547569815878254, 'batch': 64, 'norm': 'none'}. Best is trial 2 with value: -0.5694444444444443.\n",
    "Best trial: 2. Best value: -0.569444:  12%|█▎        | 5/40 [21:44<2:52:07, 295.06s/it, 1256.64/1800 seconds][I 2025-06-09 18:26:56,640] Trial 5 pruned. Trial was pruned at epoch 2.\n",
    "Best trial: 2. Best value: -0.569444:  15%|█▌        | 6/40 [22:07<1:59:46, 211.37s/it, 1305.56/1800 seconds][I 2025-06-09 18:27:19,541] Trial 6 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  18%|█▊        | 7/40 [22:51<1:22:22, 149.77s/it, 1328.51/1800 seconds][I 2025-06-09 18:28:03,649] Trial 7 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  20%|██        | 8/40 [25:29<1:01:56, 116.16s/it, 1372.68/1800 seconds][I 2025-06-09 18:30:41,459] Trial 8 pruned. Trial was pruned at epoch 2.\n",
    "Best trial: 2. Best value: -0.569444:  22%|██▎       | 9/40 [25:45<1:06:46, 129.23s/it, 1530.66/1800 seconds][I 2025-06-09 18:30:57,079] Trial 9 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  25%|██▌       | 10/40 [26:39<47:04, 94.15s/it, 1546.25/1800 seconds]  [I 2025-06-09 18:31:51,377] Trial 10 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  28%|██▊       | 11/40 [26:48<39:37, 82.00s/it, 1600.71/1800 seconds][I 2025-06-09 18:32:00,674] Trial 11 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  30%|███       | 12/40 [26:57<27:56, 59.86s/it, 1609.93/1800 seconds][I 2025-06-09 18:32:09,118] Trial 12 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  32%|███▎      | 13/40 [27:06<19:56, 44.30s/it, 1618.42/1800 seconds][I 2025-06-09 18:32:18,590] Trial 13 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  35%|███▌      | 14/40 [27:38<14:38, 33.78s/it, 1627.88/1800 seconds][I 2025-06-09 18:32:50,659] Trial 14 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 2. Best value: -0.569444:  38%|███▊      | 15/40 [27:39<13:51, 33.27s/it, 1659.99/1800 seconds]Trial 15  Fα2=0.5717  P=0.532 R=0.594  cfg={'window': 30, 'filters': 32, 'kernel': 3, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.19135781227800264, 'dense': 32, 'act': 'relu', 'lr': 5.35786547006468e-05, 'batch': 32, 'norm': 'layer'}\n",
    "Best trial: 2. Best value: -0.569444:  38%|███▊      | 15/40 [28:35<13:51, 33.27s/it, 1659.99/1800 seconds][I 2025-06-09 18:33:47,413] Trial 15 finished with value: -0.5716803760282021 and parameters: {'window': 30, 'filters': 32, 'kernel': 3, 'nb_stacks': 1, 'blocks_per_stack': 2, 'dropout': 0.19135781227800264, 'dense': 32, 'act': 'relu', 'lr': 5.35786547006468e-05, 'batch': 32, 'norm': 'layer'}. Best is trial 15 with value: -0.5716803760282021.\n",
    "Best trial: 15. Best value: -0.57168:  40%|████      | 16/40 [29:14<16:08, 40.33s/it, 1716.72/1800 seconds][I 2025-06-09 18:34:26,236] Trial 16 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 15. Best value: -0.57168:  42%|████▎     | 17/40 [29:29<15:18, 39.93s/it, 1755.72/1800 seconds][I 2025-06-09 18:34:41,644] Trial 17 pruned. Trial was pruned at epoch 0.\n",
    "Best trial: 15. Best value: -0.57168:  45%|████▌     | 18/40 [32:38<11:56, 32.56s/it, 1771.12/1800 seconds][I 2025-06-09 18:37:50,265] Trial 18 pruned. Trial was pruned at epoch 1.\n",
    "Best trial: 15. Best value: -0.57168:  48%|████▊     | 19/40 [32:39<36:06, 103.15s/it, 1959.93/1800 seconds]\n",
    "\n",
    "═══════════ BEST RESULT ═══════════\n",
    "weighted-F1 (α=2) : 0.5717\n",
    "precision         : 0.5323\n",
    "recall            : 0.5937\n",
    "best epoch        : 7\n",
    "hyper-parameters  :\n",
    "  window            : 30\n",
    "  filters           : 32\n",
    "  kernel            : 3\n",
    "  nb_stacks         : 1\n",
    "  blocks_per_stack  : 2\n",
    "  dropout           : 0.19135781227800264\n",
    "  dense             : 32\n",
    "  act               : relu\n",
    "  lr                : 5.35786547006468e-05\n",
    "  batch             : 32\n",
    "  norm              : layer\n",
    "\n",
    "📝 Artefacts saved (timestamp 20250609_153751).  Scaler → tcn_scaler.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813c7b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loading data …\n",
      "Data after cleaning : (15855, 59)\n",
      "Class weights 0 / 1 → 1.00 / 0.97\n",
      "Train windows : (12660, 24, 58) • Val windows : (3147, 24, 58)\n",
      "WARNING:tensorflow:From c:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                        </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">               Para</span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                         │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                             │                <span style=\"color: #00af00; text-decoration-color: #00af00\">80,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">4,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m58\u001b[0m)                         │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ tcn (\u001b[38;5;33mTCN\u001b[0m)                                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                             │                \u001b[38;5;34m80,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            │                 \u001b[38;5;34m4,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,089</span> (332.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m85,089\u001b[0m (332.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,089</span> (332.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m85,089\u001b[0m (332.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training …\n",
      "Epoch 1/100\n",
      "198/198 - 38s - 192ms/step - loss: 1.0617 - val_loss: 0.7057 - learning_rate: 2.4553e-04\n",
      "Epoch 2/100\n",
      "198/198 - 18s - 92ms/step - loss: 0.8069 - val_loss: 0.7041 - learning_rate: 2.4553e-04\n",
      "Epoch 3/100\n",
      "198/198 - 18s - 91ms/step - loss: 0.7418 - val_loss: 0.7051 - learning_rate: 2.4553e-04\n",
      "Epoch 4/100\n",
      "198/198 - 17s - 85ms/step - loss: 0.7195 - val_loss: 0.6986 - learning_rate: 2.4553e-04\n",
      "Epoch 5/100\n",
      "198/198 - 17s - 85ms/step - loss: 0.7059 - val_loss: 0.7019 - learning_rate: 2.4553e-04\n",
      "Epoch 6/100\n",
      "198/198 - 17s - 84ms/step - loss: 0.7013 - val_loss: 0.6982 - learning_rate: 2.4553e-04\n",
      "Epoch 7/100\n",
      "198/198 - 17s - 83ms/step - loss: 0.6954 - val_loss: 0.7003 - learning_rate: 2.4553e-04\n",
      "Epoch 8/100\n",
      "198/198 - 17s - 84ms/step - loss: 0.6917 - val_loss: 0.6960 - learning_rate: 2.4553e-04\n",
      "Epoch 9/100\n",
      "198/198 - 12s - 61ms/step - loss: 0.6906 - val_loss: 0.6921 - learning_rate: 2.4553e-04\n",
      "Epoch 10/100\n",
      "198/198 - 12s - 61ms/step - loss: 0.6914 - val_loss: 0.6894 - learning_rate: 2.4553e-04\n",
      "Epoch 11/100\n",
      "198/198 - 12s - 62ms/step - loss: 0.6876 - val_loss: 0.6890 - learning_rate: 2.4553e-04\n",
      "Epoch 12/100\n",
      "198/198 - 9s - 43ms/step - loss: 0.6880 - val_loss: 0.6883 - learning_rate: 2.4553e-04\n",
      "Epoch 13/100\n",
      "198/198 - 8s - 41ms/step - loss: 0.6867 - val_loss: 0.6871 - learning_rate: 2.4553e-04\n",
      "Epoch 14/100\n",
      "198/198 - 8s - 41ms/step - loss: 0.6869 - val_loss: 0.6867 - learning_rate: 2.4553e-04\n",
      "Epoch 15/100\n",
      "198/198 - 8s - 41ms/step - loss: 0.6863 - val_loss: 0.6869 - learning_rate: 2.4553e-04\n",
      "Epoch 16/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6861 - val_loss: 0.6880 - learning_rate: 2.4553e-04\n",
      "Epoch 17/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6848 - val_loss: 0.6866 - learning_rate: 2.4553e-04\n",
      "Epoch 18/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6847 - val_loss: 0.6863 - learning_rate: 2.4553e-04\n",
      "Epoch 19/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6833 - val_loss: 0.6871 - learning_rate: 2.4553e-04\n",
      "Epoch 20/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6847 - val_loss: 0.6868 - learning_rate: 2.4553e-04\n",
      "Epoch 21/100\n",
      "198/198 - 8s - 42ms/step - loss: 0.6834 - val_loss: 0.6856 - learning_rate: 2.4553e-04\n",
      "Epoch 22/100\n",
      "198/198 - 8s - 40ms/step - loss: 0.6831 - val_loss: 0.6868 - learning_rate: 2.4553e-04\n",
      "Epoch 23/100\n",
      "198/198 - 8s - 40ms/step - loss: 0.6836 - val_loss: 0.6863 - learning_rate: 2.4553e-04\n",
      "Epoch 24/100\n",
      "198/198 - 10s - 50ms/step - loss: 0.6834 - val_loss: 0.6868 - learning_rate: 2.4553e-04\n",
      "Epoch 25/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6831 - val_loss: 0.6872 - learning_rate: 2.4553e-04\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00012276286724954844.\n",
      "198/198 - 16s - 83ms/step - loss: 0.6840 - val_loss: 0.6863 - learning_rate: 2.4553e-04\n",
      "Epoch 27/100\n",
      "198/198 - 16s - 83ms/step - loss: 0.6826 - val_loss: 0.6854 - learning_rate: 1.2276e-04\n",
      "Epoch 28/100\n",
      "198/198 - 16s - 81ms/step - loss: 0.6835 - val_loss: 0.6847 - learning_rate: 1.2276e-04\n",
      "Epoch 29/100\n",
      "198/198 - 13s - 64ms/step - loss: 0.6823 - val_loss: 0.6842 - learning_rate: 1.2276e-04\n",
      "Epoch 30/100\n",
      "198/198 - 9s - 43ms/step - loss: 0.6820 - val_loss: 0.6843 - learning_rate: 1.2276e-04\n",
      "Epoch 31/100\n",
      "198/198 - 8s - 43ms/step - loss: 0.6815 - val_loss: 0.6844 - learning_rate: 1.2276e-04\n",
      "Epoch 32/100\n",
      "198/198 - 12s - 61ms/step - loss: 0.6824 - val_loss: 0.6844 - learning_rate: 1.2276e-04\n",
      "Epoch 33/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6829 - val_loss: 0.6846 - learning_rate: 1.2276e-04\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.138143362477422e-05.\n",
      "198/198 - 16s - 81ms/step - loss: 0.6823 - val_loss: 0.6848 - learning_rate: 1.2276e-04\n",
      "Epoch 35/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6830 - val_loss: 0.6840 - learning_rate: 6.1381e-05\n",
      "Epoch 36/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6819 - val_loss: 0.6841 - learning_rate: 6.1381e-05\n",
      "Epoch 37/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6824 - val_loss: 0.6837 - learning_rate: 6.1381e-05\n",
      "Epoch 38/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6821 - val_loss: 0.6842 - learning_rate: 6.1381e-05\n",
      "Epoch 39/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6819 - val_loss: 0.6841 - learning_rate: 6.1381e-05\n",
      "Epoch 40/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6818 - val_loss: 0.6844 - learning_rate: 6.1381e-05\n",
      "Epoch 41/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6822 - val_loss: 0.6843 - learning_rate: 6.1381e-05\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 3.069071681238711e-05.\n",
      "198/198 - 21s - 104ms/step - loss: 0.6821 - val_loss: 0.6846 - learning_rate: 6.1381e-05\n",
      "Epoch 43/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6819 - val_loss: 0.6843 - learning_rate: 3.0691e-05\n",
      "Epoch 44/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6818 - val_loss: 0.6843 - learning_rate: 3.0691e-05\n",
      "Epoch 45/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6826 - val_loss: 0.6843 - learning_rate: 3.0691e-05\n",
      "Epoch 46/100\n",
      "198/198 - 16s - 82ms/step - loss: 0.6812 - val_loss: 0.6843 - learning_rate: 3.0691e-05\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.5345358406193554e-05.\n",
      "198/198 - 16s - 82ms/step - loss: 0.6819 - val_loss: 0.6842 - learning_rate: 3.0691e-05\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "\n",
      "📈 Final evaluation …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "───── VALIDATION METRICS ─────\n",
      "Accuracy            :  0.493\n",
      "Precision           :  0.565\n",
      "Recall              :  0.127\n",
      "Weighted-F1 (α=2)   :  0.171\n",
      "Confusion matrix    : [1343, 160, 1436, 208]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 32, 'kernel_size': 2, 'padding': 'causal', 'activation': 'swish', 'dropout_rate': 0.3318496824692567, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 24, 58]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 211\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# ─────────────────────── 4. save artefacts ─────────────────\u001b[39;00m\n\u001b[0;32m    210\u001b[0m ts \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mutcnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 211\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_H5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m summary \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m      : ts \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: CFG,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m: cm\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    226\u001b[0m }\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(SUMMARY_JS, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [deepcopy(a, memo) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:265\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[0;32m    264\u001b[0m     args \u001b[38;5;241m=\u001b[39m (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[1;32m--> 265\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m    267\u001b[0m     memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 32, 'kernel_size': 2, 'padding': 'causal', 'activation': 'swish', 'dropout_rate': 0.3318496824692567, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 24, 58]}}"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_tcn_final.py  ·  2025-06-09\n",
    "────────────────────────────────────────────────────\n",
    "One-shot training of a Temporal Convolutional Network\n",
    "for 4-hour BTC direction, using the fixed hyper-params\n",
    "supplied by the user (see CFG below).\n",
    "\n",
    "Outputs\n",
    "• tcn_btc_direction.h5\n",
    "• tcn_scaler.pkl\n",
    "• tcn_training_summary.json\n",
    "\"\"\"\n",
    "\n",
    "# ─────────────────── imports & hygiene ───────────────────\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             confusion_matrix, accuracy_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN                     # pip install tcn==3.*\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ───────────────────── paths & constants ──────────────────\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "SCALER_PKL = \"tcn_scaler.pkl\"\n",
    "MODEL_H5   = \"tcn_btc_direction.h5\"\n",
    "SUMMARY_JS = \"tcn_training_summary.json\"\n",
    "\n",
    "VAL_FRAC = 0.20         # last 20 % for validation\n",
    "ALPHA    = 2.0          # precision weight in Fβ (β=√α)\n",
    "\n",
    "DROP_COLS = [           # minimal leakage list – extend as needed\n",
    "    \"open\", \"high\", \"low\", \"close\", \"typical_price\",\n",
    "    \"high_low\", \"high_close\", \"low_close\", \"EMA_21\", \"SMA_20\",\n",
    "    \"vwap_24h\", \"close_4h\"\n",
    "]\n",
    "\n",
    "# ─────────────────── hyper-parameters (fixed) ─────────────\n",
    "CFG: Dict = {\n",
    "    'window'          : 24,\n",
    "    'filters'         : 32,\n",
    "    'kernel'          : 2,\n",
    "    'nb_stacks'       : 3,\n",
    "    'blocks_per_stack': 2,\n",
    "    'dropout'         : 0.3318496824692567,\n",
    "    'dense'           : 128,\n",
    "    'act'             : 'swish',\n",
    "    'lr'              : 0.0002455257311459749,\n",
    "    'batch'           : 64,\n",
    "    'norm'            : 'layer'            # \"none\" | \"batch\" | \"layer\"\n",
    "}\n",
    "\n",
    "# ───────────────────── helper functions ───────────────────\n",
    "def make_windows(arr: np.ndarray,\n",
    "                 labels: np.ndarray,\n",
    "                 win: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Turn a 2-D feature matrix into sliding 3-D windows.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i - win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.asarray(X, np.float32), np.asarray(y, np.int8)\n",
    "\n",
    "def f1_alpha2(y_true, y_prob, alpha: float) -> float:\n",
    "    \"\"\"Weighted F1 where precision gets α-times the weight of recall.\"\"\"\n",
    "    y_pred = (y_prob >= .5).astype(int)\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score   (y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def build_model(cfg: Dict,\n",
    "                n_feat: int,\n",
    "                class_w0: float,\n",
    "                class_w1: float) -> keras.Model:\n",
    "    \"\"\"Create & compile a single-output TCN binary classifier.\"\"\"\n",
    "    # -- validation of activation string (fix #1) --\n",
    "    act = cfg[\"act\"].lower()\n",
    "    assert act in {\"relu\", \"elu\", \"selu\", \"swish\", \"tanh\"}, \\\n",
    "        f\"Unsupported activation: {cfg['act']}\"\n",
    "\n",
    "    # dilations: 1 → …, 2**k\n",
    "    dilations = [2 ** i\n",
    "                 for i in range(cfg[\"nb_stacks\"] * cfg[\"blocks_per_stack\"])]\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    x = TCN(\n",
    "            nb_filters        = cfg[\"filters\"],\n",
    "            kernel_size       = cfg[\"kernel\"],\n",
    "            nb_stacks         = cfg[\"nb_stacks\"],\n",
    "            dilations         = dilations,\n",
    "            padding           = \"causal\",\n",
    "            dropout_rate      = cfg[\"dropout\"],\n",
    "            activation        = act,\n",
    "            use_skip_connections=True,\n",
    "            use_batch_norm    = cfg[\"norm\"] == \"batch\",\n",
    "            use_layer_norm    = cfg[\"norm\"] == \"layer\",\n",
    "            return_sequences  = False\n",
    "        )(inputs)\n",
    "\n",
    "    x = keras.layers.Dense(cfg[\"dense\"], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # custom weighted BCE (float32 safe)\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), class_w1, class_w0)\n",
    "        w   = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(cfg[\"lr\"]),\n",
    "                  loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# ─────────────────────── 1. load dataset ────────────────────\n",
    "print(\"📊 Loading data …\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Data after cleaning : {df.shape}\")\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "# class weights (fix #2 clarity)\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = (np.float32((1 - pos_rate) / pos_rate)\n",
    "            if pos_rate != 0 else np.float32(1.0))\n",
    "print(f\"Class weights 0 / 1 → {CLASS_W0:.2f} / {CLASS_W1:.2f}\")\n",
    "\n",
    "# slide into windows\n",
    "X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, CFG[\"window\"])\n",
    "X_va, y_va = make_windows(X_va_raw, y_va_raw, CFG[\"window\"])\n",
    "print(f\"Train windows : {X_tr.shape} • Val windows : {X_va.shape}\")\n",
    "\n",
    "# ─────────────────────── 2. train model ─────────────────────\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "model = build_model(CFG, n_features, CLASS_W0, CLASS_W1)\n",
    "model.summary(line_length=120)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\n🚀 Training …\")\n",
    "history = model.fit(X_tr, y_tr,\n",
    "                    validation_data=(X_va, y_va),\n",
    "                    epochs=100,\n",
    "                    batch_size=CFG[\"batch\"],\n",
    "                    shuffle=False,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "# ─────────────────────── 3. evaluation ─────────────────────\n",
    "print(\"\\n📈 Final evaluation …\")\n",
    "prob = model.predict(X_va, batch_size=CFG[\"batch\"], verbose=0).ravel()\n",
    "pred = (prob >= .5).astype(int)\n",
    "\n",
    "precision = precision_score(y_va, pred, zero_division=0)\n",
    "recall    = recall_score   (y_va, pred, zero_division=0)\n",
    "f1a2      = f1_alpha2(y_va, prob, ALPHA)   # fix #3\n",
    "acc       = accuracy_score(y_va, pred)\n",
    "cm        = confusion_matrix(y_va, pred)\n",
    "\n",
    "print(\"\\n───── VALIDATION METRICS ─────\")\n",
    "print(f\"Accuracy            : {acc:6.3f}\")\n",
    "print(f\"Precision           : {precision:6.3f}\")\n",
    "print(f\"Recall              : {recall:6.3f}\")\n",
    "print(f\"Weighted-F1 (α=2)   : {f1a2:6.3f}\")\n",
    "print(f\"Confusion matrix    : {cm.ravel().tolist()}\")\n",
    "\n",
    "# ─────────────────────── 4. save artefacts ─────────────────\n",
    "ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model.save(MODEL_H5)\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\"      : ts + \"Z\",\n",
    "    \"hyperparameters\": CFG,\n",
    "    \"alpha\"          : ALPHA,\n",
    "    \"n_features\"     : n_features,\n",
    "    \"train_windows\"  : int(len(X_tr)),\n",
    "    \"val_windows\"    : int(len(X_va)),\n",
    "    \"class_weights\"  : [float(CLASS_W0), float(CLASS_W1)],\n",
    "    \"metrics\"        : dict(accuracy=float(acc),\n",
    "                            precision=float(precision),\n",
    "                            recall=float(recall),\n",
    "                            f1_alpha2=float(f1a2)),\n",
    "    \"confusion_matrix\": cm.ravel().tolist()\n",
    "}\n",
    "with open(SUMMARY_JS, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Model   saved → {MODEL_H5}\")\n",
    "print(f\"✅ Scaler  saved → {SCALER_PKL}\")\n",
    "print(f\"✅ Summary saved → {SUMMARY_JS}\")\n",
    "print(\"🎉 Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "702b4076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loading data …\n",
      "Data after cleaning : (15855, 59)\n",
      "Class weights 0 / 1 → 1.00 / 0.97\n",
      "Train windows : (12672, 12, 58) • Val windows : (3159, 12, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                        </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">               Para</span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                         │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">425,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">6,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m58\u001b[0m)                         │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ tcn (\u001b[38;5;33mTCN\u001b[0m)                                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                             │               \u001b[38;5;34m425,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            │                 \u001b[38;5;34m6,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,537</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m431,537\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,537</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m431,537\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training …\n",
      "Epoch 1/100\n",
      "396/396 - 25s - 63ms/step - loss: 0.8768 - val_loss: 0.6852 - learning_rate: 5.9473e-04\n",
      "Epoch 2/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6861 - val_loss: 0.6837 - learning_rate: 5.9473e-04\n",
      "Epoch 3/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6846 - val_loss: 0.6823 - learning_rate: 5.9473e-04\n",
      "Epoch 4/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6830 - val_loss: 0.6821 - learning_rate: 5.9473e-04\n",
      "Epoch 5/100\n",
      "396/396 - 13s - 34ms/step - loss: 0.6823 - val_loss: 0.6829 - learning_rate: 5.9473e-04\n",
      "Epoch 6/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6825 - val_loss: 0.6817 - learning_rate: 5.9473e-04\n",
      "Epoch 7/100\n",
      "396/396 - 16s - 40ms/step - loss: 0.6827 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 8/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6832 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 9/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 5.9473e-04\n",
      "Epoch 10/100\n",
      "396/396 - 13s - 34ms/step - loss: 0.6824 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 11/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6824 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 12/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6823 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00029736640863120556.\n",
      "396/396 - 13s - 33ms/step - loss: 0.6823 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 14/100\n",
      "396/396 - 13s - 34ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 2.9737e-04\n",
      "Epoch 15/100\n",
      "396/396 - 13s - 34ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 2.9737e-04\n",
      "Epoch 16/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 2.9737e-04\n",
      "Epoch 17/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6823 - val_loss: 0.6832 - learning_rate: 2.9737e-04\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00014868320431560278.\n",
      "396/396 - 13s - 34ms/step - loss: 0.6824 - val_loss: 0.6815 - learning_rate: 2.9737e-04\n",
      "Epoch 19/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 1.4868e-04\n",
      "Epoch 20/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 1.4868e-04\n",
      "Epoch 21/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 1.4868e-04\n",
      "Epoch 22/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 1.4868e-04\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 7.434160215780139e-05.\n",
      "396/396 - 13s - 32ms/step - loss: 0.6820 - val_loss: 0.6829 - learning_rate: 1.4868e-04\n",
      "Epoch 24/100\n",
      "396/396 - 12s - 32ms/step - loss: 0.6825 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 25/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6824 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 26/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 27/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 28/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.7170801078900695e-05.\n",
      "396/396 - 12s - 31ms/step - loss: 0.6823 - val_loss: 0.6815 - learning_rate: 7.4342e-05\n",
      "Epoch 30/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 3.7171e-05\n",
      "Epoch 31/100\n",
      "396/396 - 12s - 31ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 3.7171e-05\n",
      "Epoch 32/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 3.7171e-05\n",
      "Epoch 33/100\n",
      "396/396 - 13s - 33ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 3.7171e-05\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.8585400539450347e-05.\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 3.7171e-05\n",
      "Epoch 35/100\n",
      "396/396 - 13s - 32ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 1.8585e-05\n",
      "Epoch 36/100\n",
      "396/396 - 27s - 69ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 1.8585e-05\n",
      "Epoch 37/100\n",
      "396/396 - 29s - 72ms/step - loss: 0.6822 - val_loss: 0.6815 - learning_rate: 1.8585e-05\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\n",
      "📈 Final evaluation …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "───── VALIDATION METRICS ─────\n",
      "Accuracy            :  0.523\n",
      "Precision           :  0.523\n",
      "Recall              :  1.000\n",
      "Weighted-F1 (α=2)   :  0.767\n",
      "Confusion matrix    : [0, 1508, 0, 1651]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 48, 'kernel_size': 5, 'padding': 'causal', 'activation': 'relu', 'dropout_rate': 0.3118914406542517, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 12, 58]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 210\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# ─────────────────────── 4. save artefacts ─────────────────\u001b[39;00m\n\u001b[0;32m    209\u001b[0m ts \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mutcnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 210\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_H5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m summary \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m      : ts \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: CFG,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m: cm\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    225\u001b[0m }\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(SUMMARY_JS, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [deepcopy(a, memo) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:265\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[0;32m    264\u001b[0m     args \u001b[38;5;241m=\u001b[39m (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[1;32m--> 265\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m    267\u001b[0m     memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 48, 'kernel_size': 5, 'padding': 'causal', 'activation': 'relu', 'dropout_rate': 0.3118914406542517, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 12, 58]}}"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_tcn_final.py  ·  2025-06-09\n",
    "────────────────────────────────────────────────────\n",
    "One-shot training of a Temporal Convolutional Network\n",
    "for 4-hour BTC direction, using the fixed hyper-params\n",
    "supplied by the user (see CFG below).\n",
    "\n",
    "Outputs\n",
    "• tcn_btc_direction.h5\n",
    "• tcn_scaler.pkl\n",
    "• tcn_training_summary.json\n",
    "\"\"\"\n",
    "\n",
    "# ─────────────────── imports & hygiene ───────────────────\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             confusion_matrix, accuracy_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN                     # pip install tcn==3.*\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ───────────────────── paths & constants ──────────────────\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "SCALER_PKL = \"tcn_scaler.pkl\"\n",
    "MODEL_H5   = \"tcn_btc_direction.h5\"\n",
    "SUMMARY_JS = \"tcn_training_summary.json\"\n",
    "\n",
    "VAL_FRAC = 0.20         # last 20 % for validation\n",
    "ALPHA    = 2.0          # precision weight in Fβ (β=√α)\n",
    "\n",
    "DROP_COLS = [           # minimal leakage list – extend as needed\n",
    "    \"open\", \"high\", \"low\", \"close\", \"typical_price\",\n",
    "    \"high_low\", \"high_close\", \"low_close\", \"EMA_21\", \"SMA_20\",\n",
    "    \"vwap_24h\", \"close_4h\"\n",
    "]\n",
    "\n",
    "# ─────────────────── hyper-parameters (fixed) ─────────────\n",
    "CFG: Dict = {\n",
    "    'window'          : 12,\n",
    "    'filters'         : 48,\n",
    "    'kernel'          : 5,\n",
    "    'nb_stacks'       : 3,\n",
    "    'blocks_per_stack': 2,\n",
    "    'dropout'         : 0.3118914406542517,\n",
    "    'dense'           : 128,\n",
    "    'act'             : 'relu',\n",
    "    'lr'              : 5.947328436650964e-4,\n",
    "    'batch'           : 32,\n",
    "    'norm'            : 'layer'            # \"none\" | \"batch\" | \"layer\"\n",
    "}\n",
    "\n",
    "# ───────────────────── helper functions ───────────────────\n",
    "def make_windows(arr: np.ndarray,\n",
    "                 labels: np.ndarray,\n",
    "                 win: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Turn a 2-D feature matrix into sliding 3-D windows.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i - win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.asarray(X, np.float32), np.asarray(y, np.int8)\n",
    "\n",
    "def f1_alpha2(y_true, y_prob, alpha: float) -> float:\n",
    "    \"\"\"Weighted F1 where precision gets α-times the weight of recall.\"\"\"\n",
    "    y_pred = (y_prob >= .5).astype(int)\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score   (y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def build_model(cfg: Dict,\n",
    "                n_feat: int,\n",
    "                class_w0: float,\n",
    "                class_w1: float) -> keras.Model:\n",
    "    \"\"\"Create & compile a single-output TCN binary classifier.\"\"\"\n",
    "    # -- validation of activation string (fix #1) --\n",
    "    act = cfg[\"act\"].lower()\n",
    "    assert act in {\"relu\", \"elu\", \"selu\", \"swish\", \"tanh\"}, \\\n",
    "        f\"Unsupported activation: {cfg['act']}\"\n",
    "\n",
    "    # dilations: 1 → …, 2**k\n",
    "    dilations = [2 ** i\n",
    "                 for i in range(cfg[\"nb_stacks\"] * cfg[\"blocks_per_stack\"])]\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    x = TCN(\n",
    "            nb_filters        = cfg[\"filters\"],\n",
    "            kernel_size       = cfg[\"kernel\"],\n",
    "            nb_stacks         = cfg[\"nb_stacks\"],\n",
    "            dilations         = dilations,\n",
    "            padding           = \"causal\",\n",
    "            dropout_rate      = cfg[\"dropout\"],\n",
    "            activation        = act,\n",
    "            use_skip_connections=True,\n",
    "            use_batch_norm    = cfg[\"norm\"] == \"batch\",\n",
    "            use_layer_norm    = cfg[\"norm\"] == \"layer\",\n",
    "            return_sequences  = False\n",
    "        )(inputs)\n",
    "\n",
    "    x = keras.layers.Dense(cfg[\"dense\"], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # custom weighted BCE (float32 safe)\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), class_w1, class_w0)\n",
    "        w   = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(cfg[\"lr\"]),\n",
    "                  loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# ─────────────────────── 1. load dataset ────────────────────\n",
    "print(\"📊 Loading data …\")\n",
    "df = (pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "        .loc[\"2018-01-01\":]\n",
    "        .drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "        .dropna(subset=[\"target\"])\n",
    "        .dropna())\n",
    "print(f\"Data after cleaning : {df.shape}\")\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "# class weights (fix #2 clarity)\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = (np.float32((1 - pos_rate) / pos_rate)\n",
    "            if pos_rate != 0 else np.float32(1.0))\n",
    "print(f\"Class weights 0 / 1 → {CLASS_W0:.2f} / {CLASS_W1:.2f}\")\n",
    "\n",
    "# slide into windows\n",
    "X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, CFG[\"window\"])\n",
    "X_va, y_va = make_windows(X_va_raw, y_va_raw, CFG[\"window\"])\n",
    "print(f\"Train windows : {X_tr.shape} • Val windows : {X_va.shape}\")\n",
    "\n",
    "# ─────────────────────── 2. train model ─────────────────────\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "model = build_model(CFG, n_features, CLASS_W0, CLASS_W1)\n",
    "model.summary(line_length=120)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\n🚀 Training …\")\n",
    "history = model.fit(X_tr, y_tr,\n",
    "                    validation_data=(X_va, y_va),\n",
    "                    epochs=100,\n",
    "                    batch_size=CFG[\"batch\"],\n",
    "                    shuffle=False,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "# ─────────────────────── 3. evaluation ─────────────────────\n",
    "print(\"\\n📈 Final evaluation …\")\n",
    "prob = model.predict(X_va, batch_size=CFG[\"batch\"], verbose=0).ravel()\n",
    "pred = (prob >= .5).astype(int)\n",
    "\n",
    "precision = precision_score(y_va, pred, zero_division=0)\n",
    "recall    = recall_score   (y_va, pred, zero_division=0)\n",
    "f1a2      = f1_alpha2(y_va, prob, ALPHA)   # fix #3\n",
    "acc       = accuracy_score(y_va, pred)\n",
    "cm        = confusion_matrix(y_va, pred)\n",
    "\n",
    "print(\"\\n───── VALIDATION METRICS ─────\")\n",
    "print(f\"Accuracy            : {acc:6.3f}\")\n",
    "print(f\"Precision           : {precision:6.3f}\")\n",
    "print(f\"Recall              : {recall:6.3f}\")\n",
    "print(f\"Weighted-F1 (α=2)   : {f1a2:6.3f}\")\n",
    "print(f\"Confusion matrix    : {cm.ravel().tolist()}\")\n",
    "\n",
    "# ─────────────────────── 4. save artefacts ─────────────────\n",
    "ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model.save(MODEL_H5)\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\"      : ts + \"Z\",\n",
    "    \"hyperparameters\": CFG,\n",
    "    \"alpha\"          : ALPHA,\n",
    "    \"n_features\"     : n_features,\n",
    "    \"train_windows\"  : int(len(X_tr)),\n",
    "    \"val_windows\"    : int(len(X_va)),\n",
    "    \"class_weights\"  : [float(CLASS_W0), float(CLASS_W1)],\n",
    "    \"metrics\"        : dict(accuracy=float(acc),\n",
    "                            precision=float(precision),\n",
    "                            recall=float(recall),\n",
    "                            f1_alpha2=float(f1a2)),\n",
    "    \"confusion_matrix\": cm.ravel().tolist()\n",
    "}\n",
    "with open(SUMMARY_JS, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Model   saved → {MODEL_H5}\")\n",
    "print(f\"✅ Scaler  saved → {SCALER_PKL}\")\n",
    "print(f\"✅ Summary saved → {SUMMARY_JS}\")\n",
    "print(\"🎉 Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8050c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loading data …\n",
      "Data after cleaning : (15855, 59)\n",
      "Class weights 0 / 1 → 1.00 / 0.97\n",
      "Train windows : (12660, 24, 58) • Val windows : (3147, 24, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                        </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">               Para</span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                         │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                             │                <span style=\"color: #00af00; text-decoration-color: #00af00\">80,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">4,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m58\u001b[0m)                         │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ tcn (\u001b[38;5;33mTCN\u001b[0m)                                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                             │                \u001b[38;5;34m80,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            │                 \u001b[38;5;34m4,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,089</span> (332.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m85,089\u001b[0m (332.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,089</span> (332.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m85,089\u001b[0m (332.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training …\n",
      "Epoch 1/100\n",
      "198/198 - 44s - 220ms/step - loss: 0.9470 - val_loss: 0.6877 - learning_rate: 2.4553e-04\n",
      "Epoch 2/100\n",
      "198/198 - 19s - 94ms/step - loss: 0.7569 - val_loss: 0.6850 - learning_rate: 2.4553e-04\n",
      "Epoch 3/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.7161 - val_loss: 0.6851 - learning_rate: 2.4553e-04\n",
      "Epoch 4/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.7040 - val_loss: 0.6845 - learning_rate: 2.4553e-04\n",
      "Epoch 5/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.6982 - val_loss: 0.6844 - learning_rate: 2.4553e-04\n",
      "Epoch 6/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.6934 - val_loss: 0.6832 - learning_rate: 2.4553e-04\n",
      "Epoch 7/100\n",
      "198/198 - 19s - 94ms/step - loss: 0.6906 - val_loss: 0.6834 - learning_rate: 2.4553e-04\n",
      "Epoch 8/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.6896 - val_loss: 0.6822 - learning_rate: 2.4553e-04\n",
      "Epoch 9/100\n",
      "198/198 - 19s - 95ms/step - loss: 0.6896 - val_loss: 0.6830 - learning_rate: 2.4553e-04\n",
      "Epoch 10/100\n",
      "198/198 - 18s - 93ms/step - loss: 0.6879 - val_loss: 0.6828 - learning_rate: 2.4553e-04\n",
      "Epoch 11/100\n",
      "198/198 - 19s - 94ms/step - loss: 0.6869 - val_loss: 0.6826 - learning_rate: 2.4553e-04\n",
      "Epoch 12/100\n",
      "198/198 - 18s - 93ms/step - loss: 0.6856 - val_loss: 0.6829 - learning_rate: 2.4553e-04\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00012276286724954844.\n",
      "198/198 - 18s - 93ms/step - loss: 0.6862 - val_loss: 0.6825 - learning_rate: 2.4553e-04\n",
      "Epoch 14/100\n",
      "198/198 - 19s - 94ms/step - loss: 0.6848 - val_loss: 0.6819 - learning_rate: 1.2276e-04\n",
      "Epoch 15/100\n",
      "198/198 - 15s - 76ms/step - loss: 0.6846 - val_loss: 0.6816 - learning_rate: 1.2276e-04\n",
      "Epoch 16/100\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_tcn_final.py  ·  2025-06-09\n",
    "────────────────────────────────────────────────────\n",
    "One-shot training of a Temporal Convolutional Network\n",
    "for 4-hour BTC direction, using the fixed hyper-params\n",
    "supplied by the user (see CFG below).\n",
    "\n",
    "Outputs\n",
    "• tcn_btc_direction.h5\n",
    "• tcn_scaler.pkl\n",
    "• tcn_training_summary.json\n",
    "\"\"\"\n",
    "\n",
    "# ─────────────────── imports & hygiene ───────────────────\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             confusion_matrix, accuracy_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN                     # pip install tcn==3.*\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ───────────────────── paths & constants ──────────────────\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "SCALER_PKL = \"tcn_scaler.pkl\"\n",
    "MODEL_H5   = \"tcn_btc_direction.h5\"\n",
    "SUMMARY_JS = \"tcn_training_summary.json\"\n",
    "\n",
    "VAL_FRAC = 0.20         # last 20 % for validation\n",
    "ALPHA    = 2.0          # precision weight in Fβ (β=√α)\n",
    "\n",
    "DROP_COLS = [           # minimal leakage list – extend as needed\n",
    "    \"open\", \"high\", \"low\", \"close\", \"typical_price\",\n",
    "    \"high_low\", \"high_close\", \"low_close\", \"EMA_21\", \"SMA_20\",\n",
    "    \"vwap_24h\", \"close_4h\"\n",
    "]\n",
    "\n",
    "# ─────────────────── hyper-parameters (fixed) ─────────────\n",
    "CFG: Dict = {\n",
    "  'window': 24,\n",
    "  'filters': 32,\n",
    "  'kernel': 2,\n",
    "  'nb_stacks': 3,\n",
    "  'blocks_per_stack': 2,\n",
    "  'dropout': 0.3318496824692567,\n",
    "  'dense': 128,\n",
    "  'act': 'swish',\n",
    "  'lr': 0.0002455257311459749,\n",
    "  'batch': 64,\n",
    "  'norm': 'layer'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# ───────────────────── helper functions ───────────────────\n",
    "def make_windows(arr: np.ndarray,\n",
    "                 labels: np.ndarray,\n",
    "                 win: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Turn a 2-D feature matrix into sliding 3-D windows.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i - win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.asarray(X, np.float32), np.asarray(y, np.int8)\n",
    "\n",
    "def f1_alpha2(y_true, y_prob, alpha: float) -> float:\n",
    "    \"\"\"Weighted F1 where precision gets α-times the weight of recall.\"\"\"\n",
    "    y_pred = (y_prob >= .5).astype(int)\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score   (y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def build_model(cfg: Dict,\n",
    "                n_feat: int,\n",
    "                class_w0: float,\n",
    "                class_w1: float) -> keras.Model:\n",
    "    \"\"\"Create & compile a single-output TCN binary classifier.\"\"\"\n",
    "    # -- validation of activation string (fix #1) --\n",
    "    act = cfg[\"act\"].lower()\n",
    "    assert act in {\"relu\", \"elu\", \"selu\", \"swish\", \"tanh\"}, \\\n",
    "        f\"Unsupported activation: {cfg['act']}\"\n",
    "\n",
    "    # dilations: 1 → …, 2**k\n",
    "    dilations = [2 ** i\n",
    "                 for i in range(cfg[\"nb_stacks\"] * cfg[\"blocks_per_stack\"])]\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    x = TCN(\n",
    "            nb_filters        = cfg[\"filters\"],\n",
    "            kernel_size       = cfg[\"kernel\"],\n",
    "            nb_stacks         = cfg[\"nb_stacks\"],\n",
    "            dilations         = dilations,\n",
    "            padding           = \"causal\",\n",
    "            dropout_rate      = cfg[\"dropout\"],\n",
    "            activation        = act,\n",
    "            use_skip_connections=True,\n",
    "            use_batch_norm    = cfg[\"norm\"] == \"batch\",\n",
    "            use_layer_norm    = cfg[\"norm\"] == \"layer\",\n",
    "            return_sequences  = False\n",
    "        )(inputs)\n",
    "\n",
    "    x = keras.layers.Dense(cfg[\"dense\"], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # custom weighted BCE (float32 safe)\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), class_w1, class_w0)\n",
    "        w   = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(cfg[\"lr\"]),\n",
    "                  loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# ─────────────────────── 1. load dataset ────────────────────\n",
    "print(\"📊 Loading data …\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Data after cleaning : {df.shape}\")\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "# class weights (fix #2 clarity)\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = (np.float32((1 - pos_rate) / pos_rate)\n",
    "            if pos_rate != 0 else np.float32(1.0))\n",
    "print(f\"Class weights 0 / 1 → {CLASS_W0:.2f} / {CLASS_W1:.2f}\")\n",
    "\n",
    "# slide into windows\n",
    "X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, CFG[\"window\"])\n",
    "X_va, y_va = make_windows(X_va_raw, y_va_raw, CFG[\"window\"])\n",
    "print(f\"Train windows : {X_tr.shape} • Val windows : {X_va.shape}\")\n",
    "\n",
    "# ─────────────────────── 2. train model ─────────────────────\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "model = build_model(CFG, n_features, CLASS_W0, CLASS_W1)\n",
    "model.summary(line_length=120)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\n🚀 Training …\")\n",
    "history = model.fit(X_tr, y_tr,\n",
    "                    validation_data=(X_va, y_va),\n",
    "                    epochs=100,\n",
    "                    batch_size=CFG[\"batch\"],\n",
    "                    shuffle=False,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "# ─────────────────────── 3. evaluation ─────────────────────\n",
    "print(\"\\n📈 Final evaluation …\")\n",
    "prob = model.predict(X_va, batch_size=CFG[\"batch\"], verbose=0).ravel()\n",
    "pred = (prob >= .5).astype(int)\n",
    "\n",
    "precision = precision_score(y_va, pred, zero_division=0)\n",
    "recall    = recall_score   (y_va, pred, zero_division=0)\n",
    "f1a2      = f1_alpha2(y_va, prob, ALPHA)   # fix #3\n",
    "acc       = accuracy_score(y_va, pred)\n",
    "cm        = confusion_matrix(y_va, pred)\n",
    "\n",
    "print(\"\\n───── VALIDATION METRICS ─────\")\n",
    "print(f\"Accuracy            : {acc:6.3f}\")\n",
    "print(f\"Precision           : {precision:6.3f}\")\n",
    "print(f\"Recall              : {recall:6.3f}\")\n",
    "print(f\"Weighted-F1 (α=2)   : {f1a2:6.3f}\")\n",
    "print(f\"Confusion matrix    : {cm.ravel().tolist()}\")\n",
    "\n",
    "# ─────────────────────── 4. save artefacts ─────────────────\n",
    "ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model.save(MODEL_H5)\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\"      : ts + \"Z\",\n",
    "    \"hyperparameters\": CFG,\n",
    "    \"alpha\"          : ALPHA,\n",
    "    \"n_features\"     : n_features,\n",
    "    \"train_windows\"  : int(len(X_tr)),\n",
    "    \"val_windows\"    : int(len(X_va)),\n",
    "    \"class_weights\"  : [float(CLASS_W0), float(CLASS_W1)],\n",
    "    \"metrics\"        : dict(accuracy=float(acc),\n",
    "                            precision=float(precision),\n",
    "                            recall=float(recall),\n",
    "                            f1_alpha2=float(f1a2)),\n",
    "    \"confusion_matrix\": cm.ravel().tolist()\n",
    "}\n",
    "with open(SUMMARY_JS, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Model   saved → {MODEL_H5}\")\n",
    "print(f\"✅ Scaler  saved → {SCALER_PKL}\")\n",
    "print(f\"✅ Summary saved → {SUMMARY_JS}\")\n",
    "print(\"🎉 Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b703651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loading data …\n",
      "Data after cleaning : (15855, 59)\n",
      "Class weights 0 / 1 → 1.00 / 0.97\n",
      "Train windows : (12672, 12, 58) • Val windows : (3159, 12, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                        </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">               Para</span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                         │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">425,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">6,</span>\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m              Para\u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m58\u001b[0m)                         │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ tcn (\u001b[38;5;33mTCN\u001b[0m)                                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                             │               \u001b[38;5;34m425,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            │                 \u001b[38;5;34m6,\u001b[0m\n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            │                   \n",
       "├─────────────────────────────────────────────────────┼────────────────────────────────────────┼───────────────────\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              │                   \n",
       "└─────────────────────────────────────────────────────┴────────────────────────────────────────┴───────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,537</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m431,537\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,537</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m431,537\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training …\n",
      "Epoch 1/100\n",
      "396/396 - 24s - 60ms/step - loss: 0.8478 - val_loss: 0.6884 - learning_rate: 5.9473e-04\n",
      "Epoch 2/100\n",
      "396/396 - 11s - 28ms/step - loss: 0.6874 - val_loss: 0.6842 - learning_rate: 5.9473e-04\n",
      "Epoch 3/100\n",
      "396/396 - 24s - 60ms/step - loss: 0.6846 - val_loss: 0.6839 - learning_rate: 5.9473e-04\n",
      "Epoch 4/100\n",
      "396/396 - 21s - 52ms/step - loss: 0.6832 - val_loss: 0.6831 - learning_rate: 5.9473e-04\n",
      "Epoch 5/100\n",
      "396/396 - 17s - 42ms/step - loss: 0.6826 - val_loss: 0.6830 - learning_rate: 5.9473e-04\n",
      "Epoch 6/100\n",
      "396/396 - 27s - 67ms/step - loss: 0.6829 - val_loss: 0.6839 - learning_rate: 5.9473e-04\n",
      "Epoch 7/100\n",
      "396/396 - 27s - 69ms/step - loss: 0.6823 - val_loss: 0.6822 - learning_rate: 5.9473e-04\n",
      "Epoch 8/100\n",
      "396/396 - 27s - 68ms/step - loss: 0.6820 - val_loss: 0.6874 - learning_rate: 5.9473e-04\n",
      "Epoch 9/100\n",
      "396/396 - 28s - 70ms/step - loss: 0.6824 - val_loss: 0.6822 - learning_rate: 5.9473e-04\n",
      "Epoch 10/100\n",
      "396/396 - 28s - 71ms/step - loss: 0.6821 - val_loss: 0.6872 - learning_rate: 5.9473e-04\n",
      "Epoch 11/100\n",
      "396/396 - 28s - 70ms/step - loss: 0.6826 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 12/100\n",
      "396/396 - 26s - 66ms/step - loss: 0.6822 - val_loss: 0.6859 - learning_rate: 5.9473e-04\n",
      "Epoch 13/100\n",
      "396/396 - 26s - 66ms/step - loss: 0.6823 - val_loss: 0.6843 - learning_rate: 5.9473e-04\n",
      "Epoch 14/100\n",
      "396/396 - 27s - 69ms/step - loss: 0.6823 - val_loss: 0.6831 - learning_rate: 5.9473e-04\n",
      "Epoch 15/100\n",
      "396/396 - 27s - 69ms/step - loss: 0.6830 - val_loss: 0.6823 - learning_rate: 5.9473e-04\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00029736640863120556.\n",
      "396/396 - 27s - 69ms/step - loss: 0.6823 - val_loss: 0.6816 - learning_rate: 5.9473e-04\n",
      "Epoch 17/100\n",
      "396/396 - 27s - 69ms/step - loss: 0.6820 - val_loss: 0.6837 - learning_rate: 2.9737e-04\n",
      "Epoch 18/100\n",
      "396/396 - 27s - 68ms/step - loss: 0.6820 - val_loss: 0.6836 - learning_rate: 2.9737e-04\n",
      "Epoch 19/100\n",
      "396/396 - 27s - 68ms/step - loss: 0.6812 - val_loss: 0.6878 - learning_rate: 2.9737e-04\n",
      "Epoch 20/100\n",
      "396/396 - 27s - 68ms/step - loss: 0.6814 - val_loss: 0.6863 - learning_rate: 2.9737e-04\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00014868320431560278.\n",
      "396/396 - 27s - 68ms/step - loss: 0.6805 - val_loss: 0.6879 - learning_rate: 2.9737e-04\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\n",
      "📈 Final evaluation …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "───── VALIDATION METRICS ─────\n",
      "Accuracy            :  0.523\n",
      "Precision           :  0.523\n",
      "Recall              :  1.000\n",
      "Weighted-F1 (α=2)   :  0.767\n",
      "Confusion matrix    : [0, 1508, 0, 1651]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 48, 'kernel_size': 5, 'padding': 'causal', 'activation': 'relu', 'dropout_rate': 0.3118914406542517, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 12, 58]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 212\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# ─────────────────────── 4. save artefacts ─────────────────\u001b[39;00m\n\u001b[0;32m    211\u001b[0m ts \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mutcnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 212\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_H5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m summary \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m      : ts \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: CFG,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m: cm\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    227\u001b[0m }\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(SUMMARY_JS, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [deepcopy(a, memo) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:265\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[0;32m    264\u001b[0m     args \u001b[38;5;241m=\u001b[39m (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[1;32m--> 265\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m    267\u001b[0m     memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate class 'ResidualBlock'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'tcn.tcn', 'class_name': 'ResidualBlock', 'config': {'name': 'residual_block_0', 'dilation_rate': 1, 'nb_filters': 48, 'kernel_size': 5, 'padding': 'causal', 'activation': 'relu', 'dropout_rate': 0.3118914406542517, 'use_batch_norm': False, 'use_layer_norm': True, 'kernel_initializer': 'he_normal', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ResidualBlock', 'build_config': {'input_shape': [None, 12, 58]}}"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_tcn_final.py  ·  2025-06-09\n",
    "────────────────────────────────────────────────────\n",
    "One-shot training of a Temporal Convolutional Network\n",
    "for 4-hour BTC direction, using the fixed hyper-params\n",
    "supplied by the user (see CFG below).\n",
    "\n",
    "Outputs\n",
    "• tcn_btc_direction.h5\n",
    "• tcn_scaler.pkl\n",
    "• tcn_training_summary.json\n",
    "\"\"\"\n",
    "\n",
    "# ─────────────────── imports & hygiene ───────────────────\n",
    "import os, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             confusion_matrix, accuracy_score)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN                     # pip install tcn==3.*\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "for g in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# ───────────────────── paths & constants ──────────────────\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "SCALER_PKL = \"tcn_scaler.pkl\"\n",
    "MODEL_H5   = \"tcn_btc_direction.h5\"\n",
    "SUMMARY_JS = \"tcn_training_summary.json\"\n",
    "\n",
    "VAL_FRAC = 0.20         # last 20 % for validation\n",
    "ALPHA    = 2.0          # precision weight in Fβ (β=√α)\n",
    "\n",
    "DROP_COLS = [           # minimal leakage list – extend as needed\n",
    "    \"open\", \"high\", \"low\", \"close\", \"typical_price\",\n",
    "    \"high_low\", \"high_close\", \"low_close\", \"EMA_21\", \"SMA_20\",\n",
    "    \"vwap_24h\", \"close_4h\"\n",
    "]\n",
    "\n",
    "# ─────────────────── hyper-parameters (fixed) ─────────────\n",
    "CFG: Dict = {\n",
    "  'window': 12,\n",
    "  'filters': 48,\n",
    "  'kernel': 5,\n",
    "  'nb_stacks': 3,\n",
    "  'blocks_per_stack': 2,\n",
    "  'dropout': 0.3118914406542517,\n",
    "  'dense': 128,\n",
    "  'act': 'relu',\n",
    "  'lr': 0.0005947328436650964,\n",
    "  'batch': 32,\n",
    "  'norm': 'layer'\n",
    "}\n",
    "\n",
    "\n",
    "# ───────────────────── helper functions ───────────────────\n",
    "def make_windows(arr: np.ndarray,\n",
    "                 labels: np.ndarray,\n",
    "                 win: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Turn a 2-D feature matrix into sliding 3-D windows.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(arr)):\n",
    "        X.append(arr[i - win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.asarray(X, np.float32), np.asarray(y, np.int8)\n",
    "\n",
    "def f1_alpha2(y_true, y_prob, alpha: float) -> float:\n",
    "    \"\"\"Weighted F1 where precision gets α-times the weight of recall.\"\"\"\n",
    "    y_pred = (y_prob >= .5).astype(int)\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score   (y_true, y_pred, zero_division=0)\n",
    "    return 0.0 if p + r == 0 else (1 + alpha) * p * r / (alpha * p + r)\n",
    "\n",
    "def build_model(cfg: Dict,\n",
    "                n_feat: int,\n",
    "                class_w0: float,\n",
    "                class_w1: float) -> keras.Model:\n",
    "    \"\"\"Create & compile a single-output TCN binary classifier.\"\"\"\n",
    "    # -- validation of activation string (fix #1) --\n",
    "    act = cfg[\"act\"].lower()\n",
    "    assert act in {\"relu\", \"elu\", \"selu\", \"swish\", \"tanh\"}, \\\n",
    "        f\"Unsupported activation: {cfg['act']}\"\n",
    "\n",
    "    # dilations: 1 → …, 2**k\n",
    "    dilations = [2 ** i\n",
    "                 for i in range(cfg[\"nb_stacks\"] * cfg[\"blocks_per_stack\"])]\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(cfg[\"window\"], n_feat))\n",
    "\n",
    "    x = TCN(\n",
    "            nb_filters        = cfg[\"filters\"],\n",
    "            kernel_size       = cfg[\"kernel\"],\n",
    "            nb_stacks         = cfg[\"nb_stacks\"],\n",
    "            dilations         = dilations,\n",
    "            padding           = \"causal\",\n",
    "            dropout_rate      = cfg[\"dropout\"],\n",
    "            activation        = act,\n",
    "            use_skip_connections=True,\n",
    "            use_batch_norm    = cfg[\"norm\"] == \"batch\",\n",
    "            use_layer_norm    = cfg[\"norm\"] == \"layer\",\n",
    "            return_sequences  = False\n",
    "        )(inputs)\n",
    "\n",
    "    x = keras.layers.Dense(cfg[\"dense\"], activation=act)(x)\n",
    "    x = keras.layers.Dropout(cfg[\"dropout\"])(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # custom weighted BCE (float32 safe)\n",
    "    def weighted_bce(y_t, y_p):\n",
    "        y_t = tf.cast(y_t, y_p.dtype)\n",
    "        w   = tf.where(tf.equal(y_t, 1), class_w1, class_w0)\n",
    "        w   = tf.cast(w, y_p.dtype)\n",
    "        return tf.reduce_mean(w * keras.losses.binary_crossentropy(y_t, y_p))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(cfg[\"lr\"]),\n",
    "                  loss=weighted_bce)\n",
    "    return model\n",
    "\n",
    "# ─────────────────────── 1. load dataset ────────────────────\n",
    "print(\"📊 Loading data …\")\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df.loc[\"2018-01-01\":]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Data after cleaning : {df.shape}\")\n",
    "\n",
    "X_raw = df.drop(columns=\"target\").values\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "n_features = X_raw.shape[1]\n",
    "\n",
    "split = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler().fit(X_raw[:split])\n",
    "joblib.dump(scaler, SCALER_PKL)\n",
    "\n",
    "X_tr_raw = scaler.transform(X_raw[:split]).astype(np.float32)\n",
    "X_va_raw = scaler.transform(X_raw[split:]).astype(np.float32)\n",
    "y_tr_raw, y_va_raw = y_raw[:split], y_raw[split:]\n",
    "\n",
    "# class weights (fix #2 clarity)\n",
    "pos_rate = y_tr_raw.mean()\n",
    "CLASS_W0 = np.float32(1.0)\n",
    "CLASS_W1 = (np.float32((1 - pos_rate) / pos_rate)\n",
    "            if pos_rate != 0 else np.float32(1.0))\n",
    "print(f\"Class weights 0 / 1 → {CLASS_W0:.2f} / {CLASS_W1:.2f}\")\n",
    "\n",
    "# slide into windows\n",
    "X_tr, y_tr = make_windows(X_tr_raw, y_tr_raw, CFG[\"window\"])\n",
    "X_va, y_va = make_windows(X_va_raw, y_va_raw, CFG[\"window\"])\n",
    "print(f\"Train windows : {X_tr.shape} • Val windows : {X_va.shape}\")\n",
    "\n",
    "# ─────────────────────── 2. train model ─────────────────────\n",
    "tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "model = build_model(CFG, n_features, CLASS_W0, CLASS_W1)\n",
    "model.summary(line_length=120)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\n🚀 Training …\")\n",
    "history = model.fit(X_tr, y_tr,\n",
    "                    validation_data=(X_va, y_va),\n",
    "                    epochs=100,\n",
    "                    batch_size=CFG[\"batch\"],\n",
    "                    shuffle=False,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=2)\n",
    "\n",
    "# ─────────────────────── 3. evaluation ─────────────────────\n",
    "print(\"\\n📈 Final evaluation …\")\n",
    "prob = model.predict(X_va, batch_size=CFG[\"batch\"], verbose=0).ravel()\n",
    "pred = (prob >= .5).astype(int)\n",
    "\n",
    "precision = precision_score(y_va, pred, zero_division=0)\n",
    "recall    = recall_score   (y_va, pred, zero_division=0)\n",
    "f1a2      = f1_alpha2(y_va, prob, ALPHA)   # fix #3\n",
    "acc       = accuracy_score(y_va, pred)\n",
    "cm        = confusion_matrix(y_va, pred)\n",
    "\n",
    "print(\"\\n───── VALIDATION METRICS ─────\")\n",
    "print(f\"Accuracy            : {acc:6.3f}\")\n",
    "print(f\"Precision           : {precision:6.3f}\")\n",
    "print(f\"Recall              : {recall:6.3f}\")\n",
    "print(f\"Weighted-F1 (α=2)   : {f1a2:6.3f}\")\n",
    "print(f\"Confusion matrix    : {cm.ravel().tolist()}\")\n",
    "\n",
    "# ─────────────────────── 4. save artefacts ─────────────────\n",
    "ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model.save(MODEL_H5)\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\"      : ts + \"Z\",\n",
    "    \"hyperparameters\": CFG,\n",
    "    \"alpha\"          : ALPHA,\n",
    "    \"n_features\"     : n_features,\n",
    "    \"train_windows\"  : int(len(X_tr)),\n",
    "    \"val_windows\"    : int(len(X_va)),\n",
    "    \"class_weights\"  : [float(CLASS_W0), float(CLASS_W1)],\n",
    "    \"metrics\"        : dict(accuracy=float(acc),\n",
    "                            precision=float(precision),\n",
    "                            recall=float(recall),\n",
    "                            f1_alpha2=float(f1a2)),\n",
    "    \"confusion_matrix\": cm.ravel().tolist()\n",
    "}\n",
    "with open(SUMMARY_JS, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Model   saved → {MODEL_H5}\")\n",
    "print(f\"✅ Scaler  saved → {SCALER_PKL}\")\n",
    "print(f\"✅ Summary saved → {SUMMARY_JS}\")\n",
    "print(\"🎉 Training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

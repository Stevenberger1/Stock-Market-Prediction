{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a84382f",
   "metadata": {},
   "source": [
    "# In this notebook we will train the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb96deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43884a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading 4H Bitcoin data...\n",
      "   ğŸ“… Date range: 2022-01-01 00:00:00 to 2025-03-28 00:00:00\n",
      "   ğŸ“Š Train: 5,672 samples | Test: 1,419 samples\n",
      "   ğŸ¯ Features: 37 | Target balance: 50.6% bullish\n",
      "\n",
      "ğŸ” Running hyperparameter optimization...\n",
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "â±ï¸  Optimization completed in 147.0s\n",
      "ğŸ¯ Best CV score: 0.5588\n",
      "\n",
      "ğŸŒŸ OPTIMAL PARAMETERS:\n",
      "----------------------------------------\n",
      "   n_estimators        : 300\n",
      "   min_samples_split   : 15\n",
      "   min_samples_leaf    : 4\n",
      "   max_samples         : 0.9\n",
      "   max_leaf_nodes      : 200\n",
      "   max_features        : 0.3\n",
      "   max_depth           : 10\n",
      "   class_weight        : balanced\n",
      "   bootstrap           : True\n",
      "\n",
      "ğŸ“Š TEST SET PERFORMANCE:\n",
      "----------------------------------------\n",
      "   Accuracy                : 0.5321\n",
      "   Precision               : 0.5494\n",
      "   Recall                  : 0.4890\n",
      "   F1 (standard)           : 0.5174\n",
      "   F1 (precision-weighted) : 0.5361\n",
      "   ROC-AUC                 : 0.5344\n",
      "\n",
      "ğŸŒŸ TOP 10 MOST IMPORTANT FEATURES:\n",
      "----------------------------------------\n",
      "    1. roc_4h              : 0.0645\n",
      "    2. buying_pressure     : 0.0505\n",
      "    3. volume_ratio        : 0.0435\n",
      "    4. stoch_%K            : 0.0427\n",
      "    5. bb_position         : 0.0419\n",
      "    6. CCI                 : 0.0400\n",
      "    7. atr_ratio           : 0.0394\n",
      "    8. volume              : 0.0392\n",
      "    9. fear_greed_score    : 0.0378\n",
      "   10. stoch_%D            : 0.0377\n",
      "\n",
      "ğŸ“ˆ TRAINING INSIGHTS:\n",
      "----------------------------------------\n",
      "   Train period: 2022-01-01 00:00:00 to 2024-08-03 12:00:00\n",
      "   Test period:  2024-08-03 16:00:00 to 2025-03-28 00:00:00\n",
      "   CV folds:     4\n",
      "   Total params tested: 50\n",
      "\n",
      "âœ… Optimization complete! Use these parameters for your production Random Forest model.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, time, sys, warnings\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score,\n",
    "                             make_scorer, accuracy_score, roc_auc_score)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CONFIG\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_FILE = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "TIME_COLUMN, TARGET_COL = \"timestamp\", \"target\"\n",
    "START_DATE, TEST_FRAC = \"2022-01-01\", 0.20 \n",
    "DROP_COLS = [ \n",
    "    'open', 'high', 'low', 'high_low', 'high_close', 'low_close', 'typical_price',\n",
    "    'volume_breakout', 'volume_breakdown', 'break_upper_band', 'break_lower_band',\n",
    "    'vol_spike_1_5x', 'rsi_oversold', 'rsi_overbought', 'stoch_overbought',\n",
    "    'stoch_oversold', 'cci_overbought', 'cci_oversold', 'near_upper_band',\n",
    "    'near_lower_band', 'overbought_reversal', 'oversold_reversal',\n",
    "    'ema_cross_up', 'ema_cross_down', 'macd_cross_up', 'macd_cross_down',\n",
    "    'trending_market', 'trend_alignment', 'ema7_above_ema21', 'macd_rising',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bullish_scenario_1',\n",
    "    'bullish_scenario_5', 'bearish_scenario_1'\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# LOAD DATA\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ“Š Loading 4H Bitcoin data...\")\n",
    "if not CSV_FILE.exists():\n",
    "    sys.exit(f\"âŒ File not found: {CSV_FILE}\")\n",
    "\n",
    "df = pd.read_csv(CSV_FILE, parse_dates=[TIME_COLUMN]).set_index(TIME_COLUMN).sort_index()\n",
    "df = df.loc[START_DATE:].copy()\n",
    "\n",
    "# Verify target column exists\n",
    "if TARGET_COL not in df.columns:\n",
    "    sys.exit(f\"âŒ Target column '{TARGET_COL}' not found!\")\n",
    "\n",
    "X = df.drop(columns=[col for col in DROP_COLS if col in df.columns] + [TARGET_COL], errors=\"ignore\")\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Chronological split (IMPORTANT: maintains time order)\n",
    "split = int(len(df) * (1 - TEST_FRAC))\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "print(f\"   ğŸ“… Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"   ğŸ“Š Train: {X_train.shape[0]:,} samples | Test: {X_test.shape[0]:,} samples\")\n",
    "print(f\"   ğŸ¯ Features: {X_train.shape[1]} | Target balance: {y.mean():.1%} bullish\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CUSTOM SCORER (FÎ² WITH Î² = 0.5 for 2x precision weight)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def precision_weighted_f1(y_true, y_pred):\n",
    "    \"\"\"F-beta score with beta=0.5 to weight precision 2x more than recall.\"\"\"\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score(y_true, y_pred, zero_division=0)\n",
    "    beta = 0.5\n",
    "    if p + r == 0:\n",
    "        return 0.0\n",
    "    return (1 + beta**2) * p * r / (beta**2 * p + r)\n",
    "\n",
    "scorer = make_scorer(precision_weighted_f1, greater_is_better=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# HYPERPARAMETER SEARCH\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "param_dist = {\n",
    "    \"n_estimators\":       [100, 150, 200, 250, 300, 400, 500],\n",
    "    \"max_depth\":          [8, 10, 12, 15, 18, 20, None],\n",
    "    \"min_samples_split\":  [5, 10, 15, 20, 25],\n",
    "    \"min_samples_leaf\":   [2, 4, 6, 8, 10],\n",
    "    \"max_leaf_nodes\":     [None, 50, 100, 200, 500],\n",
    "    \"max_features\":       [\"sqrt\", \"log2\", 0.3, 0.5, 0.7],\n",
    "    \"bootstrap\":          [True, False],\n",
    "    \"max_samples\":        [0.7, 0.8, 0.9, 1.0],\n",
    "    \"class_weight\":       [None, \"balanced\", \"balanced_subsample\"],\n",
    "}\n",
    "\n",
    "# Time-series cross-validation (respects temporal order)\n",
    "cv = TimeSeriesSplit(n_splits=4)\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    scoring=scorer,\n",
    "    n_iter=50,\n",
    "    cv=cv,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1  # Show progress\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ” Running hyperparameter optimization...\")\n",
    "start = time.time()\n",
    "search.fit(X_train, y_train)\n",
    "search_time = time.time() - start\n",
    "\n",
    "print(f\"â±ï¸  Optimization completed in {search_time:.1f}s\")\n",
    "print(f\"ğŸ¯ Best CV score: {search.best_score_:.4f}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# RESULTS & EVALUATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸŒŸ OPTIMAL PARAMETERS:\")\n",
    "print(\"-\" * 40)\n",
    "for k, v in search.best_params_.items():\n",
    "    print(f\"   {k:<20}: {v}\")\n",
    "\n",
    "# Test set evaluation\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nğŸ“Š TEST SET PERFORMANCE:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   Accuracy                : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"   Precision               : {precision_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"   Recall                  : {recall_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"   F1 (standard)           : {f1_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"   F1 (precision-weighted) : {precision_weighted_f1(y_test, y_pred):.4f}\")\n",
    "print(f\"   ROC-AUC                 : {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "\n",
    "# Feature importance (top 10)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nğŸŒŸ TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "print(\"-\" * 40)\n",
    "for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):\n",
    "    print(f\"   {i:2d}. {row['feature']:<20}: {row['importance']:.4f}\")\n",
    "\n",
    "# Additional insights\n",
    "print(f\"\\nğŸ“ˆ TRAINING INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   Train period: {df.index[0]} to {df.index[split-1]}\")\n",
    "print(f\"   Test period:  {df.index[split]} to {df.index[-1]}\")\n",
    "print(f\"   CV folds:     {cv.n_splits}\")\n",
    "print(f\"   Total params tested: {len(search.cv_results_['params'])}\")\n",
    "\n",
    "print(f\"\\nâœ… Optimization complete! Use these parameters for your production Random Forest model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5717988",
   "metadata": {},
   "source": [
    "ğŸ“Š Loading 4H Bitcoin data...\n",
    "   ğŸ“… Date range: 2016-01-01 00:00:00 to 2025-03-28 00:00:00\n",
    "   ğŸ“Š Train: 16,184 samples | Test: 4,046 samples\n",
    "   ğŸ¯ Features: 37 | Target balance: 51.8% bullish\n",
    "\n",
    "ğŸ” Running hyperparameter optimization...\n",
    "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
    "â±ï¸  Optimization completed in 344.3s\n",
    "ğŸ¯ Best CV score: 0.5087\n",
    "\n",
    "ğŸŒŸ OPTIMAL PARAMETERS:\n",
    "----------------------------------------\n",
    "   n_estimators        : 100\n",
    "   min_samples_split   : 5\n",
    "   min_samples_leaf    : 8\n",
    "   max_samples         : 0.9\n",
    "   max_leaf_nodes      : 100\n",
    "   max_features        : 0.7\n",
    "   max_depth           : 20\n",
    "   class_weight        : None\n",
    "   bootstrap           : True\n",
    "\n",
    "ğŸ“Š TEST SET PERFORMANCE:\n",
    "----------------------------------------\n",
    "   Accuracy                : 0.5368\n",
    "   Precision               : 0.5677\n",
    "   Recall                  : 0.4115\n",
    "   F1 (standard)           : 0.4771\n",
    "   F1 (precision-weighted) : 0.5276\n",
    "   ROC-AUC                 : 0.5510\n",
    "\n",
    "ğŸŒŸ TOP 10 MOST IMPORTANT FEATURES:\n",
    "----------------------------------------\n",
    "    1. roc_4h              : 0.0810\n",
    "    2. buying_pressure     : 0.0535\n",
    "    3. atr_ratio           : 0.0462\n",
    "    4. volume_mean_20      : 0.0445\n",
    "    5. adx                 : 0.0430\n",
    "    6. volume              : 0.0424\n",
    "    7. fear_greed_score    : 0.0416\n",
    "    8. roc_24h             : 0.0415\n",
    "    9. OBV                 : 0.0398\n",
    "   10. stoch_%K            : 0.0398\n",
    "\n",
    "ğŸ“ˆ TRAINING INSIGHTS:\n",
    "----------------------------------------\n",
    "   Train period: 2016-01-01 00:00:00 to 2023-05-23 16:00:00\n",
    "   Test period:  2023-05-23 20:00:00 to 2025-03-28 00:00:00\n",
    "   CV folds:     4\n",
    "   Total params tested: 50\n",
    "\n",
    "âœ… Optimization complete! Use these parameters for your production Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fdc5ed",
   "metadata": {},
   "source": [
    "ğŸ“Š Loading 4H Bitcoin data...\n",
    "   ğŸ“… Date range: 2018-01-01 00:00:00 to 2025-03-28 00:00:00\n",
    "   ğŸ“Š Train: 12,684 samples | Test: 3,171 samples\n",
    "   ğŸ¯ Features: 37 | Target balance: 51.1% bullish\n",
    "\n",
    "ğŸ” Running hyperparameter optimization...\n",
    "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
    "â±ï¸  Optimization completed in 343.2s\n",
    "ğŸ¯ Best CV score: 0.5165\n",
    "\n",
    "ğŸŒŸ OPTIMAL PARAMETERS:\n",
    "----------------------------------------\n",
    "   n_estimators        : 400\n",
    "   min_samples_split   : 5\n",
    "   min_samples_leaf    : 10\n",
    "   max_samples         : 0.9\n",
    "   max_leaf_nodes      : 500\n",
    "   max_features        : 0.5\n",
    "   max_depth           : 8\n",
    "   class_weight        : balanced_subsample\n",
    "   bootstrap           : True\n",
    "\n",
    "ğŸ“Š TEST SET PERFORMANCE:\n",
    "----------------------------------------\n",
    "   Accuracy                : 0.5244\n",
    "   Precision               : 0.5769\n",
    "   Recall                  : 0.3351\n",
    "   F1 (standard)           : 0.4240\n",
    "   F1 (precision-weighted) : 0.5042\n",
    "   ROC-AUC                 : 0.5501\n",
    "\n",
    "ğŸŒŸ TOP 10 MOST IMPORTANT FEATURES:\n",
    "----------------------------------------\n",
    "    1. roc_4h              : 0.0778\n",
    "    2. buying_pressure     : 0.0613\n",
    "    3. roc_24h             : 0.0469\n",
    "    4. bb_position         : 0.0459\n",
    "    5. fear_greed_score    : 0.0449\n",
    "    6. atr_ratio           : 0.0431\n",
    "    7. adx                 : 0.0415\n",
    "    8. volume_mean_20      : 0.0404\n",
    "    9. stoch_%K            : 0.0404\n",
    "   10. CCI                 : 0.0386\n",
    "\n",
    "ğŸ“ˆ TRAINING INSIGHTS:\n",
    "----------------------------------------\n",
    "   Train period: 2018-01-01 00:00:00 to 2023-10-16 12:00:00\n",
    "   Test period:  2023-10-16 16:00:00 to 2025-03-28 00:00:00\n",
    "   CV folds:     4\n",
    "   Total params tested: 50\n",
    "\n",
    "âœ… Optimization complete! Use these parameters for your production Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784f94e8",
   "metadata": {},
   "source": [
    "ğŸ“Š Loading 4H Bitcoin data...\n",
    "   ğŸ“… Date range: 2020-01-01 00:00:00 to 2025-03-28 00:00:00\n",
    "   ğŸ“Š Train: 9,180 samples | Test: 2,296 samples\n",
    "   ğŸ¯ Features: 37 | Target balance: 51.0% bullish\n",
    "\n",
    "ğŸ” Running hyperparameter optimization...\n",
    "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
    "â±ï¸  Optimization completed in 314.8s\n",
    "ğŸ¯ Best CV score: 0.5496\n",
    "\n",
    "ğŸŒŸ OPTIMAL PARAMETERS:\n",
    "----------------------------------------\n",
    "   n_estimators        : 300\n",
    "   min_samples_split   : 15\n",
    "   min_samples_leaf    : 2\n",
    "   max_samples         : 0.9\n",
    "   max_leaf_nodes      : 100\n",
    "   max_features        : log2\n",
    "   max_depth           : None\n",
    "   class_weight        : None\n",
    "   bootstrap           : True\n",
    "\n",
    "ğŸ“Š TEST SET PERFORMANCE:\n",
    "----------------------------------------\n",
    "   Accuracy                : 0.5366\n",
    "   Precision               : 0.5727\n",
    "   Recall                  : 0.4228\n",
    "   F1 (standard)           : 0.4865\n",
    "   F1 (precision-weighted) : 0.5348\n",
    "   ROC-AUC                 : 0.5327\n",
    "\n",
    "ğŸŒŸ TOP 10 MOST IMPORTANT FEATURES:\n",
    "----------------------------------------\n",
    "    1. roc_4h              : 0.0611\n",
    "    2. buying_pressure     : 0.0475\n",
    "    3. bb_position         : 0.0431\n",
    "    4. stoch_%K            : 0.0418\n",
    "    5. fear_greed_score    : 0.0417\n",
    "    6. price_vs_vwap       : 0.0397\n",
    "    7. CCI                 : 0.0384\n",
    "    8. roc_24h             : 0.0371\n",
    "    9. stoch_%D            : 0.0367\n",
    "   10. OBV                 : 0.0363\n",
    "\n",
    "ğŸ“ˆ TRAINING INSIGHTS:\n",
    "----------------------------------------\n",
    "   Train period: 2020-01-01 00:00:00 to 2024-03-10 08:00:00\n",
    "   Test period:  2024-03-10 12:00:00 to 2025-03-28 00:00:00\n",
    "   CV folds:     4\n",
    "   Total params tested: 50\n",
    "\n",
    "âœ… Optimization complete! Use these parameters for your production Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9194b38",
   "metadata": {},
   "source": [
    "ğŸ“Š Loading 4H Bitcoin data...\n",
    "   ğŸ“… Date range: 2022-01-01 00:00:00 to 2025-03-28 00:00:00\n",
    "   ğŸ“Š Train: 5,672 samples | Test: 1,419 samples\n",
    "   ğŸ¯ Features: 37 | Target balance: 50.6% bullish\n",
    "\n",
    "ğŸ” Running hyperparameter optimization...\n",
    "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
    "â±ï¸  Optimization completed in 147.0s\n",
    "ğŸ¯ Best CV score: 0.5588\n",
    "\n",
    "ğŸŒŸ OPTIMAL PARAMETERS:\n",
    "----------------------------------------\n",
    "   n_estimators        : 300\n",
    "   min_samples_split   : 15\n",
    "   min_samples_leaf    : 4\n",
    "   max_samples         : 0.9\n",
    "   max_leaf_nodes      : 200\n",
    "   max_features        : 0.3\n",
    "   max_depth           : 10\n",
    "   class_weight        : balanced\n",
    "   bootstrap           : True\n",
    "\n",
    "ğŸ“Š TEST SET PERFORMANCE:\n",
    "----------------------------------------\n",
    "   Accuracy                : 0.5321\n",
    "   Precision               : 0.5494\n",
    "   Recall                  : 0.4890\n",
    "   F1 (standard)           : 0.5174\n",
    "   F1 (precision-weighted) : 0.5361\n",
    "   ROC-AUC                 : 0.5344\n",
    "\n",
    "ğŸŒŸ TOP 10 MOST IMPORTANT FEATURES:\n",
    "----------------------------------------\n",
    "    1. roc_4h              : 0.0645\n",
    "    2. buying_pressure     : 0.0505\n",
    "    3. volume_ratio        : 0.0435\n",
    "    4. stoch_%K            : 0.0427\n",
    "    5. bb_position         : 0.0419\n",
    "    6. CCI                 : 0.0400\n",
    "    7. atr_ratio           : 0.0394\n",
    "    8. volume              : 0.0392\n",
    "    9. fear_greed_score    : 0.0378\n",
    "   10. stoch_%D            : 0.0377\n",
    "\n",
    "ğŸ“ˆ TRAINING INSIGHTS:\n",
    "----------------------------------------\n",
    "   Train period: 2022-01-01 00:00:00 to 2024-08-03 12:00:00\n",
    "   Test period:  2024-08-03 16:00:00 to 2025-03-28 00:00:00\n",
    "   CV folds:     4\n",
    "   Total params tested: 50\n",
    "\n",
    "âœ… Optimization complete! Use these parameters for your production Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ee927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading 4H Bitcoin data for final Random Forest training...\n",
      "   ğŸ“… Date range: 2018-01-01 00:00:00 to 2025-03-28 00:00:00\n",
      "   ğŸ“Š Train: 12,684 | Test: 3,171\n",
      "   ğŸ¯ Features: 37 | Target balance: 51.1% bullish\n",
      "   â° Train period: 2018-01-01 00:00:00 to 2023-10-16 12:00:00\n",
      "   ğŸ§ª Test period:  2023-10-16 16:00:00 to 2025-03-28 00:00:00\n",
      "\n",
      "ğŸš€ Training final Random Forest with optimal parameters...\n",
      "   Parameters:\n",
      "      n_estimators      : 500\n",
      "      max_depth         : 6\n",
      "      min_samples_split : 25\n",
      "      min_samples_leaf  : 8\n",
      "      max_leaf_nodes    : 200\n",
      "      max_features      : sqrt\n",
      "      bootstrap         : True\n",
      "      max_samples       : 0.8\n",
      "      class_weight      : None\n",
      "      random_state      : 42\n",
      "      n_jobs            : -1\n",
      "ğŸŸ¢ Model trained successfully in 1.3s\n",
      "\n",
      "ğŸ“Š FINAL MODEL EVALUATION\n",
      "========================================\n",
      "ğŸ¯ Test Set Performance:\n",
      "   Accuracy                 : 0.5282\n",
      "   Precision                : 0.5813\n",
      "   Recall                   : 0.3454\n",
      "   F1 (standard)            : 0.4333\n",
      "   F1 (precision-weighted)  : 0.5114\n",
      "   ROC-AUC                  : 0.5536\n",
      "\n",
      "ğŸŒŸ FEATURE IMPORTANCE ANALYSIS\n",
      "----------------------------------------\n",
      "Top 15 Most Important Features:\n",
      "    1. roc_4h              : 0.0874\n",
      "    2. buying_pressure     : 0.0714\n",
      "    3. bb_position         : 0.0514\n",
      "    4. stoch_%K            : 0.0472\n",
      "    5. fear_greed_score    : 0.0465\n",
      "    6. CCI                 : 0.0435\n",
      "    7. roc_24h             : 0.0430\n",
      "    8. price_vs_vwap       : 0.0413\n",
      "    9. stoch_%D            : 0.0369\n",
      "   10. volume_mean_20      : 0.0323\n",
      "   11. atr_ratio           : 0.0322\n",
      "   12. OBV                 : 0.0304\n",
      "   13. bollinger_width     : 0.0294\n",
      "   14. volume              : 0.0292\n",
      "   15. adx                 : 0.0288\n",
      "\n",
      "ğŸ‰ TRAINING COMPLETE!\n",
      "==================================================\n",
      "ğŸ¯ Model Performance Summary:\n",
      "   â€¢ Accuracy: 0.528\n",
      "   â€¢ Precision: 0.581 (optimized metric)\n",
      "   â€¢ F1-weighted: 0.511\n",
      "   â€¢ Training time: 1.3s\n",
      "   â€¢ Features used: 37\n",
      "\n",
      "ğŸš€ Ready for downstream use or ensemble integration!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "#  RANDOM-FOREST  â€¢  FINAL TRAINING WITH OPTIMAL PARAMS\n",
    "# =============================================================\n",
    "import numpy as np, pandas as pd, time, sys, warnings\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1) CONFIGURATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_FILE     = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                    r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "TIME_COLUMN  = \"timestamp\"\n",
    "TARGET_COL   = \"target\"\n",
    "START_DATE   = \"2018-01-01\"\n",
    "TEST_FRAC    = 0.20\n",
    "\n",
    "DROP_COLS = [\n",
    "    'open','high','low','high_low','high_close','low_close','typical_price',\n",
    "    'volume_breakout','volume_breakdown','break_upper_band','break_lower_band',\n",
    "    'vol_spike_1_5x','rsi_oversold','rsi_overbought','stoch_overbought',\n",
    "    'stoch_oversold','cci_overbought','cci_oversold','near_upper_band',\n",
    "    'near_lower_band','overbought_reversal','oversold_reversal',\n",
    "    'ema_cross_up','ema_cross_down','macd_cross_up','macd_cross_down',\n",
    "    'trending_market','trend_alignment','ema7_above_ema21','macd_rising',\n",
    "    'bollinger_upper','bollinger_lower','bullish_scenario_1',\n",
    "    'bullish_scenario_5','bearish_scenario_1'\n",
    "]\n",
    "\n",
    "best_params = {\n",
    "    \"n_estimators\":     500,\n",
    "    \"max_depth\":        6,\n",
    "    \"min_samples_split\": 25,\n",
    "    \"min_samples_leaf\": 8,\n",
    "    \"max_leaf_nodes\":   200,\n",
    "    \"max_features\":    \"sqrt\",\n",
    "    \"bootstrap\":        True,\n",
    "    \"max_samples\":      0.8,\n",
    "    \"class_weight\":     None,\n",
    "    \"random_state\":     42,\n",
    "    \"n_jobs\":           -1\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2) LOAD & PREP DATA\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ“Š Loading 4H Bitcoin data for final Random Forest training...\")\n",
    "\n",
    "if not CSV_FILE.exists():\n",
    "    sys.exit(f\"âŒ File not found: {CSV_FILE}\")\n",
    "\n",
    "df = pd.read_csv(CSV_FILE, parse_dates=[TIME_COLUMN]).set_index(TIME_COLUMN).sort_index()\n",
    "df = df.loc[START_DATE:].copy()\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    sys.exit(f\"âŒ '{TARGET_COL}' column missing!\")\n",
    "\n",
    "X = df.drop(columns=[col for col in DROP_COLS if col in df.columns] + [TARGET_COL], errors=\"ignore\")\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "split = int(len(df) * (1 - TEST_FRAC))\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "print(f\"   ğŸ“… Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"   ğŸ“Š Train: {X_train.shape[0]:,} | Test: {X_test.shape[0]:,}\")\n",
    "print(f\"   ğŸ¯ Features: {X_train.shape[1]} | Target balance: {y.mean():.1%} bullish\")\n",
    "print(f\"   â° Train period: {df.index[0]} to {df.index[split-1]}\")\n",
    "print(f\"   ğŸ§ª Test period:  {df.index[split]} to {df.index[-1]}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3) TRAIN FINAL MODEL\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nğŸš€ Training final Random Forest with optimal parameters...\")\n",
    "print(\"   Parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"      {k:<18}: {v}\")\n",
    "\n",
    "t0 = time.time()\n",
    "rf_final = RandomForestClassifier(**best_params)\n",
    "rf_final.fit(X_train, y_train)\n",
    "training_time = time.time() - t0\n",
    "\n",
    "print(f\"ğŸŸ¢ Model trained successfully in {training_time:.1f}s\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4) EVALUATE MODEL\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nğŸ“Š FINAL MODEL EVALUATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "y_pred = rf_final.predict(X_test)\n",
    "y_prob = rf_final.predict_proba(X_test)[:, 1] if rf_final.n_classes_ == 2 else rf_final.predict_proba(X_test).max(axis=1)\n",
    "\n",
    "def precision_weighted_f1(y_true, y_pred):\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score(y_true, y_pred, zero_division=0)\n",
    "    beta = 0.5\n",
    "    return (1 + beta**2) * p * r / (beta**2 * p + r) if (p + r) > 0 else 0.0\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\":                 accuracy_score(y_test, y_pred),\n",
    "    \"Precision\":                precision_score(y_test, y_pred, zero_division=0),\n",
    "    \"Recall\":                   recall_score(y_test, y_pred, zero_division=0),\n",
    "    \"F1 (standard)\":            f1_score(y_test, y_pred, zero_division=0),\n",
    "    \"F1 (precision-weighted)\":  precision_weighted_f1(y_test, y_pred),\n",
    "    \"ROC-AUC\":                  roc_auc_score(y_test, y_prob)\n",
    "}\n",
    "\n",
    "print(\"ğŸ¯ Test Set Performance:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"   {k:<25}: {v:.4f}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5) FEATURE IMPORTANCE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nğŸŒŸ FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(15).iterrows(), 1):\n",
    "    print(f\"   {i:2d}. {row['feature']:<20}: {row['importance']:.4f}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 6) SUMMARY\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nğŸ‰ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ¯ Model Performance Summary:\")\n",
    "print(f\"   â€¢ Accuracy: {metrics['Accuracy']:.3f}\")\n",
    "print(f\"   â€¢ Precision: {metrics['Precision']:.3f} (optimized metric)\")\n",
    "print(f\"   â€¢ F1-weighted: {metrics['F1 (precision-weighted)']:.3f}\")\n",
    "print(f\"   â€¢ Training time: {training_time:.1f}s\")\n",
    "print(f\"   â€¢ Features used: {len(X_train.columns)}\")\n",
    "print(f\"\\nğŸš€ Ready for downstream use or ensemble integration!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37379e5",
   "metadata": {},
   "source": [
    "ğŸ“Š Loading 4H Bitcoin data for final Random Forest training...\n",
    "   ğŸ“… Date range: 2016-01-01 00:00:00 to 2025-03-28 00:00:00\n",
    "   ğŸ“Š Train: 16,184 | Test: 4,046\n",
    "   ğŸ¯ Features: 37 | Target balance: 51.8% bullish\n",
    "   â° Train period: 2016-01-01 00:00:00 to 2023-05-23 16:00:00\n",
    "   ğŸ§ª Test period:  2023-05-23 20:00:00 to 2025-03-28 00:00:00\n",
    "\n",
    "ğŸš€ Training final Random Forest with optimal parameters...\n",
    "   Parameters:\n",
    "      n_estimators      : 300\n",
    "      max_depth         : 15\n",
    "      min_samples_split : 10\n",
    "      min_samples_leaf  : 4\n",
    "      max_leaf_nodes    : 200\n",
    "      max_features      : sqrt\n",
    "      bootstrap         : True\n",
    "      max_samples       : 0.8\n",
    "      class_weight      : balanced_subsample\n",
    "      random_state      : 42\n",
    "      n_jobs            : -1\n",
    "ğŸŸ¢ Model trained successfully in 1.7s\n",
    "\n",
    "ğŸ“Š FINAL MODEL EVALUATION\n",
    "========================================\n",
    "ğŸ¯ Test Set Performance:\n",
    "   Accuracy                 : 0.5309\n",
    "   Precision                : 0.5776\n",
    "   Recall                   : 0.3224\n",
    "   F1 (standard)            : 0.4138\n",
    "   F1 (precision-weighted)  : 0.4987\n",
    "   ROC-AUC                  : 0.5489\n",
    "\n",
    "ğŸŒŸ FEATURE IMPORTANCE ANALYSIS\n",
    "----------------------------------------\n",
    "Top 15 Most Important Features:\n",
    "    1. roc_4h              : 0.0530\n",
    "    2. buying_pressure     : 0.0427\n",
    "    3. bb_position         : 0.0406\n",
    "    4. stoch_%K            : 0.0395\n",
    "    5. fear_greed_score    : 0.0393\n",
    "    6. atr_ratio           : 0.0385\n",
    "    7. roc_24h             : 0.0376\n",
    "    8. volume_ratio        : 0.0374\n",
    "    9. adx                 : 0.0373\n",
    "   10. stoch_%D            : 0.0373\n",
    "   11. volume              : 0.0369\n",
    "   12. price_vs_vwap       : 0.0363\n",
    "   13. CCI                 : 0.0363\n",
    "   14. volume_mean_20      : 0.0360\n",
    "   15. parkinson_vol       : 0.0351\n",
    "\n",
    "ğŸ‰ TRAINING COMPLETE!\n",
    "==================================================\n",
    "ğŸ¯ Model Performance Summary:\n",
    "   â€¢ Accuracy: 0.531\n",
    "   â€¢ Precision: 0.578 (optimized metric)\n",
    "   â€¢ F1-weighted: 0.499\n",
    "   â€¢ Training time: 1.7s\n",
    "   â€¢ Features used: 37\n",
    "\n",
    "ğŸš€ Ready for downstream use or ensemble integration!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18143455",
   "metadata": {},
   "source": [
    "ğŸ“Š Loading 4H Bitcoin data for final Random Forest training...\n",
    "   ğŸ“… Date range: 2016-01-01 00:00:00 to 2025-03-28 00:00:00\n",
    "   ğŸ“Š Train: 16,184 | Test: 4,046\n",
    "   ğŸ¯ Features: 37 | Target balance: 51.8% bullish\n",
    "   â° Train period: 2016-01-01 00:00:00 to 2023-05-23 16:00:00\n",
    "   ğŸ§ª Test period:  2023-05-23 20:00:00 to 2025-03-28 00:00:00\n",
    "\n",
    "ğŸš€ Training final Random Forest with optimal parameters...\n",
    "   Parameters:\n",
    "      n_estimators      : 300\n",
    "      max_depth         : 10\n",
    "      min_samples_split : 15\n",
    "      min_samples_leaf  : 4\n",
    "      max_leaf_nodes    : 200\n",
    "      max_features      : 0.3\n",
    "      bootstrap         : True\n",
    "      max_samples       : 0.9\n",
    "      class_weight      : balanced_subsample\n",
    "      random_state      : 42\n",
    "      n_jobs            : -1\n",
    "ğŸŸ¢ Model trained successfully in 2.7s\n",
    "\n",
    "ğŸ“Š FINAL MODEL EVALUATION\n",
    "========================================\n",
    "ğŸ¯ Test Set Performance:\n",
    "   Accuracy                 : 0.5314\n",
    "   Precision                : 0.5750\n",
    "   Recall                   : 0.3359\n",
    "   F1 (standard)            : 0.4241\n",
    "   F1 (precision-weighted)  : 0.5033\n",
    "   ROC-AUC                  : 0.5537\n",
    "\n",
    "ğŸŒŸ FEATURE IMPORTANCE ANALYSIS\n",
    "----------------------------------------\n",
    "Top 15 Most Important Features:\n",
    "    1. roc_4h              : 0.0628\n",
    "    2. buying_pressure     : 0.0481\n",
    "    3. stoch_%K            : 0.0426\n",
    "    4. bb_position         : 0.0426\n",
    "    5. fear_greed_score    : 0.0407\n",
    "    6. stoch_%D            : 0.0400\n",
    "    7. volume_mean_20      : 0.0397\n",
    "    8. atr_ratio           : 0.0396\n",
    "    9. volume              : 0.0391\n",
    "   10. roc_24h             : 0.0388\n",
    "   11. volume_ratio        : 0.0383\n",
    "   12. adx                 : 0.0379\n",
    "   13. price_vs_vwap       : 0.0373\n",
    "   14. RSI                 : 0.0367\n",
    "   15. CCI                 : 0.0364\n",
    "\n",
    "ğŸ‰ TRAINING COMPLETE!\n",
    "==================================================\n",
    "ğŸ¯ Model Performance Summary:\n",
    "   â€¢ Accuracy: 0.531\n",
    "   â€¢ Precision: 0.575 (optimized metric)\n",
    "   â€¢ F1-weighted: 0.503\n",
    "   â€¢ Training time: 2.7s\n",
    "   â€¢ Features used: 37\n",
    "\n",
    "ğŸš€ Ready for downstream use or ensemble integration!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2e0c64",
   "metadata": {},
   "source": [
    "ğŸ“Š Loading 4H Bitcoin data for final Random Forest training...\n",
    "   ğŸ“… Date range: 2018-01-01 00:00:00 to 2025-03-28 00:00:00\n",
    "   ğŸ“Š Train: 12,684 | Test: 3,171\n",
    "   ğŸ¯ Features: 37 | Target balance: 51.1% bullish\n",
    "   â° Train period: 2018-01-01 00:00:00 to 2023-10-16 12:00:00\n",
    "   ğŸ§ª Test period:  2023-10-16 16:00:00 to 2025-03-28 00:00:00\n",
    "\n",
    "ğŸš€ Training final Random Forest with optimal parameters...\n",
    "   Parameters:\n",
    "      n_estimators      : 300\n",
    "      max_depth         : 15\n",
    "      min_samples_split : 10\n",
    "      min_samples_leaf  : 4\n",
    "      max_leaf_nodes    : 200\n",
    "      max_features      : sqrt\n",
    "      bootstrap         : True\n",
    "      max_samples       : 0.8\n",
    "      class_weight      : balanced_subsample\n",
    "      random_state      : 42\n",
    "      n_jobs            : -1\n",
    "ğŸŸ¢ Model trained successfully in 1.4s\n",
    "\n",
    "ğŸ“Š FINAL MODEL EVALUATION\n",
    "========================================\n",
    "ğŸ¯ Test Set Performance:\n",
    "   Accuracy                 : 0.5251\n",
    "   Precision                : 0.5908\n",
    "   Recall                   : 0.2947\n",
    "   F1 (standard)            : 0.3932\n",
    "   F1 (precision-weighted)  : 0.4919\n",
    "   ROC-AUC                  : 0.5537\n",
    "\n",
    "ğŸŒŸ FEATURE IMPORTANCE ANALYSIS\n",
    "----------------------------------------\n",
    "Top 15 Most Important Features:\n",
    "    1. roc_4h              : 0.0526\n",
    "    2. buying_pressure     : 0.0456\n",
    "    3. fear_greed_score    : 0.0421\n",
    "    4. bb_position         : 0.0415\n",
    "    5. roc_24h             : 0.0403\n",
    "    6. stoch_%K            : 0.0389\n",
    "    7. CCI                 : 0.0382\n",
    "    8. adx                 : 0.0374\n",
    "    9. stoch_%D            : 0.0365\n",
    "   10. volume_mean_20      : 0.0363\n",
    "   11. volume              : 0.0356\n",
    "   12. atr_ratio           : 0.0356\n",
    "   13. price_vs_vwap       : 0.0355\n",
    "   14. volume_ratio        : 0.0351\n",
    "   15. MACD_histogram      : 0.0339\n",
    "\n",
    "ğŸ‰ TRAINING COMPLETE!\n",
    "==================================================\n",
    "ğŸ¯ Model Performance Summary:\n",
    "   â€¢ Accuracy: 0.525\n",
    "   â€¢ Precision: 0.591 (optimized metric)\n",
    "   â€¢ F1-weighted: 0.492\n",
    "   â€¢ Training time: 1.4s\n",
    "   â€¢ Features used: 37\n",
    "\n",
    "ğŸš€ Ready for downstream use or ensemble integration!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f1982",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ff493d",
   "metadata": {},
   "source": [
    "ğŸ“Š Loading 4H Bitcoin data for final Random Forest training...\n",
    "   ğŸ“… Date range: 2018-01-01 00:00:00 to 2025-03-28 00:00:00\n",
    "   ğŸ“Š Train: 12,684 | Test: 3,171\n",
    "   ğŸ¯ Features: 37 | Target balance: 51.1% bullish\n",
    "   â° Train period: 2018-01-01 00:00:00 to 2023-10-16 12:00:00\n",
    "   ğŸ§ª Test period:  2023-10-16 16:00:00 to 2025-03-28 00:00:00\n",
    "\n",
    "ğŸš€ Training final Random Forest with optimal parameters...\n",
    "   Parameters:\n",
    "      n_estimators      : 400\n",
    "      max_depth         : 8\n",
    "      min_samples_split : 5\n",
    "      min_samples_leaf  : 10\n",
    "      max_leaf_nodes    : 500\n",
    "      max_features      : 0.5\n",
    "      bootstrap         : True\n",
    "      max_samples       : 0.9\n",
    "      class_weight      : balanced_subsample\n",
    "      random_state      : 42\n",
    "      n_jobs            : -1\n",
    "ğŸŸ¢ Model trained successfully in 3.6s\n",
    "\n",
    "ğŸ“Š FINAL MODEL EVALUATION\n",
    "========================================\n",
    "ğŸ¯ Test Set Performance:\n",
    "   Accuracy                 : 0.5244\n",
    "   Precision                : 0.5769\n",
    "   Recall                   : 0.3351\n",
    "   F1 (standard)            : 0.4240\n",
    "   F1 (precision-weighted)  : 0.5042\n",
    "   ROC-AUC                  : 0.5501\n",
    "\n",
    "ğŸŒŸ FEATURE IMPORTANCE ANALYSIS\n",
    "----------------------------------------\n",
    "Top 15 Most Important Features:\n",
    "    1. roc_4h              : 0.0778\n",
    "    2. buying_pressure     : 0.0613\n",
    "    3. roc_24h             : 0.0469\n",
    "    4. bb_position         : 0.0459\n",
    "    5. fear_greed_score    : 0.0449\n",
    "    6. atr_ratio           : 0.0431\n",
    "    7. adx                 : 0.0415\n",
    "    8. volume_mean_20      : 0.0404\n",
    "    9. stoch_%K            : 0.0404\n",
    "   10. CCI                 : 0.0386\n",
    "   11. stoch_%D            : 0.0377\n",
    "   12. price_vs_vwap       : 0.0369\n",
    "   13. volume              : 0.0354\n",
    "   14. bollinger_width     : 0.0354\n",
    "   15. volume_ratio        : 0.0353\n",
    "\n",
    "ğŸ‰ TRAINING COMPLETE!\n",
    "==================================================\n",
    "ğŸ¯ Model Performance Summary:\n",
    "   â€¢ Accuracy: 0.524\n",
    "   â€¢ Precision: 0.577 (optimized metric)\n",
    "   â€¢ F1-weighted: 0.504\n",
    "   â€¢ Training time: 3.6s\n",
    "   â€¢ Features used: 37\n",
    "\n",
    "ğŸš€ Ready for downstream use or ensemble integration!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e1c0bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98956be8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b48f90bb",
   "metadata": {},
   "source": [
    "ğŸ“Š Loading data and training model with your best parameters...\n",
    "   ğŸ“Š Train: 12,684 | Test: 3,171 | Features: 37\n",
    "ğŸš€ Training Random Forest...\n",
    "âœ… Model trained in 1.4s\n",
    "\n",
    "ğŸ¯ THRESHOLD SENSITIVITY ANALYSIS\n",
    "==========================================================================================\n",
    "Threshold  Accuracy   Precision   Recall     F1         Predictions  % of Test  % Change  \n",
    "------------------------------------------------------------------------------------------\n",
    "0.3        0.523      0.523       0.992      0.685      3140         99.0      %    +0.0%\n",
    "0.4        0.538      0.540       0.778      0.637      2386         75.2      %    +0.0%\n",
    "0.5        0.525      0.591       0.295      0.393      826          26.0      %    +0.0%\n",
    "0.6        0.479      0.556       0.015      0.029      45           1.4       %   -94.6%\n",
    "0.7        0.478      0.000       0.000      0.000      0            0.0       %  -100.0%\n",
    "0.8        0.478      0.000       0.000      0.000      0            0.0       %  -100.0%\n",
    "\n",
    "ğŸ† BEST THRESHOLDS BY METRIC:\n",
    "------------------------------------------------------------\n",
    "   Best Accuracy:  0.4  (Acc: 0.538, Prec: 0.540, Rec: 0.778)\n",
    "   Best Precision: 0.5  (Prec: 0.591, Rec: 0.295, F1: 0.393)\n",
    "   Best Recall:    0.3  (Rec: 0.992, Prec: 0.523, F1: 0.685)\n",
    "   Best F1:        0.3  (F1: 0.685, Prec: 0.523, Rec: 0.992)\n",
    "\n",
    "ğŸ’¡ TRADING STRATEGY RECOMMENDATIONS:\n",
    "------------------------------------------------------------\n",
    "   ğŸ›¡ï¸  Conservative:  No threshold achieves 65%+ precision\n",
    "   âš–ï¸  Balanced:     0.3  (Prec: 0.523, Rec: 0.992, 3140 signals)\n",
    "   âš¡ Aggressive:   0.4  (Rec: 0.778, 2386 signals)\n",
    "\n",
    "ğŸ“Š SIGNAL VOLUME ANALYSIS:\n",
    "------------------------------------------------------------\n",
    "   Default (0.5):   826 signals (26.0% of test set)\n",
    "   High Volume:     3,140 signals at 0.3 (+0% vs default)\n",
    "   Selective:       0 signals at 0.8 (-100% vs default)\n",
    "\n",
    "ğŸ“ˆ PERFORMANCE RANGES ACROSS THRESHOLDS:\n",
    "------------------------------------------------------------\n",
    "   Accuracy:   0.478 - 0.538\n",
    "   Precision:  0.000 - 0.591\n",
    "   Recall:     0.000 - 0.992\n",
    "   F1 Score:   0.000 - 0.685\n",
    "   Signals:    0 - 3,140\n",
    "\n",
    "ğŸ¯ FINAL RECOMMENDATION:\n",
    "============================================================\n",
    "   ğŸ† Use threshold: 0.3\n",
    "   ğŸ“Š Performance:   Accuracy=0.523, Precision=0.523, Recall=0.992, F1=0.685\n",
    "   ğŸ“ˆ Signals:       3,140 (99.0% of test set)\n",
    "   ğŸ’¡ Reason:        F1 score improved +74.1%\n",
    "\n",
    "âœ… Threshold analysis complete! Use threshold 0.3 for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ebf25",
   "metadata": {},
   "source": [
    "ğŸ“Š Loading data and training model with your best parameters...\n",
    "   ğŸ“Š Train: 12,684 | Test: 3,171 | Features: 37\n",
    "ğŸš€ Training Random Forest...\n",
    "âœ… Model trained in 1.7s\n",
    "\n",
    "ğŸ¯ THRESHOLD SENSITIVITY ANALYSIS\n",
    "==========================================================================================\n",
    "Threshold  Accuracy   Precision   Recall     F1         Predictions  % of Test  % Change  \n",
    "------------------------------------------------------------------------------------------\n",
    "0.3        0.522      0.522       1.000      0.686      3171         100.0     %    +0.0%\n",
    "0.4        0.534      0.534       0.855      0.657      2653         83.7      %    +0.0%\n",
    "0.5        0.524      0.580       0.321      0.413      915          28.9      %    +0.0%\n",
    "0.6        0.479      0.750       0.004      0.007      8            0.3       %   -99.1%\n",
    "0.7        0.478      0.000       0.000      0.000      0            0.0       %  -100.0%\n",
    "0.8        0.478      0.000       0.000      0.000      0            0.0       %  -100.0%\n",
    "\n",
    "ğŸ† BEST THRESHOLDS BY METRIC:\n",
    "------------------------------------------------------------\n",
    "   Best Accuracy:  0.4  (Acc: 0.534, Prec: 0.534, Rec: 0.855)\n",
    "   Best Precision: 0.6  (Prec: 0.750, Rec: 0.004, F1: 0.007)\n",
    "   Best Recall:    0.3  (Rec: 1.000, Prec: 0.522, F1: 0.686)\n",
    "   Best F1:        0.3  (F1: 0.686, Prec: 0.522, Rec: 1.000)\n",
    "\n",
    "ğŸ’¡ TRADING STRATEGY RECOMMENDATIONS:\n",
    "------------------------------------------------------------\n",
    "   ğŸ›¡ï¸  Conservative:  0.6  (Prec: 0.750, 8 signals)\n",
    "   âš–ï¸  Balanced:     0.3  (Prec: 0.522, Rec: 1.000, 3171 signals)\n",
    "   âš¡ Aggressive:   0.4  (Rec: 0.855, 2653 signals)\n",
    "\n",
    "ğŸ“Š SIGNAL VOLUME ANALYSIS:\n",
    "------------------------------------------------------------\n",
    "   Default (0.5):   915 signals (28.9% of test set)\n",
    "   High Volume:     3,171 signals at 0.3 (+0% vs default)\n",
    "   Selective:       0 signals at 0.8 (-100% vs default)\n",
    "\n",
    "ğŸ“ˆ PERFORMANCE RANGES ACROSS THRESHOLDS:\n",
    "------------------------------------------------------------\n",
    "   Accuracy:   0.478 - 0.534\n",
    "   Precision:  0.000 - 0.750\n",
    "   Recall:     0.000 - 1.000\n",
    "   F1 Score:   0.000 - 0.686\n",
    "   Signals:    0 - 3,171\n",
    "\n",
    "ğŸ¯ FINAL RECOMMENDATION:\n",
    "============================================================\n",
    "   ğŸ† Use threshold: 0.3\n",
    "   ğŸ“Š Performance:   Accuracy=0.522, Precision=0.522, Recall=1.000, F1=0.686\n",
    "   ğŸ“ˆ Signals:       3,171 (100.0% of test set)\n",
    "   ğŸ’¡ Reason:        F1 score improved +66.1%\n",
    "\n",
    "âœ… Threshold analysis complete! Use threshold 0.3 for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97801fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading data and training model with your best parameters...\n",
      "   ğŸ“Š Train: 12,684 | Test: 3,171 | Features: 37\n",
      "ğŸš€ Training Random Forest...\n",
      "âœ… Model trained in 1.4s\n",
      "\n",
      "ğŸ¯ THRESHOLD SENSITIVITY ANALYSIS\n",
      "==========================================================================================\n",
      "Threshold  Accuracy   Precision   Recall     F1         Predictions  % of Test  % Change  \n",
      "------------------------------------------------------------------------------------------\n",
      "0.3        0.523      0.523       0.992      0.685      3140         99.0      %    +0.0%\n",
      "0.4        0.538      0.540       0.778      0.637      2386         75.2      %    +0.0%\n",
      "0.5        0.525      0.591       0.295      0.393      826          26.0      %    +0.0%\n",
      "0.6        0.479      0.556       0.015      0.029      45           1.4       %   -94.6%\n",
      "0.7        0.478      0.000       0.000      0.000      0            0.0       %  -100.0%\n",
      "0.8        0.478      0.000       0.000      0.000      0            0.0       %  -100.0%\n",
      "\n",
      "ğŸ† BEST THRESHOLDS BY METRIC:\n",
      "------------------------------------------------------------\n",
      "   Best Accuracy:  0.4  (Acc: 0.538, Prec: 0.540, Rec: 0.778)\n",
      "   Best Precision: 0.5  (Prec: 0.591, Rec: 0.295, F1: 0.393)\n",
      "   Best Recall:    0.3  (Rec: 0.992, Prec: 0.523, F1: 0.685)\n",
      "   Best F1:        0.3  (F1: 0.685, Prec: 0.523, Rec: 0.992)\n",
      "\n",
      "ğŸ’¡ TRADING STRATEGY RECOMMENDATIONS:\n",
      "------------------------------------------------------------\n",
      "   ğŸ›¡ï¸  Conservative:  No threshold achieves 65%+ precision\n",
      "   âš–ï¸  Balanced:     0.3  (Prec: 0.523, Rec: 0.992, 3140 signals)\n",
      "   âš¡ Aggressive:   0.4  (Rec: 0.778, 2386 signals)\n",
      "\n",
      "ğŸ“Š SIGNAL VOLUME ANALYSIS:\n",
      "------------------------------------------------------------\n",
      "   Default (0.5):   826 signals (26.0% of test set)\n",
      "   High Volume:     3,140 signals at 0.3 (+0% vs default)\n",
      "   Selective:       0 signals at 0.8 (-100% vs default)\n",
      "\n",
      "ğŸ“ˆ PERFORMANCE RANGES ACROSS THRESHOLDS:\n",
      "------------------------------------------------------------\n",
      "   Accuracy:   0.478 - 0.538\n",
      "   Precision:  0.000 - 0.591\n",
      "   Recall:     0.000 - 0.992\n",
      "   F1 Score:   0.000 - 0.685\n",
      "   Signals:    0 - 3,140\n",
      "\n",
      "ğŸ“… GENERATING DATE-BY-DATE PREDICTIONS...\n",
      "ğŸ“Š SAMPLE PREDICTIONS (First 20 rows):\n",
      "==========================================================================================\n",
      "Date                 Actual  Predicted  Probability  Confidence   Correct \n",
      "------------------------------------------------------------------------------------------\n",
      "2023-10-16 16:00     ğŸŸ¢ Bull  ğŸŸ¢ Bull     0.5163       Medium       âœ…       \n",
      "2023-10-16 20:00     ğŸ”´ Bear  ğŸ”´ Bear     0.4639       Medium       âœ…       \n",
      "2023-10-17 00:00     ğŸ”´ Bear  ğŸŸ¢ Bull     0.5233       Medium       âŒ       \n",
      "2023-10-17 04:00     ğŸŸ¢ Bull  ğŸ”´ Bear     0.4762       Medium       âŒ       \n",
      "2023-10-17 08:00     ğŸ”´ Bear  ğŸ”´ Bear     0.4151       Medium       âœ…       \n",
      "2023-10-17 12:00     ğŸŸ¢ Bull  ğŸŸ¢ Bull     0.5489       Medium       âœ…       \n",
      "2023-10-17 16:00     ğŸ”´ Bear  ğŸ”´ Bear     0.3870       Low          âœ…       \n",
      "2023-10-17 20:00     ğŸ”´ Bear  ğŸ”´ Bear     0.4716       Medium       âœ…       \n",
      "2023-10-18 00:00     ğŸŸ¢ Bull  ğŸŸ¢ Bull     0.5333       Medium       âœ…       \n",
      "2023-10-18 04:00     ğŸ”´ Bear  ğŸ”´ Bear     0.4142       Medium       âœ…       \n",
      "2023-10-18 08:00     ğŸ”´ Bear  ğŸŸ¢ Bull     0.5298       Medium       âŒ       \n",
      "2023-10-18 12:00     ğŸŸ¢ Bull  ğŸŸ¢ Bull     0.5833       Medium       âœ…       \n",
      "2023-10-18 16:00     ğŸ”´ Bear  ğŸŸ¢ Bull     0.5198       Medium       âŒ       \n",
      "2023-10-18 20:00     ğŸŸ¢ Bull  ğŸŸ¢ Bull     0.5840       Medium       âœ…       \n",
      "2023-10-19 00:00     ğŸ”´ Bear  ğŸ”´ Bear     0.4402       Medium       âœ…       \n",
      "2023-10-19 04:00     ğŸŸ¢ Bull  ğŸŸ¢ Bull     0.5252       Medium       âœ…       \n",
      "2023-10-19 08:00     ğŸŸ¢ Bull  ğŸ”´ Bear     0.4817       Medium       âŒ       \n",
      "2023-10-19 12:00     ğŸŸ¢ Bull  ğŸ”´ Bear     0.4237       Medium       âŒ       \n",
      "2023-10-19 16:00     ğŸŸ¢ Bull  ğŸ”´ Bear     0.4110       Medium       âŒ       \n",
      "2023-10-19 20:00     ğŸ”´ Bear  ğŸ”´ Bear     0.4013       Medium       âœ…       \n",
      "\n",
      "ğŸ“ˆ ACCURACY BY CONFIDENCE LEVEL:\n",
      "--------------------------------------------------\n",
      "   Very_Low    :   31 predictions, 54.8% accuracy, avg prob: 0.284\n",
      "   Low         :  754 predictions, 53.0% accuracy, avg prob: 0.367\n",
      "   Medium      : 2341 predictions, 52.2% accuracy, avg prob: 0.478\n",
      "   High        :   45 predictions, 55.6% accuracy, avg prob: 0.618\n",
      "   Very_High   :    0 predictions, nan% accuracy, avg prob: nan\n",
      "\n",
      "ğŸ’¾ PREDICTIONS SAVED:\n",
      "   Primary file: C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\rf_predictions_20180101.csv\n",
      "   Desktop copy: C:\\Users\\ADMIN\\Desktop\\bitcoin_rf_predictions_20180101.csv\n",
      "   âœ… Ready to download from Desktop!\n",
      "   Rows: 3,171\n",
      "   Columns: ['timestamp', 'actual', 'probability', 'predicted', 'confidence', 'correct']\n",
      "   Summary file: C:\\Users\\ADMIN\\Desktop\\bitcoin_model_summary_20180101.csv\n",
      "\n",
      "ğŸ¤– ENSEMBLE INTEGRATION READY:\n",
      "--------------------------------------------------\n",
      "   Model Type:       Random Forest\n",
      "   Test Period:      2023-10-16 16:00:00 to 2025-03-28 00:00:00\n",
      "   Total Predictions: 3,171\n",
      "   Bullish Signals:   826 (26.0%)\n",
      "   Overall Accuracy:  52.5%\n",
      "   Avg Probability:   0.452\n",
      "\n",
      "ğŸ¯ PROBABILITY DISTRIBUTION:\n",
      "--------------------------------------------------\n",
      "   High confidence Bear: 31 (prob â‰¤ 0.3)\n",
      "   Sample dates: 2024-07-17, 2024-07-22, 2024-11-07\n",
      "   ğŸ’¡ You can experiment with any threshold using the 'probability' column!\n",
      "\n",
      "ğŸ¯ FINAL RECOMMENDATION:\n",
      "============================================================\n",
      "   ğŸ† Use threshold: 0.3\n",
      "   ğŸ“Š Performance:   Accuracy=0.523, Precision=0.523, Recall=0.992, F1=0.685\n",
      "   ğŸ“ˆ Signals:       3,140 (99.0% of test set)\n",
      "   ğŸ’¡ Reason:        F1 score improved +74.1%\n",
      "\n",
      "âœ… Threshold analysis complete! Use threshold 0.3 for optimal performance.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "#  THRESHOLD EVALUATION  â€¢  TEST YOUR TRAINED MODEL\n",
    "# =============================================================\n",
    "import numpy as np, pandas as pd, time, sys, warnings\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1) CONFIGURATION - PUT YOUR BEST PARAMETERS HERE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_FILE     = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                    r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "TIME_COLUMN  = \"timestamp\"\n",
    "TARGET_COL   = \"target\"\n",
    "START_DATE   = \"2018-01-01\"\n",
    "TEST_FRAC    = 0.20\n",
    "\n",
    "DROP_COLS = [\n",
    "    'open','high','low','high_low','high_close','low_close','typical_price',\n",
    "    'volume_breakout','volume_breakdown','break_upper_band','break_lower_band',\n",
    "    'vol_spike_1_5x','rsi_oversold','rsi_overbought','stoch_overbought',\n",
    "    'stoch_oversold','cci_overbought','cci_oversold','near_upper_band',\n",
    "    'near_lower_band','overbought_reversal','oversold_reversal',\n",
    "    'ema_cross_up','ema_cross_down','macd_cross_up','macd_cross_down',\n",
    "    'trending_market','trend_alignment','ema7_above_ema21','macd_rising',\n",
    "    'bollinger_upper','bollinger_lower','bullish_scenario_1',\n",
    "    'bullish_scenario_5','bearish_scenario_1'\n",
    "]\n",
    "\n",
    "# ğŸ¯ PUT YOUR BEST PARAMETERS HERE (from hyperparameter search)\n",
    "BEST_PARAMS = {\n",
    "    \"n_estimators\":     300,\n",
    "    \"max_depth\":        15,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"max_leaf_nodes\":   200,\n",
    "    \"max_features\":    \"sqrt\",\n",
    "    \"bootstrap\":        True,\n",
    "    \"max_samples\":      0.8,\n",
    "    \"class_weight\":     \"balanced_subsample\",\n",
    "    \"random_state\":     42,\n",
    "    \"n_jobs\":           -1\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2) LOAD DATA & TRAIN MODEL\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ“Š Loading data and training model with your best parameters...\")\n",
    "\n",
    "if not CSV_FILE.exists():\n",
    "    sys.exit(f\"âŒ File not found: {CSV_FILE}\")\n",
    "\n",
    "df = pd.read_csv(CSV_FILE, parse_dates=[TIME_COLUMN]).set_index(TIME_COLUMN).sort_index()\n",
    "df = df.loc[START_DATE:].copy()\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    sys.exit(f\"âŒ '{TARGET_COL}' column missing!\")\n",
    "\n",
    "X = df.drop(columns=[col for col in DROP_COLS if col in df.columns] + [TARGET_COL], errors=\"ignore\")\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "split = int(len(df) * (1 - TEST_FRAC))\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "print(f\"   ğŸ“Š Train: {X_train.shape[0]:,} | Test: {X_test.shape[0]:,} | Features: {X_train.shape[1]}\")\n",
    "\n",
    "# Train model\n",
    "print(\"ğŸš€ Training Random Forest...\")\n",
    "start_time = time.time()\n",
    "model = RandomForestClassifier(**BEST_PARAMS)\n",
    "model.fit(X_train, y_train)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Get predictions and probabilities\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "print(f\"âœ… Model trained in {train_time:.1f}s\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3) THRESHOLD ANALYSIS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nğŸ¯ THRESHOLD SENSITIVITY ANALYSIS\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"{'Threshold':<10} {'Accuracy':<10} {'Precision':<11} {'Recall':<10} {'F1':<10} {'Predictions':<12} {'% of Test':<10} {'% Change':<10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "baseline_predictions = None\n",
    "threshold_results = []\n",
    "\n",
    "for i, threshold in enumerate(thresholds):\n",
    "    # Apply threshold to probabilities\n",
    "    y_pred_thresh = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred_thresh)\n",
    "    precision = precision_score(y_test, y_pred_thresh, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred_thresh, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_thresh, zero_division=0)\n",
    "    \n",
    "    # Count predictions\n",
    "    positive_predictions = sum(y_pred_thresh)\n",
    "    pct_of_test = (positive_predictions / len(y_test)) * 100\n",
    "    \n",
    "    # Set baseline (0.5 threshold) for comparison\n",
    "    if threshold == 0.5:\n",
    "        baseline_predictions = positive_predictions\n",
    "    \n",
    "    # Calculate percentage change from baseline\n",
    "    if baseline_predictions is not None:\n",
    "        pct_change = ((positive_predictions - baseline_predictions) / baseline_predictions * 100) if baseline_predictions > 0 else 0\n",
    "    else:\n",
    "        pct_change = 0\n",
    "    \n",
    "    threshold_results.append({\n",
    "        'threshold': threshold,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'predictions': positive_predictions,\n",
    "        'pct_of_test': pct_of_test,\n",
    "        'pct_change': pct_change\n",
    "    })\n",
    "    \n",
    "    # Display row\n",
    "    print(f\"{threshold:<10.1f} {accuracy:<10.3f} {precision:<11.3f} {recall:<10.3f} {f1:<10.3f} \"\n",
    "          f\"{positive_predictions:<12} {pct_of_test:<10.1f}% {pct_change:>+7.1f}%\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4) ANALYSIS & RECOMMENDATIONS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Find best thresholds for different objectives\n",
    "best_accuracy = max(threshold_results, key=lambda x: x['accuracy'])\n",
    "best_precision = max(threshold_results, key=lambda x: x['precision'])\n",
    "best_recall = max(threshold_results, key=lambda x: x['recall'])\n",
    "best_f1 = max(threshold_results, key=lambda x: x['f1'])\n",
    "\n",
    "print(f\"\\nğŸ† BEST THRESHOLDS BY METRIC:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"   Best Accuracy:  {best_accuracy['threshold']:.1f}  \"\n",
    "      f\"(Acc: {best_accuracy['accuracy']:.3f}, Prec: {best_accuracy['precision']:.3f}, Rec: {best_accuracy['recall']:.3f})\")\n",
    "print(f\"   Best Precision: {best_precision['threshold']:.1f}  \"\n",
    "      f\"(Prec: {best_precision['precision']:.3f}, Rec: {best_precision['recall']:.3f}, F1: {best_precision['f1']:.3f})\")\n",
    "print(f\"   Best Recall:    {best_recall['threshold']:.1f}  \"\n",
    "      f\"(Rec: {best_recall['recall']:.3f}, Prec: {best_recall['precision']:.3f}, F1: {best_recall['f1']:.3f})\")\n",
    "print(f\"   Best F1:        {best_f1['threshold']:.1f}  \"\n",
    "      f\"(F1: {best_f1['f1']:.3f}, Prec: {best_f1['precision']:.3f}, Rec: {best_f1['recall']:.3f})\")\n",
    "\n",
    "# Find balanced options\n",
    "print(f\"\\nğŸ’¡ TRADING STRATEGY RECOMMENDATIONS:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Conservative (high precision, low false positives)\n",
    "conservative = [r for r in threshold_results if r['precision'] >= 0.65]\n",
    "if conservative:\n",
    "    best_conservative = max(conservative, key=lambda x: x['recall'])\n",
    "    print(f\"   ğŸ›¡ï¸  Conservative:  {best_conservative['threshold']:.1f}  \"\n",
    "          f\"(Prec: {best_conservative['precision']:.3f}, {best_conservative['predictions']} signals)\")\n",
    "else:\n",
    "    print(f\"   ğŸ›¡ï¸  Conservative:  No threshold achieves 65%+ precision\")\n",
    "\n",
    "# Balanced (good precision AND recall)\n",
    "balanced = [r for r in threshold_results if r['precision'] >= 0.50 and r['recall'] >= 0.40]\n",
    "if balanced:\n",
    "    best_balanced = max(balanced, key=lambda x: x['f1'])\n",
    "    print(f\"   âš–ï¸  Balanced:     {best_balanced['threshold']:.1f}  \"\n",
    "          f\"(Prec: {best_balanced['precision']:.3f}, Rec: {best_balanced['recall']:.3f}, {best_balanced['predictions']} signals)\")\n",
    "else:\n",
    "    print(f\"   âš–ï¸  Balanced:     No threshold achieves 50%+ precision AND 40%+ recall\")\n",
    "\n",
    "# Aggressive (high recall, catch more opportunities)\n",
    "aggressive = [r for r in threshold_results if r['recall'] >= 0.50]\n",
    "if aggressive:\n",
    "    best_aggressive = max(aggressive, key=lambda x: x['precision'])\n",
    "    print(f\"   âš¡ Aggressive:   {best_aggressive['threshold']:.1f}  \"\n",
    "          f\"(Rec: {best_aggressive['recall']:.3f}, {best_aggressive['predictions']} signals)\")\n",
    "else:\n",
    "    print(f\"   âš¡ Aggressive:   No threshold achieves 50%+ recall\")\n",
    "\n",
    "# Volume analysis\n",
    "print(f\"\\nğŸ“Š SIGNAL VOLUME ANALYSIS:\")\n",
    "print(\"-\" * 60)\n",
    "baseline_result = next(r for r in threshold_results if r['threshold'] == 0.5)\n",
    "print(f\"   Default (0.5):   {baseline_result['predictions']:,} signals ({baseline_result['pct_of_test']:.1f}% of test set)\")\n",
    "\n",
    "high_volume = [r for r in threshold_results if r['predictions'] >= baseline_result['predictions'] * 1.5]\n",
    "if high_volume:\n",
    "    best_volume = min(high_volume, key=lambda x: x['threshold'])  # Lowest threshold with high volume\n",
    "    print(f\"   High Volume:     {best_volume['predictions']:,} signals at {best_volume['threshold']:.1f} \"\n",
    "          f\"({best_volume['pct_change']:+.0f}% vs default)\")\n",
    "\n",
    "low_volume = [r for r in threshold_results if r['predictions'] <= baseline_result['predictions'] * 0.6]\n",
    "if low_volume:\n",
    "    best_selective = max(low_volume, key=lambda x: x['threshold'])  # Highest threshold with low volume\n",
    "    print(f\"   Selective:       {best_selective['predictions']:,} signals at {best_selective['threshold']:.1f} \"\n",
    "          f\"({best_selective['pct_change']:+.0f}% vs default)\")\n",
    "\n",
    "# Performance ranges\n",
    "print(f\"\\nğŸ“ˆ PERFORMANCE RANGES ACROSS THRESHOLDS:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"   Accuracy:   {min(r['accuracy'] for r in threshold_results):.3f} - {max(r['accuracy'] for r in threshold_results):.3f}\")\n",
    "print(f\"   Precision:  {min(r['precision'] for r in threshold_results):.3f} - {max(r['precision'] for r in threshold_results):.3f}\")\n",
    "print(f\"   Recall:     {min(r['recall'] for r in threshold_results):.3f} - {max(r['recall'] for r in threshold_results):.3f}\")\n",
    "print(f\"   F1 Score:   {min(r['f1'] for r in threshold_results):.3f} - {max(r['f1'] for r in threshold_results):.3f}\")\n",
    "print(f\"   Signals:    {min(r['predictions'] for r in threshold_results):,} - {max(r['predictions'] for r in threshold_results):,}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5) DATE-BY-DATE PREDICTIONS OUTPUT\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nğŸ“… GENERATING DATE-BY-DATE PREDICTIONS...\")\n",
    "\n",
    "# Use default 0.5 threshold for predictions\n",
    "y_pred_final = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "# Create detailed predictions DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'timestamp': X_test.index,\n",
    "    'actual': y_test.values,\n",
    "    'probability': y_prob,\n",
    "    'predicted': y_pred_final\n",
    "})\n",
    "\n",
    "# Add prediction confidence categories\n",
    "predictions_df['confidence'] = pd.cut(\n",
    "    predictions_df['probability'], \n",
    "    bins=[0, 0.3, 0.4, 0.6, 0.7, 1.0],\n",
    "    labels=['Very_Low', 'Low', 'Medium', 'High', 'Very_High']\n",
    ")\n",
    "\n",
    "# Add correctness\n",
    "predictions_df['correct'] = (predictions_df['actual'] == predictions_df['predicted'])\n",
    "\n",
    "print(f\"ğŸ“Š SAMPLE PREDICTIONS (First 20 rows):\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"{'Date':<20} {'Actual':<7} {'Predicted':<10} {'Probability':<12} {'Confidence':<12} {'Correct':<8}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for i, (_, row) in enumerate(predictions_df.head(20).iterrows()):\n",
    "    date_str = row['timestamp'].strftime('%Y-%m-%d %H:%M')\n",
    "    actual_str = \"ğŸŸ¢ Bull\" if row['actual'] == 1 else \"ğŸ”´ Bear\"\n",
    "    pred_str = \"ğŸŸ¢ Bull\" if row['predicted'] == 1 else \"ğŸ”´ Bear\"\n",
    "    prob_str = f\"{row['probability']:.4f}\"\n",
    "    conf_str = str(row['confidence'])\n",
    "    correct_str = \"âœ…\" if row['correct'] else \"âŒ\"\n",
    "    \n",
    "    print(f\"{date_str:<20} {actual_str:<7} {pred_str:<10} {prob_str:<12} {conf_str:<12} {correct_str:<8}\")\n",
    "\n",
    "# Show statistics by confidence level\n",
    "print(f\"\\nğŸ“ˆ ACCURACY BY CONFIDENCE LEVEL:\")\n",
    "print(\"-\" * 50)\n",
    "confidence_stats = predictions_df.groupby('confidence').agg({\n",
    "    'correct': ['count', 'sum', 'mean'],\n",
    "    'probability': ['mean', 'std']\n",
    "}).round(4)\n",
    "\n",
    "for conf_level in predictions_df['confidence'].cat.categories:\n",
    "    if conf_level in confidence_stats.index:\n",
    "        stats = confidence_stats.loc[conf_level]\n",
    "        count = int(stats[('correct', 'count')])\n",
    "        accuracy = stats[('correct', 'mean')]\n",
    "        avg_prob = stats[('probability', 'mean')]\n",
    "        \n",
    "        print(f\"   {conf_level:<12}: {count:>4} predictions, {accuracy:.1%} accuracy, avg prob: {avg_prob:.3f}\")\n",
    "\n",
    "# Save predictions to CSV for ensemble analysis\n",
    "output_file = CSV_FILE.parent / f\"rf_predictions_{START_DATE.replace('-', '')}.csv\"\n",
    "\n",
    "# Also save to Desktop for easy access\n",
    "desktop_path = Path.home() / \"Desktop\"\n",
    "desktop_file = desktop_path / f\"bitcoin_rf_predictions_{START_DATE.replace('-', '')}.csv\"\n",
    "\n",
    "try:\n",
    "    predictions_df.to_csv(desktop_file, index=False)\n",
    "    desktop_saved = True\n",
    "except:\n",
    "    desktop_saved = False\n",
    "\n",
    "print(f\"\\nğŸ’¾ PREDICTIONS SAVED:\")\n",
    "print(f\"   Primary file: {output_file}\")\n",
    "if desktop_saved:\n",
    "    print(f\"   Desktop copy: {desktop_file}\")\n",
    "    print(f\"   âœ… Ready to download from Desktop!\")\n",
    "else:\n",
    "    print(f\"   âŒ Could not save to Desktop, check permissions\")\n",
    "print(f\"   Rows: {len(predictions_df):,}\")\n",
    "print(f\"   Columns: {list(predictions_df.columns)}\")\n",
    "\n",
    "# Create a summary file for quick reference\n",
    "summary_data = {\n",
    "    'Model': ['Random_Forest'],\n",
    "    'Start_Date': [START_DATE],\n",
    "    'Test_Samples': [len(predictions_df)],\n",
    "    'Accuracy': [predictions_df['correct'].mean()],\n",
    "    'Precision': [precision_score(predictions_df['actual'], predictions_df['predicted'])],\n",
    "    'Recall': [recall_score(predictions_df['actual'], predictions_df['predicted'])],\n",
    "    'F1_Score': [f1_score(predictions_df['actual'], predictions_df['predicted'])],\n",
    "    'Avg_Probability': [predictions_df['probability'].mean()],\n",
    "    'Bull_Signals': [sum(predictions_df['predicted'])],\n",
    "    'Bull_Percentage': [sum(predictions_df['predicted'])/len(predictions_df)*100],\n",
    "    'File_Path': [str(desktop_file if desktop_saved else output_file)]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_file = desktop_path / f\"bitcoin_model_summary_{START_DATE.replace('-', '')}.csv\" if desktop_saved else CSV_FILE.parent / f\"model_summary_{START_DATE.replace('-', '')}.csv\"\n",
    "\n",
    "try:\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    print(f\"   Summary file: {summary_file}\")\n",
    "except:\n",
    "    print(f\"   âŒ Could not save summary file\")\n",
    "\n",
    "# Summary for ensemble integration\n",
    "print(f\"\\nğŸ¤– ENSEMBLE INTEGRATION READY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"   Model Type:       Random Forest\")\n",
    "print(f\"   Test Period:      {predictions_df['timestamp'].min()} to {predictions_df['timestamp'].max()}\")\n",
    "print(f\"   Total Predictions: {len(predictions_df):,}\")\n",
    "print(f\"   Bullish Signals:   {sum(predictions_df['predicted']):,} ({sum(predictions_df['predicted'])/len(predictions_df)*100:.1f}%)\")\n",
    "print(f\"   Overall Accuracy:  {predictions_df['correct'].mean():.1%}\")\n",
    "print(f\"   Avg Probability:   {predictions_df['probability'].mean():.3f}\")\n",
    "\n",
    "# Show high confidence predictions (for ensemble voting)\n",
    "high_conf_mask = predictions_df['probability'] >= 0.7\n",
    "low_conf_mask = predictions_df['probability'] <= 0.3\n",
    "\n",
    "print(f\"\\nğŸ¯ PROBABILITY DISTRIBUTION:\")\n",
    "print(\"-\" * 50)\n",
    "if high_conf_mask.any():\n",
    "    high_conf_bull = high_conf_mask & (predictions_df['predicted'] == 1)\n",
    "    print(f\"   High confidence Bull: {sum(high_conf_bull):,} (prob â‰¥ 0.7)\")\n",
    "    if sum(high_conf_bull) > 0:\n",
    "        print(f\"   Sample dates: {', '.join(predictions_df[high_conf_bull]['timestamp'].dt.strftime('%Y-%m-%d').head(3).tolist())}\")\n",
    "\n",
    "if low_conf_mask.any():\n",
    "    high_conf_bear = low_conf_mask & (predictions_df['predicted'] == 0)\n",
    "    print(f\"   High confidence Bear: {sum(high_conf_bear):,} (prob â‰¤ 0.3)\")\n",
    "    if sum(high_conf_bear) > 0:\n",
    "        print(f\"   Sample dates: {', '.join(predictions_df[high_conf_bear]['timestamp'].dt.strftime('%Y-%m-%d').head(3).tolist())}\")\n",
    "\n",
    "print(f\"   ğŸ’¡ You can experiment with any threshold using the 'probability' column!\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 6) FINAL RECOMMENDATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nğŸ¯ FINAL RECOMMENDATION:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Choose best overall threshold\n",
    "if best_f1['f1'] > baseline_result['f1'] * 1.1:  # If F1 improved by 10%+\n",
    "    recommended = best_f1\n",
    "    reason = f\"F1 score improved {((best_f1['f1'] / baseline_result['f1']) - 1) * 100:+.1f}%\"\n",
    "elif best_recall['recall'] > baseline_result['recall'] * 1.5:  # If recall improved significantly\n",
    "    recommended = best_recall\n",
    "    reason = f\"Recall improved {((best_recall['recall'] / baseline_result['recall']) - 1) * 100:+.1f}%\"\n",
    "else:\n",
    "    recommended = baseline_result\n",
    "    reason = \"Default threshold performs best\"\n",
    "\n",
    "print(f\"   ğŸ† Use threshold: {recommended['threshold']:.1f}\")\n",
    "print(f\"   ğŸ“Š Performance:   Accuracy={recommended['accuracy']:.3f}, Precision={recommended['precision']:.3f}, \"\n",
    "      f\"Recall={recommended['recall']:.3f}, F1={recommended['f1']:.3f}\")\n",
    "print(f\"   ğŸ“ˆ Signals:       {recommended['predictions']:,} ({recommended['pct_of_test']:.1f}% of test set)\")\n",
    "print(f\"   ğŸ’¡ Reason:        {reason}\")\n",
    "\n",
    "print(f\"\\nâœ… Threshold analysis complete! Use threshold {recommended['threshold']:.1f} for optimal performance.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec912cc",
   "metadata": {},
   "source": [
    "# In this notebook we would train the GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f59053",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep \n",
    "atr_14  , OBV\n",
    "\n",
    "drop\n",
    "\n",
    "'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'trending_market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d490cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_gru = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'bollinger_width', 'volatility_regime', 'CCI', 'stoch_%D',\n",
    "    'parkinson_vol', 'ema_cross_down', 'macd_cross_down',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6''ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c85cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 22:43:01,166] A new study created in memory with name: no-name-d8105f4e-9a60-45b8-a1ee-2354578f522f\n",
      "Best trial: 0. Best value: 0.434793:   4%|▍         | 1/25 [00:47<18:57, 47.41s/it, 47.41/900 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 22:43:48,577] Trial 0 finished with value: 0.43479295573536414 and parameters: {'window': 18, 'units': 192, 'layers': 2, 'dropout': 0.17959754525911098, 'lr': 0.0002051338263087451, 'l2': 2.9375384576328313e-06, 'batch': 64}. Best is trial 0 with value: 0.43479295573536414.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.434793:   8%|▊         | 2/25 [01:21<15:07, 39.47s/it, 81.32/900 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 22:44:22,490] Trial 1 finished with value: 0.517478152309613 and parameters: {'window': 30, 'units': 192, 'layers': 1, 'dropout': 0.29097295564859826, 'lr': 0.004622589001020831, 'l2': 4.335281794951567e-06, 'batch': 64}. Best is trial 0 with value: 0.43479295573536414.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.327151:  12%|█▏        | 3/25 [01:34<10:02, 27.37s/it, 94.30/900 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 22:44:35,468] Trial 2 finished with value: 0.3271514192016284 and parameters: {'window': 18, 'units': 128, 'layers': 1, 'dropout': 0.08736874205941257, 'lr': 0.0016738085788752138, 'l2': 2.62108787826544e-06, 'batch': 64}. Best is trial 2 with value: 0.3271514192016284.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.327151:  16%|█▌        | 4/25 [02:09<10:42, 30.60s/it, 129.86/900 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 22:45:11,021] Trial 3 finished with value: 0.5615826419910657 and parameters: {'window': 24, 'units': 192, 'layers': 1, 'dropout': 0.15427033152408348, 'lr': 0.0015304852121831463, 'l2': 1.3783237455007196e-06, 'batch': 32}. Best is trial 2 with value: 0.3271514192016284.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.327151:  20%|██        | 5/25 [02:48<11:12, 33.63s/it, 168.84/900 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 22:45:50,006] Trial 4 finished with value: 0.49406582650189645 and parameters: {'window': 12, 'units': 192, 'layers': 2, 'dropout': 0.24251920443493832, 'lr': 0.0004066563313514797, 'l2': 1.9634341572933354e-06, 'batch': 32}. Best is trial 2 with value: 0.3271514192016284.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.327151:  24%|██▍       | 6/25 [03:02<08:28, 26.77s/it, 182.30/900 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 22:46:03,467] Trial 5 finished with value: 0.45776599590312084 and parameters: {'window': 12, 'units': 128, 'layers': 1, 'dropout': 0.2727961206236346, 'lr': 0.00032927591344236165, 'l2': 9.717775305059631e-05, 'batch': 64}. Best is trial 2 with value: 0.3271514192016284.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.212958:  28%|██▊       | 7/25 [03:34<08:35, 28.61s/it, 214.71/900 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 22:46:35,877] Trial 6 finished with value: 0.21295804567180032 and parameters: {'window': 24, 'units': 64, 'layers': 2, 'dropout': 0.23253984700833435, 'lr': 0.007568292060167619, 'l2': 0.00048359527764659497, 'batch': 64}. Best is trial 6 with value: 0.21295804567180032.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.212958:  32%|███▏      | 8/25 [03:43<06:18, 22.29s/it, 223.45/900 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 22:46:44,614] Trial 7 finished with value: 0.4251781472684085 and parameters: {'window': 12, 'units': 64, 'layers': 1, 'dropout': 0.0975990992289793, 'lr': 0.0005989003672254305, 'l2': 6.516990611177181e-06, 'batch': 32}. Best is trial 6 with value: 0.21295804567180032.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.212958:  36%|███▌      | 9/25 [04:56<10:10, 38.14s/it, 296.46/900 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 22:47:57,625] Trial 8 finished with value: 0.46489104116222757 and parameters: {'window': 18, 'units': 128, 'layers': 1, 'dropout': 0.2406590942262119, 'lr': 0.00014096175149815865, 'l2': 0.0009133995846860973, 'batch': 32}. Best is trial 6 with value: 0.21295804567180032.\n"
     ]
    }
   ],
   "source": [
    "import os, json, optuna, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import fbeta_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# GPU Memory growth setup\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Config\n",
    "CSV_PATH = Path(r\"C:\\\\Users\\\\ADMIN\\\\Desktop\\\\Coding_projects\\\\stock_market_prediction\\\\Stock-Market-Prediction\\\\data\\\\processed\\\\gemini_btc_with_features_4h.csv\")\n",
    "VAL_FRAC = 0.2\n",
    "BETA = 2.0\n",
    "SEED = 42\n",
    "MODEL_NAME = \"gru_fast_val20_model.h5\"\n",
    "N_TRIALS = 25\n",
    "TIMEOUT = 15 * 60\n",
    "\n",
    "drop_cols = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'bollinger_width', 'volatility_regime', 'CCI', 'stoch_%D',\n",
    "    'parkinson_vol', 'ema_cross_down', 'macd_cross_down',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6''ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df[df.index >= \"2018-01-01\"]\n",
    "df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)\n",
    "df = df[df[\"target\"].notna()].dropna()\n",
    "\n",
    "features = df.drop(columns=\"target\")\n",
    "target = df[\"target\"].astype(int).values\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "X_train_raw, X_val_raw = features_scaled[:split_idx], features_scaled[split_idx:]\n",
    "y_train, y_val = target[:split_idx], target[split_idx:]\n",
    "\n",
    "def make_windows(data, labels, win):\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(data)):\n",
    "        X.append(data[i-win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "def objective(trial):\n",
    "    win = trial.suggest_int(\"window\", 12, 36, step=6)\n",
    "    units = trial.suggest_int(\"units\", 64, 192, step=64)\n",
    "    layers = trial.suggest_int(\"layers\", 1, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    l2reg = trial.suggest_float(\"l2\", 1e-6, 1e-3, log=True)\n",
    "    batch = trial.suggest_categorical(\"batch\", [32, 64])\n",
    "\n",
    "    X_tr, y_tr = make_windows(X_train_raw, y_train, win)\n",
    "    X_va, y_va = make_windows(X_val_raw, y_val, win)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = keras.Sequential()\n",
    "    for i in range(layers):\n",
    "        model.add(keras.layers.GRU(units, return_sequences=(i < layers-1),\n",
    "                                   dropout=dropout,\n",
    "                                   kernel_regularizer=keras.regularizers.l2(l2reg)))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss=\"binary_crossentropy\")\n",
    "\n",
    "    model.fit(X_tr, y_tr,\n",
    "              epochs=50,\n",
    "              batch_size=batch,\n",
    "              validation_data=(X_va, y_va),\n",
    "              callbacks=[\n",
    "                  keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True)\n",
    "              ],\n",
    "              verbose=0)\n",
    "\n",
    "    prob = model.predict(X_va, verbose=0).ravel()\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "    return 1.0 - fbeta_score(y_va, pred, beta=BETA, zero_division=0)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "study.optimize(objective, n_trials=N_TRIALS, timeout=TIMEOUT, show_progress_bar=True)\n",
    "\n",
    "print(\"Best F2:\", 1 - study.best_value)\n",
    "print(\"Params:\", study.best_params)\n",
    "\n",
    "with open(\"gru_fast_best_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_params, f, indent=2)\n",
    "\n",
    "# Final model\n",
    "p = study.best_params\n",
    "X_tr, y_tr = make_windows(X_train_raw, y_train, p[\"window\"])\n",
    "X_va, y_va = make_windows(X_val_raw, y_val, p[\"window\"])\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "final = keras.Sequential()\n",
    "for i in range(p[\"layers\"]):\n",
    "    final.add(keras.layers.GRU(p[\"units\"], return_sequences=(i < p[\"layers\"]-1),\n",
    "                               dropout=p[\"dropout\"],\n",
    "                               kernel_regularizer=keras.regularizers.l2(p[\"l2\"])))\n",
    "final.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "final.compile(optimizer=keras.optimizers.Adam(learning_rate=p[\"lr\"]),\n",
    "              loss=\"binary_crossentropy\")\n",
    "final.fit(X_tr, y_tr, epochs=50, batch_size=p[\"batch\"],\n",
    "          validation_data=(X_va, y_va),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "          verbose=1)\n",
    "\n",
    "final.save(MODEL_NAME)\n",
    "print(\"\\\\n✔ GRU model saved →\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a31e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1008/1008 - 21s - 21ms/step - loss: 0.6942 - val_loss: 0.6947 - val_weighted_f1: 0.2462 - weighted_f1: 0.5537 - learning_rate: 0.0027\n",
      "Epoch 2/50\n",
      "1008/1008 - 19s - 19ms/step - loss: 0.6922 - val_loss: 0.6932 - val_weighted_f1: 0.4798 - weighted_f1: 0.5613 - learning_rate: 0.0027\n",
      "Epoch 3/50\n",
      "1008/1008 - 30s - 29ms/step - loss: 0.6923 - val_loss: 0.6933 - val_weighted_f1: 0.3422 - weighted_f1: 0.5678 - learning_rate: 0.0027\n",
      "Epoch 4/50\n",
      "1008/1008 - 35s - 35ms/step - loss: 0.6922 - val_loss: 0.6926 - val_weighted_f1: 0.5837 - weighted_f1: 0.5724 - learning_rate: 0.0027\n",
      "Epoch 5/50\n",
      "1008/1008 - 35s - 35ms/step - loss: 0.6920 - val_loss: 0.6929 - val_weighted_f1: 0.5935 - weighted_f1: 0.5694 - learning_rate: 0.0027\n",
      "Epoch 6/50\n",
      "1008/1008 - 35s - 35ms/step - loss: 0.6924 - val_loss: 0.6929 - val_weighted_f1: 0.4824 - weighted_f1: 0.5637 - learning_rate: 0.0027\n",
      "Epoch 7/50\n",
      "1008/1008 - 35s - 35ms/step - loss: 0.6918 - val_loss: 0.6932 - val_weighted_f1: 0.6431 - weighted_f1: 0.5502 - learning_rate: 0.0027\n",
      "Epoch 8/50\n",
      "1008/1008 - 35s - 35ms/step - loss: 0.6925 - val_loss: 0.6939 - val_weighted_f1: 0.6850 - weighted_f1: 0.5567 - learning_rate: 0.0027\n",
      "Epoch 9/50\n",
      "1008/1008 - 35s - 35ms/step - loss: 0.6919 - val_loss: 0.6937 - val_weighted_f1: 0.4356 - weighted_f1: 0.5541 - learning_rate: 0.0027\n",
      "Epoch 10/50\n",
      "1008/1008 - 37s - 36ms/step - loss: 0.6928 - val_loss: 0.6972 - val_weighted_f1: 0.0017 - weighted_f1: 0.5665 - learning_rate: 0.0027\n",
      "Epoch 11/50\n",
      "1008/1008 - 30s - 30ms/step - loss: 0.6939 - val_loss: 0.6934 - val_weighted_f1: 0.5667 - weighted_f1: 0.5513 - learning_rate: 0.0027\n",
      "Epoch 12/50\n",
      "1008/1008 - 19s - 19ms/step - loss: 0.6938 - val_loss: 0.6937 - val_weighted_f1: 0.3785 - weighted_f1: 0.5574 - learning_rate: 0.0027\n",
      "Epoch 13/50\n",
      "1008/1008 - 19s - 19ms/step - loss: 0.6929 - val_loss: 0.6927 - val_weighted_f1: 0.6169 - weighted_f1: 0.5658 - learning_rate: 0.0014\n",
      "Epoch 14/50\n",
      "1008/1008 - 19s - 19ms/step - loss: 0.6930 - val_loss: 0.6931 - val_weighted_f1: 0.3724 - weighted_f1: 0.5912 - learning_rate: 0.0014\n",
      "Epoch 15/50\n",
      "1008/1008 - 19s - 18ms/step - loss: 0.6928 - val_loss: 0.6930 - val_weighted_f1: 0.5691 - weighted_f1: 0.5769 - learning_rate: 0.0014\n",
      "Epoch 16/50\n",
      "1008/1008 - 20s - 19ms/step - loss: 0.6924 - val_loss: 0.6930 - val_weighted_f1: 0.4426 - weighted_f1: 0.5705 - learning_rate: 0.0014\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "\n",
      "──── Validation metrics (thr = 0.50) ────\n",
      "Accuracy          :  0.510\n",
      "Class 0 (Down) →  Precision:  0.498  Recall:  0.260  F1:  0.341\n",
      "Class 1 (Up  ) →  Precision:  0.513  Recall:  0.750  F1:  0.609\n",
      "Macro-F1          :  0.475\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (16119) does not match length of index (16131)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 147\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# ───────── optional: save predictions ─────────\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SAVE_PROB:\n\u001b[1;32m--> 147\u001b[0m     pred_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprob_up\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m              \u001b[38;5;66;03m# original timestamps\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     pred_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgru_val_predictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions saved → gru_val_predictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:630\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    627\u001b[0m         val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m    629\u001b[0m     val \u001b[38;5;241m=\u001b[39m sanitize_array(val, index, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 630\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m     refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    633\u001b[0m homogenized\u001b[38;5;241m.\u001b[39mappend(val)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (16119) does not match length of index (16131)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "final_gru_train.py\n",
    "------------------\n",
    "GRU model for BTC next-hour direction with fixed hyper-parameters:\n",
    "\n",
    "    # ── layer 0 ──\n",
    "    units       = 32\n",
    "    dropout     = 0.40\n",
    "    return_seq  = True\n",
    "    # ── layer 1 ──\n",
    "    units       = 64\n",
    "    dropout     = 0.40\n",
    "    return_seq  = False\n",
    "    # ── optimiser ──\n",
    "    learning rate = 0.0027215464940055565\n",
    "\n",
    "Outputs per-class metrics and (optionally) prediction table.\n",
    "\"\"\"\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "import numpy as np, pandas as pd, tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# ───────── configuration ─────────\n",
    "CSV_PATH  = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_data_final_version_with_features_2016_final.csv\"\n",
    "DROP_COLS = [\"vol_ratio_24h\", \"macd_diff\", \"macd_line\", \"upper_shadow\", \"lower_shadow\"]\n",
    "\n",
    "SEQ_LEN   = 60           # timesteps per sample\n",
    "VAL_FRAC  = 0.20         # 80 % train · 20 % validation\n",
    "PREC_W    = 2.0          # β=2  (precision has ×2 weight in F-score)\n",
    "LR        = 0.0027215464940055565\n",
    "EPOCHS    = 25\n",
    "BATCH     = 64\n",
    "SEED      = 42\n",
    "SAVE_PROB = True         # set False if you don’t want CSV\n",
    "\n",
    "# ───────── custom weighted-F1 metric ─────────\n",
    "class WeightedF1(tf.keras.metrics.Metric):\n",
    "    def __init__(self, beta=2.0, name=\"weighted_f1\", threshold=0.5, **kw):\n",
    "        super().__init__(name=name, **kw)\n",
    "        self.b  = beta; self.th = threshold\n",
    "        self.tp = self.add_weight(name=\"tp\", initializer=\"zeros\")\n",
    "        self.fp = self.add_weight(name=\"fp\", initializer=\"zeros\")\n",
    "        self.fn = self.add_weight(name=\"fn\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred >= self.th, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        self.tp.assign_add(tf.reduce_sum(y_true * y_pred))\n",
    "        self.fp.assign_add(tf.reduce_sum((1 - y_true) * y_pred))\n",
    "        self.fn.assign_add(tf.reduce_sum(y_true * (1 - y_pred)))\n",
    "\n",
    "    def result(self):\n",
    "        p = self.tp / (self.tp + self.fp + 1e-7)\n",
    "        r = self.tp / (self.tp + self.fn + 1e-7)\n",
    "        return (1 + self.b**2) * p * r / (self.b**2 * p + r + 1e-7)\n",
    "\n",
    "    def reset_states(self):\n",
    "        for v in (self.tp, self.fp, self.fn):\n",
    "            v.assign(0.)\n",
    "\n",
    "# ───────── data loading & preprocessing ─────────\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df.drop(columns=[c for c in DROP_COLS if c in df.columns], inplace=True)\n",
    "df[\"Volume BTC\"] = np.log1p(df[\"Volume BTC\"])\n",
    "df[\"target\"] = (df[\"close\"].shift(-1) > df[\"close\"]).astype(int)\n",
    "df = df.dropna().select_dtypes(include=[np.number])\n",
    "\n",
    "X_raw = df.drop(columns=[\"target\"])\n",
    "y_raw = df[\"target\"].astype(int).values\n",
    "\n",
    "split_raw = int(len(df) * (1 - VAL_FRAC))\n",
    "X_train_raw, X_val_raw = X_raw.iloc[:split_raw], X_raw.iloc[split_raw:]\n",
    "y_train, y_val         = y_raw[:split_raw], y_raw[split_raw:]\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_raw)\n",
    "X_scaled = scaler.transform(X_raw)\n",
    "\n",
    "def to_seq(matrix, labels, length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(length, len(matrix)):\n",
    "        xs.append(matrix[i-length:i])\n",
    "        ys.append(labels[i])\n",
    "    return np.array(xs, dtype=np.float32), np.array(ys, dtype=np.float32)\n",
    "\n",
    "X_seq, y_seq = to_seq(X_scaled, y_raw, SEQ_LEN)\n",
    "split_seq    = int(len(X_seq) * (1 - VAL_FRAC))\n",
    "X_train, X_val = X_seq[:split_seq], X_seq[split_seq:]\n",
    "y_train, y_val = y_seq[:split_seq], y_seq[split_seq:]\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "# ───────── build GRU model ─────────\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(SEQ_LEN, n_features)),\n",
    "    tf.keras.layers.GRU(32, dropout=0.4, return_sequences=True,\n",
    "                        activation=\"tanh\", recurrent_activation=\"sigmoid\"),\n",
    "    tf.keras.layers.GRU(64, dropout=0.4, return_sequences=False,\n",
    "                        activation=\"tanh\", recurrent_activation=\"sigmoid\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[WeightedF1(beta=PREC_W)]   # β=2 → precision ×2\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_weighted_f1\", mode=\"max\",\n",
    "        patience=8, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_weighted_f1\", mode=\"max\",\n",
    "        factor=0.5, patience=4)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=False,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ───────── evaluation ─────────\n",
    "y_prob = model.predict(X_val, batch_size=BATCH).flatten()\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "acc  = accuracy_score(y_val, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    y_val, y_pred, labels=[0, 1], zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n──── Validation metrics (thr = 0.50) ────\")\n",
    "print(f\"Accuracy          : {acc:6.3f}\")\n",
    "print(f\"Class 0 (Down) →  Precision: {prec[0]:6.3f}  Recall: {rec[0]:6.3f}  F1: {f1[0]:6.3f}\")\n",
    "print(f\"Class 1 (Up  ) →  Precision: {prec[1]:6.3f}  Recall: {rec[1]:6.3f}  F1: {f1[1]:6.3f}\")\n",
    "print(f\"Macro-F1          : {f1.mean():6.3f}\")\n",
    "\n",
    "# ───────── optional: save predictions ─────────\n",
    "if SAVE_PROB:\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"prob_up\": y_prob,\n",
    "        \"pred\": y_pred\n",
    "    }, index=X_val_raw.index)              # original timestamps\n",
    "    pred_df.to_csv(\"gru_val_predictions.csv\")\n",
    "    print(\"Predictions saved → gru_val_predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

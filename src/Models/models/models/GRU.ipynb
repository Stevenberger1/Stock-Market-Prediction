{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec912cc",
   "metadata": {},
   "source": [
    "# In this notebook we would train the GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f59053",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep \n",
    "atr_14  , OBV\n",
    "\n",
    "drop\n",
    "\n",
    "'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'trending_market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d490cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_gru = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'bollinger_width', 'volatility_regime', 'CCI', 'stoch_%D',\n",
    "    'parkinson_vol', 'ema_cross_down', 'macd_cross_down',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6''ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c85cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 12:55:45,523] A new study created in memory with name: gru_precision_optimized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ PRECISION-OPTIMIZED GRU HYPERPARAMETER SEARCH\n",
      "üéØ Maximizing PRECISION for Bitcoin Direction Prediction\n",
      "======================================================================\n",
      "üìä Using F0.5 score (Œ≤=0.5) - Emphasizes PRECISION\n",
      "üéØ Precision gets 2.0x weight in scoring\n",
      "‚ö†Ô∏è  No GPU detected, using CPU\n",
      "üöÄ Loading Bitcoin data for PRECISION-optimized GRU...\n",
      "============================================================\n",
      "‚úÖ Loaded data: (20718, 66)\n",
      "üìÖ Using data from 2020+: 11476 rows\n",
      "üéØ Target distribution: {1: 5858, 0: 5618}\n",
      "üßπ After cleaning: (11476, 20)\n",
      "‚úÖ Features (19): ['volume', 'RSI', 'MACD_histogram', 'OBV', 'stoch_%K', 'atr_14', 'atr_ratio', 'price_vs_vwap', 'volume_ratio', 'buying_pressure', 'adx', 'fear_greed_score', 'roc_4h', 'roc_24h', 'bb_position', 'macd_rising', 'obv_rising_24h', 'momentum_alignment', 'trend_alignment']\n",
      "‚úÖ PRECISION OPTIMIZATION: No price data leakage\n",
      "üìä Train: 9180 samples, Val: 2296 samples\n",
      "\n",
      "üîç Starting PRECISION optimization...\n",
      "   Focus: Maximize precision with 2x weight\n",
      "   Trials: 30, Timeout: 100min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.981382:   3%|‚ñé         | 1/30 [06:53<3:19:57, 413.71s/it, 413.71/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:02:39,228] Trial 0 finished with value: 0.9813824931254083 and parameters: {'window': 24, 'units': 128, 'layers': 2, 'dropout': 0.379597545259111, 'lr': 0.00018410729205738696, 'l2': 2.9375384576328295e-05, 'batch': 64, 'threshold': 0.5803345035229626}. Best is trial 0 with value: 0.9813824931254083.\n",
      "Trial  0: P=0.409 R=0.008 F0.5=0.036 Thr=0.58 Pos=22 | Best=0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.981382:   7%|‚ñã         | 2/30 [10:45<2:23:00, 306.45s/it, 645.08/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:06:30,604] Trial 1 finished with value: 1.0 and parameters: {'window': 36, 'units': 32, 'layers': 2, 'dropout': 0.4497327922401265, 'lr': 0.00022948683681130568, 'l2': 3.511356313970405e-05, 'batch': 64, 'threshold': 0.5574269294896713}. Best is trial 0 with value: 0.9813824931254083.\n",
      "Trial  1: P=0.000 R=0.000 F0.5=0.000 Thr=0.56 Pos=0 | Best=0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  10%|‚ñà         | 3/30 [15:05<2:08:28, 285.50s/it, 905.66/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:10:51,179] Trial 2 finished with value: 0.4393220019172188 and parameters: {'window': 30, 'units': 64, 'layers': 2, 'dropout': 0.24184815819561256, 'lr': 0.0003135775732257748, 'l2': 0.00012562773503807024, 'batch': 64, 'threshold': 0.45990213464750795}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  2: P=0.523 R=0.817 F0.5=0.564 Thr=0.46 Pos=1838 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  13%|‚ñà‚ñé        | 4/30 [15:42<1:21:10, 187.32s/it, 942.47/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:11:27,989] Trial 3 finished with value: 1.0 and parameters: {'window': 30, 'units': 96, 'layers': 1, 'dropout': 0.3822634555704315, 'lr': 0.00019485671251272575, 'l2': 1.5673095467235405e-05, 'batch': 64, 'threshold': 0.6425192044349384}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  3: P=0.000 R=0.000 F0.5=0.000 Thr=0.64 Pos=0 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  17%|‚ñà‚ñã        | 5/30 [18:25<1:14:23, 178.54s/it, 1105.44/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:14:10,963] Trial 4 finished with value: 0.4655274778167142 and parameters: {'window': 24, 'units': 32, 'layers': 2, 'dropout': 0.33204574812188037, 'lr': 0.000161190447276092, 'l2': 0.0003058656666978527, 'batch': 64, 'threshold': 0.4776339944800051}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  4: P=0.522 R=0.733 F0.5=0.554 Thr=0.48 Pos=1654 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  20%|‚ñà‚ñà        | 6/30 [21:44<1:14:15, 185.65s/it, 1304.90/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:17:30,419] Trial 5 finished with value: 1.0 and parameters: {'window': 36, 'units': 64, 'layers': 2, 'dropout': 0.3640130838029839, 'lr': 0.0002060924941320236, 'l2': 0.008105016126411584, 'batch': 64, 'threshold': 0.6684482051282946}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  5: P=0.000 R=0.000 F0.5=0.000 Thr=0.67 Pos=0 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  23%|‚ñà‚ñà‚ñé       | 7/30 [27:39<1:32:22, 240.97s/it, 1659.74/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:23:25,266] Trial 6 finished with value: 0.9877265399516552 and parameters: {'window': 36, 'units': 128, 'layers': 1, 'dropout': 0.2587948587257436, 'lr': 0.00011935477742481393, 'l2': 9.46217535646148e-05, 'batch': 32, 'threshold': 0.6486212527455788}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  6: P=0.500 R=0.001 F0.5=0.004 Thr=0.65 Pos=2 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.403288:  27%|‚ñà‚ñà‚ñã       | 8/30 [29:34<1:13:37, 200.81s/it, 1774.56/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:25:20,080] Trial 7 finished with value: 0.40328812258617375 and parameters: {'window': 24, 'units': 64, 'layers': 2, 'dropout': 0.2422772674924288, 'lr': 0.0023062618121677952, 'l2': 1.6736010167825783e-05, 'batch': 32, 'threshold': 0.4596147044602517}. Best is trial 7 with value: 0.40328812258617375.\n",
      "Trial  7: P=0.525 R=0.942 F0.5=0.576 Thr=0.46 Pos=2117 | Best=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.403288:  30%|‚ñà‚ñà‚ñà       | 9/30 [31:27<1:00:41, 173.38s/it, 1887.65/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:27:13,171] Trial 8 finished with value: 1.0 and parameters: {'window': 12, 'units': 128, 'layers': 2, 'dropout': 0.4187021504122962, 'lr': 0.0020434554984161395, 'l2': 1.667761543019792e-05, 'batch': 32, 'threshold': 0.6589310277626781}. Best is trial 7 with value: 0.40328812258617375.\n",
      "Trial  8: P=0.000 R=0.000 F0.5=0.000 Thr=0.66 Pos=0 | Best=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.403288:  33%|‚ñà‚ñà‚ñà‚ñé      | 10/30 [33:44<53:59, 161.99s/it, 2024.13/6000 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:29:29,654] Trial 9 finished with value: 0.9323950583708072 and parameters: {'window': 36, 'units': 64, 'layers': 1, 'dropout': 0.29329469651469864, 'lr': 0.00035684261232554244, 'l2': 0.0015446089075047066, 'batch': 64, 'threshold': 0.5416644775485848}. Best is trial 7 with value: 0.40328812258617375.\n",
      "Trial  9: P=0.519 R=0.023 F0.5=0.098 Thr=0.54 Pos=52 | Best=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  37%|‚ñà‚ñà‚ñà‚ñã      | 11/30 [35:35<46:20, 146.36s/it, 2135.06/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:31:20,581] Trial 10 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20538856268444594, 'lr': 0.004643119974738191, 'l2': 0.0011769044926591633, 'batch': 32, 'threshold': 0.4038643448510695}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 10: P=0.519 R=1.000 F0.5=0.574 Thr=0.40 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  40%|‚ñà‚ñà‚ñà‚ñà      | 12/30 [37:56<43:25, 144.74s/it, 2276.07/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:33:41,593] Trial 11 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20271964043217916, 'lr': 0.0045110368278437115, 'l2': 0.001231953070800331, 'batch': 32, 'threshold': 0.4032829795924933}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 11: P=0.519 R=1.000 F0.5=0.574 Thr=0.40 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 13/30 [39:35<37:07, 131.04s/it, 2375.59/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:35:21,111] Trial 12 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20106387535923462, 'lr': 0.004686540626347904, 'l2': 0.0015246426973306176, 'batch': 32, 'threshold': 0.41364991827314684}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 12: P=0.519 R=1.000 F0.5=0.574 Thr=0.41 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 14/30 [41:16<32:30, 121.90s/it, 2476.39/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:37:01,909] Trial 13 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20296502033876676, 'lr': 0.004804830538141239, 'l2': 0.0016565711747343972, 'batch': 32, 'threshold': 0.4007362248331011}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 13: P=0.519 R=1.000 F0.5=0.574 Thr=0.40 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 15/30 [44:32<36:04, 144.33s/it, 2672.67/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:40:18,196] Trial 14 finished with value: 0.5932252029111332 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.2970094826765549, 'lr': 0.001278412165651303, 'l2': 0.007238819361166793, 'batch': 32, 'threshold': 0.5082226063632376}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 14: P=0.553 R=0.353 F0.5=0.497 Thr=0.51 Pos=745 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 16/30 [48:28<40:05, 171.79s/it, 2908.24/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:44:13,757] Trial 15 finished with value: 0.39224319889903203 and parameters: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.28827248013286977, 'lr': 0.0006919056242980709, 'l2': 0.0007616029338564875, 'batch': 32, 'threshold': 0.4329912133834338}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 15: P=0.520 R=1.000 F0.5=0.575 Thr=0.43 Pos=2254 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 17/30 [54:08<48:13, 222.54s/it, 3248.81/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:49:54,334] Trial 16 finished with value: 0.3924493339392343 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.49382767753182344, 'lr': 0.0004954316037435775, 'l2': 0.0005276583740187119, 'batch': 32, 'threshold': 0.4431400266055239}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 16: P=0.520 R=0.999 F0.5=0.575 Thr=0.44 Pos=2252 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 18/30 [59:10<49:17, 246.45s/it, 3550.93/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:54:56,448] Trial 17 finished with value: 0.45089264738056445 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.48404147792406904, 'lr': 0.0005784555170259785, 'l2': 0.0004773618185168044, 'batch': 32, 'threshold': 0.48838215541787816}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 17: P=0.521 R=0.785 F0.5=0.558 Thr=0.49 Pos=1765 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 19/30 [1:04:47<50:09, 273.60s/it, 3887.76/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:00:33,280] Trial 18 finished with value: 0.3927951291026791 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.3336127999190471, 'lr': 0.000638182307402298, 'l2': 0.0004410423127125506, 'batch': 32, 'threshold': 0.4441276651369434}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 18: P=0.521 R=0.993 F0.5=0.576 Thr=0.44 Pos=2232 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 20/30 [1:08:10<42:04, 252.42s/it, 4090.82/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:03:56,344] Trial 19 finished with value: 0.7834270987152218 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.4858039653351313, 'lr': 0.000978223571639541, 'l2': 0.00355633097063596, 'batch': 32, 'threshold': 0.5173577353340968}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 19: P=0.581 R=0.104 F0.5=0.303 Thr=0.52 Pos=210 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 21/30 [1:14:40<44:03, 293.77s/it, 4480.99/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:10:26,517] Trial 20 finished with value: 1.0 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.43990896599030516, 'lr': 0.00045428721391847484, 'l2': 0.00017008314108141117, 'batch': 32, 'threshold': 0.5974824571672048}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 20: P=0.000 R=0.000 F0.5=0.000 Thr=0.60 Pos=0 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 22/30 [1:18:16<36:01, 270.21s/it, 4696.27/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:14:01,787] Trial 21 finished with value: 0.3924493339392343 and parameters: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.2857423263379768, 'lr': 0.0009625091444340295, 'l2': 0.0007566309331758348, 'batch': 32, 'threshold': 0.4302813004287318}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 21: P=0.520 R=0.999 F0.5=0.575 Thr=0.43 Pos=2252 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 23/30 [1:20:39<27:04, 232.08s/it, 4839.42/6000 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:16:24,942] Trial 22 finished with value: 0.3918097792402703 and parameters: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.29304784026893504, 'lr': 0.0009539147035893642, 'l2': 0.0006182071520515096, 'batch': 32, 'threshold': 0.4449592913770786}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 22: P=0.521 R=0.996 F0.5=0.576 Thr=0.44 Pos=2236 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 24/30 [1:22:53<20:15, 202.58s/it, 4973.19/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:18:38,716] Trial 23 finished with value: 0.3919346379287192 and parameters: {'window': 36, 'units': 96, 'layers': 1, 'dropout': 0.31449659466022817, 'lr': 0.0008609248578277, 'l2': 0.0002499889592006828, 'batch': 32, 'threshold': 0.436464562697107}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 23: P=0.520 R=1.000 F0.5=0.575 Thr=0.44 Pos=2260 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 25/30 [1:24:38<14:26, 173.30s/it, 5078.17/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:20:23,691] Trial 24 finished with value: 0.5012143040835038 and parameters: {'window': 36, 'units': 96, 'layers': 1, 'dropout': 0.3137524089899081, 'lr': 0.0013170450542755625, 'l2': 6.992934972302688e-05, 'batch': 32, 'threshold': 0.48207168363593456}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 24: P=0.537 R=0.596 F0.5=0.548 Thr=0.48 Pos=1303 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 26/30 [1:26:00<09:43, 145.86s/it, 5160.02/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:21:45,538] Trial 25 finished with value: 1.0 and parameters: {'window': 30, 'units': 64, 'layers': 1, 'dropout': 0.2707533997515279, 'lr': 0.0009136112323651378, 'l2': 0.00022239294651077825, 'batch': 32, 'threshold': 0.6998240482263056}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 25: P=0.000 R=0.000 F0.5=0.000 Thr=0.70 Pos=0 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 27/30 [1:26:26<05:30, 110.13s/it, 5186.80/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:22:12,315] Trial 26 finished with value: 0.49431354845953823 and parameters: {'window': 12, 'units': 96, 'layers': 1, 'dropout': 0.32212340410694484, 'lr': 0.0017513485444801214, 'l2': 0.0024143624863597613, 'batch': 32, 'threshold': 0.5088289834277683}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 26: P=0.524 R=0.640 F0.5=0.544 Thr=0.51 Pos=1450 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 28/30 [1:27:54<03:26, 103.37s/it, 5274.38/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:23:39,902] Trial 27 finished with value: 0.3919346379287192 and parameters: {'window': 36, 'units': 64, 'layers': 1, 'dropout': 0.34882690126287674, 'lr': 0.0007750288765009825, 'l2': 0.0007786020101904646, 'batch': 32, 'threshold': 0.42606199161643293}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 27: P=0.520 R=1.000 F0.5=0.575 Thr=0.43 Pos=2260 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 29/30 [1:28:31<01:23, 83.40s/it, 5311.20/6000 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:24:16,725] Trial 28 finished with value: 0.39240567982827246 and parameters: {'window': 18, 'units': 32, 'layers': 1, 'dropout': 0.3454456702065626, 'lr': 0.003010191223030362, 'l2': 0.0002696124550195139, 'batch': 32, 'threshold': 0.4640763508312489}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 28: P=0.519 R=1.000 F0.5=0.575 Thr=0.46 Pos=2278 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [1:29:41<00:00, 179.40s/it, 5381.86/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:25:27,379] Trial 29 finished with value: 1.0 and parameters: {'window': 30, 'units': 64, 'layers': 1, 'dropout': 0.37182564519122707, 'lr': 0.001233010707619071, 'l2': 5.347995878462169e-05, 'batch': 32, 'threshold': 0.5989922993489152}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 29: P=0.000 R=0.000 F0.5=0.000 Thr=0.60 Pos=0 | Best=0.608\n",
      "\n",
      "üèÜ PRECISION OPTIMIZATION COMPLETED\n",
      "==================================================\n",
      "‚≠ê Best combined score: 0.6082\n",
      "üìä Completed trials: 30\n",
      "‚è±Ô∏è  Total time: 89.7 minutes\n",
      "\n",
      "üéØ BEST TRIAL PRECISION METRICS:\n",
      "   Precision: 0.5215 ‚≠ê\n",
      "   Recall: 0.9957\n",
      "   F0.5-score: 0.5764 (precision-focused)\n",
      "   F1-score: 0.6845\n",
      "   Decision threshold: 0.445\n",
      "   Positive predictions: 2236\n",
      "\n",
      "üéØ BEST PARAMETERS:\n",
      "   window         : 42\n",
      "   units          : 96\n",
      "   layers         : 1\n",
      "   dropout        : 0.29304784026893504\n",
      "   lr             : 0.0009539147035893642\n",
      "   l2             : 0.0006182071520515096\n",
      "   batch          : 32\n",
      "   threshold      : 0.4449592913770786\n",
      "\n",
      "‚úÖ Precision-optimized parameters saved!\n",
      "üéØ Model optimized for HIGH PRECISION trading signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Precision-Optimized GRU for Bitcoin Direction Prediction\n",
    "=======================================================\n",
    "Modified to maximize PRECISION with 2x weight to precision over recall.\n",
    "Using F0.5 score (beta=0.5) which emphasizes precision.\n",
    "\n",
    "F-beta formula:\n",
    "- F2 (Œ≤=2): Emphasizes RECALL (2x weight to recall)\n",
    "- F1 (Œ≤=1): Equal weight to precision and recall  \n",
    "- F0.5 (Œ≤=0.5): Emphasizes PRECISION (2x weight to precision)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import optuna\n",
    "import warnings\n",
    "import joblib\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Configuration - PRECISION FOCUSED\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "VAL_FRAC = 0.2\n",
    "\n",
    "# PRECISION OPTIMIZATION: Use F0.5 score (emphasizes precision)\n",
    "BETA = 0.5  # ‚Üê CHANGED: Œ≤=0.5 gives 2x weight to PRECISION\n",
    "PRECISION_WEIGHT = 2.0  # Additional precision weighting\n",
    "\n",
    "MODEL_NAME = \"gru_precision_optimized.h5\"\n",
    "N_TRIALS = 30\n",
    "TIMEOUT = 100 * 60\n",
    "\n",
    "# Same comprehensive drop list\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    'typical_price', 'vwap_24h', 'close_4h',\n",
    "    'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bollinger_width',\n",
    "    'resistance_level', 'support_level',\n",
    "    'high_low', 'high_close', 'low_close', 'true_range',\n",
    "    'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'CCI', 'stoch_%D', 'parkinson_vol',\n",
    "    'ema_cross_down', 'macd_cross_down', 'ema_cross_up', 'macd_cross_up',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'oversold_reversal', 'overbought_reversal',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'timestamp', 'date', 'Unnamed: 0'\n",
    "]\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# GPU Configuration\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def configure_gpu():\n",
    "    \"\"\"Configure GPU with proper error handling.\"\"\"\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"‚úÖ GPU configured: {len(gpus)} device(s)\")\n",
    "            return True\n",
    "        except RuntimeError as e:\n",
    "            print(f\"‚ö†Ô∏è  GPU configuration failed: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No GPU detected, using CPU\")\n",
    "        return False\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Custom Precision-Focused Metrics\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def precision_weighted_score(y_true, y_pred, precision_weight=2.0):\n",
    "    \"\"\"\n",
    "    Custom metric that emphasizes precision over recall.\n",
    "    \n",
    "    Formula: (1 + precision_weight¬≤) * precision * recall / (precision_weight¬≤ * precision + recall)\n",
    "    This is similar to F-beta but with explicit precision weighting.\n",
    "    \"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Custom precision-weighted F-score\n",
    "    score = (1 + precision_weight**2) * precision * recall / (precision_weight**2 * precision + recall)\n",
    "    return score\n",
    "\n",
    "def conservative_precision_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Conservative precision metric that penalizes low precision heavily.\n",
    "    Combines precision with penalty for low confidence predictions.\n",
    "    \"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Penalty for low precision (precision < 0.6 gets heavily penalized)\n",
    "    precision_penalty = max(0, (precision - 0.6) / 0.4) if precision > 0.6 else 0\n",
    "    \n",
    "    # Bonus for high precision (precision > 0.7 gets bonus)\n",
    "    precision_bonus = max(0, (precision - 0.7) / 0.3) if precision > 0.7 else 0\n",
    "    \n",
    "    # Base score with precision emphasis\n",
    "    base_score = precision * 0.7 + recall * 0.3  # 70% precision, 30% recall\n",
    "    \n",
    "    # Apply bonuses and penalties\n",
    "    final_score = base_score + precision_bonus * 0.2 - (1 - precision_penalty) * 0.3\n",
    "    \n",
    "    return max(0, min(1, final_score))\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Data Loading and Preprocessing\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess data with comprehensive validation.\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Loading Bitcoin data for PRECISION-optimized GRU...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not CSV_PATH.exists():\n",
    "        raise FileNotFoundError(f\"‚ùå Data file not found: {CSV_PATH}\")\n",
    "    \n",
    "    df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "    print(f\"‚úÖ Loaded data: {df.shape}\")\n",
    "    \n",
    "    # Filter to stable period\n",
    "    df = df[df.index >= \"2020-01-01\"]\n",
    "    print(f\"üìÖ Using data from 2020+: {len(df)} rows\")\n",
    "    \n",
    "    if 'target' not in df.columns:\n",
    "        raise ValueError(\"‚ùå Target column not found!\")\n",
    "    \n",
    "    target_dist = df['target'].value_counts().to_dict()\n",
    "    print(f\"üéØ Target distribution: {target_dist}\")\n",
    "    \n",
    "    # Drop columns\n",
    "    cols_to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    df = df[df[\"target\"].notna()].dropna()\n",
    "    print(f\"üßπ After cleaning: {df.shape}\")\n",
    "    \n",
    "    # Validate no data leakage\n",
    "    features = df.drop(columns=\"target\")\n",
    "    forbidden_cols = ['open', 'high', 'low', 'close']\n",
    "    found_forbidden = [col for col in forbidden_cols if col in features.columns]\n",
    "    \n",
    "    if found_forbidden:\n",
    "        raise ValueError(f\"‚ùå DATA LEAKAGE: {found_forbidden} in features!\")\n",
    "    \n",
    "    print(f\"‚úÖ Features ({len(features.columns)}): {list(features.columns)}\")\n",
    "    print(f\"‚úÖ PRECISION OPTIMIZATION: No price data leakage\")\n",
    "    \n",
    "    target = df[\"target\"].astype(int).values\n",
    "    \n",
    "    if len(df) < 1000:\n",
    "        raise ValueError(f\"‚ùå Insufficient data: {len(df)} rows\")\n",
    "    \n",
    "    return features, target, df.index\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Sequence Creation\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def create_sequences(data, labels, window_size):\n",
    "    \"\"\"Create sequences with validation.\"\"\"\n",
    "    if window_size >= len(data):\n",
    "        raise ValueError(f\"Window {window_size} >= data length {len(data)}\")\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(labels[i])\n",
    "    \n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Precision-Optimized Objective Function\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def precision_objective(trial, data_info):\n",
    "    \"\"\"\n",
    "    Objective function optimized for PRECISION.\n",
    "    Uses multiple precision-focused metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train_scaled, X_val_scaled, y_train, y_val = data_info\n",
    "    \n",
    "    try:\n",
    "        # Sample hyperparameters (slightly more conservative for precision)\n",
    "        window_size = trial.suggest_int(\"window\", 12, 48, step=6)\n",
    "        n_units = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "        n_layers = trial.suggest_int(\"layers\", 1, 2)\n",
    "        dropout_rate = trial.suggest_float(\"dropout\", 0.2, 0.5)  # Higher dropout for precision\n",
    "        learning_rate = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "        l2_reg = trial.suggest_float(\"l2\", 1e-5, 1e-2, log=True)  # More regularization\n",
    "        batch_size = trial.suggest_categorical(\"batch\", [32, 64])\n",
    "        \n",
    "        # PRECISION OPTIMIZATION: Threshold tuning\n",
    "        decision_threshold = trial.suggest_float(\"threshold\", 0.4, 0.7)  # Conservative thresholds\n",
    "        \n",
    "        # Create sequences\n",
    "        X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, window_size)\n",
    "        X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, window_size)\n",
    "        \n",
    "        if len(X_train_seq) < 100 or len(X_val_seq) < 50:\n",
    "            return float('inf')\n",
    "        \n",
    "        if len(np.unique(y_train_seq)) < 2 or len(np.unique(y_val_seq)) < 2:\n",
    "            return float('inf')\n",
    "        \n",
    "        # Build model (more conservative architecture for precision)\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = keras.Sequential()\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            return_sequences = (i < n_layers - 1)\n",
    "            model.add(keras.layers.GRU(\n",
    "                n_units,\n",
    "                return_sequences=return_sequences,\n",
    "                dropout=dropout_rate,\n",
    "                recurrent_dropout=dropout_rate * 0.6,  # Higher recurrent dropout\n",
    "                kernel_regularizer=keras.regularizers.l2(l2_reg),\n",
    "                recurrent_regularizer=keras.regularizers.l2(l2_reg)\n",
    "            ))\n",
    "        \n",
    "        # Add extra regularization for precision\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "        model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train model with patience for precision\n",
    "        history = model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=80,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val_seq, y_val_seq),\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=15,  # More patience for precision optimization\n",
    "                    restore_best_weights=True,\n",
    "                    verbose=0\n",
    "                )\n",
    "            ],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Evaluate with custom threshold\n",
    "        y_pred_prob = model.predict(X_val_seq, verbose=0).ravel()\n",
    "        y_pred = (y_pred_prob >= decision_threshold).astype(int)\n",
    "        \n",
    "        # Calculate precision-focused metrics\n",
    "        precision = precision_score(y_val_seq, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_val_seq, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val_seq, y_pred, zero_division=0)\n",
    "        f_half = fbeta_score(y_val_seq, y_pred, beta=BETA, zero_division=0)  # F0.5 (precision-focused)\n",
    "        accuracy = accuracy_score(y_val_seq, y_pred)\n",
    "        \n",
    "        # Custom precision metrics\n",
    "        precision_weighted = precision_weighted_score(y_val_seq, y_pred, PRECISION_WEIGHT)\n",
    "        conservative_precision = conservative_precision_score(y_val_seq, y_pred)\n",
    "        \n",
    "        # Store all metrics\n",
    "        trial.set_user_attr(\"precision\", precision)\n",
    "        trial.set_user_attr(\"recall\", recall)\n",
    "        trial.set_user_attr(\"f1_score\", f1)\n",
    "        trial.set_user_attr(\"f_half_score\", f_half)  # F0.5 score\n",
    "        trial.set_user_attr(\"accuracy\", accuracy)\n",
    "        trial.set_user_attr(\"precision_weighted\", precision_weighted)\n",
    "        trial.set_user_attr(\"conservative_precision\", conservative_precision)\n",
    "        trial.set_user_attr(\"decision_threshold\", decision_threshold)\n",
    "        trial.set_user_attr(\"n_positive_predictions\", int(np.sum(y_pred)))\n",
    "        \n",
    "        # PRECISION OPTIMIZATION: Multiple scoring strategies\n",
    "        \n",
    "        # Strategy 1: Pure F0.5 (emphasizes precision)\n",
    "        score_f_half = f_half\n",
    "        \n",
    "        # Strategy 2: Precision-weighted custom score\n",
    "        score_custom = precision_weighted\n",
    "        \n",
    "        # Strategy 3: Conservative precision score\n",
    "        score_conservative = conservative_precision\n",
    "        \n",
    "        # Strategy 4: Precision with minimum recall constraint\n",
    "        if recall >= 0.2:  # Minimum 20% recall required\n",
    "            score_constrained = precision\n",
    "        else:\n",
    "            score_constrained = precision * (recall / 0.2)  # Penalty for low recall\n",
    "        \n",
    "        # Combine strategies (weighted average)\n",
    "        final_score = (\n",
    "            0.4 * score_f_half +           # 40% F0.5 score\n",
    "            0.3 * score_custom +           # 30% custom precision score  \n",
    "            0.2 * score_conservative +     # 20% conservative score\n",
    "            0.1 * score_constrained        # 10% constrained precision\n",
    "        )\n",
    "        \n",
    "        trial.set_user_attr(\"final_combined_score\", final_score)\n",
    "        \n",
    "        # Return negative score for minimization\n",
    "        return 1.0 - final_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Trial {trial.number} failed: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Enhanced Progress Callback\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def precision_progress_callback(study, trial):\n",
    "    \"\"\"Progress callback focused on precision metrics.\"\"\"\n",
    "    \n",
    "    if trial.state == optuna.trial.TrialState.COMPLETE:\n",
    "        attrs = trial.user_attrs\n",
    "        precision = attrs.get('precision', 0)\n",
    "        recall = attrs.get('recall', 0)\n",
    "        f_half = attrs.get('f_half_score', 0)\n",
    "        threshold = attrs.get('decision_threshold', 0.5)\n",
    "        n_pos_pred = attrs.get('n_positive_predictions', 0)\n",
    "        \n",
    "        best_score = 1 - study.best_value if study.best_value != float('inf') else 0\n",
    "        \n",
    "        print(f\"Trial {trial.number:2d}: P={precision:.3f} R={recall:.3f} F0.5={f_half:.3f} \"\n",
    "              f\"Thr={threshold:.2f} Pos={n_pos_pred} | Best={best_score:.3f}\")\n",
    "    \n",
    "    elif trial.state == optuna.trial.TrialState.PRUNED:\n",
    "        print(f\"Trial {trial.number:2d}: PRUNED\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Main Precision Optimization Pipeline\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ PRECISION-OPTIMIZED GRU HYPERPARAMETER SEARCH\")\n",
    "    print(\"üéØ Maximizing PRECISION for Bitcoin Direction Prediction\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"üìä Using F{BETA} score (Œ≤={BETA}) - Emphasizes PRECISION\")\n",
    "    print(f\"üéØ Precision gets {PRECISION_WEIGHT}x weight in scoring\")\n",
    "    \n",
    "    try:\n",
    "        # Configure GPU\n",
    "        gpu_available = configure_gpu()\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        features, target, dates = load_and_preprocess_data()\n",
    "        \n",
    "        # Proper scaling\n",
    "        split_idx = int(len(features) * (1 - VAL_FRAC))\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(features.iloc[:split_idx])\n",
    "        \n",
    "        X_train_scaled = scaler.transform(features.iloc[:split_idx])\n",
    "        X_val_scaled = scaler.transform(features.iloc[split_idx:])\n",
    "        y_train = target[:split_idx]\n",
    "        y_val = target[split_idx:]\n",
    "        \n",
    "        print(f\"üìä Train: {len(X_train_scaled)} samples, Val: {len(X_val_scaled)} samples\")\n",
    "        \n",
    "        # Save scaler\n",
    "        joblib.dump(scaler, \"gru_precision_scaler.pkl\")\n",
    "        \n",
    "        # Prepare data\n",
    "        data_info = (X_train_scaled, X_val_scaled, y_train, y_val)\n",
    "        \n",
    "        # Create study\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "            pruner=optuna.pruners.MedianPruner(\n",
    "                n_startup_trials=5,\n",
    "                n_warmup_steps=3\n",
    "            ),\n",
    "            study_name=\"gru_precision_optimized\"\n",
    "        )\n",
    "        \n",
    "        # Run optimization\n",
    "        print(f\"\\nüîç Starting PRECISION optimization...\")\n",
    "        print(f\"   Focus: Maximize precision with 2x weight\")\n",
    "        print(f\"   Trials: {N_TRIALS}, Timeout: {TIMEOUT//60}min\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        study.optimize(\n",
    "            lambda trial: precision_objective(trial, data_info),\n",
    "            n_trials=N_TRIALS,\n",
    "            timeout=TIMEOUT,\n",
    "            show_progress_bar=True,\n",
    "            callbacks=[precision_progress_callback]\n",
    "        )\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Results analysis\n",
    "        print(f\"\\nüèÜ PRECISION OPTIMIZATION COMPLETED\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "        \n",
    "        if completed_trials:\n",
    "            best_combined_score = 1 - study.best_value\n",
    "            best_trial = study.best_trial\n",
    "            \n",
    "            print(f\"‚≠ê Best combined score: {best_combined_score:.4f}\")\n",
    "            print(f\"üìä Completed trials: {len(completed_trials)}\")\n",
    "            print(f\"‚è±Ô∏è  Total time: {total_time/60:.1f} minutes\")\n",
    "            \n",
    "            # Best trial precision metrics\n",
    "            if hasattr(best_trial, 'user_attrs'):\n",
    "                attrs = best_trial.user_attrs\n",
    "                print(f\"\\nüéØ BEST TRIAL PRECISION METRICS:\")\n",
    "                print(f\"   Precision: {attrs.get('precision', 'N/A'):.4f} ‚≠ê\")\n",
    "                print(f\"   Recall: {attrs.get('recall', 'N/A'):.4f}\")\n",
    "                print(f\"   F0.5-score: {attrs.get('f_half_score', 'N/A'):.4f} (precision-focused)\")\n",
    "                print(f\"   F1-score: {attrs.get('f1_score', 'N/A'):.4f}\")\n",
    "                print(f\"   Decision threshold: {attrs.get('decision_threshold', 'N/A'):.3f}\")\n",
    "                print(f\"   Positive predictions: {attrs.get('n_positive_predictions', 'N/A')}\")\n",
    "            \n",
    "            print(f\"\\nüéØ BEST PARAMETERS:\")\n",
    "            for param, value in study.best_params.items():\n",
    "                print(f\"   {param:15s}: {value}\")\n",
    "            \n",
    "            # Save results\n",
    "            enhanced_params = {\n",
    "                **study.best_params,\n",
    "                \"optimization_focus\": \"precision\",\n",
    "                \"beta_score\": BETA,\n",
    "                \"precision_weight\": PRECISION_WEIGHT,\n",
    "                \"best_metrics\": {\n",
    "                    k: float(v) if isinstance(v, (int, float, np.number)) else v\n",
    "                    for k, v in best_trial.user_attrs.items()\n",
    "                    if k in ['precision', 'recall', 'f_half_score', 'f1_score', 'decision_threshold']\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(\"gru_precision_optimized_params.json\", \"w\") as f:\n",
    "                json.dump(enhanced_params, f, indent=2)\n",
    "            \n",
    "            print(f\"\\n‚úÖ Precision-optimized parameters saved!\")\n",
    "            print(f\"üéØ Model optimized for HIGH PRECISION trading signals\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå No trials completed successfully!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Optimization failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fd366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-06-13 10:23:10,397] A new study created in memory with name: gru_enhanced_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ENHANCED PRECISION-OPTIMIZED GRU SEARCH\n",
      "üéØ Maximizing PRECISION with improved parameters\n",
      "======================================================================\n",
      "üìä Using F0.5 score (Œ≤=0.5) - 2x weight to PRECISION\n",
      "üéØ Enhanced with 50 trials and focused ranges\n",
      "‚ö†Ô∏è  No GPU detected, using CPU\n",
      "üöÄ Loading Bitcoin data for ENHANCED PRECISION GRU...\n",
      "=================================================================\n",
      "‚úÖ Loaded data: (20718, 66)\n",
      "üìÖ Using data from 2020+: 11476 rows\n",
      "üéØ Target distribution: {1: 5858, 0: 5618}\n",
      "üßπ After cleaning: (11476, 20)\n",
      "‚úÖ Features (19): ['volume', 'RSI', 'MACD_histogram', 'OBV', 'stoch_%K', 'atr_14', 'atr_ratio', 'price_vs_vwap', 'volume_ratio', 'buying_pressure', 'adx', 'fear_greed_score', 'roc_4h', 'roc_24h', 'bb_position', 'macd_rising', 'obv_rising_24h', 'momentum_alignment', 'trend_alignment']\n",
      "‚úÖ ENHANCED PRECISION: No price data leakage\n",
      "üìä Train: 9180 samples, Val: 2296 samples\n",
      "\n",
      "üîç Starting ENHANCED PRECISION optimization...\n",
      "   Focus: Precision with focused parameter ranges\n",
      "   Trials: 50, Timeout: 120min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.337167:   2%|‚ñè         | 1/50 [04:58<4:03:35, 298.27s/it, 298.27/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:28:08,666] Trial 0 finished with value: 0.3371671041142523 and parameters: {'window': 24, 'units': 128, 'layers': 2, 'dropout': 0.2916145155592091, 'lr': 0.0005187855301194422, 'l2': 0.0008706020878304854, 'batch': 32, 'threshold': 0.3863649934414201}. Best is trial 0 with value: 0.3371671041142523.\n",
      "‚úÖ Trial  0 | P=0.519 R=1.000 F1=0.683 F0.5=0.574 | Thr=0.39 Pos=2272 | Combined=0.663 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.337167:   4%|‚ñç         | 2/50 [05:36<1:56:26, 145.56s/it, 336.93/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:28:47,330] Trial 1 finished with value: 0.33810592626155533 and parameters: {'window': 30, 'units': 64, 'layers': 1, 'dropout': 0.24121399684340716, 'lr': 0.002041529502947848, 'l2': 2.5081156860452307e-05, 'batch': 64, 'threshold': 0.3592900825439995}. Best is trial 0 with value: 0.3371671041142523.\n",
      "‚úÖ Trial  1 | P=0.519 R=0.997 F1=0.682 F0.5=0.574 | Thr=0.36 Pos=2261 | Combined=0.662 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.337167:   6%|‚ñå         | 3/50 [09:09<2:17:50, 175.96s/it, 549.07/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:32:19,472] Trial 2 finished with value: 0.33784425533753715 and parameters: {'window': 42, 'units': 64, 'layers': 2, 'dropout': 0.23803049874792026, 'lr': 0.0006222060209649932, 'l2': 9.7803370166594e-05, 'batch': 64, 'threshold': 0.40175599632000336}. Best is trial 0 with value: 0.3371671041142523.\n",
      "‚úÖ Trial  2 | P=0.519 R=0.997 F1=0.683 F0.5=0.574 | Thr=0.40 Pos=2248 | Combined=0.662 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.336854:   8%|‚ñä         | 4/50 [10:00<1:37:09, 126.72s/it, 600.32/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:33:10,714] Trial 3 finished with value: 0.3368541737953141 and parameters: {'window': 18, 'units': 64, 'layers': 2, 'dropout': 0.26957999576221703, 'lr': 0.002608120141371272, 'l2': 1.5030900645056805e-05, 'batch': 32, 'threshold': 0.41506606615265285}. Best is trial 3 with value: 0.3368541737953141.\n",
      "‚úÖ Trial  3 | P=0.519 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.42 Pos=2278 | Combined=0.663 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.336854:  10%|‚ñà         | 5/50 [10:33<1:09:43, 92.97s/it, 633.42/7200 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:33:43,823] Trial 4 finished with value: 0.5028769110998154 and parameters: {'window': 30, 'units': 128, 'layers': 1, 'dropout': 0.3473773873201034, 'lr': 0.0019947718789028682, 'l2': 2.497073714505272e-05, 'batch': 64, 'threshold': 0.4913714687695234}. Best is trial 3 with value: 0.3368541737953141.\n",
      "‚úÖ Trial  4 | P=0.547 R=0.424 F1=0.478 F0.5=0.517 | Thr=0.49 Pos=912 | Combined=0.497 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.336854:  12%|‚ñà‚ñè        | 6/50 [11:07<53:34, 73.05s/it, 667.82/7200 seconds]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:34:18,221] Trial 5 finished with value: 0.34415505786264033 and parameters: {'window': 24, 'units': 64, 'layers': 1, 'dropout': 0.21219646434313244, 'lr': 0.0008953891201428856, 'l2': 0.0002878805718308924, 'batch': 64, 'threshold': 0.4444429850323899}. Best is trial 3 with value: 0.3368541737953141.\n",
      "‚úÖ Trial  5 | P=0.522 R=0.961 F1=0.677 F0.5=0.575 | Thr=0.44 Pos=2169 | Combined=0.656 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.336854:  14%|‚ñà‚ñç        | 7/50 [12:27<53:51, 75.15s/it, 747.28/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:35:37,679] Trial 6 finished with value: 0.6086624222800995 and parameters: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.17157828539866088, 'lr': 0.0005289646680152981, 'l2': 0.000187422109855557, 'batch': 64, 'threshold': 0.5315132947852186}. Best is trial 3 with value: 0.3368541737953141.\n",
      "‚úÖ Trial  6 | P=0.556 R=0.221 F1=0.316 F0.5=0.427 | Thr=0.53 Pos=466 | Combined=0.391 | Best=0.663\n",
      "   üéØ HIGH PRECISION TRIAL! Conservative=0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.336772:  16%|‚ñà‚ñå        | 8/50 [13:53<55:00, 78.60s/it, 833.26/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:37:03,657] Trial 7 finished with value: 0.33677193249468607 and parameters: {'window': 30, 'units': 128, 'layers': 2, 'dropout': 0.2766807513020847, 'lr': 0.00238285794371812, 'l2': 0.00040489662225846743, 'batch': 64, 'threshold': 0.4578684483831302}. Best is trial 7 with value: 0.33677193249468607.\n",
      "‚úÖ Trial  7 | P=0.519 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.46 Pos=2266 | Combined=0.663 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.336772:  18%|‚ñà‚ñä        | 9/50 [14:16<41:47, 61.15s/it, 856.05/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:37:26,453] Trial 8 finished with value: 0.7084481234735871 and parameters: {'window': 24, 'units': 128, 'layers': 1, 'dropout': 0.2521494605155131, 'lr': 0.0010562796147104163, 'l2': 2.781093697926551e-05, 'batch': 64, 'threshold': 0.5385819407825039}. Best is trial 7 with value: 0.33677193249468607.\n",
      "‚úÖ Trial  8 | P=0.585 R=0.111 F1=0.187 F0.5=0.316 | Thr=0.54 Pos=224 | Combined=0.292 | Best=0.663\n",
      "   üéØ HIGH PRECISION TRIAL! Conservative=0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.336772:  20%|‚ñà‚ñà        | 10/50 [16:08<51:24, 77.12s/it, 968.94/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:39:19,339] Trial 9 finished with value: 0.3388701272237875 and parameters: {'window': 42, 'units': 64, 'layers': 1, 'dropout': 0.2069680988754935, 'lr': 0.0005341627862317534, 'l2': 0.0001656260589333595, 'batch': 32, 'threshold': 0.4057292928473223}. Best is trial 7 with value: 0.33677193249468607.\n",
      "‚úÖ Trial  9 | P=0.520 R=0.989 F1=0.682 F0.5=0.575 | Thr=0.41 Pos=2226 | Combined=0.661 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.33657:  22%|‚ñà‚ñà‚ñè       | 11/50 [18:12<59:22, 91.35s/it, 1092.54/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:41:22,943] Trial 10 finished with value: 0.33656987041370845 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.32409872795493855, 'lr': 0.0015741846487190218, 'l2': 0.0006536264082965735, 'batch': 32, 'threshold': 0.4775943510422122}. Best is trial 10 with value: 0.33656987041370845.\n",
      "‚úÖ Trial 10 | P=0.520 R=0.999 F1=0.684 F0.5=0.575 | Thr=0.48 Pos=2258 | Combined=0.663 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  24%|‚ñà‚ñà‚ñç       | 12/50 [20:53<1:11:13, 112.45s/it, 1253.27/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:44:03,668] Trial 11 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.323957750393217, 'lr': 0.0015190233563579104, 'l2': 0.0009583723340357708, 'batch': 32, 'threshold': 0.47716756994461185}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 11 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.48 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  26%|‚ñà‚ñà‚ñå       | 13/50 [23:23<1:16:19, 123.78s/it, 1403.11/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:46:33,509] Trial 12 finished with value: 0.37998923630041626 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3340680020429286, 'lr': 0.0014635679224724492, 'l2': 0.0009942672296441586, 'batch': 32, 'threshold': 0.49414840502356794}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 12 | P=0.523 R=0.824 F1=0.640 F0.5=0.564 | Thr=0.49 Pos=1850 | Combined=0.620 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  28%|‚ñà‚ñà‚ñä       | 14/50 [26:46<1:28:46, 147.95s/it, 1606.91/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:49:57,303] Trial 13 finished with value: 0.3406901779041759 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.324976653746651, 'lr': 0.0014423876910183836, 'l2': 0.0005756773583797651, 'batch': 32, 'threshold': 0.48575197444464246}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 13 | P=0.520 R=0.981 F1=0.680 F0.5=0.574 | Thr=0.49 Pos=2216 | Combined=0.659 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  30%|‚ñà‚ñà‚ñà       | 15/50 [33:43<2:13:31, 228.89s/it, 2023.37/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:56:53,766] Trial 14 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.307501803285623, 'lr': 0.0014763754699183664, 'l2': 6.810384885504048e-05, 'batch': 32, 'threshold': 0.45229204124343925}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 14 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.45 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [39:02<2:25:08, 256.14s/it, 2342.80/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:02:13,200] Trial 15 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.30680826039456066, 'lr': 0.000855693720550432, 'l2': 7.098701732564448e-05, 'batch': 32, 'threshold': 0.4351278635538124}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 15 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.44 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [43:23<2:21:37, 257.51s/it, 2603.49/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:06:33,887] Trial 16 finished with value: 0.6055101107732644 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.30094837842359834, 'lr': 0.0012323935680785315, 'l2': 6.268172739785502e-05, 'batch': 32, 'threshold': 0.5155574518915083}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 16 | P=0.577 R=0.213 F1=0.311 F0.5=0.430 | Thr=0.52 Pos=433 | Combined=0.394 | Best=0.664\n",
      "   üéØ HIGH PRECISION TRIAL! Conservative=0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [45:44<1:58:42, 222.59s/it, 2744.78/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:08:55,183] Trial 17 finished with value: 0.3372315263638972 and parameters: {'window': 18, 'units': 96, 'layers': 2, 'dropout': 0.31298689732390383, 'lr': 0.0018228577656177302, 'l2': 4.6941767381049645e-05, 'batch': 32, 'threshold': 0.46084613384664563}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 17 | P=0.519 R=0.999 F1=0.683 F0.5=0.574 | Thr=0.46 Pos=2277 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [48:41<1:47:49, 208.69s/it, 2921.09/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:11:51,493] Trial 18 finished with value: 0.8094476959779303 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.28135490095950766, 'lr': 0.0029696342650254496, 'l2': 0.00015210385928238603, 'batch': 32, 'threshold': 0.509295737788421}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 18 | P=0.592 R=0.052 F1=0.095 F0.5=0.192 | Thr=0.51 Pos=103 | Combined=0.191 | Best=0.664\n",
      "   üéØ HIGH PRECISION TRIAL! Conservative=0.430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [50:58<1:33:38, 187.30s/it, 3058.53/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:14:08,934] Trial 19 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3392011633983561, 'lr': 0.0011230794730060219, 'l2': 0.00029768887391758446, 'batch': 32, 'threshold': 0.43078667226160083}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 19 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.43 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [54:12<1:31:30, 189.31s/it, 3252.55/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:17:22,947] Trial 20 finished with value: 0.40461902449226417 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.26126299099534406, 'lr': 0.0008574666921947649, 'l2': 4.0337715213162597e-05, 'batch': 32, 'threshold': 0.4664441856235078}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 20 | P=0.530 R=0.723 F1=0.612 F0.5=0.560 | Thr=0.47 Pos=1601 | Combined=0.595 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [58:26<1:37:22, 208.67s/it, 3506.36/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:21:36,762] Trial 21 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3035562543715858, 'lr': 0.0006609703492891972, 'l2': 8.718235147367303e-05, 'batch': 32, 'threshold': 0.4318002142140648}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 21 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.43 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [1:01:57<1:34:16, 209.50s/it, 3717.81/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:25:08,208] Trial 22 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.30504984999945417, 'lr': 0.0008822086610378337, 'l2': 6.801368149307332e-05, 'batch': 32, 'threshold': 0.44086488168349214}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 22 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.44 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [1:05:13<1:28:57, 205.29s/it, 3913.27/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:28:23,669] Trial 23 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.34860360535079365, 'lr': 0.001282379030648687, 'l2': 0.00012463250283994442, 'batch': 32, 'threshold': 0.46653426038517015}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 23 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.47 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [1:08:35<1:25:05, 204.23s/it, 4115.04/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:31:45,439] Trial 24 finished with value: 0.3605252856332136 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.32140294242903733, 'lr': 0.0017034287883189462, 'l2': 1.1414961135986039e-05, 'batch': 32, 'threshold': 0.4268076510175774}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 24 | P=0.521 R=0.900 F1=0.660 F0.5=0.569 | Thr=0.43 Pos=2029 | Combined=0.639 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [1:12:20<1:24:15, 210.66s/it, 4340.68/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:35:31,082] Trial 25 finished with value: 0.3368541737953141 and parameters: {'window': 18, 'units': 96, 'layers': 2, 'dropout': 0.28800240621711304, 'lr': 0.0010036129665531616, 'l2': 5.284942116907877e-05, 'batch': 32, 'threshold': 0.3740445789294572}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 25 | P=0.519 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.37 Pos=2278 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [1:15:25<1:17:47, 202.92s/it, 4525.56/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:38:35,960] Trial 26 finished with value: 0.616712433867378 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.1563243310695384, 'lr': 0.0007068772344860779, 'l2': 3.464206474801883e-05, 'batch': 32, 'threshold': 0.5061311664261949}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 26 | P=0.542 R=0.218 F1=0.311 F0.5=0.418 | Thr=0.51 Pos=472 | Combined=0.383 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [1:21:44<1:33:48, 255.85s/it, 4904.89/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:44:55,291] Trial 27 finished with value: 0.3391048942218998 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3141300741478716, 'lr': 0.0007688428359082904, 'l2': 7.379194369147983e-05, 'batch': 32, 'threshold': 0.4482817957657989}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 27 | P=0.520 R=0.989 F1=0.682 F0.5=0.574 | Thr=0.45 Pos=2235 | Combined=0.661 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [1:26:03<1:29:53, 256.82s/it, 5163.97/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:49:14,370] Trial 28 finished with value: 0.3374073820954745 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.2944123891707492, 'lr': 0.0013899204674669833, 'l2': 0.0002516233411563695, 'batch': 32, 'threshold': 0.4758777072185244}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 28 | P=0.522 R=0.991 F1=0.683 F0.5=0.576 | Thr=0.48 Pos=2232 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [1:31:48<1:34:22, 283.14s/it, 5508.54/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:54:58,944] Trial 29 finished with value: 0.3371671041142523 and parameters: {'window': 24, 'units': 128, 'layers': 2, 'dropout': 0.33282524513845346, 'lr': 0.0011972173564380882, 'l2': 0.00011795974460139173, 'batch': 32, 'threshold': 0.3836839178822975}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 29 | P=0.519 R=1.000 F1=0.683 F0.5=0.574 | Thr=0.38 Pos=2272 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [1:34:37<1:18:49, 248.91s/it, 5677.58/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:57:47,978] Trial 30 finished with value: 0.33956895406357024 and parameters: {'window': 18, 'units': 128, 'layers': 2, 'dropout': 0.22262451253538612, 'lr': 0.0009680969393718183, 'l2': 1.722562165763756e-05, 'batch': 32, 'threshold': 0.41180462079069724}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 30 | P=0.519 R=0.989 F1=0.681 F0.5=0.574 | Thr=0.41 Pos=2253 | Combined=0.660 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [1:39:47<1:20:08, 267.17s/it, 5987.34/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:02:57,735] Trial 31 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3381185839462113, 'lr': 0.0010954055774438527, 'l2': 0.00042082702791979313, 'batch': 32, 'threshold': 0.4188096954569438}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 31 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.42 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [1:44:00<1:14:31, 263.02s/it, 6240.70/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:07:11,097] Trial 32 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3118041815784202, 'lr': 0.0011481337178492381, 'l2': 0.0006220191296519702, 'batch': 32, 'threshold': 0.4350106921557595}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 32 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.44 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [1:47:39<1:06:35, 249.74s/it, 6459.45/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:10:49,845] Trial 33 finished with value: 0.33677193249468607 and parameters: {'window': 30, 'units': 96, 'layers': 2, 'dropout': 0.33816121248332126, 'lr': 0.0013575578444139694, 'l2': 0.00023091327721722117, 'batch': 32, 'threshold': 0.38851196679521616}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 33 | P=0.519 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.39 Pos=2266 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [1:51:51<1:02:37, 250.50s/it, 6711.71/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:15:02,109] Trial 34 finished with value: 0.33688472878054954 and parameters: {'window': 42, 'units': 64, 'layers': 2, 'dropout': 0.2948521598667029, 'lr': 0.001766280177103257, 'l2': 0.00031823524395262166, 'batch': 32, 'threshold': 0.4527134988656639}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 34 | P=0.520 R=0.999 F1=0.684 F0.5=0.575 | Thr=0.45 Pos=2252 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [1:55:38<56:47, 243.37s/it, 6938.45/7200 seconds]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:18:48,844] Trial 35 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3497330817000635, 'lr': 0.00210390084930548, 'l2': 9.726370534741423e-05, 'batch': 32, 'threshold': 0.43060993423577765}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 35 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.43 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [1:57:20<43:31, 200.85s/it, 7040.09/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:20:30,491] Trial 36 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 64, 'layers': 1, 'dropout': 0.32410843910799725, 'lr': 0.001593853375642476, 'l2': 0.0003939823902581817, 'batch': 64, 'threshold': 0.394527650935701}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 36 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.39 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [2:00:50<38:09, 190.81s/it, 7250.66/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:24:01,057] Trial 37 finished with value: 0.33677193249468607 and parameters: {'window': 30, 'units': 96, 'layers': 2, 'dropout': 0.267142572545942, 'lr': 0.000808836272445403, 'l2': 0.0007783687973588303, 'batch': 32, 'threshold': 0.4199580965645373}. Best is trial 11 with value: 0.33637481028500593.\n",
      "‚úÖ Trial 37 | P=0.519 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.42 Pos=2266 | Combined=0.663 | Best=0.664\n",
      "\n",
      "üèÜ ENHANCED PRECISION OPTIMIZATION COMPLETED\n",
      "=======================================================\n",
      "‚≠ê Best combined score: 0.6636\n",
      "üìä Completed trials: 38\n",
      "‚è±Ô∏è  Total time: 120.8 minutes\n",
      "\n",
      "üéØ BEST ENHANCED PRECISION METRICS:\n",
      "   Precision: 0.5199 ‚≠ê\n",
      "   Recall: 1.0000\n",
      "   F0.5-score: 0.5751\n",
      "   F1-score: 0.6841\n",
      "   Decision threshold: 0.477\n",
      "   Positive predictions: 2260\n",
      "\n",
      "üéØ ENHANCED BEST PARAMETERS:\n",
      "   window         : 36\n",
      "   units          : 96\n",
      "   layers         : 2\n",
      "   dropout        : 0.323957750393217\n",
      "   lr             : 0.0015190233563579104\n",
      "   l2             : 0.0009583723340357708\n",
      "   batch          : 32\n",
      "   threshold      : 0.47716756994461185\n",
      "\n",
      "‚úÖ Enhanced precision parameters saved!\n",
      "üéØ Target: >0.60 precision with balanced recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Enhanced Precision-Optimized GRU for Bitcoin Direction Prediction\n",
    "=================================================================\n",
    "FIXED VERSION with improved parameter ranges and more trials.\n",
    "Focus: Maximize PRECISION with F0.5 score (2x weight to precision).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import optuna\n",
    "import warnings\n",
    "import joblib\n",
    "import time\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# ENHANCED Configuration - PRECISION FOCUSED\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "VAL_FRAC = 0.2\n",
    "\n",
    "# PRECISION OPTIMIZATION: Use F0.5 score (emphasizes precision)\n",
    "BETA = 0.5  # Œ≤=0.5 gives 2x weight to PRECISION\n",
    "PRECISION_WEIGHT = 2.0\n",
    "\n",
    "MODEL_NAME = \"gru_precision_enhanced.h5\"\n",
    "N_TRIALS = 50  # INCREASED from 30\n",
    "TIMEOUT = 120 * 60  # 2 hours instead of 100 minutes\n",
    "\n",
    "# Complete drop list\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    'typical_price', 'vwap_24h', 'close_4h',\n",
    "    'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bollinger_width',\n",
    "    'resistance_level', 'support_level',\n",
    "    'high_low', 'high_close', 'low_close', 'true_range',\n",
    "    'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'CCI', 'stoch_%D', 'parkinson_vol',\n",
    "    'ema_cross_down', 'macd_cross_down', 'ema_cross_up', 'macd_cross_up',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'oversold_reversal', 'overbought_reversal',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'timestamp', 'date', 'Unnamed: 0'\n",
    "]\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# GPU Configuration\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def configure_gpu():\n",
    "    \"\"\"Configure GPU with proper error handling.\"\"\"\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"‚úÖ GPU configured: {len(gpus)} device(s)\")\n",
    "            return True\n",
    "        except RuntimeError as e:\n",
    "            print(f\"‚ö†Ô∏è  GPU configuration failed: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No GPU detected, using CPU\")\n",
    "        return False\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Custom Precision-Focused Metrics\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def precision_weighted_score(y_true, y_pred, precision_weight=2.0):\n",
    "    \"\"\"Custom metric that emphasizes precision over recall.\"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Custom precision-weighted F-score\n",
    "    score = (1 + precision_weight**2) * precision * recall / (precision_weight**2 * precision + recall)\n",
    "    return score\n",
    "\n",
    "def conservative_precision_score(y_true, y_pred):\n",
    "    \"\"\"Conservative precision metric with bonuses for high precision.\"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Bonus for high precision\n",
    "    precision_bonus = max(0, (precision - 0.6) / 0.4) if precision > 0.6 else 0\n",
    "    \n",
    "    # Base score with precision emphasis\n",
    "    base_score = precision * 0.7 + recall * 0.3\n",
    "    \n",
    "    # Apply bonus\n",
    "    final_score = base_score + precision_bonus * 0.2\n",
    "    \n",
    "    return max(0, min(1, final_score))\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Data Loading and Preprocessing\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess data with comprehensive validation.\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Loading Bitcoin data for ENHANCED PRECISION GRU...\")\n",
    "    print(\"=\" * 65)\n",
    "    \n",
    "    if not CSV_PATH.exists():\n",
    "        raise FileNotFoundError(f\"‚ùå Data file not found: {CSV_PATH}\")\n",
    "    \n",
    "    df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "    print(f\"‚úÖ Loaded data: {df.shape}\")\n",
    "    \n",
    "    # Filter to stable period\n",
    "    df = df[df.index >= \"2020-01-01\"]\n",
    "    print(f\"üìÖ Using data from 2020+: {len(df)} rows\")\n",
    "    \n",
    "    if 'target' not in df.columns:\n",
    "        raise ValueError(\"‚ùå Target column not found!\")\n",
    "    \n",
    "    target_dist = df['target'].value_counts().to_dict()\n",
    "    print(f\"üéØ Target distribution: {target_dist}\")\n",
    "    \n",
    "    # Drop columns\n",
    "    cols_to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    df = df[df[\"target\"].notna()].dropna()\n",
    "    print(f\"üßπ After cleaning: {df.shape}\")\n",
    "    \n",
    "    # Validate no data leakage\n",
    "    features = df.drop(columns=\"target\")\n",
    "    forbidden_cols = ['open', 'high', 'low', 'close']\n",
    "    found_forbidden = [col for col in forbidden_cols if col in features.columns]\n",
    "    \n",
    "    if found_forbidden:\n",
    "        raise ValueError(f\"‚ùå DATA LEAKAGE: {found_forbidden} in features!\")\n",
    "    \n",
    "    print(f\"‚úÖ Features ({len(features.columns)}): {list(features.columns)}\")\n",
    "    print(f\"‚úÖ ENHANCED PRECISION: No price data leakage\")\n",
    "    \n",
    "    target = df[\"target\"].astype(int).values\n",
    "    \n",
    "    if len(df) < 1000:\n",
    "        raise ValueError(f\"‚ùå Insufficient data: {len(df)} rows\")\n",
    "    \n",
    "    return features, target, df.index\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Sequence Creation\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def create_sequences(data, labels, window_size):\n",
    "    \"\"\"Create sequences with validation.\"\"\"\n",
    "    if window_size >= len(data):\n",
    "        raise ValueError(f\"Window {window_size} >= data length {len(data)}\")\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(labels[i])\n",
    "    \n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Enhanced Precision-Optimized Objective Function\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def enhanced_precision_objective(trial, data_info):\n",
    "    \"\"\"ENHANCED objective function optimized for PRECISION.\"\"\"\n",
    "    \n",
    "    X_train_scaled, X_val_scaled, y_train, y_val = data_info\n",
    "    \n",
    "    try:\n",
    "        # ENHANCED hyperparameter ranges based on previous results\n",
    "        window_size = trial.suggest_categorical(\"window\", [18, 24, 30, 36, 42])  # Focus on successful windows\n",
    "        n_units = trial.suggest_categorical(\"units\", [64, 96, 128])  # Larger networks only\n",
    "        n_layers = trial.suggest_int(\"layers\", 1, 2)  # Simple architectures\n",
    "        dropout_rate = trial.suggest_float(\"dropout\", 0.15, 0.35)  # Tighter range\n",
    "        learning_rate = trial.suggest_float(\"lr\", 0.0005, 0.003, log=True)  # Focus on working LR range\n",
    "        l2_reg = trial.suggest_float(\"l2\", 1e-5, 1e-3, log=True)  # Better regularization\n",
    "        batch_size = trial.suggest_categorical(\"batch\", [32, 64])\n",
    "        \n",
    "        # ENHANCED threshold tuning - avoid extremes\n",
    "        decision_threshold = trial.suggest_float(\"threshold\", 0.35, 0.55)  # Avoid extreme thresholds\n",
    "        \n",
    "        # Create sequences\n",
    "        X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, window_size)\n",
    "        X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, window_size)\n",
    "        \n",
    "        if len(X_train_seq) < 100 or len(X_val_seq) < 50:\n",
    "            return float('inf')\n",
    "        \n",
    "        if len(np.unique(y_train_seq)) < 2 or len(np.unique(y_val_seq)) < 2:\n",
    "            return float('inf')\n",
    "        \n",
    "        # Build enhanced model\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = keras.Sequential()\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            return_sequences = (i < n_layers - 1)\n",
    "            model.add(keras.layers.GRU(\n",
    "                n_units,\n",
    "                return_sequences=return_sequences,\n",
    "                dropout=dropout_rate,\n",
    "                recurrent_dropout=dropout_rate * 0.6,\n",
    "                kernel_regularizer=keras.regularizers.l2(l2_reg),\n",
    "                recurrent_regularizer=keras.regularizers.l2(l2_reg)\n",
    "            ))\n",
    "        \n",
    "        # Enhanced regularization\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "        model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train with enhanced patience\n",
    "        history = model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=60,  # Reduced epochs for efficiency\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val_seq, y_val_seq),\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=12,  # Balanced patience\n",
    "                    restore_best_weights=True,\n",
    "                    verbose=0\n",
    "                )\n",
    "            ],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Evaluate with custom threshold\n",
    "        y_pred_prob = model.predict(X_val_seq, verbose=0).ravel()\n",
    "        y_pred = (y_pred_prob >= decision_threshold).astype(int)\n",
    "        \n",
    "        # Calculate all metrics\n",
    "        precision = precision_score(y_val_seq, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_val_seq, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val_seq, y_pred, zero_division=0)\n",
    "        f_half = fbeta_score(y_val_seq, y_pred, beta=BETA, zero_division=0)\n",
    "        accuracy = accuracy_score(y_val_seq, y_pred)\n",
    "        \n",
    "        # Custom precision metrics\n",
    "        precision_weighted = precision_weighted_score(y_val_seq, y_pred, PRECISION_WEIGHT)\n",
    "        conservative_precision = conservative_precision_score(y_val_seq, y_pred)\n",
    "        \n",
    "        # Store metrics\n",
    "        trial.set_user_attr(\"precision\", precision)\n",
    "        trial.set_user_attr(\"recall\", recall)\n",
    "        trial.set_user_attr(\"f1_score\", f1)\n",
    "        trial.set_user_attr(\"f_half_score\", f_half)\n",
    "        trial.set_user_attr(\"accuracy\", accuracy)\n",
    "        trial.set_user_attr(\"precision_weighted\", precision_weighted)\n",
    "        trial.set_user_attr(\"conservative_precision\", conservative_precision)\n",
    "        trial.set_user_attr(\"decision_threshold\", decision_threshold)\n",
    "        trial.set_user_attr(\"n_positive_predictions\", int(np.sum(y_pred)))\n",
    "        \n",
    "        # ENHANCED scoring with focus on precision\n",
    "        score_f_half = f_half\n",
    "        score_custom = precision_weighted\n",
    "        score_conservative = conservative_precision\n",
    "        \n",
    "        # Precision with minimum recall constraint (enhanced)\n",
    "        if recall >= 0.15:  # Lower minimum recall threshold\n",
    "            score_constrained = precision\n",
    "        else:\n",
    "            score_constrained = precision * (recall / 0.15)\n",
    "        \n",
    "        # Enhanced combination weights\n",
    "        final_score = (\n",
    "            0.45 * score_f_half +         # 45% F0.5 score (increased)\n",
    "            0.30 * score_custom +         # 30% custom precision score  \n",
    "            0.15 * score_conservative +   # 15% conservative score\n",
    "            0.10 * score_constrained      # 10% constrained precision\n",
    "        )\n",
    "        \n",
    "        trial.set_user_attr(\"final_combined_score\", final_score)\n",
    "        \n",
    "        # Cleanup memory\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        return 1.0 - final_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Trial {trial.number} failed: {e}\")\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        return float('inf')\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Enhanced Progress Callback\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def enhanced_precision_callback(study, trial):\n",
    "    \"\"\"Enhanced progress callback with detailed metrics.\"\"\"\n",
    "    \n",
    "    if trial.state == optuna.trial.TrialState.COMPLETE:\n",
    "        attrs = trial.user_attrs\n",
    "        precision = attrs.get('precision', 0)\n",
    "        recall = attrs.get('recall', 0)\n",
    "        f1 = attrs.get('f1_score', 0)\n",
    "        f_half = attrs.get('f_half_score', 0)\n",
    "        threshold = attrs.get('decision_threshold', 0.5)\n",
    "        combined_score = attrs.get('final_combined_score', 0)\n",
    "        n_pos = attrs.get('n_positive_predictions', 0)\n",
    "        \n",
    "        best_score = 1 - study.best_value if study.best_value != float('inf') else 0\n",
    "        \n",
    "        print(f\"‚úÖ Trial {trial.number:2d} | P={precision:.3f} R={recall:.3f} F1={f1:.3f} \"\n",
    "              f\"F0.5={f_half:.3f} | Thr={threshold:.2f} Pos={n_pos} | Combined={combined_score:.3f} | Best={best_score:.3f}\")\n",
    "        \n",
    "        # Highlight high precision trials\n",
    "        if precision >= 0.55:\n",
    "            print(f\"   üéØ HIGH PRECISION TRIAL! Conservative={attrs.get('conservative_precision', 0):.3f}\")\n",
    "    \n",
    "    elif trial.state == optuna.trial.TrialState.PRUNED:\n",
    "        print(f\"‚è≠Ô∏è  Trial {trial.number:2d}: PRUNED\")\n",
    "    elif trial.state == optuna.trial.TrialState.FAIL:\n",
    "        print(f\"‚ùå Trial {trial.number:2d}: FAILED\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Main Enhanced Precision Optimization Pipeline\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ ENHANCED PRECISION-OPTIMIZED GRU SEARCH\")\n",
    "    print(\"üéØ Maximizing PRECISION with improved parameters\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"üìä Using F{BETA} score (Œ≤={BETA}) - 2x weight to PRECISION\")\n",
    "    print(f\"üéØ Enhanced with {N_TRIALS} trials and focused ranges\")\n",
    "    \n",
    "    try:\n",
    "        # Configure GPU\n",
    "        gpu_available = configure_gpu()\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        features, target, dates = load_and_preprocess_data()\n",
    "        \n",
    "        # Proper scaling\n",
    "        split_idx = int(len(features) * (1 - VAL_FRAC))\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(features.iloc[:split_idx])\n",
    "        \n",
    "        X_train_scaled = scaler.transform(features.iloc[:split_idx])\n",
    "        X_val_scaled = scaler.transform(features.iloc[split_idx:])\n",
    "        y_train = target[:split_idx]\n",
    "        y_val = target[split_idx:]\n",
    "        \n",
    "        print(f\"üìä Train: {len(X_train_scaled)} samples, Val: {len(X_val_scaled)} samples\")\n",
    "        \n",
    "        # Save scaler\n",
    "        joblib.dump(scaler, \"gru_enhanced_precision_scaler.pkl\")\n",
    "        \n",
    "        # Prepare data\n",
    "        data_info = (X_train_scaled, X_val_scaled, y_train, y_val)\n",
    "        \n",
    "        # Create enhanced study\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "            pruner=optuna.pruners.MedianPruner(\n",
    "                n_startup_trials=8,  # More startup trials\n",
    "                n_warmup_steps=5\n",
    "            ),\n",
    "            study_name=\"gru_enhanced_precision\"\n",
    "        )\n",
    "        \n",
    "        # Run enhanced optimization\n",
    "        print(f\"\\nüîç Starting ENHANCED PRECISION optimization...\")\n",
    "        print(f\"   Focus: Precision with focused parameter ranges\")\n",
    "        print(f\"   Trials: {N_TRIALS}, Timeout: {TIMEOUT//60}min\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        study.optimize(\n",
    "            lambda trial: enhanced_precision_objective(trial, data_info),\n",
    "            n_trials=N_TRIALS,\n",
    "            timeout=TIMEOUT,\n",
    "            show_progress_bar=True,\n",
    "            callbacks=[enhanced_precision_callback]\n",
    "        )\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Enhanced results analysis\n",
    "        print(f\"\\nüèÜ ENHANCED PRECISION OPTIMIZATION COMPLETED\")\n",
    "        print(\"=\" * 55)\n",
    "        \n",
    "        completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "        \n",
    "        if completed_trials:\n",
    "            best_combined_score = 1 - study.best_value\n",
    "            best_trial = study.best_trial\n",
    "            \n",
    "            print(f\"‚≠ê Best combined score: {best_combined_score:.4f}\")\n",
    "            print(f\"üìä Completed trials: {len(completed_trials)}\")\n",
    "            print(f\"‚è±Ô∏è  Total time: {total_time/60:.1f} minutes\")\n",
    "            \n",
    "            # Best trial metrics\n",
    "            if hasattr(best_trial, 'user_attrs'):\n",
    "                attrs = best_trial.user_attrs\n",
    "                print(f\"\\nüéØ BEST ENHANCED PRECISION METRICS:\")\n",
    "                print(f\"   Precision: {attrs.get('precision', 'N/A'):.4f} ‚≠ê\")\n",
    "                print(f\"   Recall: {attrs.get('recall', 'N/A'):.4f}\")\n",
    "                print(f\"   F0.5-score: {attrs.get('f_half_score', 'N/A'):.4f}\")\n",
    "                print(f\"   F1-score: {attrs.get('f1_score', 'N/A'):.4f}\")\n",
    "                print(f\"   Decision threshold: {attrs.get('decision_threshold', 'N/A'):.3f}\")\n",
    "                print(f\"   Positive predictions: {attrs.get('n_positive_predictions', 'N/A')}\")\n",
    "            \n",
    "            print(f\"\\nüéØ ENHANCED BEST PARAMETERS:\")\n",
    "            for param, value in study.best_params.items():\n",
    "                print(f\"   {param:15s}: {value}\")\n",
    "            \n",
    "            # Save enhanced results\n",
    "            enhanced_params = {\n",
    "                **study.best_params,\n",
    "                \"optimization_type\": \"enhanced_precision\",\n",
    "                \"beta_score\": BETA,\n",
    "                \"precision_weight\": PRECISION_WEIGHT,\n",
    "                \"n_trials\": N_TRIALS,\n",
    "                \"best_metrics\": {\n",
    "                    k: float(v) if isinstance(v, (int, float, np.number)) else v\n",
    "                    for k, v in best_trial.user_attrs.items()\n",
    "                    if k in ['precision', 'recall', 'f_half_score', 'f1_score', 'decision_threshold', 'final_combined_score']\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(\"gru_enhanced_precision_params.json\", \"w\") as f:\n",
    "                json.dump(enhanced_params, f, indent=2)\n",
    "            \n",
    "            print(f\"\\n‚úÖ Enhanced precision parameters saved!\")\n",
    "            print(f\"üéØ Target: >0.60 precision with balanced recall\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå No trials completed successfully!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Enhanced optimization failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a31e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No GPU detected, using CPU\n",
      "üöÄ GRU Multi-Configuration Performance Test\n",
      "=======================================================\n",
      "üìä Loading and preprocessing data...\n",
      "   Loaded data: (11476, 66)\n",
      "   After cleaning: (11476, 20)\n",
      "   Features: 19\n",
      "   Target distribution: [5618 5858]\n",
      "   Train samples: 9,180\n",
      "   Val samples: 2,296\n",
      "\n",
      "======================================================================\n",
      "üî¨ Testing Configuration 1/6: Trial_4_Balanced\n",
      "======================================================================\n",
      "   Window: 30, Units: 128, Layers: 1\n",
      "   Dropout: 0.347, LR: 0.001995, L2: 2.50e-05\n",
      "   Batch: 64, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.547, R=0.424, F1=0.478, F0.5=0.517\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,150\n",
      "   Val sequences: 2,266\n",
      "   üöÄ Training model...\n",
      "   ‚è±Ô∏è  Training completed in 0:01:25.188557 (41 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   üìä Results:\n",
      "   ‚îú‚îÄ Precision: 0.555 (expected: 0.547) ‚úÖ [+0.008]\n",
      "   ‚îú‚îÄ Recall:    0.366 (expected: 0.424) ‚ùå [-0.058]\n",
      "   ‚îú‚îÄ F1 Score:  0.441 (expected: 0.478) ‚ùå [-0.037]\n",
      "   ‚îú‚îÄ F0.5 Score: 0.503 (expected: 0.517) ‚úÖ [-0.014]\n",
      "   ‚îú‚îÄ Accuracy:  0.518\n",
      "   ‚îú‚îÄ AUC:       0.535\n",
      "   ‚îî‚îÄ Positive predictions: 777\n",
      "   üíæ Model saved: gru_trial_4_balanced.h5\n",
      "\n",
      "======================================================================\n",
      "üî¨ Testing Configuration 2/6: Trial_6_HighPrecision\n",
      "======================================================================\n",
      "   Window: 42, Units: 96, Layers: 1\n",
      "   Dropout: 0.172, LR: 0.000529, L2: 1.87e-04\n",
      "   Batch: 64, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.556, R=0.221, F1=0.316, F0.5=0.427\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,138\n",
      "   Val sequences: 2,254\n",
      "   üöÄ Training model...\n",
      "   ‚è±Ô∏è  Training completed in 0:02:49.410080 (60 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   üìä Results:\n",
      "   ‚îú‚îÄ Precision: 0.536 (expected: 0.556) ‚ùå [-0.020]\n",
      "   ‚îú‚îÄ Recall:    0.484 (expected: 0.221) ‚úÖ [+0.263]\n",
      "   ‚îú‚îÄ F1 Score:  0.509 (expected: 0.316) ‚úÖ [+0.193]\n",
      "   ‚îú‚îÄ F0.5 Score: 0.525 (expected: 0.427) ‚úÖ [+0.098]\n",
      "   ‚îú‚îÄ Accuracy:  0.514\n",
      "   ‚îú‚îÄ AUC:       0.520\n",
      "   ‚îî‚îÄ Positive predictions: 1058\n",
      "   üíæ Model saved: gru_trial_6_highprecision.h5\n",
      "\n",
      "======================================================================\n",
      "üî¨ Testing Configuration 3/6: Trial_8_MaxPrecision\n",
      "======================================================================\n",
      "   Window: 24, Units: 128, Layers: 1\n",
      "   Dropout: 0.252, LR: 0.001056, L2: 2.78e-05\n",
      "   Batch: 64, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.585, R=0.111, F1=0.187, F0.5=0.316\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,156\n",
      "   Val sequences: 2,272\n",
      "   üöÄ Training model...\n",
      "   ‚è±Ô∏è  Training completed in 0:00:23.845321 (19 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   üìä Results:\n",
      "   ‚îú‚îÄ Precision: 0.527 (expected: 0.585) ‚ùå [-0.058]\n",
      "   ‚îú‚îÄ Recall:    0.435 (expected: 0.111) ‚úÖ [+0.324]\n",
      "   ‚îú‚îÄ F1 Score:  0.477 (expected: 0.187) ‚úÖ [+0.290]\n",
      "   ‚îú‚îÄ F0.5 Score: 0.505 (expected: 0.316) ‚úÖ [+0.189]\n",
      "   ‚îú‚îÄ Accuracy:  0.504\n",
      "   ‚îú‚îÄ AUC:       0.515\n",
      "   ‚îî‚îÄ Positive predictions: 974\n",
      "   üíæ Model saved: gru_trial_8_maxprecision.h5\n",
      "\n",
      "======================================================================\n",
      "üî¨ Testing Configuration 4/6: Trial_16_Conservative\n",
      "======================================================================\n",
      "   Window: 36, Units: 96, Layers: 2\n",
      "   Dropout: 0.301, LR: 0.001232, L2: 6.27e-05\n",
      "   Batch: 32, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.577, R=0.213, F1=0.311, F0.5=0.430\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,144\n",
      "   Val sequences: 2,260\n",
      "   üöÄ Training model...\n",
      "   ‚è±Ô∏è  Training completed in 0:03:35.994361 (50 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   üìä Results:\n",
      "   ‚îú‚îÄ Precision: 0.543 (expected: 0.577) ‚ùå [-0.034]\n",
      "   ‚îú‚îÄ Recall:    0.384 (expected: 0.213) ‚úÖ [+0.171]\n",
      "   ‚îú‚îÄ F1 Score:  0.450 (expected: 0.311) ‚úÖ [+0.139]\n",
      "   ‚îú‚îÄ F0.5 Score: 0.501 (expected: 0.430) ‚úÖ [+0.071]\n",
      "   ‚îú‚îÄ Accuracy:  0.512\n",
      "   ‚îú‚îÄ AUC:       0.529\n",
      "   ‚îî‚îÄ Positive predictions: 831\n",
      "   üíæ Model saved: gru_trial_16_conservative.h5\n",
      "\n",
      "======================================================================\n",
      "üî¨ Testing Configuration 5/6: Trial_20_Moderate\n",
      "======================================================================\n",
      "   Window: 36, Units: 96, Layers: 2\n",
      "   Dropout: 0.261, LR: 0.000857, L2: 4.03e-05\n",
      "   Batch: 32, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.530, R=0.723, F1=0.612, F0.5=0.560\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,144\n",
      "   Val sequences: 2,260\n",
      "   üöÄ Training model...\n",
      "   ‚è±Ô∏è  Training completed in 0:03:40.015653 (48 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   üìä Results:\n",
      "   ‚îú‚îÄ Precision: 0.537 (expected: 0.530) ‚úÖ [+0.007]\n",
      "   ‚îú‚îÄ Recall:    0.386 (expected: 0.723) ‚ùå [-0.337]\n",
      "   ‚îú‚îÄ F1 Score:  0.449 (expected: 0.612) ‚ùå [-0.163]\n",
      "   ‚îú‚îÄ F0.5 Score: 0.498 (expected: 0.560) ‚ùå [-0.062]\n",
      "   ‚îú‚îÄ Accuracy:  0.508\n",
      "   ‚îú‚îÄ AUC:       0.529\n",
      "   ‚îî‚îÄ Positive predictions: 843\n",
      "   üíæ Model saved: gru_trial_20_moderate.h5\n",
      "\n",
      "======================================================================\n",
      "üî¨ Testing Configuration 6/6: Trial_28_BestOverall\n",
      "======================================================================\n",
      "   Window: 36, Units: 96, Layers: 2\n",
      "   Dropout: 0.294, LR: 0.001390, L2: 2.52e-04\n",
      "   Batch: 32, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.522, R=0.991, F1=0.683, F0.5=0.576\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,144\n",
      "   Val sequences: 2,260\n",
      "   üöÄ Training model...\n",
      "   ‚è±Ô∏è  Training completed in 0:06:04.638538 (49 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   üìä Results:\n",
      "   ‚îú‚îÄ Precision: 0.551 (expected: 0.522) ‚úÖ [+0.029]\n",
      "   ‚îú‚îÄ Recall:    0.437 (expected: 0.991) ‚ùå [-0.554]\n",
      "   ‚îú‚îÄ F1 Score:  0.488 (expected: 0.683) ‚ùå [-0.195]\n",
      "   ‚îú‚îÄ F0.5 Score: 0.524 (expected: 0.576) ‚ùå [-0.052]\n",
      "   ‚îú‚îÄ Accuracy:  0.522\n",
      "   ‚îú‚îÄ AUC:       0.526\n",
      "   ‚îî‚îÄ Positive predictions: 933\n",
      "   üíæ Model saved: gru_trial_28_bestoverall.h5\n",
      "\n",
      "================================================================================\n",
      "üèÜ MULTI-CONFIGURATION TEST RESULTS\n",
      "================================================================================\n",
      "\n",
      "üìä Performance Summary (Successful: 6/6):\n",
      "                          Precision  Recall     F1   F0.5    AUC   Status\n",
      "--------------------------------------------------------------------------------\n",
      "Trial_4_Balanced              0.555   0.366  0.441  0.503  0.535   ‚úÖ Good\n",
      "Trial_6_HighPrecision         0.536   0.484  0.509  0.525  0.520 ‚ö†Ô∏è  Poor\n",
      "Trial_8_MaxPrecision          0.527   0.435  0.477  0.505  0.515 ‚ö†Ô∏è  Poor\n",
      "Trial_16_Conservative         0.543   0.384  0.450  0.501  0.529 ‚ö†Ô∏è  Poor\n",
      "Trial_20_Moderate             0.537   0.386  0.449  0.498  0.529 ‚ö†Ô∏è  Poor\n",
      "Trial_28_BestOverall          0.551   0.437  0.488  0.524  0.526 ‚ö†Ô∏è  Poor\n",
      "\n",
      "üèÜ Top Performers:\n",
      "   üéØ Best Precision: Trial_4_Balanced (0.555)\n",
      "   üìä Best F0.5:      Trial_6_HighPrecision (0.525)\n",
      "   ‚öñÔ∏è  Best Balanced:  Trial_6_HighPrecision (0.509)\n",
      "\n",
      "üìÅ Files Generated:\n",
      "   ‚Ä¢ gru_multi_config_results_20250613_113821.json - Complete test results\n",
      "   ‚Ä¢ gru_multi_config_scaler.pkl - Feature scaler\n",
      "   ‚Ä¢ gru_trial_*.h5 - Individual trained models\n",
      "\n",
      "üí° Recommendation:\n",
      "   Use Trial_6_HighPrecision for precision-focused trading\n",
      "\n",
      "üéâ Multi-configuration test complete!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gru_multi_config_test.py\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Tests multiple GRU configurations from optimization results.\n",
    "Trains each config and provides detailed performance summary.\n",
    "Identifies the best performing configuration for final training.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, \n",
    "                             fbeta_score, accuracy_score, roc_auc_score,\n",
    "                             confusion_matrix, classification_report)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Setup\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Configure GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU configured: {len(gpus)} device(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è  GPU configuration failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected, using CPU\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Configuration\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC = 0.20\n",
    "BETA = 0.5  # For F0.5 score (precision-focused)\n",
    "EPOCHS = 60\n",
    "EARLY_STOP = 15\n",
    "\n",
    "# Complete drop columns list (same as optimization)\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    'typical_price', 'vwap_24h', 'close_4h',\n",
    "    'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bollinger_width',\n",
    "    'resistance_level', 'support_level',\n",
    "    'high_low', 'high_close', 'low_close', 'true_range',\n",
    "    'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'CCI', 'stoch_%D', 'parkinson_vol',\n",
    "    'ema_cross_down', 'macd_cross_down', 'ema_cross_up', 'macd_cross_up',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'oversold_reversal', 'overbought_reversal',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'timestamp', 'date', 'Unnamed: 0'\n",
    "]\n",
    "\n",
    "# Top 6 configurations from your optimization results (threshold fixed at 0.5)\n",
    "TEST_CONFIGS = [\n",
    "    {\n",
    "        'name': 'Trial_4_Balanced',\n",
    "        'window': 30, 'units': 128, 'layers': 1, 'dropout': 0.3473773873201034,\n",
    "        'lr': 0.0019947718789028682, 'l2': 2.497073714505272e-05, 'batch': 64,\n",
    "        'expected': {'precision': 0.547, 'recall': 0.424, 'f1': 0.478, 'f05': 0.517}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Trial_6_HighPrecision',\n",
    "        'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.17157828539866088,\n",
    "        'lr': 0.0005289646680152981, 'l2': 0.000187422109855557, 'batch': 64,\n",
    "        'expected': {'precision': 0.556, 'recall': 0.221, 'f1': 0.316, 'f05': 0.427}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Trial_8_MaxPrecision',\n",
    "        'window': 24, 'units': 128, 'layers': 1, 'dropout': 0.2521494605155131,\n",
    "        'lr': 0.0010562796147104163, 'l2': 2.781093697926551e-05, 'batch': 64,\n",
    "        'expected': {'precision': 0.585, 'recall': 0.111, 'f1': 0.187, 'f05': 0.316}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Trial_16_Conservative',\n",
    "        'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.30094837842359834,\n",
    "        'lr': 0.0012323935680785315, 'l2': 6.268172739785502e-05, 'batch': 32,\n",
    "        'expected': {'precision': 0.577, 'recall': 0.213, 'f1': 0.311, 'f05': 0.430}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Trial_20_Moderate',\n",
    "        'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.26126299099534406,\n",
    "        'lr': 0.0008574666921947649, 'l2': 4.0337715213162597e-05, 'batch': 32,\n",
    "        'expected': {'precision': 0.530, 'recall': 0.723, 'f1': 0.612, 'f05': 0.560}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Trial_28_BestOverall',\n",
    "        'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.2944123891707492,\n",
    "        'lr': 0.0013899204674669833, 'l2': 0.0002516233411563695, 'batch': 32,\n",
    "        'expected': {'precision': 0.522, 'recall': 0.991, 'f1': 0.683, 'f05': 0.576}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Fixed threshold for all configurations\n",
    "DECISION_THRESHOLD = 0.5\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Helper Functions\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def create_sequences(data, labels, window_size):\n",
    "    \"\"\"Create sequences for time series data.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(labels[i])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "def build_gru_model(config, n_features):\n",
    "    \"\"\"Build GRU model with given configuration.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    for i in range(config['layers']):\n",
    "        return_sequences = (i < config['layers'] - 1)\n",
    "        model.add(keras.layers.GRU(\n",
    "            config['units'],\n",
    "            return_sequences=return_sequences,\n",
    "            dropout=config['dropout'],\n",
    "            recurrent_dropout=config['dropout'] * 0.6,\n",
    "            kernel_regularizer=keras.regularizers.l2(config['l2']),\n",
    "            recurrent_regularizer=keras.regularizers.l2(config['l2'])\n",
    "        ))\n",
    "    \n",
    "    model.add(keras.layers.Dropout(config['dropout']))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=config['lr']),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_prob, config_name, expected_metrics):\n",
    "    \"\"\"Calculate comprehensive metrics.\"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    f05 = fbeta_score(y_true, y_pred, beta=BETA, zero_division=0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Calculate differences from expected\n",
    "    precision_diff = precision - expected_metrics['precision']\n",
    "    recall_diff = recall - expected_metrics['recall']\n",
    "    f1_diff = f1 - expected_metrics['f1']\n",
    "    f05_diff = f05 - expected_metrics['f05']\n",
    "    \n",
    "    metrics = {\n",
    "        'config_name': config_name,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'f05_score': f05,\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc,\n",
    "        'n_positive_predictions': int(np.sum(y_pred)),\n",
    "        'expected_precision': expected_metrics['precision'],\n",
    "        'expected_recall': expected_metrics['recall'],\n",
    "        'expected_f1': expected_metrics['f1'],\n",
    "        'expected_f05': expected_metrics['f05'],\n",
    "        'precision_diff': precision_diff,\n",
    "        'recall_diff': recall_diff,\n",
    "        'f1_diff': f1_diff,\n",
    "        'f05_diff': f05_diff,\n",
    "        'confusion_matrix': confusion_matrix(y_true, y_pred).tolist()\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Data Loading and Preprocessing\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(\"üöÄ GRU Multi-Configuration Performance Test\")\n",
    "print(\"=\" * 55)\n",
    "print(\"üìä Loading and preprocessing data...\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df[df.index >= \"2020-01-01\"]  # Same as optimization\n",
    "print(f\"   Loaded data: {df.shape}\")\n",
    "\n",
    "# Clean data\n",
    "if 'target' not in df.columns:\n",
    "    raise ValueError(\"‚ùå Target column not found!\")\n",
    "\n",
    "# Drop columns\n",
    "cols_to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "df = df[df[\"target\"].notna()].dropna()\n",
    "print(f\"   After cleaning: {df.shape}\")\n",
    "\n",
    "# Prepare features and target\n",
    "features = df.drop(columns=\"target\")\n",
    "target = df[\"target\"].astype(int).values\n",
    "n_features = features.shape[1]\n",
    "\n",
    "print(f\"   Features: {n_features}\")\n",
    "print(f\"   Target distribution: {np.bincount(target)}\")\n",
    "\n",
    "# Scale features\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features.iloc[:split_idx])\n",
    "\n",
    "X_train_scaled = scaler.transform(features.iloc[:split_idx])\n",
    "X_val_scaled = scaler.transform(features.iloc[split_idx:])\n",
    "y_train = target[:split_idx]\n",
    "y_val = target[split_idx:]\n",
    "\n",
    "print(f\"   Train samples: {len(X_train_scaled):,}\")\n",
    "print(f\"   Val samples: {len(X_val_scaled):,}\")\n",
    "\n",
    "# Save scaler for later use\n",
    "joblib.dump(scaler, \"gru_multi_config_scaler.pkl\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Test Each Configuration\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "results = []\n",
    "\n",
    "for i, config in enumerate(TEST_CONFIGS, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üî¨ Testing Configuration {i}/6: {config['name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Display configuration\n",
    "    print(f\"   Window: {config['window']}, Units: {config['units']}, Layers: {config['layers']}\")\n",
    "    print(f\"   Dropout: {config['dropout']:.3f}, LR: {config['lr']:.6f}, L2: {config['l2']:.2e}\")\n",
    "    print(f\"   Batch: {config['batch']}, Threshold: {DECISION_THRESHOLD} (fixed)\")\n",
    "    \n",
    "    # Expected performance\n",
    "    exp = config['expected']\n",
    "    print(f\"   Expected: P={exp['precision']:.3f}, R={exp['recall']:.3f}, F1={exp['f1']:.3f}, F0.5={exp['f05']:.3f}\")\n",
    "    print(f\"   Note: Expected values were from optimized thresholds, actual results may differ\")\n",
    "    \n",
    "    try:\n",
    "        # Create sequences\n",
    "        X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, config['window'])\n",
    "        X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, config['window'])\n",
    "        \n",
    "        print(f\"   Train sequences: {len(X_train_seq):,}\")\n",
    "        print(f\"   Val sequences: {len(X_val_seq):,}\")\n",
    "        \n",
    "        # Build model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        model = build_gru_model(config, n_features)\n",
    "        \n",
    "        print(\"   üöÄ Training model...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Train model\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=EARLY_STOP,\n",
    "                restore_best_weights=True,\n",
    "                verbose=0\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=7,\n",
    "                min_lr=1e-7,\n",
    "                verbose=0\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=config['batch'],\n",
    "            validation_data=(X_val_seq, y_val_seq),\n",
    "            callbacks=callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        training_time = datetime.now() - start_time\n",
    "        epochs_trained = len(history.history['loss'])\n",
    "        \n",
    "        print(f\"   ‚è±Ô∏è  Training completed in {training_time} ({epochs_trained} epochs)\")\n",
    "        \n",
    "        # Evaluate model\n",
    "        y_pred_prob = model.predict(X_val_seq, verbose=0).ravel()\n",
    "        y_pred = (y_pred_prob >= DECISION_THRESHOLD).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(y_val_seq, y_pred, y_pred_prob, config['name'], config['expected'])\n",
    "        metrics['training_time_seconds'] = training_time.total_seconds()\n",
    "        metrics['epochs_trained'] = epochs_trained\n",
    "        metrics['config'] = {k: v for k, v in config.items() if k not in ['name', 'expected']}\n",
    "        metrics['config']['threshold_used'] = DECISION_THRESHOLD\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\n   üìä Results:\")\n",
    "        print(f\"   ‚îú‚îÄ Precision: {metrics['precision']:.3f} (expected: {exp['precision']:.3f}) \"\n",
    "              f\"{'‚úÖ' if metrics['precision_diff'] >= -0.02 else '‚ùå'} [{metrics['precision_diff']:+.3f}]\")\n",
    "        print(f\"   ‚îú‚îÄ Recall:    {metrics['recall']:.3f} (expected: {exp['recall']:.3f}) \"\n",
    "              f\"{'‚úÖ' if metrics['recall_diff'] >= -0.02 else '‚ùå'} [{metrics['recall_diff']:+.3f}]\")\n",
    "        print(f\"   ‚îú‚îÄ F1 Score:  {metrics['f1_score']:.3f} (expected: {exp['f1']:.3f}) \"\n",
    "              f\"{'‚úÖ' if metrics['f1_diff'] >= -0.02 else '‚ùå'} [{metrics['f1_diff']:+.3f}]\")\n",
    "        print(f\"   ‚îú‚îÄ F0.5 Score: {metrics['f05_score']:.3f} (expected: {exp['f05']:.3f}) \"\n",
    "              f\"{'‚úÖ' if metrics['f05_diff'] >= -0.02 else '‚ùå'} [{metrics['f05_diff']:+.3f}]\")\n",
    "        print(f\"   ‚îú‚îÄ Accuracy:  {metrics['accuracy']:.3f}\")\n",
    "        print(f\"   ‚îú‚îÄ AUC:       {metrics['auc']:.3f}\")\n",
    "        print(f\"   ‚îî‚îÄ Positive predictions: {metrics['n_positive_predictions']}\")\n",
    "        \n",
    "        # Save model if it meets expectations\n",
    "        model_filename = f\"gru_{config['name'].lower()}.h5\"\n",
    "        model.save(model_filename)\n",
    "        print(f\"   üíæ Model saved: {model_filename}\")\n",
    "        \n",
    "        results.append(metrics)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Training failed: {str(e)}\")\n",
    "        error_metrics = {\n",
    "            'config_name': config['name'],\n",
    "            'error': str(e),\n",
    "            'status': 'failed'\n",
    "        }\n",
    "        results.append(error_metrics)\n",
    "    \n",
    "    finally:\n",
    "        # Cleanup\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Final Analysis and Summary\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üèÜ MULTI-CONFIGURATION TEST RESULTS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Filter successful results\n",
    "successful_results = [r for r in results if 'error' not in r]\n",
    "\n",
    "if successful_results:\n",
    "    print(f\"\\nüìä Performance Summary (Successful: {len(successful_results)}/{len(TEST_CONFIGS)}):\")\n",
    "    print(f\"{'':25s} {'Precision':>9s} {'Recall':>7s} {'F1':>6s} {'F0.5':>6s} {'AUC':>6s} {'Status':>8s}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for result in successful_results:\n",
    "        status = \"‚úÖ Good\" if result['precision_diff'] >= -0.02 and result['f05_diff'] >= -0.02 else \"‚ö†Ô∏è  Poor\"\n",
    "        print(f\"{result['config_name']:25s} {result['precision']:>9.3f} {result['recall']:>7.3f} \"\n",
    "              f\"{result['f1_score']:>6.3f} {result['f05_score']:>6.3f} {result['auc']:>6.3f} {status:>8s}\")\n",
    "    \n",
    "    # Find best performers\n",
    "    best_precision = max(successful_results, key=lambda x: x['precision'])\n",
    "    best_f05 = max(successful_results, key=lambda x: x['f05_score'])\n",
    "    best_balanced = max(successful_results, key=lambda x: x['f1_score'])\n",
    "    \n",
    "    print(f\"\\nüèÜ Top Performers:\")\n",
    "    print(f\"   üéØ Best Precision: {best_precision['config_name']} ({best_precision['precision']:.3f})\")\n",
    "    print(f\"   üìä Best F0.5:      {best_f05['config_name']} ({best_f05['f05_score']:.3f})\")\n",
    "    print(f\"   ‚öñÔ∏è  Best Balanced:  {best_balanced['config_name']} ({best_balanced['f1_score']:.3f})\")\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    summary = {\n",
    "        \"timestamp\": timestamp + \"Z\",\n",
    "        \"test_type\": \"multi_configuration_comparison\",\n",
    "        \"configurations_tested\": len(TEST_CONFIGS),\n",
    "        \"successful_configs\": len(successful_results),\n",
    "        \"dataset_info\": {\n",
    "            \"total_samples\": len(df),\n",
    "            \"train_samples\": len(X_train_scaled),\n",
    "            \"val_samples\": len(X_val_scaled),\n",
    "            \"features\": n_features\n",
    "        },\n",
    "        \"best_performers\": {\n",
    "            \"best_precision\": best_precision['config_name'],\n",
    "            \"best_f05\": best_f05['config_name'],\n",
    "            \"best_balanced\": best_balanced['config_name']\n",
    "        },\n",
    "        \"detailed_results\": results\n",
    "    }\n",
    "    \n",
    "    results_filename = f\"gru_multi_config_results_{timestamp}.json\"\n",
    "    with open(results_filename, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüìÅ Files Generated:\")\n",
    "    print(f\"   ‚Ä¢ {results_filename} - Complete test results\")\n",
    "    print(f\"   ‚Ä¢ gru_multi_config_scaler.pkl - Feature scaler\")\n",
    "    print(f\"   ‚Ä¢ gru_trial_*.h5 - Individual trained models\")\n",
    "    \n",
    "    print(f\"\\nüí° Recommendation:\")\n",
    "    if best_f05['f05_score'] >= 0.5:\n",
    "        print(f\"   Use {best_f05['config_name']} for precision-focused trading\")\n",
    "    elif best_balanced['f1_score'] >= 0.6:\n",
    "        print(f\"   Use {best_balanced['config_name']} for balanced performance\")\n",
    "    else:\n",
    "        print(f\"   Consider additional hyperparameter tuning or different approach\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No configurations completed successfully!\")\n",
    "\n",
    "print(f\"\\nüéâ Multi-configuration test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d45bfb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No GPU detected, using CPU\n",
      "üöÄ GRU Trial 28 Final Training\n",
      "=============================================\n",
      "üéØ Configuration: BestOverall (0.551 precision, 0.437 recall)\n",
      "üìä Loading and preprocessing data...\n",
      "   Loaded data: (11476, 66)\n",
      "   After cleaning: (11476, 20)\n",
      "   Features: 19\n",
      "   Target distribution: [5618 5858]\n",
      "   Train samples: 9,180\n",
      "   Val samples: 2,296\n",
      "   Scaler saved: gru_trial28_scaler.pkl\n",
      "\n",
      "üîÑ Creating sequences (window=36)...\n",
      "   Train sequences: 9,144\n",
      "   Val sequences: 2,260\n",
      "\n",
      "üèóÔ∏è Building GRU model...\n",
      "   Units: 96, Layers: 2\n",
      "   Dropout: 0.294, LR: 0.001390\n",
      "   L2: 2.52e-04, Batch: 32\n",
      "\n",
      "üìã Model architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                               </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                    </span>‚îÉ<span style=\"font-weight: bold\">           Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                                  ‚îÇ ?                               ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                                ‚îÇ ?                               ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                          ‚îÇ ?                               ‚îÇ                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                              ‚îÇ ?                               ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                              \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ gru (\u001b[38;5;33mGRU\u001b[0m)                                  ‚îÇ ?                               ‚îÇ       \u001b[38;5;34m0\u001b[0m (unbuilt) ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                                ‚îÇ ?                               ‚îÇ       \u001b[38;5;34m0\u001b[0m (unbuilt) ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (\u001b[38;5;33mDropout\u001b[0m)                          ‚îÇ ?                               ‚îÇ                 \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                              ‚îÇ ?                               ‚îÇ       \u001b[38;5;34m0\u001b[0m (unbuilt) ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training model...\n",
      "   Epochs: 80, Early stopping: 15\n",
      "   Expected performance: P=0.551, R=0.437\n",
      "Epoch 1/80\n",
      "286/286 - 7s - 24ms/step - accuracy: 0.5024 - loss: 0.7586 - val_accuracy: 0.4996 - val_loss: 0.7292 - learning_rate: 0.0014\n",
      "Epoch 2/80\n",
      "286/286 - 4s - 15ms/step - accuracy: 0.5094 - loss: 0.7253 - val_accuracy: 0.4867 - val_loss: 0.7220 - learning_rate: 0.0014\n",
      "Epoch 3/80\n",
      "286/286 - 6s - 20ms/step - accuracy: 0.5046 - loss: 0.7160 - val_accuracy: 0.4796 - val_loss: 0.7143 - learning_rate: 0.0014\n",
      "Epoch 4/80\n",
      "286/286 - 9s - 30ms/step - accuracy: 0.5107 - loss: 0.7094 - val_accuracy: 0.4823 - val_loss: 0.7135 - learning_rate: 0.0014\n",
      "Epoch 5/80\n",
      "286/286 - 8s - 30ms/step - accuracy: 0.5086 - loss: 0.7052 - val_accuracy: 0.4996 - val_loss: 0.7036 - learning_rate: 0.0014\n",
      "Epoch 6/80\n",
      "286/286 - 8s - 30ms/step - accuracy: 0.5172 - loss: 0.7020 - val_accuracy: 0.4987 - val_loss: 0.7010 - learning_rate: 0.0014\n",
      "Epoch 7/80\n",
      "286/286 - 8s - 30ms/step - accuracy: 0.5197 - loss: 0.6986 - val_accuracy: 0.4956 - val_loss: 0.7012 - learning_rate: 0.0014\n",
      "Epoch 8/80\n",
      "286/286 - 8s - 29ms/step - accuracy: 0.5226 - loss: 0.6978 - val_accuracy: 0.4929 - val_loss: 0.6995 - learning_rate: 0.0014\n",
      "Epoch 9/80\n",
      "286/286 - 8s - 30ms/step - accuracy: 0.5137 - loss: 0.6972 - val_accuracy: 0.5000 - val_loss: 0.6975 - learning_rate: 0.0014\n",
      "Epoch 10/80\n",
      "286/286 - 8s - 30ms/step - accuracy: 0.5122 - loss: 0.6960 - val_accuracy: 0.4929 - val_loss: 0.6967 - learning_rate: 0.0014\n",
      "Epoch 11/80\n",
      "286/286 - 9s - 30ms/step - accuracy: 0.5182 - loss: 0.6953 - val_accuracy: 0.5084 - val_loss: 0.6953 - learning_rate: 0.0014\n",
      "Epoch 12/80\n",
      "286/286 - 9s - 31ms/step - accuracy: 0.5112 - loss: 0.6950 - val_accuracy: 0.5208 - val_loss: 0.6942 - learning_rate: 0.0014\n",
      "Epoch 13/80\n",
      "286/286 - 9s - 31ms/step - accuracy: 0.5172 - loss: 0.6943 - val_accuracy: 0.5106 - val_loss: 0.6941 - learning_rate: 0.0014\n",
      "Epoch 14/80\n",
      "286/286 - 9s - 30ms/step - accuracy: 0.5165 - loss: 0.6940 - val_accuracy: 0.5150 - val_loss: 0.6936 - learning_rate: 0.0014\n",
      "Epoch 15/80\n",
      "286/286 - 9s - 30ms/step - accuracy: 0.5139 - loss: 0.6939 - val_accuracy: 0.5288 - val_loss: 0.6933 - learning_rate: 0.0014\n",
      "Epoch 16/80\n",
      "286/286 - 7s - 24ms/step - accuracy: 0.5196 - loss: 0.6935 - val_accuracy: 0.5217 - val_loss: 0.6930 - learning_rate: 0.0014\n",
      "Epoch 17/80\n",
      "286/286 - 4s - 15ms/step - accuracy: 0.5162 - loss: 0.6934 - val_accuracy: 0.5235 - val_loss: 0.6932 - learning_rate: 0.0014\n",
      "Epoch 18/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5167 - loss: 0.6932 - val_accuracy: 0.5181 - val_loss: 0.6934 - learning_rate: 0.0014\n",
      "Epoch 19/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5196 - loss: 0.6933 - val_accuracy: 0.5164 - val_loss: 0.6928 - learning_rate: 0.0014\n",
      "Epoch 20/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5171 - loss: 0.6931 - val_accuracy: 0.5208 - val_loss: 0.6931 - learning_rate: 0.0014\n",
      "Epoch 21/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5160 - loss: 0.6934 - val_accuracy: 0.5084 - val_loss: 0.6934 - learning_rate: 0.0014\n",
      "Epoch 22/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5140 - loss: 0.6931 - val_accuracy: 0.5009 - val_loss: 0.6943 - learning_rate: 0.0014\n",
      "Epoch 23/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5171 - loss: 0.6935 - val_accuracy: 0.5221 - val_loss: 0.6931 - learning_rate: 0.0014\n",
      "Epoch 24/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5160 - loss: 0.6937 - val_accuracy: 0.5133 - val_loss: 0.6946 - learning_rate: 0.0014\n",
      "Epoch 25/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5180 - loss: 0.6938 - val_accuracy: 0.5195 - val_loss: 0.6936 - learning_rate: 0.0014\n",
      "Epoch 26/80\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0006949602393433452.\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5189 - loss: 0.6936 - val_accuracy: 0.5204 - val_loss: 0.6938 - learning_rate: 0.0014\n",
      "Epoch 27/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5180 - loss: 0.6930 - val_accuracy: 0.5257 - val_loss: 0.6931 - learning_rate: 6.9496e-04\n",
      "Epoch 28/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5231 - loss: 0.6927 - val_accuracy: 0.5150 - val_loss: 0.6938 - learning_rate: 6.9496e-04\n",
      "Epoch 29/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5208 - loss: 0.6928 - val_accuracy: 0.5195 - val_loss: 0.6935 - learning_rate: 6.9496e-04\n",
      "Epoch 30/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5180 - loss: 0.6930 - val_accuracy: 0.5221 - val_loss: 0.6931 - learning_rate: 6.9496e-04\n",
      "Epoch 31/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5187 - loss: 0.6928 - val_accuracy: 0.5199 - val_loss: 0.6931 - learning_rate: 6.9496e-04\n",
      "Epoch 32/80\n",
      "286/286 - 4s - 15ms/step - accuracy: 0.5235 - loss: 0.6926 - val_accuracy: 0.5181 - val_loss: 0.6931 - learning_rate: 6.9496e-04\n",
      "Epoch 33/80\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0003474801196716726.\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5217 - loss: 0.6925 - val_accuracy: 0.5164 - val_loss: 0.6939 - learning_rate: 6.9496e-04\n",
      "Epoch 34/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5192 - loss: 0.6921 - val_accuracy: 0.5230 - val_loss: 0.6931 - learning_rate: 3.4748e-04\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\n",
      "‚è±Ô∏è  Training completed in 0:03:20.715130 (34 epochs)\n",
      "\n",
      "üìä Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Final Results:\n",
      "   Precision: 0.536 (expected: 0.551) [-0.015]\n",
      "   Recall:    0.516 (expected: 0.437) [+0.079]\n",
      "   F1 Score:  0.526 (expected: 0.488) [+0.038]\n",
      "   F0.5 Score: 0.532 (expected: 0.524) [+0.008]\n",
      "   Accuracy:  0.516\n",
      "   AUC:       0.527\n",
      "   Positive predictions: 1130\n",
      "\n",
      "üìã Confusion Matrix:\n",
      "[[561 524]\n",
      " [569 606]]\n",
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.50      0.52      0.51      1085\n",
      "          Up       0.54      0.52      0.53      1175\n",
      "\n",
      "    accuracy                           0.52      2260\n",
      "   macro avg       0.52      0.52      0.52      2260\n",
      "weighted avg       0.52      0.52      0.52      2260\n",
      "\n",
      "\n",
      "üìÅ Generating predictions CSV...\n",
      "   Predictions saved: gru_trial28_predictions.csv\n",
      "   Total predictions: 2,260\n",
      "\n",
      "üìã Sample predictions:\n",
      "          timestamp  prob_up  prob_down  winning_prob  prediction  actual\n",
      "2024-03-16 12:00:00 0.519279   0.480721      0.519279           1       1\n",
      "2024-03-16 16:00:00 0.520203   0.479797      0.520203           1       0\n",
      "2024-03-16 20:00:00 0.519091   0.480909      0.519091           1       0\n",
      "2024-03-17 00:00:00 0.519558   0.480442      0.519558           1       1\n",
      "2024-03-17 04:00:00 0.521405   0.478595      0.521405           1       1\n",
      "2024-03-17 08:00:00 0.520473   0.479527      0.520473           1       1\n",
      "2024-03-17 12:00:00 0.516235   0.483765      0.516235           1       1\n",
      "2024-03-17 16:00:00 0.512534   0.487466      0.512534           1       1\n",
      "2024-03-17 20:00:00 0.505149   0.494851      0.505149           1       0\n",
      "2024-03-18 00:00:00 0.497947   0.502053      0.502053           0       1\n",
      "\n",
      "üíæ Saving model and summary...\n",
      "\n",
      "üéâ Trial 28 Final Training Complete!\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "üìà Performance Summary:\n",
      "   Precision: 0.536 (target: 0.551)\n",
      "   Recall: 0.516 (target: 0.437)\n",
      "   F1 Score: 0.526 (target: 0.488)\n",
      "   F0.5 Score: 0.532 (target: 0.524)\n",
      "   AUC: 0.527\n",
      "\n",
      "üìÅ Files Generated:\n",
      "   ‚Ä¢ gru_trial28_final.h5 - Trained GRU model\n",
      "   ‚Ä¢ gru_trial28_scaler.pkl - Feature scaler\n",
      "   ‚Ä¢ gru_trial28_predictions.csv - Validation predictions (2,260 rows)\n",
      "   ‚Ä¢ gru_trial28_training_summary.json - Complete training summary\n",
      "\n",
      "üéØ Model ready for production trading!\n",
      "   Expected: ~55% precision with ~44% recall\n",
      "   Configuration: 36-window, 96-unit, 2-layer GRU\n",
      "\n",
      "‚ú® Training pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gru_trial28_final_training.py\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Final training of Trial 28 (BestOverall) GRU configuration.\n",
    "Trains the model and generates predictions CSV in the exact format requested.\n",
    "\n",
    "Trial 28 Config: 0.551 precision, 0.437 recall, 0.488 F1, 0.524 F0.5\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, \n",
    "                             fbeta_score, accuracy_score, roc_auc_score,\n",
    "                             confusion_matrix, classification_report)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Setup\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Configure GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU configured: {len(gpus)} device(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è  GPU configuration failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected, using CPU\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Configuration\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC = 0.20\n",
    "DECISION_THRESHOLD = 0.5\n",
    "EPOCHS = 80\n",
    "EARLY_STOP = 15\n",
    "\n",
    "# Output files\n",
    "MODEL_OUT = \"gru_trial28_final.h5\"\n",
    "SCALER_OUT = \"gru_trial28_scaler.pkl\"\n",
    "PREDICTIONS_OUT = \"gru_trial28_predictions.csv\"\n",
    "SUMMARY_JSON = \"gru_trial28_training_summary.json\"\n",
    "\n",
    "# Complete drop columns list (same as optimization)\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    'typical_price', 'vwap_24h', 'close_4h',\n",
    "    'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bollinger_width',\n",
    "    'resistance_level', 'support_level',\n",
    "    'high_low', 'high_close', 'low_close', 'true_range',\n",
    "    'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'CCI', 'stoch_%D', 'parkinson_vol',\n",
    "    'ema_cross_down', 'macd_cross_down', 'ema_cross_up', 'macd_cross_up',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'oversold_reversal', 'overbought_reversal',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'timestamp', 'date', 'Unnamed: 0'\n",
    "]\n",
    "\n",
    "# Trial 28 Optimal Configuration\n",
    "TRIAL28_CONFIG = {\n",
    "    'name': 'Trial_28_BestOverall',\n",
    "    'window': 36,\n",
    "    'units': 96,\n",
    "    'layers': 2,\n",
    "    'dropout': 0.2944123891707492,\n",
    "    'lr': 0.0013899204674669833,\n",
    "    'l2': 0.0002516233411563695,\n",
    "    'batch': 32,\n",
    "    'expected_performance': {\n",
    "        'precision': 0.551,\n",
    "        'recall': 0.437,\n",
    "        'f1': 0.488,\n",
    "        'f05': 0.524\n",
    "    }\n",
    "}\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Helper Functions\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def create_sequences(data, labels, window_size):\n",
    "    \"\"\"Create sequences for time series data.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(labels[i])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "def build_gru_model(config, n_features):\n",
    "    \"\"\"Build GRU model with Trial 28 configuration.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    for i in range(config['layers']):\n",
    "        return_sequences = (i < config['layers'] - 1)\n",
    "        model.add(keras.layers.GRU(\n",
    "            config['units'],\n",
    "            return_sequences=return_sequences,\n",
    "            dropout=config['dropout'],\n",
    "            recurrent_dropout=config['dropout'] * 0.6,\n",
    "            kernel_regularizer=keras.regularizers.l2(config['l2']),\n",
    "            recurrent_regularizer=keras.regularizers.l2(config['l2'])\n",
    "        ))\n",
    "    \n",
    "    model.add(keras.layers.Dropout(config['dropout']))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=config['lr']),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Data Loading and Preprocessing\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(\"üöÄ GRU Trial 28 Final Training\")\n",
    "print(\"=\" * 45)\n",
    "print(\"üéØ Configuration: BestOverall (0.551 precision, 0.437 recall)\")\n",
    "print(\"üìä Loading and preprocessing data...\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df[df.index >= \"2020-01-01\"]  # Same as optimization\n",
    "print(f\"   Loaded data: {df.shape}\")\n",
    "\n",
    "# Clean data\n",
    "if 'target' not in df.columns:\n",
    "    raise ValueError(\"‚ùå Target column not found!\")\n",
    "\n",
    "# Drop columns\n",
    "cols_to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "df = df[df[\"target\"].notna()].dropna()\n",
    "print(f\"   After cleaning: {df.shape}\")\n",
    "\n",
    "# Prepare features and target\n",
    "features = df.drop(columns=\"target\")\n",
    "target = df[\"target\"].astype(int).values\n",
    "n_features = features.shape[1]\n",
    "\n",
    "print(f\"   Features: {n_features}\")\n",
    "print(f\"   Target distribution: {np.bincount(target)}\")\n",
    "\n",
    "# Scale features\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features.iloc[:split_idx])\n",
    "\n",
    "X_train_scaled = scaler.transform(features.iloc[:split_idx])\n",
    "X_val_scaled = scaler.transform(features.iloc[split_idx:])\n",
    "y_train = target[:split_idx]\n",
    "y_val = target[split_idx:]\n",
    "\n",
    "print(f\"   Train samples: {len(X_train_scaled):,}\")\n",
    "print(f\"   Val samples: {len(X_val_scaled):,}\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, SCALER_OUT)\n",
    "print(f\"   Scaler saved: {SCALER_OUT}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Create Sequences\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüîÑ Creating sequences (window={TRIAL28_CONFIG['window']})...\")\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, TRIAL28_CONFIG['window'])\n",
    "X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, TRIAL28_CONFIG['window'])\n",
    "\n",
    "print(f\"   Train sequences: {len(X_train_seq):,}\")\n",
    "print(f\"   Val sequences: {len(X_val_seq):,}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Build and Train Model\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüèóÔ∏è Building GRU model...\")\n",
    "print(f\"   Units: {TRIAL28_CONFIG['units']}, Layers: {TRIAL28_CONFIG['layers']}\")\n",
    "print(f\"   Dropout: {TRIAL28_CONFIG['dropout']:.3f}, LR: {TRIAL28_CONFIG['lr']:.6f}\")\n",
    "print(f\"   L2: {TRIAL28_CONFIG['l2']:.2e}, Batch: {TRIAL28_CONFIG['batch']}\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_gru_model(TRIAL28_CONFIG, n_features)\n",
    "\n",
    "# Display model summary\n",
    "print(f\"\\nüìã Model architecture:\")\n",
    "model.summary(line_length=100)\n",
    "\n",
    "# Prepare callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=EARLY_STOP,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=7,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"\\nüöÄ Training model...\")\n",
    "print(f\"   Epochs: {EPOCHS}, Early stopping: {EARLY_STOP}\")\n",
    "print(f\"   Expected performance: P={TRIAL28_CONFIG['expected_performance']['precision']:.3f}, \"\n",
    "      f\"R={TRIAL28_CONFIG['expected_performance']['recall']:.3f}\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=TRIAL28_CONFIG['batch'],\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "training_time = datetime.now() - start_time\n",
    "epochs_trained = len(history.history['loss'])\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Training completed in {training_time} ({epochs_trained} epochs)\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Evaluate Model\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüìä Evaluating model...\")\n",
    "\n",
    "y_pred_prob = model.predict(X_val_seq, verbose=0).ravel()\n",
    "y_pred = (y_pred_prob >= DECISION_THRESHOLD).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_val_seq, y_pred, zero_division=0)\n",
    "recall = recall_score(y_val_seq, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_val_seq, y_pred, zero_division=0)\n",
    "f05 = fbeta_score(y_val_seq, y_pred, beta=0.5, zero_division=0)\n",
    "accuracy = accuracy_score(y_val_seq, y_pred)\n",
    "auc = roc_auc_score(y_val_seq, y_pred_prob)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nüìà Final Results:\")\n",
    "expected = TRIAL28_CONFIG['expected_performance']\n",
    "print(f\"   Precision: {precision:.3f} (expected: {expected['precision']:.3f}) \"\n",
    "      f\"[{precision - expected['precision']:+.3f}]\")\n",
    "print(f\"   Recall:    {recall:.3f} (expected: {expected['recall']:.3f}) \"\n",
    "      f\"[{recall - expected['recall']:+.3f}]\")\n",
    "print(f\"   F1 Score:  {f1:.3f} (expected: {expected['f1']:.3f}) \"\n",
    "      f\"[{f1 - expected['f1']:+.3f}]\")\n",
    "print(f\"   F0.5 Score: {f05:.3f} (expected: {expected['f05']:.3f}) \"\n",
    "      f\"[{f05 - expected['f05']:+.3f}]\")\n",
    "print(f\"   Accuracy:  {accuracy:.3f}\")\n",
    "print(f\"   AUC:       {auc:.3f}\")\n",
    "print(f\"   Positive predictions: {np.sum(y_pred)}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val_seq, y_pred)\n",
    "print(f\"\\nüìã Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_val_seq, y_pred, target_names=[\"Down\", \"Up\"]))\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Generate Predictions CSV\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüìÅ Generating predictions CSV...\")\n",
    "\n",
    "# Get validation timestamps (accounting for window offset)\n",
    "val_start_idx = split_idx + TRIAL28_CONFIG['window']\n",
    "val_timestamps = df.index[val_start_idx:val_start_idx + len(y_pred_prob)]\n",
    "\n",
    "# Calculate probabilities\n",
    "prob_up = y_pred_prob\n",
    "prob_down = 1.0 - prob_up\n",
    "winning_prob = np.maximum(prob_up, prob_down)\n",
    "\n",
    "# Create predictions dataframe\n",
    "predictions_df = pd.DataFrame({\n",
    "    'timestamp': val_timestamps.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'prob_up': prob_up,\n",
    "    'prob_down': prob_down,\n",
    "    'winning_prob': winning_prob,\n",
    "    'prediction': y_pred,\n",
    "    'actual': y_val_seq\n",
    "})\n",
    "\n",
    "# Save predictions CSV\n",
    "predictions_df.to_csv(PREDICTIONS_OUT, index=False, float_format='%.6f')\n",
    "\n",
    "print(f\"   Predictions saved: {PREDICTIONS_OUT}\")\n",
    "print(f\"   Total predictions: {len(predictions_df):,}\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(f\"\\nüìã Sample predictions:\")\n",
    "print(predictions_df.head(10).to_string(index=False))\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Save Model and Summary\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüíæ Saving model and summary...\")\n",
    "\n",
    "# Save model\n",
    "model.save(MODEL_OUT)\n",
    "\n",
    "# Create comprehensive summary\n",
    "summary = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "    \"model_type\": \"GRU_Trial28_BestOverall\",\n",
    "    \"configuration\": TRIAL28_CONFIG,\n",
    "    \"dataset_info\": {\n",
    "        \"total_samples\": len(df),\n",
    "        \"train_samples\": len(X_train_scaled),\n",
    "        \"val_samples\": len(X_val_scaled),\n",
    "        \"features\": n_features,\n",
    "        \"window_size\": TRIAL28_CONFIG['window'],\n",
    "        \"train_period\": f\"{df.index[0]} to {df.index[split_idx-1]}\",\n",
    "        \"val_period\": f\"{df.index[split_idx]} to {df.index[-1]}\"\n",
    "    },\n",
    "    \"training_info\": {\n",
    "        \"epochs_trained\": epochs_trained,\n",
    "        \"training_time_seconds\": training_time.total_seconds(),\n",
    "        \"early_stopping_patience\": EARLY_STOP,\n",
    "        \"final_train_loss\": float(history.history['loss'][-1]),\n",
    "        \"final_val_loss\": float(history.history['val_loss'][-1]),\n",
    "        \"best_val_loss\": float(min(history.history['val_loss']))\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1_score\": float(f1),\n",
    "        \"f05_score\": float(f05),\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"auc\": float(auc),\n",
    "        \"decision_threshold\": DECISION_THRESHOLD,\n",
    "        \"positive_predictions\": int(np.sum(y_pred)),\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    },\n",
    "    \"expected_vs_actual\": {\n",
    "        \"precision_diff\": float(precision - expected['precision']),\n",
    "        \"recall_diff\": float(recall - expected['recall']),\n",
    "        \"f1_diff\": float(f1 - expected['f1']),\n",
    "        \"f05_diff\": float(f05 - expected['f05'])\n",
    "    },\n",
    "    \"class_distribution\": {\n",
    "        \"train_positive_rate\": float(np.mean(y_train)),\n",
    "        \"val_positive_rate\": float(np.mean(y_val)),\n",
    "        \"train_counts\": [int(np.sum(y_train == 0)), int(np.sum(y_train == 1))],\n",
    "        \"val_counts\": [int(np.sum(y_val == 0)), int(np.sum(y_val == 1))]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "with open(SUMMARY_JSON, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Final Report\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüéâ Trial 28 Final Training Complete!\")\n",
    "print(f\"‚ïê\" * 50)\n",
    "print(f\"üìà Performance Summary:\")\n",
    "print(f\"   Precision: {precision:.3f} (target: 0.551)\")\n",
    "print(f\"   Recall: {recall:.3f} (target: 0.437)\")\n",
    "print(f\"   F1 Score: {f1:.3f} (target: 0.488)\")\n",
    "print(f\"   F0.5 Score: {f05:.3f} (target: 0.524)\")\n",
    "print(f\"   AUC: {auc:.3f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Files Generated:\")\n",
    "print(f\"   ‚Ä¢ {MODEL_OUT} - Trained GRU model\")\n",
    "print(f\"   ‚Ä¢ {SCALER_OUT} - Feature scaler\")\n",
    "print(f\"   ‚Ä¢ {PREDICTIONS_OUT} - Validation predictions ({len(predictions_df):,} rows)\")\n",
    "print(f\"   ‚Ä¢ {SUMMARY_JSON} - Complete training summary\")\n",
    "\n",
    "print(f\"\\nüéØ Model ready for production trading!\")\n",
    "print(f\"   Expected: ~55% precision with ~44% recall\")\n",
    "print(f\"   Configuration: 36-window, 96-unit, 2-layer GRU\")\n",
    "\n",
    "# Cleanup\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\n‚ú® Training pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47ea7d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No GPU detected, using CPU\n",
      "üöÄ GRU Trial 28 Final Training\n",
      "=============================================\n",
      "üéØ Configuration: BestOverall (0.551 precision, 0.437 recall)\n",
      "üìä Loading and preprocessing data...\n",
      "   Loaded data: (11476, 66)\n",
      "   After cleaning: (11476, 20)\n",
      "   Features: 19\n",
      "   Target distribution: [5618 5858]\n",
      "   Train samples: 9,180\n",
      "   Val samples: 2,296\n",
      "   Scaler saved: gru_trial28_scaler.pkl\n",
      "\n",
      "üîÑ Creating sequences (window=30)...\n",
      "   Train sequences: 9,150\n",
      "   Val sequences: 2,266\n",
      "\n",
      "üèóÔ∏è Building GRU model...\n",
      "   Units: 128, Layers: 1\n",
      "   Dropout: 0.347, LR: 0.001995\n",
      "   L2: 2.50e-05, Batch: 64\n",
      "\n",
      "üìã Model architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                               </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                    </span>‚îÉ<span style=\"font-weight: bold\">           Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                                  ‚îÇ ?                               ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                          ‚îÇ ?                               ‚îÇ                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                              ‚îÇ ?                               ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                              \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ gru (\u001b[38;5;33mGRU\u001b[0m)                                  ‚îÇ ?                               ‚îÇ       \u001b[38;5;34m0\u001b[0m (unbuilt) ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout (\u001b[38;5;33mDropout\u001b[0m)                          ‚îÇ ?                               ‚îÇ                 \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                              ‚îÇ ?                               ‚îÇ       \u001b[38;5;34m0\u001b[0m (unbuilt) ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training model...\n",
      "   Epochs: 80, Early stopping: 15\n",
      "   Expected performance: P=0.547, R=0.424\n",
      "Epoch 1/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5014 - loss: 0.7136 - val_accuracy: 0.4965 - val_loss: 0.7100 - learning_rate: 0.0020\n",
      "Epoch 2/80\n",
      "143/143 - 1s - 9ms/step - accuracy: 0.5014 - loss: 0.7054 - val_accuracy: 0.4943 - val_loss: 0.7075 - learning_rate: 0.0020\n",
      "Epoch 3/80\n",
      "143/143 - 1s - 9ms/step - accuracy: 0.5082 - loss: 0.6999 - val_accuracy: 0.5132 - val_loss: 0.7022 - learning_rate: 0.0020\n",
      "Epoch 4/80\n",
      "143/143 - 1s - 9ms/step - accuracy: 0.5153 - loss: 0.6976 - val_accuracy: 0.5035 - val_loss: 0.7038 - learning_rate: 0.0020\n",
      "Epoch 5/80\n",
      "143/143 - 1s - 9ms/step - accuracy: 0.5217 - loss: 0.6962 - val_accuracy: 0.4996 - val_loss: 0.7028 - learning_rate: 0.0020\n",
      "Epoch 6/80\n",
      "143/143 - 1s - 9ms/step - accuracy: 0.5144 - loss: 0.6969 - val_accuracy: 0.4978 - val_loss: 0.7039 - learning_rate: 0.0020\n",
      "Epoch 7/80\n",
      "143/143 - 1s - 10ms/step - accuracy: 0.5252 - loss: 0.6954 - val_accuracy: 0.5000 - val_loss: 0.7013 - learning_rate: 0.0020\n",
      "Epoch 8/80\n",
      "143/143 - 1s - 10ms/step - accuracy: 0.5233 - loss: 0.6953 - val_accuracy: 0.5057 - val_loss: 0.7020 - learning_rate: 0.0020\n",
      "Epoch 9/80\n",
      "143/143 - 1s - 10ms/step - accuracy: 0.5190 - loss: 0.6957 - val_accuracy: 0.5097 - val_loss: 0.7002 - learning_rate: 0.0020\n",
      "Epoch 10/80\n",
      "143/143 - 1s - 10ms/step - accuracy: 0.5212 - loss: 0.6957 - val_accuracy: 0.5040 - val_loss: 0.7001 - learning_rate: 0.0020\n",
      "Epoch 11/80\n",
      "143/143 - 2s - 17ms/step - accuracy: 0.5246 - loss: 0.6948 - val_accuracy: 0.4960 - val_loss: 0.7032 - learning_rate: 0.0020\n",
      "Epoch 12/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5214 - loss: 0.6953 - val_accuracy: 0.4974 - val_loss: 0.7009 - learning_rate: 0.0020\n",
      "Epoch 13/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5303 - loss: 0.6946 - val_accuracy: 0.4960 - val_loss: 0.7049 - learning_rate: 0.0020\n",
      "Epoch 14/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5248 - loss: 0.6956 - val_accuracy: 0.5035 - val_loss: 0.7033 - learning_rate: 0.0020\n",
      "Epoch 15/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5286 - loss: 0.6955 - val_accuracy: 0.5000 - val_loss: 0.7033 - learning_rate: 0.0020\n",
      "Epoch 16/80\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0009973859414458275.\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5295 - loss: 0.6946 - val_accuracy: 0.5044 - val_loss: 0.7009 - learning_rate: 0.0020\n",
      "Epoch 17/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5356 - loss: 0.6929 - val_accuracy: 0.5146 - val_loss: 0.6990 - learning_rate: 9.9739e-04\n",
      "Epoch 18/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5316 - loss: 0.6927 - val_accuracy: 0.5102 - val_loss: 0.7001 - learning_rate: 9.9739e-04\n",
      "Epoch 19/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5356 - loss: 0.6923 - val_accuracy: 0.5177 - val_loss: 0.6975 - learning_rate: 9.9739e-04\n",
      "Epoch 20/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5427 - loss: 0.6915 - val_accuracy: 0.5137 - val_loss: 0.6978 - learning_rate: 9.9739e-04\n",
      "Epoch 21/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5376 - loss: 0.6921 - val_accuracy: 0.5071 - val_loss: 0.7003 - learning_rate: 9.9739e-04\n",
      "Epoch 22/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5349 - loss: 0.6927 - val_accuracy: 0.5146 - val_loss: 0.6979 - learning_rate: 9.9739e-04\n",
      "Epoch 23/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5410 - loss: 0.6917 - val_accuracy: 0.5146 - val_loss: 0.6991 - learning_rate: 9.9739e-04\n",
      "Epoch 24/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5411 - loss: 0.6909 - val_accuracy: 0.5115 - val_loss: 0.6994 - learning_rate: 9.9739e-04\n",
      "Epoch 25/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5401 - loss: 0.6907 - val_accuracy: 0.5132 - val_loss: 0.7007 - learning_rate: 9.9739e-04\n",
      "Epoch 26/80\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004986929707229137.\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5438 - loss: 0.6910 - val_accuracy: 0.5093 - val_loss: 0.7024 - learning_rate: 9.9739e-04\n",
      "Epoch 27/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5478 - loss: 0.6895 - val_accuracy: 0.5146 - val_loss: 0.7009 - learning_rate: 4.9869e-04\n",
      "Epoch 28/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5434 - loss: 0.6899 - val_accuracy: 0.5093 - val_loss: 0.7006 - learning_rate: 4.9869e-04\n",
      "Epoch 29/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5436 - loss: 0.6898 - val_accuracy: 0.5044 - val_loss: 0.7015 - learning_rate: 4.9869e-04\n",
      "Epoch 30/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5475 - loss: 0.6895 - val_accuracy: 0.5110 - val_loss: 0.7012 - learning_rate: 4.9869e-04\n",
      "Epoch 31/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5494 - loss: 0.6883 - val_accuracy: 0.5079 - val_loss: 0.7005 - learning_rate: 4.9869e-04\n",
      "Epoch 32/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5497 - loss: 0.6893 - val_accuracy: 0.5150 - val_loss: 0.7016 - learning_rate: 4.9869e-04\n",
      "Epoch 33/80\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00024934648536145687.\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5523 - loss: 0.6891 - val_accuracy: 0.5079 - val_loss: 0.7019 - learning_rate: 4.9869e-04\n",
      "Epoch 34/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5539 - loss: 0.6875 - val_accuracy: 0.5106 - val_loss: 0.7023 - learning_rate: 2.4935e-04\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\n",
      "‚è±Ô∏è  Training completed in 0:01:21.100067 (34 epochs)\n",
      "\n",
      "üìä Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Final Results:\n",
      "   Precision: 0.555 (expected: 0.547) [+0.008]\n",
      "   Recall:    0.359 (expected: 0.424) [-0.065]\n",
      "   F1 Score:  0.436 (expected: 0.478) [-0.042]\n",
      "   F0.5 Score: 0.500 (expected: 0.517) [-0.017]\n",
      "   Accuracy:  0.518\n",
      "   AUC:       0.532\n",
      "   Positive predictions: 760\n",
      "\n",
      "üìã Confusion Matrix:\n",
      "[[751 338]\n",
      " [755 422]]\n",
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.50      0.69      0.58      1089\n",
      "          Up       0.56      0.36      0.44      1177\n",
      "\n",
      "    accuracy                           0.52      2266\n",
      "   macro avg       0.53      0.52      0.51      2266\n",
      "weighted avg       0.53      0.52      0.50      2266\n",
      "\n",
      "\n",
      "üìÅ Generating predictions CSV...\n",
      "   Predictions saved: gru_trial28_predictions.csv\n",
      "   Total predictions: 2,266\n",
      "\n",
      "üìã Sample predictions:\n",
      "          timestamp  prob_up  prob_down  winning_prob  prediction  actual\n",
      "2024-03-15 12:00:00 0.593111   0.406889      0.593111           1       1\n",
      "2024-03-15 16:00:00 0.631037   0.368963      0.631037           1       0\n",
      "2024-03-15 20:00:00 0.597687   0.402313      0.597687           1       1\n",
      "2024-03-16 00:00:00 0.556668   0.443332      0.556668           1       0\n",
      "2024-03-16 04:00:00 0.525571   0.474429      0.525571           1       0\n",
      "2024-03-16 08:00:00 0.502145   0.497855      0.502145           1       0\n",
      "2024-03-16 12:00:00 0.490238   0.509762      0.509762           0       1\n",
      "2024-03-16 16:00:00 0.487143   0.512857      0.512857           0       0\n",
      "2024-03-16 20:00:00 0.520760   0.479240      0.520760           1       0\n",
      "2024-03-17 00:00:00 0.550666   0.449334      0.550666           1       1\n",
      "\n",
      "üíæ Saving model and summary...\n",
      "\n",
      "üéâ Trial 28 Final Training Complete!\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "üìà Performance Summary:\n",
      "   Precision: 0.555 (target: 0.551)\n",
      "   Recall: 0.359 (target: 0.437)\n",
      "   F1 Score: 0.436 (target: 0.488)\n",
      "   F0.5 Score: 0.500 (target: 0.524)\n",
      "   AUC: 0.532\n",
      "\n",
      "üìÅ Files Generated:\n",
      "   ‚Ä¢ gru_trial28_final.h5 - Trained GRU model\n",
      "   ‚Ä¢ gru_trial28_scaler.pkl - Feature scaler\n",
      "   ‚Ä¢ gru_trial28_predictions.csv - Validation predictions (2,266 rows)\n",
      "   ‚Ä¢ gru_trial28_training_summary.json - Complete training summary\n",
      "\n",
      "üéØ Model ready for production trading!\n",
      "   Expected: ~55% precision with ~44% recall\n",
      "   Configuration: 36-window, 96-unit, 2-layer GRU\n",
      "\n",
      "‚ú® Training pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gru_trial28_final_training.py\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Final training of Trial 28 (BestOverall) GRU configuration.\n",
    "Trains the model and generates predictions CSV in the exact format requested.\n",
    "\n",
    "Trial 28 Config: 0.551 precision, 0.437 recall, 0.488 F1, 0.524 F0.5\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, \n",
    "                             fbeta_score, accuracy_score, roc_auc_score,\n",
    "                             confusion_matrix, classification_report)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Setup\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Configure GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU configured: {len(gpus)} device(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è  GPU configuration failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected, using CPU\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Configuration\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC = 0.20\n",
    "DECISION_THRESHOLD = 0.5\n",
    "EPOCHS = 80\n",
    "EARLY_STOP = 15\n",
    "\n",
    "# Output files\n",
    "MODEL_OUT = \"gru_trial28_final.h5\"\n",
    "SCALER_OUT = \"gru_trial28_scaler.pkl\"\n",
    "PREDICTIONS_OUT = \"gru_trial28_predictions.csv\"\n",
    "SUMMARY_JSON = \"gru_trial28_training_summary.json\"\n",
    "\n",
    "# Complete drop columns list (same as optimization)\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    'typical_price', 'vwap_24h', 'close_4h',\n",
    "    'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bollinger_width',\n",
    "    'resistance_level', 'support_level',\n",
    "    'high_low', 'high_close', 'low_close', 'true_range',\n",
    "    'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'CCI', 'stoch_%D', 'parkinson_vol',\n",
    "    'ema_cross_down', 'macd_cross_down', 'ema_cross_up', 'macd_cross_up',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'oversold_reversal', 'overbought_reversal',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'timestamp', 'date', 'Unnamed: 0'\n",
    "]\n",
    "\n",
    "# Trial 28 Optimal Configuration\n",
    "TRIAL28_CONFIG =     {\n",
    "        'name': 'Trial_4_Balanced',\n",
    "        'window': 30, 'units': 128, 'layers': 1, 'dropout': 0.3473773873201034,\n",
    "        'lr': 0.0019947718789028682, 'l2': 2.497073714505272e-05, 'batch': 64,\n",
    "        'expected_performance': {'precision': 0.547, 'recall': 0.424, 'f1': 0.478, 'f05': 0.517}\n",
    "    }\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Helper Functions\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def create_sequences(data, labels, window_size):\n",
    "    \"\"\"Create sequences for time series data.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(labels[i])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "def build_gru_model(config, n_features):\n",
    "    \"\"\"Build GRU model with Trial 28 configuration.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    for i in range(config['layers']):\n",
    "        return_sequences = (i < config['layers'] - 1)\n",
    "        model.add(keras.layers.GRU(\n",
    "            config['units'],\n",
    "            return_sequences=return_sequences,\n",
    "            dropout=config['dropout'],\n",
    "            recurrent_dropout=config['dropout'] * 0.6,\n",
    "            kernel_regularizer=keras.regularizers.l2(config['l2']),\n",
    "            recurrent_regularizer=keras.regularizers.l2(config['l2'])\n",
    "        ))\n",
    "    \n",
    "    model.add(keras.layers.Dropout(config['dropout']))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=config['lr']),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Data Loading and Preprocessing\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(\"üöÄ GRU Trial 28 Final Training\")\n",
    "print(\"=\" * 45)\n",
    "print(\"üéØ Configuration: BestOverall (0.551 precision, 0.437 recall)\")\n",
    "print(\"üìä Loading and preprocessing data...\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df[df.index >= \"2020-01-01\"]  # Same as optimization\n",
    "print(f\"   Loaded data: {df.shape}\")\n",
    "\n",
    "# Clean data\n",
    "if 'target' not in df.columns:\n",
    "    raise ValueError(\"‚ùå Target column not found!\")\n",
    "\n",
    "# Drop columns\n",
    "cols_to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "df = df[df[\"target\"].notna()].dropna()\n",
    "print(f\"   After cleaning: {df.shape}\")\n",
    "\n",
    "# Prepare features and target\n",
    "features = df.drop(columns=\"target\")\n",
    "target = df[\"target\"].astype(int).values\n",
    "n_features = features.shape[1]\n",
    "\n",
    "print(f\"   Features: {n_features}\")\n",
    "print(f\"   Target distribution: {np.bincount(target)}\")\n",
    "\n",
    "# Scale features\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features.iloc[:split_idx])\n",
    "\n",
    "X_train_scaled = scaler.transform(features.iloc[:split_idx])\n",
    "X_val_scaled = scaler.transform(features.iloc[split_idx:])\n",
    "y_train = target[:split_idx]\n",
    "y_val = target[split_idx:]\n",
    "\n",
    "print(f\"   Train samples: {len(X_train_scaled):,}\")\n",
    "print(f\"   Val samples: {len(X_val_scaled):,}\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, SCALER_OUT)\n",
    "print(f\"   Scaler saved: {SCALER_OUT}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Create Sequences\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüîÑ Creating sequences (window={TRIAL28_CONFIG['window']})...\")\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, TRIAL28_CONFIG['window'])\n",
    "X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, TRIAL28_CONFIG['window'])\n",
    "\n",
    "print(f\"   Train sequences: {len(X_train_seq):,}\")\n",
    "print(f\"   Val sequences: {len(X_val_seq):,}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Build and Train Model\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüèóÔ∏è Building GRU model...\")\n",
    "print(f\"   Units: {TRIAL28_CONFIG['units']}, Layers: {TRIAL28_CONFIG['layers']}\")\n",
    "print(f\"   Dropout: {TRIAL28_CONFIG['dropout']:.3f}, LR: {TRIAL28_CONFIG['lr']:.6f}\")\n",
    "print(f\"   L2: {TRIAL28_CONFIG['l2']:.2e}, Batch: {TRIAL28_CONFIG['batch']}\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_gru_model(TRIAL28_CONFIG, n_features)\n",
    "\n",
    "# Display model summary\n",
    "print(f\"\\nüìã Model architecture:\")\n",
    "model.summary(line_length=100)\n",
    "\n",
    "# Prepare callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=EARLY_STOP,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=7,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"\\nüöÄ Training model...\")\n",
    "print(f\"   Epochs: {EPOCHS}, Early stopping: {EARLY_STOP}\")\n",
    "print(f\"   Expected performance: P={TRIAL28_CONFIG['expected_performance']['precision']:.3f}, \"\n",
    "      f\"R={TRIAL28_CONFIG['expected_performance']['recall']:.3f}\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=TRIAL28_CONFIG['batch'],\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "training_time = datetime.now() - start_time\n",
    "epochs_trained = len(history.history['loss'])\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Training completed in {training_time} ({epochs_trained} epochs)\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Evaluate Model\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüìä Evaluating model...\")\n",
    "\n",
    "y_pred_prob = model.predict(X_val_seq, verbose=0).ravel()\n",
    "y_pred = (y_pred_prob >= DECISION_THRESHOLD).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_val_seq, y_pred, zero_division=0)\n",
    "recall = recall_score(y_val_seq, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_val_seq, y_pred, zero_division=0)\n",
    "f05 = fbeta_score(y_val_seq, y_pred, beta=0.5, zero_division=0)\n",
    "accuracy = accuracy_score(y_val_seq, y_pred)\n",
    "auc = roc_auc_score(y_val_seq, y_pred_prob)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nüìà Final Results:\")\n",
    "expected = TRIAL28_CONFIG['expected_performance']\n",
    "print(f\"   Precision: {precision:.3f} (expected: {expected['precision']:.3f}) \"\n",
    "      f\"[{precision - expected['precision']:+.3f}]\")\n",
    "print(f\"   Recall:    {recall:.3f} (expected: {expected['recall']:.3f}) \"\n",
    "      f\"[{recall - expected['recall']:+.3f}]\")\n",
    "print(f\"   F1 Score:  {f1:.3f} (expected: {expected['f1']:.3f}) \"\n",
    "      f\"[{f1 - expected['f1']:+.3f}]\")\n",
    "print(f\"   F0.5 Score: {f05:.3f} (expected: {expected['f05']:.3f}) \"\n",
    "      f\"[{f05 - expected['f05']:+.3f}]\")\n",
    "print(f\"   Accuracy:  {accuracy:.3f}\")\n",
    "print(f\"   AUC:       {auc:.3f}\")\n",
    "print(f\"   Positive predictions: {np.sum(y_pred)}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val_seq, y_pred)\n",
    "print(f\"\\nüìã Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_val_seq, y_pred, target_names=[\"Down\", \"Up\"]))\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Generate Predictions CSV\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüìÅ Generating predictions CSV...\")\n",
    "\n",
    "# Get validation timestamps (accounting for window offset)\n",
    "val_start_idx = split_idx + TRIAL28_CONFIG['window']\n",
    "val_timestamps = df.index[val_start_idx:val_start_idx + len(y_pred_prob)]\n",
    "\n",
    "# Calculate probabilities\n",
    "prob_up = y_pred_prob\n",
    "prob_down = 1.0 - prob_up\n",
    "winning_prob = np.maximum(prob_up, prob_down)\n",
    "\n",
    "# Create predictions dataframe\n",
    "predictions_df = pd.DataFrame({\n",
    "    'timestamp': val_timestamps.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'prob_up': prob_up,\n",
    "    'prob_down': prob_down,\n",
    "    'winning_prob': winning_prob,\n",
    "    'prediction': y_pred,\n",
    "    'actual': y_val_seq\n",
    "})\n",
    "\n",
    "# Save predictions CSV\n",
    "predictions_df.to_csv(PREDICTIONS_OUT, index=False, float_format='%.6f')\n",
    "\n",
    "print(f\"   Predictions saved: {PREDICTIONS_OUT}\")\n",
    "print(f\"   Total predictions: {len(predictions_df):,}\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(f\"\\nüìã Sample predictions:\")\n",
    "print(predictions_df.head(10).to_string(index=False))\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Save Model and Summary\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüíæ Saving model and summary...\")\n",
    "\n",
    "# Save model\n",
    "model.save(MODEL_OUT)\n",
    "\n",
    "# Create comprehensive summary\n",
    "summary = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "    \"model_type\": \"GRU_Trial28_BestOverall\",\n",
    "    \"configuration\": TRIAL28_CONFIG,\n",
    "    \"dataset_info\": {\n",
    "        \"total_samples\": len(df),\n",
    "        \"train_samples\": len(X_train_scaled),\n",
    "        \"val_samples\": len(X_val_scaled),\n",
    "        \"features\": n_features,\n",
    "        \"window_size\": TRIAL28_CONFIG['window'],\n",
    "        \"train_period\": f\"{df.index[0]} to {df.index[split_idx-1]}\",\n",
    "        \"val_period\": f\"{df.index[split_idx]} to {df.index[-1]}\"\n",
    "    },\n",
    "    \"training_info\": {\n",
    "        \"epochs_trained\": epochs_trained,\n",
    "        \"training_time_seconds\": training_time.total_seconds(),\n",
    "        \"early_stopping_patience\": EARLY_STOP,\n",
    "        \"final_train_loss\": float(history.history['loss'][-1]),\n",
    "        \"final_val_loss\": float(history.history['val_loss'][-1]),\n",
    "        \"best_val_loss\": float(min(history.history['val_loss']))\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1_score\": float(f1),\n",
    "        \"f05_score\": float(f05),\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"auc\": float(auc),\n",
    "        \"decision_threshold\": DECISION_THRESHOLD,\n",
    "        \"positive_predictions\": int(np.sum(y_pred)),\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    },\n",
    "    \"expected_vs_actual\": {\n",
    "        \"precision_diff\": float(precision - expected['precision']),\n",
    "        \"recall_diff\": float(recall - expected['recall']),\n",
    "        \"f1_diff\": float(f1 - expected['f1']),\n",
    "        \"f05_diff\": float(f05 - expected['f05'])\n",
    "    },\n",
    "    \"class_distribution\": {\n",
    "        \"train_positive_rate\": float(np.mean(y_train)),\n",
    "        \"val_positive_rate\": float(np.mean(y_val)),\n",
    "        \"train_counts\": [int(np.sum(y_train == 0)), int(np.sum(y_train == 1))],\n",
    "        \"val_counts\": [int(np.sum(y_val == 0)), int(np.sum(y_val == 1))]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "with open(SUMMARY_JSON, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Final Report\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(f\"\\nüéâ Trial 28 Final Training Complete!\")\n",
    "print(f\"‚ïê\" * 50)\n",
    "print(f\"üìà Performance Summary:\")\n",
    "print(f\"   Precision: {precision:.3f} (target: 0.551)\")\n",
    "print(f\"   Recall: {recall:.3f} (target: 0.437)\")\n",
    "print(f\"   F1 Score: {f1:.3f} (target: 0.488)\")\n",
    "print(f\"   F0.5 Score: {f05:.3f} (target: 0.524)\")\n",
    "print(f\"   AUC: {auc:.3f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Files Generated:\")\n",
    "print(f\"   ‚Ä¢ {MODEL_OUT} - Trained GRU model\")\n",
    "print(f\"   ‚Ä¢ {SCALER_OUT} - Feature scaler\")\n",
    "print(f\"   ‚Ä¢ {PREDICTIONS_OUT} - Validation predictions ({len(predictions_df):,} rows)\")\n",
    "print(f\"   ‚Ä¢ {SUMMARY_JSON} - Complete training summary\")\n",
    "\n",
    "print(f\"\\nüéØ Model ready for production trading!\")\n",
    "print(f\"   Expected: ~55% precision with ~44% recall\")\n",
    "print(f\"   Configuration: 36-window, 96-unit, 2-layer GRU\")\n",
    "\n",
    "# Cleanup\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\n‚ú® Training pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35df662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\src\\Models\\models\\models\\gru_trial28_predictions.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ca4d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation at threshold 0.5:\n",
      "Precision: 0.528\n",
      "Recall   : 0.951\n",
      "F1 Score : 0.679\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the predictions CSV\n",
    "csv_path = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\src\\Models\\models\\models\\gru_trial28_f05_preds.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Ensure column names are correct and lowercase\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Extract actual and predicted values\n",
    "y_true = df['actual']\n",
    "y_pred = df['prediction']  # prediction at threshold 0.5\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "# Print results\n",
    "print(\"üìä Evaluation at threshold 0.5:\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall   : {recall:.3f}\")\n",
    "print(f\"F1 Score : {f1:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec912cc",
   "metadata": {},
   "source": [
    "# In this notebook we would train the GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f59053",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep \n",
    "atr_14  , OBV\n",
    "\n",
    "drop\n",
    "\n",
    "'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'trending_market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d490cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_gru = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'bollinger_width', 'volatility_regime', 'CCI', 'stoch_%D',\n",
    "    'parkinson_vol', 'ema_cross_down', 'macd_cross_down',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6''ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2c85cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 12:55:45,523] A new study created in memory with name: gru_precision_optimized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ PRECISION-OPTIMIZED GRU HYPERPARAMETER SEARCH\n",
      "ğŸ¯ Maximizing PRECISION for Bitcoin Direction Prediction\n",
      "======================================================================\n",
      "ğŸ“Š Using F0.5 score (Î²=0.5) - Emphasizes PRECISION\n",
      "ğŸ¯ Precision gets 2.0x weight in scoring\n",
      "âš ï¸  No GPU detected, using CPU\n",
      "ğŸš€ Loading Bitcoin data for PRECISION-optimized GRU...\n",
      "============================================================\n",
      "âœ… Loaded data: (20718, 66)\n",
      "ğŸ“… Using data from 2020+: 11476 rows\n",
      "ğŸ¯ Target distribution: {1: 5858, 0: 5618}\n",
      "ğŸ§¹ After cleaning: (11476, 20)\n",
      "âœ… Features (19): ['volume', 'RSI', 'MACD_histogram', 'OBV', 'stoch_%K', 'atr_14', 'atr_ratio', 'price_vs_vwap', 'volume_ratio', 'buying_pressure', 'adx', 'fear_greed_score', 'roc_4h', 'roc_24h', 'bb_position', 'macd_rising', 'obv_rising_24h', 'momentum_alignment', 'trend_alignment']\n",
      "âœ… PRECISION OPTIMIZATION: No price data leakage\n",
      "ğŸ“Š Train: 9180 samples, Val: 2296 samples\n",
      "\n",
      "ğŸ” Starting PRECISION optimization...\n",
      "   Focus: Maximize precision with 2x weight\n",
      "   Trials: 30, Timeout: 100min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.981382:   3%|â–         | 1/30 [06:53<3:19:57, 413.71s/it, 413.71/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:02:39,228] Trial 0 finished with value: 0.9813824931254083 and parameters: {'window': 24, 'units': 128, 'layers': 2, 'dropout': 0.379597545259111, 'lr': 0.00018410729205738696, 'l2': 2.9375384576328295e-05, 'batch': 64, 'threshold': 0.5803345035229626}. Best is trial 0 with value: 0.9813824931254083.\n",
      "Trial  0: P=0.409 R=0.008 F0.5=0.036 Thr=0.58 Pos=22 | Best=0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.981382:   7%|â–‹         | 2/30 [10:45<2:23:00, 306.45s/it, 645.08/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:06:30,604] Trial 1 finished with value: 1.0 and parameters: {'window': 36, 'units': 32, 'layers': 2, 'dropout': 0.4497327922401265, 'lr': 0.00022948683681130568, 'l2': 3.511356313970405e-05, 'batch': 64, 'threshold': 0.5574269294896713}. Best is trial 0 with value: 0.9813824931254083.\n",
      "Trial  1: P=0.000 R=0.000 F0.5=0.000 Thr=0.56 Pos=0 | Best=0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  10%|â–ˆ         | 3/30 [15:05<2:08:28, 285.50s/it, 905.66/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:10:51,179] Trial 2 finished with value: 0.4393220019172188 and parameters: {'window': 30, 'units': 64, 'layers': 2, 'dropout': 0.24184815819561256, 'lr': 0.0003135775732257748, 'l2': 0.00012562773503807024, 'batch': 64, 'threshold': 0.45990213464750795}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  2: P=0.523 R=0.817 F0.5=0.564 Thr=0.46 Pos=1838 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  13%|â–ˆâ–        | 4/30 [15:42<1:21:10, 187.32s/it, 942.47/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:11:27,989] Trial 3 finished with value: 1.0 and parameters: {'window': 30, 'units': 96, 'layers': 1, 'dropout': 0.3822634555704315, 'lr': 0.00019485671251272575, 'l2': 1.5673095467235405e-05, 'batch': 64, 'threshold': 0.6425192044349384}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  3: P=0.000 R=0.000 F0.5=0.000 Thr=0.64 Pos=0 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  17%|â–ˆâ–‹        | 5/30 [18:25<1:14:23, 178.54s/it, 1105.44/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:14:10,963] Trial 4 finished with value: 0.4655274778167142 and parameters: {'window': 24, 'units': 32, 'layers': 2, 'dropout': 0.33204574812188037, 'lr': 0.000161190447276092, 'l2': 0.0003058656666978527, 'batch': 64, 'threshold': 0.4776339944800051}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  4: P=0.522 R=0.733 F0.5=0.554 Thr=0.48 Pos=1654 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  20%|â–ˆâ–ˆ        | 6/30 [21:44<1:14:15, 185.65s/it, 1304.90/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:17:30,419] Trial 5 finished with value: 1.0 and parameters: {'window': 36, 'units': 64, 'layers': 2, 'dropout': 0.3640130838029839, 'lr': 0.0002060924941320236, 'l2': 0.008105016126411584, 'batch': 64, 'threshold': 0.6684482051282946}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  5: P=0.000 R=0.000 F0.5=0.000 Thr=0.67 Pos=0 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  23%|â–ˆâ–ˆâ–       | 7/30 [27:39<1:32:22, 240.97s/it, 1659.74/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:23:25,266] Trial 6 finished with value: 0.9877265399516552 and parameters: {'window': 36, 'units': 128, 'layers': 1, 'dropout': 0.2587948587257436, 'lr': 0.00011935477742481393, 'l2': 9.46217535646148e-05, 'batch': 32, 'threshold': 0.6486212527455788}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  6: P=0.500 R=0.001 F0.5=0.004 Thr=0.65 Pos=2 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.403288:  27%|â–ˆâ–ˆâ–‹       | 8/30 [29:34<1:13:37, 200.81s/it, 1774.56/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:25:20,080] Trial 7 finished with value: 0.40328812258617375 and parameters: {'window': 24, 'units': 64, 'layers': 2, 'dropout': 0.2422772674924288, 'lr': 0.0023062618121677952, 'l2': 1.6736010167825783e-05, 'batch': 32, 'threshold': 0.4596147044602517}. Best is trial 7 with value: 0.40328812258617375.\n",
      "Trial  7: P=0.525 R=0.942 F0.5=0.576 Thr=0.46 Pos=2117 | Best=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.403288:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [31:27<1:00:41, 173.38s/it, 1887.65/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:27:13,171] Trial 8 finished with value: 1.0 and parameters: {'window': 12, 'units': 128, 'layers': 2, 'dropout': 0.4187021504122962, 'lr': 0.0020434554984161395, 'l2': 1.667761543019792e-05, 'batch': 32, 'threshold': 0.6589310277626781}. Best is trial 7 with value: 0.40328812258617375.\n",
      "Trial  8: P=0.000 R=0.000 F0.5=0.000 Thr=0.66 Pos=0 | Best=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.403288:  33%|â–ˆâ–ˆâ–ˆâ–      | 10/30 [33:44<53:59, 161.99s/it, 2024.13/6000 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:29:29,654] Trial 9 finished with value: 0.9323950583708072 and parameters: {'window': 36, 'units': 64, 'layers': 1, 'dropout': 0.29329469651469864, 'lr': 0.00035684261232554244, 'l2': 0.0015446089075047066, 'batch': 64, 'threshold': 0.5416644775485848}. Best is trial 7 with value: 0.40328812258617375.\n",
      "Trial  9: P=0.519 R=0.023 F0.5=0.098 Thr=0.54 Pos=52 | Best=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [35:35<46:20, 146.36s/it, 2135.06/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:31:20,581] Trial 10 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20538856268444594, 'lr': 0.004643119974738191, 'l2': 0.0011769044926591633, 'batch': 32, 'threshold': 0.4038643448510695}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 10: P=0.519 R=1.000 F0.5=0.574 Thr=0.40 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [37:56<43:25, 144.74s/it, 2276.07/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:33:41,593] Trial 11 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20271964043217916, 'lr': 0.0045110368278437115, 'l2': 0.001231953070800331, 'batch': 32, 'threshold': 0.4032829795924933}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 11: P=0.519 R=1.000 F0.5=0.574 Thr=0.40 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/30 [39:35<37:07, 131.04s/it, 2375.59/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:35:21,111] Trial 12 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20106387535923462, 'lr': 0.004686540626347904, 'l2': 0.0015246426973306176, 'batch': 32, 'threshold': 0.41364991827314684}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 12: P=0.519 R=1.000 F0.5=0.574 Thr=0.41 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [41:16<32:30, 121.90s/it, 2476.39/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:37:01,909] Trial 13 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20296502033876676, 'lr': 0.004804830538141239, 'l2': 0.0016565711747343972, 'batch': 32, 'threshold': 0.4007362248331011}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 13: P=0.519 R=1.000 F0.5=0.574 Thr=0.40 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [44:32<36:04, 144.33s/it, 2672.67/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:40:18,196] Trial 14 finished with value: 0.5932252029111332 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.2970094826765549, 'lr': 0.001278412165651303, 'l2': 0.007238819361166793, 'batch': 32, 'threshold': 0.5082226063632376}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 14: P=0.553 R=0.353 F0.5=0.497 Thr=0.51 Pos=745 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 16/30 [48:28<40:05, 171.79s/it, 2908.24/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:44:13,757] Trial 15 finished with value: 0.39224319889903203 and parameters: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.28827248013286977, 'lr': 0.0006919056242980709, 'l2': 0.0007616029338564875, 'batch': 32, 'threshold': 0.4329912133834338}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 15: P=0.520 R=1.000 F0.5=0.575 Thr=0.43 Pos=2254 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [54:08<48:13, 222.54s/it, 3248.81/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:49:54,334] Trial 16 finished with value: 0.3924493339392343 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.49382767753182344, 'lr': 0.0004954316037435775, 'l2': 0.0005276583740187119, 'batch': 32, 'threshold': 0.4431400266055239}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 16: P=0.520 R=0.999 F0.5=0.575 Thr=0.44 Pos=2252 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [59:10<49:17, 246.45s/it, 3550.93/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:54:56,448] Trial 17 finished with value: 0.45089264738056445 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.48404147792406904, 'lr': 0.0005784555170259785, 'l2': 0.0004773618185168044, 'batch': 32, 'threshold': 0.48838215541787816}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 17: P=0.521 R=0.785 F0.5=0.558 Thr=0.49 Pos=1765 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 19/30 [1:04:47<50:09, 273.60s/it, 3887.76/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:00:33,280] Trial 18 finished with value: 0.3927951291026791 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.3336127999190471, 'lr': 0.000638182307402298, 'l2': 0.0004410423127125506, 'batch': 32, 'threshold': 0.4441276651369434}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 18: P=0.521 R=0.993 F0.5=0.576 Thr=0.44 Pos=2232 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [1:08:10<42:04, 252.42s/it, 4090.82/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:03:56,344] Trial 19 finished with value: 0.7834270987152218 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.4858039653351313, 'lr': 0.000978223571639541, 'l2': 0.00355633097063596, 'batch': 32, 'threshold': 0.5173577353340968}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 19: P=0.581 R=0.104 F0.5=0.303 Thr=0.52 Pos=210 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [1:14:40<44:03, 293.77s/it, 4480.99/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:10:26,517] Trial 20 finished with value: 1.0 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.43990896599030516, 'lr': 0.00045428721391847484, 'l2': 0.00017008314108141117, 'batch': 32, 'threshold': 0.5974824571672048}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 20: P=0.000 R=0.000 F0.5=0.000 Thr=0.60 Pos=0 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 22/30 [1:18:16<36:01, 270.21s/it, 4696.27/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:14:01,787] Trial 21 finished with value: 0.3924493339392343 and parameters: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.2857423263379768, 'lr': 0.0009625091444340295, 'l2': 0.0007566309331758348, 'batch': 32, 'threshold': 0.4302813004287318}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 21: P=0.520 R=0.999 F0.5=0.575 Thr=0.43 Pos=2252 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [1:20:39<27:04, 232.08s/it, 4839.42/6000 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:16:24,942] Trial 22 finished with value: 0.3918097792402703 and parameters: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.29304784026893504, 'lr': 0.0009539147035893642, 'l2': 0.0006182071520515096, 'batch': 32, 'threshold': 0.4449592913770786}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 22: P=0.521 R=0.996 F0.5=0.576 Thr=0.44 Pos=2236 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [1:22:53<20:15, 202.58s/it, 4973.19/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:18:38,716] Trial 23 finished with value: 0.3919346379287192 and parameters: {'window': 36, 'units': 96, 'layers': 1, 'dropout': 0.31449659466022817, 'lr': 0.0008609248578277, 'l2': 0.0002499889592006828, 'batch': 32, 'threshold': 0.436464562697107}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 23: P=0.520 R=1.000 F0.5=0.575 Thr=0.44 Pos=2260 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 25/30 [1:24:38<14:26, 173.30s/it, 5078.17/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:20:23,691] Trial 24 finished with value: 0.5012143040835038 and parameters: {'window': 36, 'units': 96, 'layers': 1, 'dropout': 0.3137524089899081, 'lr': 0.0013170450542755625, 'l2': 6.992934972302688e-05, 'batch': 32, 'threshold': 0.48207168363593456}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 24: P=0.537 R=0.596 F0.5=0.548 Thr=0.48 Pos=1303 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [1:26:00<09:43, 145.86s/it, 5160.02/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:21:45,538] Trial 25 finished with value: 1.0 and parameters: {'window': 30, 'units': 64, 'layers': 1, 'dropout': 0.2707533997515279, 'lr': 0.0009136112323651378, 'l2': 0.00022239294651077825, 'batch': 32, 'threshold': 0.6998240482263056}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 25: P=0.000 R=0.000 F0.5=0.000 Thr=0.70 Pos=0 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [1:26:26<05:30, 110.13s/it, 5186.80/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:22:12,315] Trial 26 finished with value: 0.49431354845953823 and parameters: {'window': 12, 'units': 96, 'layers': 1, 'dropout': 0.32212340410694484, 'lr': 0.0017513485444801214, 'l2': 0.0024143624863597613, 'batch': 32, 'threshold': 0.5088289834277683}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 26: P=0.524 R=0.640 F0.5=0.544 Thr=0.51 Pos=1450 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 28/30 [1:27:54<03:26, 103.37s/it, 5274.38/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:23:39,902] Trial 27 finished with value: 0.3919346379287192 and parameters: {'window': 36, 'units': 64, 'layers': 1, 'dropout': 0.34882690126287674, 'lr': 0.0007750288765009825, 'l2': 0.0007786020101904646, 'batch': 32, 'threshold': 0.42606199161643293}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 27: P=0.520 R=1.000 F0.5=0.575 Thr=0.43 Pos=2260 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [1:28:31<01:23, 83.40s/it, 5311.20/6000 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:24:16,725] Trial 28 finished with value: 0.39240567982827246 and parameters: {'window': 18, 'units': 32, 'layers': 1, 'dropout': 0.3454456702065626, 'lr': 0.003010191223030362, 'l2': 0.0002696124550195139, 'batch': 32, 'threshold': 0.4640763508312489}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 28: P=0.519 R=1.000 F0.5=0.575 Thr=0.46 Pos=2278 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [1:29:41<00:00, 179.40s/it, 5381.86/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:25:27,379] Trial 29 finished with value: 1.0 and parameters: {'window': 30, 'units': 64, 'layers': 1, 'dropout': 0.37182564519122707, 'lr': 0.001233010707619071, 'l2': 5.347995878462169e-05, 'batch': 32, 'threshold': 0.5989922993489152}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 29: P=0.000 R=0.000 F0.5=0.000 Thr=0.60 Pos=0 | Best=0.608\n",
      "\n",
      "ğŸ† PRECISION OPTIMIZATION COMPLETED\n",
      "==================================================\n",
      "â­ Best combined score: 0.6082\n",
      "ğŸ“Š Completed trials: 30\n",
      "â±ï¸  Total time: 89.7 minutes\n",
      "\n",
      "ğŸ¯ BEST TRIAL PRECISION METRICS:\n",
      "   Precision: 0.5215 â­\n",
      "   Recall: 0.9957\n",
      "   F0.5-score: 0.5764 (precision-focused)\n",
      "   F1-score: 0.6845\n",
      "   Decision threshold: 0.445\n",
      "   Positive predictions: 2236\n",
      "\n",
      "ğŸ¯ BEST PARAMETERS:\n",
      "   window         : 42\n",
      "   units          : 96\n",
      "   layers         : 1\n",
      "   dropout        : 0.29304784026893504\n",
      "   lr             : 0.0009539147035893642\n",
      "   l2             : 0.0006182071520515096\n",
      "   batch          : 32\n",
      "   threshold      : 0.4449592913770786\n",
      "\n",
      "âœ… Precision-optimized parameters saved!\n",
      "ğŸ¯ Model optimized for HIGH PRECISION trading signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Precision-Optimized GRU for Bitcoin Direction Prediction\n",
    "=======================================================\n",
    "Modified to maximize PRECISION with 2x weight to precision over recall.\n",
    "Using F0.5 score (beta=0.5) which emphasizes precision.\n",
    "\n",
    "F-beta formula:\n",
    "- F2 (Î²=2): Emphasizes RECALL (2x weight to recall)\n",
    "- F1 (Î²=1): Equal weight to precision and recall  \n",
    "- F0.5 (Î²=0.5): Emphasizes PRECISION (2x weight to precision)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import optuna\n",
    "import warnings\n",
    "import joblib\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Configuration - PRECISION FOCUSED\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "VAL_FRAC = 0.2\n",
    "\n",
    "# PRECISION OPTIMIZATION: Use F0.5 score (emphasizes precision)\n",
    "BETA = 0.5  # â† CHANGED: Î²=0.5 gives 2x weight to PRECISION\n",
    "PRECISION_WEIGHT = 2.0  # Additional precision weighting\n",
    "\n",
    "MODEL_NAME = \"gru_precision_optimized.h5\"\n",
    "N_TRIALS = 30\n",
    "TIMEOUT = 100 * 60\n",
    "\n",
    "# Same comprehensive drop list\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    'typical_price', 'vwap_24h', 'close_4h',\n",
    "    'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bollinger_width',\n",
    "    'resistance_level', 'support_level',\n",
    "    'high_low', 'high_close', 'low_close', 'true_range',\n",
    "    'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'CCI', 'stoch_%D', 'parkinson_vol',\n",
    "    'ema_cross_down', 'macd_cross_down', 'ema_cross_up', 'macd_cross_up',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'oversold_reversal', 'overbought_reversal',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'timestamp', 'date', 'Unnamed: 0'\n",
    "]\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# GPU Configuration\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def configure_gpu():\n",
    "    \"\"\"Configure GPU with proper error handling.\"\"\"\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"âœ… GPU configured: {len(gpus)} device(s)\")\n",
    "            return True\n",
    "        except RuntimeError as e:\n",
    "            print(f\"âš ï¸  GPU configuration failed: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"âš ï¸  No GPU detected, using CPU\")\n",
    "        return False\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Custom Precision-Focused Metrics\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def precision_weighted_score(y_true, y_pred, precision_weight=2.0):\n",
    "    \"\"\"\n",
    "    Custom metric that emphasizes precision over recall.\n",
    "    \n",
    "    Formula: (1 + precision_weightÂ²) * precision * recall / (precision_weightÂ² * precision + recall)\n",
    "    This is similar to F-beta but with explicit precision weighting.\n",
    "    \"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Custom precision-weighted F-score\n",
    "    score = (1 + precision_weight**2) * precision * recall / (precision_weight**2 * precision + recall)\n",
    "    return score\n",
    "\n",
    "def conservative_precision_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Conservative precision metric that penalizes low precision heavily.\n",
    "    Combines precision with penalty for low confidence predictions.\n",
    "    \"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Penalty for low precision (precision < 0.6 gets heavily penalized)\n",
    "    precision_penalty = max(0, (precision - 0.6) / 0.4) if precision > 0.6 else 0\n",
    "    \n",
    "    # Bonus for high precision (precision > 0.7 gets bonus)\n",
    "    precision_bonus = max(0, (precision - 0.7) / 0.3) if precision > 0.7 else 0\n",
    "    \n",
    "    # Base score with precision emphasis\n",
    "    base_score = precision * 0.7 + recall * 0.3  # 70% precision, 30% recall\n",
    "    \n",
    "    # Apply bonuses and penalties\n",
    "    final_score = base_score + precision_bonus * 0.2 - (1 - precision_penalty) * 0.3\n",
    "    \n",
    "    return max(0, min(1, final_score))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Data Loading and Preprocessing\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess data with comprehensive validation.\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ Loading Bitcoin data for PRECISION-optimized GRU...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not CSV_PATH.exists():\n",
    "        raise FileNotFoundError(f\"âŒ Data file not found: {CSV_PATH}\")\n",
    "    \n",
    "    df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "    print(f\"âœ… Loaded data: {df.shape}\")\n",
    "    \n",
    "    # Filter to stable period\n",
    "    df = df[df.index >= \"2020-01-01\"]\n",
    "    print(f\"ğŸ“… Using data from 2020+: {len(df)} rows\")\n",
    "    \n",
    "    if 'target' not in df.columns:\n",
    "        raise ValueError(\"âŒ Target column not found!\")\n",
    "    \n",
    "    target_dist = df['target'].value_counts().to_dict()\n",
    "    print(f\"ğŸ¯ Target distribution: {target_dist}\")\n",
    "    \n",
    "    # Drop columns\n",
    "    cols_to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    df = df[df[\"target\"].notna()].dropna()\n",
    "    print(f\"ğŸ§¹ After cleaning: {df.shape}\")\n",
    "    \n",
    "    # Validate no data leakage\n",
    "    features = df.drop(columns=\"target\")\n",
    "    forbidden_cols = ['open', 'high', 'low', 'close']\n",
    "    found_forbidden = [col for col in forbidden_cols if col in features.columns]\n",
    "    \n",
    "    if found_forbidden:\n",
    "        raise ValueError(f\"âŒ DATA LEAKAGE: {found_forbidden} in features!\")\n",
    "    \n",
    "    print(f\"âœ… Features ({len(features.columns)}): {list(features.columns)}\")\n",
    "    print(f\"âœ… PRECISION OPTIMIZATION: No price data leakage\")\n",
    "    \n",
    "    target = df[\"target\"].astype(int).values\n",
    "    \n",
    "    if len(df) < 1000:\n",
    "        raise ValueError(f\"âŒ Insufficient data: {len(df)} rows\")\n",
    "    \n",
    "    return features, target, df.index\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Sequence Creation\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def create_sequences(data, labels, window_size):\n",
    "    \"\"\"Create sequences with validation.\"\"\"\n",
    "    if window_size >= len(data):\n",
    "        raise ValueError(f\"Window {window_size} >= data length {len(data)}\")\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(labels[i])\n",
    "    \n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Precision-Optimized Objective Function\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def precision_objective(trial, data_info):\n",
    "    \"\"\"\n",
    "    Objective function optimized for PRECISION.\n",
    "    Uses multiple precision-focused metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train_scaled, X_val_scaled, y_train, y_val = data_info\n",
    "    \n",
    "    try:\n",
    "        # Sample hyperparameters (slightly more conservative for precision)\n",
    "        window_size = trial.suggest_int(\"window\", 12, 48, step=6)\n",
    "        n_units = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "        n_layers = trial.suggest_int(\"layers\", 1, 2)\n",
    "        dropout_rate = trial.suggest_float(\"dropout\", 0.2, 0.5)  # Higher dropout for precision\n",
    "        learning_rate = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "        l2_reg = trial.suggest_float(\"l2\", 1e-5, 1e-2, log=True)  # More regularization\n",
    "        batch_size = trial.suggest_categorical(\"batch\", [32, 64])\n",
    "        \n",
    "        # PRECISION OPTIMIZATION: Threshold tuning\n",
    "        decision_threshold = trial.suggest_float(\"threshold\", 0.4, 0.7)  # Conservative thresholds\n",
    "        \n",
    "        # Create sequences\n",
    "        X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, window_size)\n",
    "        X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, window_size)\n",
    "        \n",
    "        if len(X_train_seq) < 100 or len(X_val_seq) < 50:\n",
    "            return float('inf')\n",
    "        \n",
    "        if len(np.unique(y_train_seq)) < 2 or len(np.unique(y_val_seq)) < 2:\n",
    "            return float('inf')\n",
    "        \n",
    "        # Build model (more conservative architecture for precision)\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = keras.Sequential()\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            return_sequences = (i < n_layers - 1)\n",
    "            model.add(keras.layers.GRU(\n",
    "                n_units,\n",
    "                return_sequences=return_sequences,\n",
    "                dropout=dropout_rate,\n",
    "                recurrent_dropout=dropout_rate * 0.6,  # Higher recurrent dropout\n",
    "                kernel_regularizer=keras.regularizers.l2(l2_reg),\n",
    "                recurrent_regularizer=keras.regularizers.l2(l2_reg)\n",
    "            ))\n",
    "        \n",
    "        # Add extra regularization for precision\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "        model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train model with patience for precision\n",
    "        history = model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=80,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val_seq, y_val_seq),\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=15,  # More patience for precision optimization\n",
    "                    restore_best_weights=True,\n",
    "                    verbose=0\n",
    "                )\n",
    "            ],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Evaluate with custom threshold\n",
    "        y_pred_prob = model.predict(X_val_seq, verbose=0).ravel()\n",
    "        y_pred = (y_pred_prob >= decision_threshold).astype(int)\n",
    "        \n",
    "        # Calculate precision-focused metrics\n",
    "        precision = precision_score(y_val_seq, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_val_seq, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val_seq, y_pred, zero_division=0)\n",
    "        f_half = fbeta_score(y_val_seq, y_pred, beta=BETA, zero_division=0)  # F0.5 (precision-focused)\n",
    "        accuracy = accuracy_score(y_val_seq, y_pred)\n",
    "        \n",
    "        # Custom precision metrics\n",
    "        precision_weighted = precision_weighted_score(y_val_seq, y_pred, PRECISION_WEIGHT)\n",
    "        conservative_precision = conservative_precision_score(y_val_seq, y_pred)\n",
    "        \n",
    "        # Store all metrics\n",
    "        trial.set_user_attr(\"precision\", precision)\n",
    "        trial.set_user_attr(\"recall\", recall)\n",
    "        trial.set_user_attr(\"f1_score\", f1)\n",
    "        trial.set_user_attr(\"f_half_score\", f_half)  # F0.5 score\n",
    "        trial.set_user_attr(\"accuracy\", accuracy)\n",
    "        trial.set_user_attr(\"precision_weighted\", precision_weighted)\n",
    "        trial.set_user_attr(\"conservative_precision\", conservative_precision)\n",
    "        trial.set_user_attr(\"decision_threshold\", decision_threshold)\n",
    "        trial.set_user_attr(\"n_positive_predictions\", int(np.sum(y_pred)))\n",
    "        \n",
    "        # PRECISION OPTIMIZATION: Multiple scoring strategies\n",
    "        \n",
    "        # Strategy 1: Pure F0.5 (emphasizes precision)\n",
    "        score_f_half = f_half\n",
    "        \n",
    "        # Strategy 2: Precision-weighted custom score\n",
    "        score_custom = precision_weighted\n",
    "        \n",
    "        # Strategy 3: Conservative precision score\n",
    "        score_conservative = conservative_precision\n",
    "        \n",
    "        # Strategy 4: Precision with minimum recall constraint\n",
    "        if recall >= 0.2:  # Minimum 20% recall required\n",
    "            score_constrained = precision\n",
    "        else:\n",
    "            score_constrained = precision * (recall / 0.2)  # Penalty for low recall\n",
    "        \n",
    "        # Combine strategies (weighted average)\n",
    "        final_score = (\n",
    "            0.4 * score_f_half +           # 40% F0.5 score\n",
    "            0.3 * score_custom +           # 30% custom precision score  \n",
    "            0.2 * score_conservative +     # 20% conservative score\n",
    "            0.1 * score_constrained        # 10% constrained precision\n",
    "        )\n",
    "        \n",
    "        trial.set_user_attr(\"final_combined_score\", final_score)\n",
    "        \n",
    "        # Return negative score for minimization\n",
    "        return 1.0 - final_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Trial {trial.number} failed: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Enhanced Progress Callback\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def precision_progress_callback(study, trial):\n",
    "    \"\"\"Progress callback focused on precision metrics.\"\"\"\n",
    "    \n",
    "    if trial.state == optuna.trial.TrialState.COMPLETE:\n",
    "        attrs = trial.user_attrs\n",
    "        precision = attrs.get('precision', 0)\n",
    "        recall = attrs.get('recall', 0)\n",
    "        f_half = attrs.get('f_half_score', 0)\n",
    "        threshold = attrs.get('decision_threshold', 0.5)\n",
    "        n_pos_pred = attrs.get('n_positive_predictions', 0)\n",
    "        \n",
    "        best_score = 1 - study.best_value if study.best_value != float('inf') else 0\n",
    "        \n",
    "        print(f\"Trial {trial.number:2d}: P={precision:.3f} R={recall:.3f} F0.5={f_half:.3f} \"\n",
    "              f\"Thr={threshold:.2f} Pos={n_pos_pred} | Best={best_score:.3f}\")\n",
    "    \n",
    "    elif trial.state == optuna.trial.TrialState.PRUNED:\n",
    "        print(f\"Trial {trial.number:2d}: PRUNED\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Main Precision Optimization Pipeline\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ PRECISION-OPTIMIZED GRU HYPERPARAMETER SEARCH\")\n",
    "    print(\"ğŸ¯ Maximizing PRECISION for Bitcoin Direction Prediction\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"ğŸ“Š Using F{BETA} score (Î²={BETA}) - Emphasizes PRECISION\")\n",
    "    print(f\"ğŸ¯ Precision gets {PRECISION_WEIGHT}x weight in scoring\")\n",
    "    \n",
    "    try:\n",
    "        # Configure GPU\n",
    "        gpu_available = configure_gpu()\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        features, target, dates = load_and_preprocess_data()\n",
    "        \n",
    "        # Proper scaling\n",
    "        split_idx = int(len(features) * (1 - VAL_FRAC))\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(features.iloc[:split_idx])\n",
    "        \n",
    "        X_train_scaled = scaler.transform(features.iloc[:split_idx])\n",
    "        X_val_scaled = scaler.transform(features.iloc[split_idx:])\n",
    "        y_train = target[:split_idx]\n",
    "        y_val = target[split_idx:]\n",
    "        \n",
    "        print(f\"ğŸ“Š Train: {len(X_train_scaled)} samples, Val: {len(X_val_scaled)} samples\")\n",
    "        \n",
    "        # Save scaler\n",
    "        joblib.dump(scaler, \"gru_precision_scaler.pkl\")\n",
    "        \n",
    "        # Prepare data\n",
    "        data_info = (X_train_scaled, X_val_scaled, y_train, y_val)\n",
    "        \n",
    "        # Create study\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "            pruner=optuna.pruners.MedianPruner(\n",
    "                n_startup_trials=5,\n",
    "                n_warmup_steps=3\n",
    "            ),\n",
    "            study_name=\"gru_precision_optimized\"\n",
    "        )\n",
    "        \n",
    "        # Run optimization\n",
    "        print(f\"\\nğŸ” Starting PRECISION optimization...\")\n",
    "        print(f\"   Focus: Maximize precision with 2x weight\")\n",
    "        print(f\"   Trials: {N_TRIALS}, Timeout: {TIMEOUT//60}min\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        study.optimize(\n",
    "            lambda trial: precision_objective(trial, data_info),\n",
    "            n_trials=N_TRIALS,\n",
    "            timeout=TIMEOUT,\n",
    "            show_progress_bar=True,\n",
    "            callbacks=[precision_progress_callback]\n",
    "        )\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Results analysis\n",
    "        print(f\"\\nğŸ† PRECISION OPTIMIZATION COMPLETED\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "        \n",
    "        if completed_trials:\n",
    "            best_combined_score = 1 - study.best_value\n",
    "            best_trial = study.best_trial\n",
    "            \n",
    "            print(f\"â­ Best combined score: {best_combined_score:.4f}\")\n",
    "            print(f\"ğŸ“Š Completed trials: {len(completed_trials)}\")\n",
    "            print(f\"â±ï¸  Total time: {total_time/60:.1f} minutes\")\n",
    "            \n",
    "            # Best trial precision metrics\n",
    "            if hasattr(best_trial, 'user_attrs'):\n",
    "                attrs = best_trial.user_attrs\n",
    "                print(f\"\\nğŸ¯ BEST TRIAL PRECISION METRICS:\")\n",
    "                print(f\"   Precision: {attrs.get('precision', 'N/A'):.4f} â­\")\n",
    "                print(f\"   Recall: {attrs.get('recall', 'N/A'):.4f}\")\n",
    "                print(f\"   F0.5-score: {attrs.get('f_half_score', 'N/A'):.4f} (precision-focused)\")\n",
    "                print(f\"   F1-score: {attrs.get('f1_score', 'N/A'):.4f}\")\n",
    "                print(f\"   Decision threshold: {attrs.get('decision_threshold', 'N/A'):.3f}\")\n",
    "                print(f\"   Positive predictions: {attrs.get('n_positive_predictions', 'N/A')}\")\n",
    "            \n",
    "            print(f\"\\nğŸ¯ BEST PARAMETERS:\")\n",
    "            for param, value in study.best_params.items():\n",
    "                print(f\"   {param:15s}: {value}\")\n",
    "            \n",
    "            # Save results\n",
    "            enhanced_params = {\n",
    "                **study.best_params,\n",
    "                \"optimization_focus\": \"precision\",\n",
    "                \"beta_score\": BETA,\n",
    "                \"precision_weight\": PRECISION_WEIGHT,\n",
    "                \"best_metrics\": {\n",
    "                    k: float(v) if isinstance(v, (int, float, np.number)) else v\n",
    "                    for k, v in best_trial.user_attrs.items()\n",
    "                    if k in ['precision', 'recall', 'f_half_score', 'f1_score', 'decision_threshold']\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(\"gru_precision_optimized_params.json\", \"w\") as f:\n",
    "                json.dump(enhanced_params, f, indent=2)\n",
    "            \n",
    "            print(f\"\\nâœ… Precision-optimized parameters saved!\")\n",
    "            print(f\"ğŸ¯ Model optimized for HIGH PRECISION trading signals\")\n",
    "            \n",
    "        else:\n",
    "            print(\"âŒ No trials completed successfully!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Optimization failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21a31e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ” GRU model saved â†’ gru_best_model_val20.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "MODEL_NAME = \"gru_best_model_val20.h5\"\n",
    "VAL_FRAC = 0.20\n",
    "SEED = 42\n",
    "\n",
    "# â”€â”€â”€ Best Parameters from Optuna â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "BEST_PARAMS = {\n",
    "    'window': 48,\n",
    "    'units': 96,\n",
    "    'layers': 1,\n",
    "    'dropout': 0.2970094826765549,\n",
    "    'lr': 0.001278412165651303,\n",
    "    'l2': 0.007238819361166793,\n",
    "    'batch': 32\n",
    "}\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# â”€â”€â”€ Load & Preprocess Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df[df.index >= \"2018-01-01\"]\n",
    "drop_cols = [  # must match your Optuna script\n",
    "    'open', 'high', 'low', 'close', 'typical_price', 'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower', 'resistance_level',\n",
    "    'support_level', 'high_low', 'high_close', 'low_close', 'true_range', 'volume_mean_20',\n",
    "    'MACD_line', 'MACD_signal', 'bollinger_width', 'volatility_regime', 'CCI', 'stoch_%D',\n",
    "    'parkinson_vol', 'ema_cross_down', 'macd_cross_down', 'vol_spike_1_5x', 'near_upper_band',\n",
    "    'near_lower_band', 'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive', 'volume_breakout',\n",
    "    'volume_breakdown', 'stoch_overbought', 'stoch_oversold', 'cci_overbought', 'cci_oversold',\n",
    "    'trending_market', 'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6', 'bearish_scenario_1',\n",
    "    'bearish_scenario_2', 'bearish_scenario_3', 'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal'\n",
    "]\n",
    "df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)\n",
    "df = df[df[\"target\"].notna()].dropna()\n",
    "\n",
    "features = df.drop(columns=\"target\")\n",
    "target = df[\"target\"].astype(int).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "X_train_raw, X_val_raw = features_scaled[:split_idx], features_scaled[split_idx:]\n",
    "y_train, y_val = target[:split_idx], target[split_idx:]\n",
    "\n",
    "# â”€â”€â”€ Sequence Windows â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_windows(data, labels, win):\n",
    "    X, y = [], []\n",
    "    for i in range(win, len(data)):\n",
    "        X.append(data[i-win:i])\n",
    "        y.append(labels[i])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "X_tr, y_tr = make_windows(X_train_raw, y_train, BEST_PARAMS[\"window\"])\n",
    "X_va, y_va = make_windows(X_val_raw, y_val, BEST_PARAMS[\"window\"])\n",
    "\n",
    "# â”€â”€â”€ Build and Train GRU Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "for i in range(BEST_PARAMS[\"layers\"]):\n",
    "    model.add(tf.keras.layers.GRU(\n",
    "        BEST_PARAMS[\"units\"],\n",
    "        return_sequences=(i < BEST_PARAMS[\"layers\"] - 1),\n",
    "        dropout=BEST_PARAMS[\"dropout\"],\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(BEST_PARAMS[\"l2\"])\n",
    "    ))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=BEST_PARAMS[\"lr\"]),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_tr, y_tr,\n",
    "    epochs=50,\n",
    "    batch_size=BEST_PARAMS[\"batch\"],\n",
    "    validation_data=(X_va, y_va),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "model.save(MODEL_NAME)\n",
    "print(f\"\\nâœ” GRU model saved â†’ {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "ğŸ§ª Training GRU #1 with params: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.39398, 'lr': 0.001585, 'l2': 0.000266, 'batch': 64}\n",
    "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
    "âœ… GRU #1 Results:\n",
    "   Precision: 0.522\n",
    "   Recall   : 0.425\n",
    "   F1-score : 0.469\n",
    "   F2-score : 0.441\n",
    "   Accuracy : 0.497\n",
    "\n",
    "ğŸ§ª Training GRU #2 with params: {'window': 36, 'units': 64, 'layers': 1, 'dropout': 0.26507, 'lr': 0.000857, 'l2': 0.000349, 'batch': 32}\n",
    "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
    "âœ… GRU #2 Results:\n",
    "   Precision: 0.517\n",
    "   Recall   : 0.477\n",
    "   F1-score : 0.496\n",
    "   F2-score : 0.485\n",
    "   Accuracy : 0.494\n",
    "\n",
    "ğŸ§ª Training GRU #3 with params: {'window': 36, 'units': 96, 'layers': 1, 'dropout': 0.25825, 'lr': 0.001168, 'l2': 0.00019, 'batch': 64}\n",
    "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step\n",
    "âœ… GRU #3 Results:\n",
    "   Precision: 0.514\n",
    "   Recall   : 0.443\n",
    "   F1-score : 0.476\n",
    "   F2-score : 0.456\n",
    "   Accuracy : 0.491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066741c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ğŸ§ª Training GRU #2 with params: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.297, 'lr': 0.001278, 'l2': 0.007239, 'batch': 32}\n",
    "98/98 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 15ms/step\n",
    "âœ… GRU #2 Results:\n",
    "   Precision: 0.522\n",
    "   Recall   : 1.000\n",
    "   F1-score : 0.686\n",
    "   F2-score : 0.845\n",
    "   Accuracy : 0.522"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

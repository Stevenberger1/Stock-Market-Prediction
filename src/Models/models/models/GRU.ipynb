{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec912cc",
   "metadata": {},
   "source": [
    "# In this notebook we would train the GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f59053",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep \n",
    "atr_14  , OBV\n",
    "\n",
    "drop\n",
    "\n",
    "'ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal', 'trending_market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d490cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_gru = [\n",
    "    'open', 'high', 'low', 'typical_price', 'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'vwap_24h', 'close_4h', 'bollinger_upper', 'bollinger_lower',\n",
    "    'resistance_level', 'support_level', 'high_low', 'high_close', 'low_close',\n",
    "    'true_range', 'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'bollinger_width', 'volatility_regime', 'CCI', 'stoch_%D',\n",
    "    'parkinson_vol', 'ema_cross_down', 'macd_cross_down',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6''ema_cross_up', 'macd_cross_up', 'oversold_reversal', 'overbought_reversal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c85cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 12:55:45,523] A new study created in memory with name: gru_precision_optimized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ PRECISION-OPTIMIZED GRU HYPERPARAMETER SEARCH\n",
      "ğŸ¯ Maximizing PRECISION for Bitcoin Direction Prediction\n",
      "======================================================================\n",
      "ğŸ“Š Using F0.5 score (Î²=0.5) - Emphasizes PRECISION\n",
      "ğŸ¯ Precision gets 2.0x weight in scoring\n",
      "âš ï¸  No GPU detected, using CPU\n",
      "ğŸš€ Loading Bitcoin data for PRECISION-optimized GRU...\n",
      "============================================================\n",
      "âœ… Loaded data: (20718, 66)\n",
      "ğŸ“… Using data from 2020+: 11476 rows\n",
      "ğŸ¯ Target distribution: {1: 5858, 0: 5618}\n",
      "ğŸ§¹ After cleaning: (11476, 20)\n",
      "âœ… Features (19): ['volume', 'RSI', 'MACD_histogram', 'OBV', 'stoch_%K', 'atr_14', 'atr_ratio', 'price_vs_vwap', 'volume_ratio', 'buying_pressure', 'adx', 'fear_greed_score', 'roc_4h', 'roc_24h', 'bb_position', 'macd_rising', 'obv_rising_24h', 'momentum_alignment', 'trend_alignment']\n",
      "âœ… PRECISION OPTIMIZATION: No price data leakage\n",
      "ğŸ“Š Train: 9180 samples, Val: 2296 samples\n",
      "\n",
      "ğŸ” Starting PRECISION optimization...\n",
      "   Focus: Maximize precision with 2x weight\n",
      "   Trials: 30, Timeout: 100min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.981382:   3%|â–         | 1/30 [06:53<3:19:57, 413.71s/it, 413.71/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:02:39,228] Trial 0 finished with value: 0.9813824931254083 and parameters: {'window': 24, 'units': 128, 'layers': 2, 'dropout': 0.379597545259111, 'lr': 0.00018410729205738696, 'l2': 2.9375384576328295e-05, 'batch': 64, 'threshold': 0.5803345035229626}. Best is trial 0 with value: 0.9813824931254083.\n",
      "Trial  0: P=0.409 R=0.008 F0.5=0.036 Thr=0.58 Pos=22 | Best=0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.981382:   7%|â–‹         | 2/30 [10:45<2:23:00, 306.45s/it, 645.08/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:06:30,604] Trial 1 finished with value: 1.0 and parameters: {'window': 36, 'units': 32, 'layers': 2, 'dropout': 0.4497327922401265, 'lr': 0.00022948683681130568, 'l2': 3.511356313970405e-05, 'batch': 64, 'threshold': 0.5574269294896713}. Best is trial 0 with value: 0.9813824931254083.\n",
      "Trial  1: P=0.000 R=0.000 F0.5=0.000 Thr=0.56 Pos=0 | Best=0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  10%|â–ˆ         | 3/30 [15:05<2:08:28, 285.50s/it, 905.66/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:10:51,179] Trial 2 finished with value: 0.4393220019172188 and parameters: {'window': 30, 'units': 64, 'layers': 2, 'dropout': 0.24184815819561256, 'lr': 0.0003135775732257748, 'l2': 0.00012562773503807024, 'batch': 64, 'threshold': 0.45990213464750795}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  2: P=0.523 R=0.817 F0.5=0.564 Thr=0.46 Pos=1838 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  13%|â–ˆâ–        | 4/30 [15:42<1:21:10, 187.32s/it, 942.47/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:11:27,989] Trial 3 finished with value: 1.0 and parameters: {'window': 30, 'units': 96, 'layers': 1, 'dropout': 0.3822634555704315, 'lr': 0.00019485671251272575, 'l2': 1.5673095467235405e-05, 'batch': 64, 'threshold': 0.6425192044349384}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  3: P=0.000 R=0.000 F0.5=0.000 Thr=0.64 Pos=0 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  17%|â–ˆâ–‹        | 5/30 [18:25<1:14:23, 178.54s/it, 1105.44/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:14:10,963] Trial 4 finished with value: 0.4655274778167142 and parameters: {'window': 24, 'units': 32, 'layers': 2, 'dropout': 0.33204574812188037, 'lr': 0.000161190447276092, 'l2': 0.0003058656666978527, 'batch': 64, 'threshold': 0.4776339944800051}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  4: P=0.522 R=0.733 F0.5=0.554 Thr=0.48 Pos=1654 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  20%|â–ˆâ–ˆ        | 6/30 [21:44<1:14:15, 185.65s/it, 1304.90/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:17:30,419] Trial 5 finished with value: 1.0 and parameters: {'window': 36, 'units': 64, 'layers': 2, 'dropout': 0.3640130838029839, 'lr': 0.0002060924941320236, 'l2': 0.008105016126411584, 'batch': 64, 'threshold': 0.6684482051282946}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  5: P=0.000 R=0.000 F0.5=0.000 Thr=0.67 Pos=0 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.439322:  23%|â–ˆâ–ˆâ–       | 7/30 [27:39<1:32:22, 240.97s/it, 1659.74/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:23:25,266] Trial 6 finished with value: 0.9877265399516552 and parameters: {'window': 36, 'units': 128, 'layers': 1, 'dropout': 0.2587948587257436, 'lr': 0.00011935477742481393, 'l2': 9.46217535646148e-05, 'batch': 32, 'threshold': 0.6486212527455788}. Best is trial 2 with value: 0.4393220019172188.\n",
      "Trial  6: P=0.500 R=0.001 F0.5=0.004 Thr=0.65 Pos=2 | Best=0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.403288:  27%|â–ˆâ–ˆâ–‹       | 8/30 [29:34<1:13:37, 200.81s/it, 1774.56/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:25:20,080] Trial 7 finished with value: 0.40328812258617375 and parameters: {'window': 24, 'units': 64, 'layers': 2, 'dropout': 0.2422772674924288, 'lr': 0.0023062618121677952, 'l2': 1.6736010167825783e-05, 'batch': 32, 'threshold': 0.4596147044602517}. Best is trial 7 with value: 0.40328812258617375.\n",
      "Trial  7: P=0.525 R=0.942 F0.5=0.576 Thr=0.46 Pos=2117 | Best=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.403288:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [31:27<1:00:41, 173.38s/it, 1887.65/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:27:13,171] Trial 8 finished with value: 1.0 and parameters: {'window': 12, 'units': 128, 'layers': 2, 'dropout': 0.4187021504122962, 'lr': 0.0020434554984161395, 'l2': 1.667761543019792e-05, 'batch': 32, 'threshold': 0.6589310277626781}. Best is trial 7 with value: 0.40328812258617375.\n",
      "Trial  8: P=0.000 R=0.000 F0.5=0.000 Thr=0.66 Pos=0 | Best=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.403288:  33%|â–ˆâ–ˆâ–ˆâ–      | 10/30 [33:44<53:59, 161.99s/it, 2024.13/6000 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:29:29,654] Trial 9 finished with value: 0.9323950583708072 and parameters: {'window': 36, 'units': 64, 'layers': 1, 'dropout': 0.29329469651469864, 'lr': 0.00035684261232554244, 'l2': 0.0015446089075047066, 'batch': 64, 'threshold': 0.5416644775485848}. Best is trial 7 with value: 0.40328812258617375.\n",
      "Trial  9: P=0.519 R=0.023 F0.5=0.098 Thr=0.54 Pos=52 | Best=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [35:35<46:20, 146.36s/it, 2135.06/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:31:20,581] Trial 10 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20538856268444594, 'lr': 0.004643119974738191, 'l2': 0.0011769044926591633, 'batch': 32, 'threshold': 0.4038643448510695}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 10: P=0.519 R=1.000 F0.5=0.574 Thr=0.40 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [37:56<43:25, 144.74s/it, 2276.07/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:33:41,593] Trial 11 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20271964043217916, 'lr': 0.0045110368278437115, 'l2': 0.001231953070800331, 'batch': 32, 'threshold': 0.4032829795924933}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 11: P=0.519 R=1.000 F0.5=0.574 Thr=0.40 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/30 [39:35<37:07, 131.04s/it, 2375.59/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:35:21,111] Trial 12 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20106387535923462, 'lr': 0.004686540626347904, 'l2': 0.0015246426973306176, 'batch': 32, 'threshold': 0.41364991827314684}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 12: P=0.519 R=1.000 F0.5=0.574 Thr=0.41 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [41:16<32:30, 121.90s/it, 2476.39/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:37:01,909] Trial 13 finished with value: 0.3925534969524289 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.20296502033876676, 'lr': 0.004804830538141239, 'l2': 0.0016565711747343972, 'batch': 32, 'threshold': 0.4007362248331011}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 13: P=0.519 R=1.000 F0.5=0.574 Thr=0.40 Pos=2248 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.392553:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [44:32<36:04, 144.33s/it, 2672.67/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:40:18,196] Trial 14 finished with value: 0.5932252029111332 and parameters: {'window': 48, 'units': 96, 'layers': 1, 'dropout': 0.2970094826765549, 'lr': 0.001278412165651303, 'l2': 0.007238819361166793, 'batch': 32, 'threshold': 0.5082226063632376}. Best is trial 10 with value: 0.3925534969524289.\n",
      "Trial 14: P=0.553 R=0.353 F0.5=0.497 Thr=0.51 Pos=745 | Best=0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 16/30 [48:28<40:05, 171.79s/it, 2908.24/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:44:13,757] Trial 15 finished with value: 0.39224319889903203 and parameters: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.28827248013286977, 'lr': 0.0006919056242980709, 'l2': 0.0007616029338564875, 'batch': 32, 'threshold': 0.4329912133834338}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 15: P=0.520 R=1.000 F0.5=0.575 Thr=0.43 Pos=2254 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [54:08<48:13, 222.54s/it, 3248.81/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:49:54,334] Trial 16 finished with value: 0.3924493339392343 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.49382767753182344, 'lr': 0.0004954316037435775, 'l2': 0.0005276583740187119, 'batch': 32, 'threshold': 0.4431400266055239}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 16: P=0.520 R=0.999 F0.5=0.575 Thr=0.44 Pos=2252 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [59:10<49:17, 246.45s/it, 3550.93/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 13:54:56,448] Trial 17 finished with value: 0.45089264738056445 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.48404147792406904, 'lr': 0.0005784555170259785, 'l2': 0.0004773618185168044, 'batch': 32, 'threshold': 0.48838215541787816}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 17: P=0.521 R=0.785 F0.5=0.558 Thr=0.49 Pos=1765 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 19/30 [1:04:47<50:09, 273.60s/it, 3887.76/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:00:33,280] Trial 18 finished with value: 0.3927951291026791 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.3336127999190471, 'lr': 0.000638182307402298, 'l2': 0.0004410423127125506, 'batch': 32, 'threshold': 0.4441276651369434}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 18: P=0.521 R=0.993 F0.5=0.576 Thr=0.44 Pos=2232 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [1:08:10<42:04, 252.42s/it, 4090.82/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:03:56,344] Trial 19 finished with value: 0.7834270987152218 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.4858039653351313, 'lr': 0.000978223571639541, 'l2': 0.00355633097063596, 'batch': 32, 'threshold': 0.5173577353340968}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 19: P=0.581 R=0.104 F0.5=0.303 Thr=0.52 Pos=210 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [1:14:40<44:03, 293.77s/it, 4480.99/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:10:26,517] Trial 20 finished with value: 1.0 and parameters: {'window': 42, 'units': 128, 'layers': 1, 'dropout': 0.43990896599030516, 'lr': 0.00045428721391847484, 'l2': 0.00017008314108141117, 'batch': 32, 'threshold': 0.5974824571672048}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 20: P=0.000 R=0.000 F0.5=0.000 Thr=0.60 Pos=0 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.392243:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 22/30 [1:18:16<36:01, 270.21s/it, 4696.27/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:14:01,787] Trial 21 finished with value: 0.3924493339392343 and parameters: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.2857423263379768, 'lr': 0.0009625091444340295, 'l2': 0.0007566309331758348, 'batch': 32, 'threshold': 0.4302813004287318}. Best is trial 15 with value: 0.39224319889903203.\n",
      "Trial 21: P=0.520 R=0.999 F0.5=0.575 Thr=0.43 Pos=2252 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [1:20:39<27:04, 232.08s/it, 4839.42/6000 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:16:24,942] Trial 22 finished with value: 0.3918097792402703 and parameters: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.29304784026893504, 'lr': 0.0009539147035893642, 'l2': 0.0006182071520515096, 'batch': 32, 'threshold': 0.4449592913770786}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 22: P=0.521 R=0.996 F0.5=0.576 Thr=0.44 Pos=2236 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [1:22:53<20:15, 202.58s/it, 4973.19/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:18:38,716] Trial 23 finished with value: 0.3919346379287192 and parameters: {'window': 36, 'units': 96, 'layers': 1, 'dropout': 0.31449659466022817, 'lr': 0.0008609248578277, 'l2': 0.0002499889592006828, 'batch': 32, 'threshold': 0.436464562697107}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 23: P=0.520 R=1.000 F0.5=0.575 Thr=0.44 Pos=2260 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 25/30 [1:24:38<14:26, 173.30s/it, 5078.17/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:20:23,691] Trial 24 finished with value: 0.5012143040835038 and parameters: {'window': 36, 'units': 96, 'layers': 1, 'dropout': 0.3137524089899081, 'lr': 0.0013170450542755625, 'l2': 6.992934972302688e-05, 'batch': 32, 'threshold': 0.48207168363593456}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 24: P=0.537 R=0.596 F0.5=0.548 Thr=0.48 Pos=1303 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [1:26:00<09:43, 145.86s/it, 5160.02/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:21:45,538] Trial 25 finished with value: 1.0 and parameters: {'window': 30, 'units': 64, 'layers': 1, 'dropout': 0.2707533997515279, 'lr': 0.0009136112323651378, 'l2': 0.00022239294651077825, 'batch': 32, 'threshold': 0.6998240482263056}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 25: P=0.000 R=0.000 F0.5=0.000 Thr=0.70 Pos=0 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [1:26:26<05:30, 110.13s/it, 5186.80/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:22:12,315] Trial 26 finished with value: 0.49431354845953823 and parameters: {'window': 12, 'units': 96, 'layers': 1, 'dropout': 0.32212340410694484, 'lr': 0.0017513485444801214, 'l2': 0.0024143624863597613, 'batch': 32, 'threshold': 0.5088289834277683}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 26: P=0.524 R=0.640 F0.5=0.544 Thr=0.51 Pos=1450 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 28/30 [1:27:54<03:26, 103.37s/it, 5274.38/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:23:39,902] Trial 27 finished with value: 0.3919346379287192 and parameters: {'window': 36, 'units': 64, 'layers': 1, 'dropout': 0.34882690126287674, 'lr': 0.0007750288765009825, 'l2': 0.0007786020101904646, 'batch': 32, 'threshold': 0.42606199161643293}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 27: P=0.520 R=1.000 F0.5=0.575 Thr=0.43 Pos=2260 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [1:28:31<01:23, 83.40s/it, 5311.20/6000 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:24:16,725] Trial 28 finished with value: 0.39240567982827246 and parameters: {'window': 18, 'units': 32, 'layers': 1, 'dropout': 0.3454456702065626, 'lr': 0.003010191223030362, 'l2': 0.0002696124550195139, 'batch': 32, 'threshold': 0.4640763508312489}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 28: P=0.519 R=1.000 F0.5=0.575 Thr=0.46 Pos=2278 | Best=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.39181: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [1:29:41<00:00, 179.40s/it, 5381.86/6000 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 14:25:27,379] Trial 29 finished with value: 1.0 and parameters: {'window': 30, 'units': 64, 'layers': 1, 'dropout': 0.37182564519122707, 'lr': 0.001233010707619071, 'l2': 5.347995878462169e-05, 'batch': 32, 'threshold': 0.5989922993489152}. Best is trial 22 with value: 0.3918097792402703.\n",
      "Trial 29: P=0.000 R=0.000 F0.5=0.000 Thr=0.60 Pos=0 | Best=0.608\n",
      "\n",
      "ğŸ† PRECISION OPTIMIZATION COMPLETED\n",
      "==================================================\n",
      "â­ Best combined score: 0.6082\n",
      "ğŸ“Š Completed trials: 30\n",
      "â±ï¸  Total time: 89.7 minutes\n",
      "\n",
      "ğŸ¯ BEST TRIAL PRECISION METRICS:\n",
      "   Precision: 0.5215 â­\n",
      "   Recall: 0.9957\n",
      "   F0.5-score: 0.5764 (precision-focused)\n",
      "   F1-score: 0.6845\n",
      "   Decision threshold: 0.445\n",
      "   Positive predictions: 2236\n",
      "\n",
      "ğŸ¯ BEST PARAMETERS:\n",
      "   window         : 42\n",
      "   units          : 96\n",
      "   layers         : 1\n",
      "   dropout        : 0.29304784026893504\n",
      "   lr             : 0.0009539147035893642\n",
      "   l2             : 0.0006182071520515096\n",
      "   batch          : 32\n",
      "   threshold      : 0.4449592913770786\n",
      "\n",
      "âœ… Precision-optimized parameters saved!\n",
      "ğŸ¯ Model optimized for HIGH PRECISION trading signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Precision-Optimized GRU for Bitcoin Direction Prediction\n",
    "=======================================================\n",
    "Modified to maximize PRECISION with 2x weight to precision over recall.\n",
    "Using F0.5 score (beta=0.5) which emphasizes precision.\n",
    "\n",
    "F-beta formula:\n",
    "- F2 (Î²=2): Emphasizes RECALL (2x weight to recall)\n",
    "- F1 (Î²=1): Equal weight to precision and recall  \n",
    "- F0.5 (Î²=0.5): Emphasizes PRECISION (2x weight to precision)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import optuna\n",
    "import warnings\n",
    "import joblib\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Configuration - PRECISION FOCUSED\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "VAL_FRAC = 0.2\n",
    "\n",
    "# PRECISION OPTIMIZATION: Use F0.5 score (emphasizes precision)\n",
    "BETA = 0.5  # â† CHANGED: Î²=0.5 gives 2x weight to PRECISION\n",
    "PRECISION_WEIGHT = 2.0  # Additional precision weighting\n",
    "\n",
    "MODEL_NAME = \"gru_precision_optimized.h5\"\n",
    "N_TRIALS = 30\n",
    "TIMEOUT = 100 * 60\n",
    "\n",
    "# Same comprehensive drop list\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    'typical_price', 'vwap_24h', 'close_4h',\n",
    "    'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bollinger_width',\n",
    "    'resistance_level', 'support_level',\n",
    "    'high_low', 'high_close', 'low_close', 'true_range',\n",
    "    'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'CCI', 'stoch_%D', 'parkinson_vol',\n",
    "    'ema_cross_down', 'macd_cross_down', 'ema_cross_up', 'macd_cross_up',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'oversold_reversal', 'overbought_reversal',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'timestamp', 'date', 'Unnamed: 0'\n",
    "]\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# GPU Configuration\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def configure_gpu():\n",
    "    \"\"\"Configure GPU with proper error handling.\"\"\"\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"âœ… GPU configured: {len(gpus)} device(s)\")\n",
    "            return True\n",
    "        except RuntimeError as e:\n",
    "            print(f\"âš ï¸  GPU configuration failed: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"âš ï¸  No GPU detected, using CPU\")\n",
    "        return False\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Custom Precision-Focused Metrics\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def precision_weighted_score(y_true, y_pred, precision_weight=2.0):\n",
    "    \"\"\"\n",
    "    Custom metric that emphasizes precision over recall.\n",
    "    \n",
    "    Formula: (1 + precision_weightÂ²) * precision * recall / (precision_weightÂ² * precision + recall)\n",
    "    This is similar to F-beta but with explicit precision weighting.\n",
    "    \"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Custom precision-weighted F-score\n",
    "    score = (1 + precision_weight**2) * precision * recall / (precision_weight**2 * precision + recall)\n",
    "    return score\n",
    "\n",
    "def conservative_precision_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Conservative precision metric that penalizes low precision heavily.\n",
    "    Combines precision with penalty for low confidence predictions.\n",
    "    \"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Penalty for low precision (precision < 0.6 gets heavily penalized)\n",
    "    precision_penalty = max(0, (precision - 0.6) / 0.4) if precision > 0.6 else 0\n",
    "    \n",
    "    # Bonus for high precision (precision > 0.7 gets bonus)\n",
    "    precision_bonus = max(0, (precision - 0.7) / 0.3) if precision > 0.7 else 0\n",
    "    \n",
    "    # Base score with precision emphasis\n",
    "    base_score = precision * 0.7 + recall * 0.3  # 70% precision, 30% recall\n",
    "    \n",
    "    # Apply bonuses and penalties\n",
    "    final_score = base_score + precision_bonus * 0.2 - (1 - precision_penalty) * 0.3\n",
    "    \n",
    "    return max(0, min(1, final_score))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Data Loading and Preprocessing\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess data with comprehensive validation.\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ Loading Bitcoin data for PRECISION-optimized GRU...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not CSV_PATH.exists():\n",
    "        raise FileNotFoundError(f\"âŒ Data file not found: {CSV_PATH}\")\n",
    "    \n",
    "    df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "    print(f\"âœ… Loaded data: {df.shape}\")\n",
    "    \n",
    "    # Filter to stable period\n",
    "    df = df[df.index >= \"2020-01-01\"]\n",
    "    print(f\"ğŸ“… Using data from 2020+: {len(df)} rows\")\n",
    "    \n",
    "    if 'target' not in df.columns:\n",
    "        raise ValueError(\"âŒ Target column not found!\")\n",
    "    \n",
    "    target_dist = df['target'].value_counts().to_dict()\n",
    "    print(f\"ğŸ¯ Target distribution: {target_dist}\")\n",
    "    \n",
    "    # Drop columns\n",
    "    cols_to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    df = df[df[\"target\"].notna()].dropna()\n",
    "    print(f\"ğŸ§¹ After cleaning: {df.shape}\")\n",
    "    \n",
    "    # Validate no data leakage\n",
    "    features = df.drop(columns=\"target\")\n",
    "    forbidden_cols = ['open', 'high', 'low', 'close']\n",
    "    found_forbidden = [col for col in forbidden_cols if col in features.columns]\n",
    "    \n",
    "    if found_forbidden:\n",
    "        raise ValueError(f\"âŒ DATA LEAKAGE: {found_forbidden} in features!\")\n",
    "    \n",
    "    print(f\"âœ… Features ({len(features.columns)}): {list(features.columns)}\")\n",
    "    print(f\"âœ… PRECISION OPTIMIZATION: No price data leakage\")\n",
    "    \n",
    "    target = df[\"target\"].astype(int).values\n",
    "    \n",
    "    if len(df) < 1000:\n",
    "        raise ValueError(f\"âŒ Insufficient data: {len(df)} rows\")\n",
    "    \n",
    "    return features, target, df.index\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Sequence Creation\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def create_sequences(data, labels, window_size):\n",
    "    \"\"\"Create sequences with validation.\"\"\"\n",
    "    if window_size >= len(data):\n",
    "        raise ValueError(f\"Window {window_size} >= data length {len(data)}\")\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(labels[i])\n",
    "    \n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Precision-Optimized Objective Function\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def precision_objective(trial, data_info):\n",
    "    \"\"\"\n",
    "    Objective function optimized for PRECISION.\n",
    "    Uses multiple precision-focused metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train_scaled, X_val_scaled, y_train, y_val = data_info\n",
    "    \n",
    "    try:\n",
    "        # Sample hyperparameters (slightly more conservative for precision)\n",
    "        window_size = trial.suggest_int(\"window\", 12, 48, step=6)\n",
    "        n_units = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "        n_layers = trial.suggest_int(\"layers\", 1, 2)\n",
    "        dropout_rate = trial.suggest_float(\"dropout\", 0.2, 0.5)  # Higher dropout for precision\n",
    "        learning_rate = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "        l2_reg = trial.suggest_float(\"l2\", 1e-5, 1e-2, log=True)  # More regularization\n",
    "        batch_size = trial.suggest_categorical(\"batch\", [32, 64])\n",
    "        \n",
    "        # PRECISION OPTIMIZATION: Threshold tuning\n",
    "        decision_threshold = trial.suggest_float(\"threshold\", 0.4, 0.7)  # Conservative thresholds\n",
    "        \n",
    "        # Create sequences\n",
    "        X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, window_size)\n",
    "        X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, window_size)\n",
    "        \n",
    "        if len(X_train_seq) < 100 or len(X_val_seq) < 50:\n",
    "            return float('inf')\n",
    "        \n",
    "        if len(np.unique(y_train_seq)) < 2 or len(np.unique(y_val_seq)) < 2:\n",
    "            return float('inf')\n",
    "        \n",
    "        # Build model (more conservative architecture for precision)\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = keras.Sequential()\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            return_sequences = (i < n_layers - 1)\n",
    "            model.add(keras.layers.GRU(\n",
    "                n_units,\n",
    "                return_sequences=return_sequences,\n",
    "                dropout=dropout_rate,\n",
    "                recurrent_dropout=dropout_rate * 0.6,  # Higher recurrent dropout\n",
    "                kernel_regularizer=keras.regularizers.l2(l2_reg),\n",
    "                recurrent_regularizer=keras.regularizers.l2(l2_reg)\n",
    "            ))\n",
    "        \n",
    "        # Add extra regularization for precision\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "        model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train model with patience for precision\n",
    "        history = model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=80,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val_seq, y_val_seq),\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=15,  # More patience for precision optimization\n",
    "                    restore_best_weights=True,\n",
    "                    verbose=0\n",
    "                )\n",
    "            ],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Evaluate with custom threshold\n",
    "        y_pred_prob = model.predict(X_val_seq, verbose=0).ravel()\n",
    "        y_pred = (y_pred_prob >= decision_threshold).astype(int)\n",
    "        \n",
    "        # Calculate precision-focused metrics\n",
    "        precision = precision_score(y_val_seq, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_val_seq, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val_seq, y_pred, zero_division=0)\n",
    "        f_half = fbeta_score(y_val_seq, y_pred, beta=BETA, zero_division=0)  # F0.5 (precision-focused)\n",
    "        accuracy = accuracy_score(y_val_seq, y_pred)\n",
    "        \n",
    "        # Custom precision metrics\n",
    "        precision_weighted = precision_weighted_score(y_val_seq, y_pred, PRECISION_WEIGHT)\n",
    "        conservative_precision = conservative_precision_score(y_val_seq, y_pred)\n",
    "        \n",
    "        # Store all metrics\n",
    "        trial.set_user_attr(\"precision\", precision)\n",
    "        trial.set_user_attr(\"recall\", recall)\n",
    "        trial.set_user_attr(\"f1_score\", f1)\n",
    "        trial.set_user_attr(\"f_half_score\", f_half)  # F0.5 score\n",
    "        trial.set_user_attr(\"accuracy\", accuracy)\n",
    "        trial.set_user_attr(\"precision_weighted\", precision_weighted)\n",
    "        trial.set_user_attr(\"conservative_precision\", conservative_precision)\n",
    "        trial.set_user_attr(\"decision_threshold\", decision_threshold)\n",
    "        trial.set_user_attr(\"n_positive_predictions\", int(np.sum(y_pred)))\n",
    "        \n",
    "        # PRECISION OPTIMIZATION: Multiple scoring strategies\n",
    "        \n",
    "        # Strategy 1: Pure F0.5 (emphasizes precision)\n",
    "        score_f_half = f_half\n",
    "        \n",
    "        # Strategy 2: Precision-weighted custom score\n",
    "        score_custom = precision_weighted\n",
    "        \n",
    "        # Strategy 3: Conservative precision score\n",
    "        score_conservative = conservative_precision\n",
    "        \n",
    "        # Strategy 4: Precision with minimum recall constraint\n",
    "        if recall >= 0.2:  # Minimum 20% recall required\n",
    "            score_constrained = precision\n",
    "        else:\n",
    "            score_constrained = precision * (recall / 0.2)  # Penalty for low recall\n",
    "        \n",
    "        # Combine strategies (weighted average)\n",
    "        final_score = (\n",
    "            0.4 * score_f_half +           # 40% F0.5 score\n",
    "            0.3 * score_custom +           # 30% custom precision score  \n",
    "            0.2 * score_conservative +     # 20% conservative score\n",
    "            0.1 * score_constrained        # 10% constrained precision\n",
    "        )\n",
    "        \n",
    "        trial.set_user_attr(\"final_combined_score\", final_score)\n",
    "        \n",
    "        # Return negative score for minimization\n",
    "        return 1.0 - final_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Trial {trial.number} failed: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Enhanced Progress Callback\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def precision_progress_callback(study, trial):\n",
    "    \"\"\"Progress callback focused on precision metrics.\"\"\"\n",
    "    \n",
    "    if trial.state == optuna.trial.TrialState.COMPLETE:\n",
    "        attrs = trial.user_attrs\n",
    "        precision = attrs.get('precision', 0)\n",
    "        recall = attrs.get('recall', 0)\n",
    "        f_half = attrs.get('f_half_score', 0)\n",
    "        threshold = attrs.get('decision_threshold', 0.5)\n",
    "        n_pos_pred = attrs.get('n_positive_predictions', 0)\n",
    "        \n",
    "        best_score = 1 - study.best_value if study.best_value != float('inf') else 0\n",
    "        \n",
    "        print(f\"Trial {trial.number:2d}: P={precision:.3f} R={recall:.3f} F0.5={f_half:.3f} \"\n",
    "              f\"Thr={threshold:.2f} Pos={n_pos_pred} | Best={best_score:.3f}\")\n",
    "    \n",
    "    elif trial.state == optuna.trial.TrialState.PRUNED:\n",
    "        print(f\"Trial {trial.number:2d}: PRUNED\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Main Precision Optimization Pipeline\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ PRECISION-OPTIMIZED GRU HYPERPARAMETER SEARCH\")\n",
    "    print(\"ğŸ¯ Maximizing PRECISION for Bitcoin Direction Prediction\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"ğŸ“Š Using F{BETA} score (Î²={BETA}) - Emphasizes PRECISION\")\n",
    "    print(f\"ğŸ¯ Precision gets {PRECISION_WEIGHT}x weight in scoring\")\n",
    "    \n",
    "    try:\n",
    "        # Configure GPU\n",
    "        gpu_available = configure_gpu()\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        features, target, dates = load_and_preprocess_data()\n",
    "        \n",
    "        # Proper scaling\n",
    "        split_idx = int(len(features) * (1 - VAL_FRAC))\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(features.iloc[:split_idx])\n",
    "        \n",
    "        X_train_scaled = scaler.transform(features.iloc[:split_idx])\n",
    "        X_val_scaled = scaler.transform(features.iloc[split_idx:])\n",
    "        y_train = target[:split_idx]\n",
    "        y_val = target[split_idx:]\n",
    "        \n",
    "        print(f\"ğŸ“Š Train: {len(X_train_scaled)} samples, Val: {len(X_val_scaled)} samples\")\n",
    "        \n",
    "        # Save scaler\n",
    "        joblib.dump(scaler, \"gru_precision_scaler.pkl\")\n",
    "        \n",
    "        # Prepare data\n",
    "        data_info = (X_train_scaled, X_val_scaled, y_train, y_val)\n",
    "        \n",
    "        # Create study\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "            pruner=optuna.pruners.MedianPruner(\n",
    "                n_startup_trials=5,\n",
    "                n_warmup_steps=3\n",
    "            ),\n",
    "            study_name=\"gru_precision_optimized\"\n",
    "        )\n",
    "        \n",
    "        # Run optimization\n",
    "        print(f\"\\nğŸ” Starting PRECISION optimization...\")\n",
    "        print(f\"   Focus: Maximize precision with 2x weight\")\n",
    "        print(f\"   Trials: {N_TRIALS}, Timeout: {TIMEOUT//60}min\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        study.optimize(\n",
    "            lambda trial: precision_objective(trial, data_info),\n",
    "            n_trials=N_TRIALS,\n",
    "            timeout=TIMEOUT,\n",
    "            show_progress_bar=True,\n",
    "            callbacks=[precision_progress_callback]\n",
    "        )\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Results analysis\n",
    "        print(f\"\\nğŸ† PRECISION OPTIMIZATION COMPLETED\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "        \n",
    "        if completed_trials:\n",
    "            best_combined_score = 1 - study.best_value\n",
    "            best_trial = study.best_trial\n",
    "            \n",
    "            print(f\"â­ Best combined score: {best_combined_score:.4f}\")\n",
    "            print(f\"ğŸ“Š Completed trials: {len(completed_trials)}\")\n",
    "            print(f\"â±ï¸  Total time: {total_time/60:.1f} minutes\")\n",
    "            \n",
    "            # Best trial precision metrics\n",
    "            if hasattr(best_trial, 'user_attrs'):\n",
    "                attrs = best_trial.user_attrs\n",
    "                print(f\"\\nğŸ¯ BEST TRIAL PRECISION METRICS:\")\n",
    "                print(f\"   Precision: {attrs.get('precision', 'N/A'):.4f} â­\")\n",
    "                print(f\"   Recall: {attrs.get('recall', 'N/A'):.4f}\")\n",
    "                print(f\"   F0.5-score: {attrs.get('f_half_score', 'N/A'):.4f} (precision-focused)\")\n",
    "                print(f\"   F1-score: {attrs.get('f1_score', 'N/A'):.4f}\")\n",
    "                print(f\"   Decision threshold: {attrs.get('decision_threshold', 'N/A'):.3f}\")\n",
    "                print(f\"   Positive predictions: {attrs.get('n_positive_predictions', 'N/A')}\")\n",
    "            \n",
    "            print(f\"\\nğŸ¯ BEST PARAMETERS:\")\n",
    "            for param, value in study.best_params.items():\n",
    "                print(f\"   {param:15s}: {value}\")\n",
    "            \n",
    "            # Save results\n",
    "            enhanced_params = {\n",
    "                **study.best_params,\n",
    "                \"optimization_focus\": \"precision\",\n",
    "                \"beta_score\": BETA,\n",
    "                \"precision_weight\": PRECISION_WEIGHT,\n",
    "                \"best_metrics\": {\n",
    "                    k: float(v) if isinstance(v, (int, float, np.number)) else v\n",
    "                    for k, v in best_trial.user_attrs.items()\n",
    "                    if k in ['precision', 'recall', 'f_half_score', 'f1_score', 'decision_threshold']\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(\"gru_precision_optimized_params.json\", \"w\") as f:\n",
    "                json.dump(enhanced_params, f, indent=2)\n",
    "            \n",
    "            print(f\"\\nâœ… Precision-optimized parameters saved!\")\n",
    "            print(f\"ğŸ¯ Model optimized for HIGH PRECISION trading signals\")\n",
    "            \n",
    "        else:\n",
    "            print(\"âŒ No trials completed successfully!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Optimization failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fd366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-06-13 10:23:10,397] A new study created in memory with name: gru_enhanced_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ENHANCED PRECISION-OPTIMIZED GRU SEARCH\n",
      "ğŸ¯ Maximizing PRECISION with improved parameters\n",
      "======================================================================\n",
      "ğŸ“Š Using F0.5 score (Î²=0.5) - 2x weight to PRECISION\n",
      "ğŸ¯ Enhanced with 50 trials and focused ranges\n",
      "âš ï¸  No GPU detected, using CPU\n",
      "ğŸš€ Loading Bitcoin data for ENHANCED PRECISION GRU...\n",
      "=================================================================\n",
      "âœ… Loaded data: (20718, 66)\n",
      "ğŸ“… Using data from 2020+: 11476 rows\n",
      "ğŸ¯ Target distribution: {1: 5858, 0: 5618}\n",
      "ğŸ§¹ After cleaning: (11476, 20)\n",
      "âœ… Features (19): ['volume', 'RSI', 'MACD_histogram', 'OBV', 'stoch_%K', 'atr_14', 'atr_ratio', 'price_vs_vwap', 'volume_ratio', 'buying_pressure', 'adx', 'fear_greed_score', 'roc_4h', 'roc_24h', 'bb_position', 'macd_rising', 'obv_rising_24h', 'momentum_alignment', 'trend_alignment']\n",
      "âœ… ENHANCED PRECISION: No price data leakage\n",
      "ğŸ“Š Train: 9180 samples, Val: 2296 samples\n",
      "\n",
      "ğŸ” Starting ENHANCED PRECISION optimization...\n",
      "   Focus: Precision with focused parameter ranges\n",
      "   Trials: 50, Timeout: 120min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.337167:   2%|â–         | 1/50 [04:58<4:03:35, 298.27s/it, 298.27/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:28:08,666] Trial 0 finished with value: 0.3371671041142523 and parameters: {'window': 24, 'units': 128, 'layers': 2, 'dropout': 0.2916145155592091, 'lr': 0.0005187855301194422, 'l2': 0.0008706020878304854, 'batch': 32, 'threshold': 0.3863649934414201}. Best is trial 0 with value: 0.3371671041142523.\n",
      "âœ… Trial  0 | P=0.519 R=1.000 F1=0.683 F0.5=0.574 | Thr=0.39 Pos=2272 | Combined=0.663 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.337167:   4%|â–         | 2/50 [05:36<1:56:26, 145.56s/it, 336.93/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:28:47,330] Trial 1 finished with value: 0.33810592626155533 and parameters: {'window': 30, 'units': 64, 'layers': 1, 'dropout': 0.24121399684340716, 'lr': 0.002041529502947848, 'l2': 2.5081156860452307e-05, 'batch': 64, 'threshold': 0.3592900825439995}. Best is trial 0 with value: 0.3371671041142523.\n",
      "âœ… Trial  1 | P=0.519 R=0.997 F1=0.682 F0.5=0.574 | Thr=0.36 Pos=2261 | Combined=0.662 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.337167:   6%|â–Œ         | 3/50 [09:09<2:17:50, 175.96s/it, 549.07/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:32:19,472] Trial 2 finished with value: 0.33784425533753715 and parameters: {'window': 42, 'units': 64, 'layers': 2, 'dropout': 0.23803049874792026, 'lr': 0.0006222060209649932, 'l2': 9.7803370166594e-05, 'batch': 64, 'threshold': 0.40175599632000336}. Best is trial 0 with value: 0.3371671041142523.\n",
      "âœ… Trial  2 | P=0.519 R=0.997 F1=0.683 F0.5=0.574 | Thr=0.40 Pos=2248 | Combined=0.662 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.336854:   8%|â–Š         | 4/50 [10:00<1:37:09, 126.72s/it, 600.32/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:33:10,714] Trial 3 finished with value: 0.3368541737953141 and parameters: {'window': 18, 'units': 64, 'layers': 2, 'dropout': 0.26957999576221703, 'lr': 0.002608120141371272, 'l2': 1.5030900645056805e-05, 'batch': 32, 'threshold': 0.41506606615265285}. Best is trial 3 with value: 0.3368541737953141.\n",
      "âœ… Trial  3 | P=0.519 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.42 Pos=2278 | Combined=0.663 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.336854:  10%|â–ˆ         | 5/50 [10:33<1:09:43, 92.97s/it, 633.42/7200 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:33:43,823] Trial 4 finished with value: 0.5028769110998154 and parameters: {'window': 30, 'units': 128, 'layers': 1, 'dropout': 0.3473773873201034, 'lr': 0.0019947718789028682, 'l2': 2.497073714505272e-05, 'batch': 64, 'threshold': 0.4913714687695234}. Best is trial 3 with value: 0.3368541737953141.\n",
      "âœ… Trial  4 | P=0.547 R=0.424 F1=0.478 F0.5=0.517 | Thr=0.49 Pos=912 | Combined=0.497 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.336854:  12%|â–ˆâ–        | 6/50 [11:07<53:34, 73.05s/it, 667.82/7200 seconds]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:34:18,221] Trial 5 finished with value: 0.34415505786264033 and parameters: {'window': 24, 'units': 64, 'layers': 1, 'dropout': 0.21219646434313244, 'lr': 0.0008953891201428856, 'l2': 0.0002878805718308924, 'batch': 64, 'threshold': 0.4444429850323899}. Best is trial 3 with value: 0.3368541737953141.\n",
      "âœ… Trial  5 | P=0.522 R=0.961 F1=0.677 F0.5=0.575 | Thr=0.44 Pos=2169 | Combined=0.656 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.336854:  14%|â–ˆâ–        | 7/50 [12:27<53:51, 75.15s/it, 747.28/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:35:37,679] Trial 6 finished with value: 0.6086624222800995 and parameters: {'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.17157828539866088, 'lr': 0.0005289646680152981, 'l2': 0.000187422109855557, 'batch': 64, 'threshold': 0.5315132947852186}. Best is trial 3 with value: 0.3368541737953141.\n",
      "âœ… Trial  6 | P=0.556 R=0.221 F1=0.316 F0.5=0.427 | Thr=0.53 Pos=466 | Combined=0.391 | Best=0.663\n",
      "   ğŸ¯ HIGH PRECISION TRIAL! Conservative=0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.336772:  16%|â–ˆâ–Œ        | 8/50 [13:53<55:00, 78.60s/it, 833.26/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:37:03,657] Trial 7 finished with value: 0.33677193249468607 and parameters: {'window': 30, 'units': 128, 'layers': 2, 'dropout': 0.2766807513020847, 'lr': 0.00238285794371812, 'l2': 0.00040489662225846743, 'batch': 64, 'threshold': 0.4578684483831302}. Best is trial 7 with value: 0.33677193249468607.\n",
      "âœ… Trial  7 | P=0.519 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.46 Pos=2266 | Combined=0.663 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.336772:  18%|â–ˆâ–Š        | 9/50 [14:16<41:47, 61.15s/it, 856.05/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:37:26,453] Trial 8 finished with value: 0.7084481234735871 and parameters: {'window': 24, 'units': 128, 'layers': 1, 'dropout': 0.2521494605155131, 'lr': 0.0010562796147104163, 'l2': 2.781093697926551e-05, 'batch': 64, 'threshold': 0.5385819407825039}. Best is trial 7 with value: 0.33677193249468607.\n",
      "âœ… Trial  8 | P=0.585 R=0.111 F1=0.187 F0.5=0.316 | Thr=0.54 Pos=224 | Combined=0.292 | Best=0.663\n",
      "   ğŸ¯ HIGH PRECISION TRIAL! Conservative=0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.336772:  20%|â–ˆâ–ˆ        | 10/50 [16:08<51:24, 77.12s/it, 968.94/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:39:19,339] Trial 9 finished with value: 0.3388701272237875 and parameters: {'window': 42, 'units': 64, 'layers': 1, 'dropout': 0.2069680988754935, 'lr': 0.0005341627862317534, 'l2': 0.0001656260589333595, 'batch': 32, 'threshold': 0.4057292928473223}. Best is trial 7 with value: 0.33677193249468607.\n",
      "âœ… Trial  9 | P=0.520 R=0.989 F1=0.682 F0.5=0.575 | Thr=0.41 Pos=2226 | Combined=0.661 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.33657:  22%|â–ˆâ–ˆâ–       | 11/50 [18:12<59:22, 91.35s/it, 1092.54/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:41:22,943] Trial 10 finished with value: 0.33656987041370845 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.32409872795493855, 'lr': 0.0015741846487190218, 'l2': 0.0006536264082965735, 'batch': 32, 'threshold': 0.4775943510422122}. Best is trial 10 with value: 0.33656987041370845.\n",
      "âœ… Trial 10 | P=0.520 R=0.999 F1=0.684 F0.5=0.575 | Thr=0.48 Pos=2258 | Combined=0.663 | Best=0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  24%|â–ˆâ–ˆâ–       | 12/50 [20:53<1:11:13, 112.45s/it, 1253.27/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:44:03,668] Trial 11 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.323957750393217, 'lr': 0.0015190233563579104, 'l2': 0.0009583723340357708, 'batch': 32, 'threshold': 0.47716756994461185}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 11 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.48 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [23:23<1:16:19, 123.78s/it, 1403.11/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:46:33,509] Trial 12 finished with value: 0.37998923630041626 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3340680020429286, 'lr': 0.0014635679224724492, 'l2': 0.0009942672296441586, 'batch': 32, 'threshold': 0.49414840502356794}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 12 | P=0.523 R=0.824 F1=0.640 F0.5=0.564 | Thr=0.49 Pos=1850 | Combined=0.620 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  28%|â–ˆâ–ˆâ–Š       | 14/50 [26:46<1:28:46, 147.95s/it, 1606.91/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:49:57,303] Trial 13 finished with value: 0.3406901779041759 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.324976653746651, 'lr': 0.0014423876910183836, 'l2': 0.0005756773583797651, 'batch': 32, 'threshold': 0.48575197444464246}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 13 | P=0.520 R=0.981 F1=0.680 F0.5=0.574 | Thr=0.49 Pos=2216 | Combined=0.659 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [33:43<2:13:31, 228.89s/it, 2023.37/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 10:56:53,766] Trial 14 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.307501803285623, 'lr': 0.0014763754699183664, 'l2': 6.810384885504048e-05, 'batch': 32, 'threshold': 0.45229204124343925}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 14 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.45 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [39:02<2:25:08, 256.14s/it, 2342.80/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:02:13,200] Trial 15 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.30680826039456066, 'lr': 0.000855693720550432, 'l2': 7.098701732564448e-05, 'batch': 32, 'threshold': 0.4351278635538124}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 15 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.44 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [43:23<2:21:37, 257.51s/it, 2603.49/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:06:33,887] Trial 16 finished with value: 0.6055101107732644 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.30094837842359834, 'lr': 0.0012323935680785315, 'l2': 6.268172739785502e-05, 'batch': 32, 'threshold': 0.5155574518915083}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 16 | P=0.577 R=0.213 F1=0.311 F0.5=0.430 | Thr=0.52 Pos=433 | Combined=0.394 | Best=0.664\n",
      "   ğŸ¯ HIGH PRECISION TRIAL! Conservative=0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [45:44<1:58:42, 222.59s/it, 2744.78/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:08:55,183] Trial 17 finished with value: 0.3372315263638972 and parameters: {'window': 18, 'units': 96, 'layers': 2, 'dropout': 0.31298689732390383, 'lr': 0.0018228577656177302, 'l2': 4.6941767381049645e-05, 'batch': 32, 'threshold': 0.46084613384664563}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 17 | P=0.519 R=0.999 F1=0.683 F0.5=0.574 | Thr=0.46 Pos=2277 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [48:41<1:47:49, 208.69s/it, 2921.09/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:11:51,493] Trial 18 finished with value: 0.8094476959779303 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.28135490095950766, 'lr': 0.0029696342650254496, 'l2': 0.00015210385928238603, 'batch': 32, 'threshold': 0.509295737788421}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 18 | P=0.592 R=0.052 F1=0.095 F0.5=0.192 | Thr=0.51 Pos=103 | Combined=0.191 | Best=0.664\n",
      "   ğŸ¯ HIGH PRECISION TRIAL! Conservative=0.430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [50:58<1:33:38, 187.30s/it, 3058.53/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:14:08,934] Trial 19 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3392011633983561, 'lr': 0.0011230794730060219, 'l2': 0.00029768887391758446, 'batch': 32, 'threshold': 0.43078667226160083}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 19 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.43 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [54:12<1:31:30, 189.31s/it, 3252.55/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:17:22,947] Trial 20 finished with value: 0.40461902449226417 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.26126299099534406, 'lr': 0.0008574666921947649, 'l2': 4.0337715213162597e-05, 'batch': 32, 'threshold': 0.4664441856235078}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 20 | P=0.530 R=0.723 F1=0.612 F0.5=0.560 | Thr=0.47 Pos=1601 | Combined=0.595 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [58:26<1:37:22, 208.67s/it, 3506.36/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:21:36,762] Trial 21 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3035562543715858, 'lr': 0.0006609703492891972, 'l2': 8.718235147367303e-05, 'batch': 32, 'threshold': 0.4318002142140648}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 21 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.43 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [1:01:57<1:34:16, 209.50s/it, 3717.81/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:25:08,208] Trial 22 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.30504984999945417, 'lr': 0.0008822086610378337, 'l2': 6.801368149307332e-05, 'batch': 32, 'threshold': 0.44086488168349214}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 22 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.44 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [1:05:13<1:28:57, 205.29s/it, 3913.27/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:28:23,669] Trial 23 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.34860360535079365, 'lr': 0.001282379030648687, 'l2': 0.00012463250283994442, 'batch': 32, 'threshold': 0.46653426038517015}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 23 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.47 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [1:08:35<1:25:05, 204.23s/it, 4115.04/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:31:45,439] Trial 24 finished with value: 0.3605252856332136 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.32140294242903733, 'lr': 0.0017034287883189462, 'l2': 1.1414961135986039e-05, 'batch': 32, 'threshold': 0.4268076510175774}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 24 | P=0.521 R=0.900 F1=0.660 F0.5=0.569 | Thr=0.43 Pos=2029 | Combined=0.639 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [1:12:20<1:24:15, 210.66s/it, 4340.68/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:35:31,082] Trial 25 finished with value: 0.3368541737953141 and parameters: {'window': 18, 'units': 96, 'layers': 2, 'dropout': 0.28800240621711304, 'lr': 0.0010036129665531616, 'l2': 5.284942116907877e-05, 'batch': 32, 'threshold': 0.3740445789294572}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 25 | P=0.519 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.37 Pos=2278 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [1:15:25<1:17:47, 202.92s/it, 4525.56/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:38:35,960] Trial 26 finished with value: 0.616712433867378 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.1563243310695384, 'lr': 0.0007068772344860779, 'l2': 3.464206474801883e-05, 'batch': 32, 'threshold': 0.5061311664261949}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 26 | P=0.542 R=0.218 F1=0.311 F0.5=0.418 | Thr=0.51 Pos=472 | Combined=0.383 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [1:21:44<1:33:48, 255.85s/it, 4904.89/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:44:55,291] Trial 27 finished with value: 0.3391048942218998 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3141300741478716, 'lr': 0.0007688428359082904, 'l2': 7.379194369147983e-05, 'batch': 32, 'threshold': 0.4482817957657989}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 27 | P=0.520 R=0.989 F1=0.682 F0.5=0.574 | Thr=0.45 Pos=2235 | Combined=0.661 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [1:26:03<1:29:53, 256.82s/it, 5163.97/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:49:14,370] Trial 28 finished with value: 0.3374073820954745 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.2944123891707492, 'lr': 0.0013899204674669833, 'l2': 0.0002516233411563695, 'batch': 32, 'threshold': 0.4758777072185244}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 28 | P=0.522 R=0.991 F1=0.683 F0.5=0.576 | Thr=0.48 Pos=2232 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [1:31:48<1:34:22, 283.14s/it, 5508.54/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:54:58,944] Trial 29 finished with value: 0.3371671041142523 and parameters: {'window': 24, 'units': 128, 'layers': 2, 'dropout': 0.33282524513845346, 'lr': 0.0011972173564380882, 'l2': 0.00011795974460139173, 'batch': 32, 'threshold': 0.3836839178822975}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 29 | P=0.519 R=1.000 F1=0.683 F0.5=0.574 | Thr=0.38 Pos=2272 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [1:34:37<1:18:49, 248.91s/it, 5677.58/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 11:57:47,978] Trial 30 finished with value: 0.33956895406357024 and parameters: {'window': 18, 'units': 128, 'layers': 2, 'dropout': 0.22262451253538612, 'lr': 0.0009680969393718183, 'l2': 1.722562165763756e-05, 'batch': 32, 'threshold': 0.41180462079069724}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 30 | P=0.519 R=0.989 F1=0.681 F0.5=0.574 | Thr=0.41 Pos=2253 | Combined=0.660 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [1:39:47<1:20:08, 267.17s/it, 5987.34/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:02:57,735] Trial 31 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3381185839462113, 'lr': 0.0010954055774438527, 'l2': 0.00042082702791979313, 'batch': 32, 'threshold': 0.4188096954569438}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 31 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.42 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [1:44:00<1:14:31, 263.02s/it, 6240.70/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:07:11,097] Trial 32 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3118041815784202, 'lr': 0.0011481337178492381, 'l2': 0.0006220191296519702, 'batch': 32, 'threshold': 0.4350106921557595}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 32 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.44 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [1:47:39<1:06:35, 249.74s/it, 6459.45/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:10:49,845] Trial 33 finished with value: 0.33677193249468607 and parameters: {'window': 30, 'units': 96, 'layers': 2, 'dropout': 0.33816121248332126, 'lr': 0.0013575578444139694, 'l2': 0.00023091327721722117, 'batch': 32, 'threshold': 0.38851196679521616}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 33 | P=0.519 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.39 Pos=2266 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [1:51:51<1:02:37, 250.50s/it, 6711.71/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:15:02,109] Trial 34 finished with value: 0.33688472878054954 and parameters: {'window': 42, 'units': 64, 'layers': 2, 'dropout': 0.2948521598667029, 'lr': 0.001766280177103257, 'l2': 0.00031823524395262166, 'batch': 32, 'threshold': 0.4527134988656639}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 34 | P=0.520 R=0.999 F1=0.684 F0.5=0.575 | Thr=0.45 Pos=2252 | Combined=0.663 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [1:55:38<56:47, 243.37s/it, 6938.45/7200 seconds]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:18:48,844] Trial 35 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.3497330817000635, 'lr': 0.00210390084930548, 'l2': 9.726370534741423e-05, 'batch': 32, 'threshold': 0.43060993423577765}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 35 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.43 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [1:57:20<43:31, 200.85s/it, 7040.09/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:20:30,491] Trial 36 finished with value: 0.33637481028500593 and parameters: {'window': 36, 'units': 64, 'layers': 1, 'dropout': 0.32410843910799725, 'lr': 0.001593853375642476, 'l2': 0.0003939823902581817, 'batch': 64, 'threshold': 0.394527650935701}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 36 | P=0.520 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.39 Pos=2260 | Combined=0.664 | Best=0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.336375:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [2:00:50<38:09, 190.81s/it, 7250.66/7200 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 12:24:01,057] Trial 37 finished with value: 0.33677193249468607 and parameters: {'window': 30, 'units': 96, 'layers': 2, 'dropout': 0.267142572545942, 'lr': 0.000808836272445403, 'l2': 0.0007783687973588303, 'batch': 32, 'threshold': 0.4199580965645373}. Best is trial 11 with value: 0.33637481028500593.\n",
      "âœ… Trial 37 | P=0.519 R=1.000 F1=0.684 F0.5=0.575 | Thr=0.42 Pos=2266 | Combined=0.663 | Best=0.664\n",
      "\n",
      "ğŸ† ENHANCED PRECISION OPTIMIZATION COMPLETED\n",
      "=======================================================\n",
      "â­ Best combined score: 0.6636\n",
      "ğŸ“Š Completed trials: 38\n",
      "â±ï¸  Total time: 120.8 minutes\n",
      "\n",
      "ğŸ¯ BEST ENHANCED PRECISION METRICS:\n",
      "   Precision: 0.5199 â­\n",
      "   Recall: 1.0000\n",
      "   F0.5-score: 0.5751\n",
      "   F1-score: 0.6841\n",
      "   Decision threshold: 0.477\n",
      "   Positive predictions: 2260\n",
      "\n",
      "ğŸ¯ ENHANCED BEST PARAMETERS:\n",
      "   window         : 36\n",
      "   units          : 96\n",
      "   layers         : 2\n",
      "   dropout        : 0.323957750393217\n",
      "   lr             : 0.0015190233563579104\n",
      "   l2             : 0.0009583723340357708\n",
      "   batch          : 32\n",
      "   threshold      : 0.47716756994461185\n",
      "\n",
      "âœ… Enhanced precision parameters saved!\n",
      "ğŸ¯ Target: >0.60 precision with balanced recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Enhanced Precision-Optimized GRU for Bitcoin Direction Prediction\n",
    "=================================================================\n",
    "FIXED VERSION with improved parameter ranges and more trials.\n",
    "Focus: Maximize PRECISION with F0.5 score (2x weight to precision).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import optuna\n",
    "import warnings\n",
    "import joblib\n",
    "import time\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ENHANCED Configuration - PRECISION FOCUSED\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "VAL_FRAC = 0.2\n",
    "\n",
    "# PRECISION OPTIMIZATION: Use F0.5 score (emphasizes precision)\n",
    "BETA = 0.5  # Î²=0.5 gives 2x weight to PRECISION\n",
    "PRECISION_WEIGHT = 2.0\n",
    "\n",
    "MODEL_NAME = \"gru_precision_enhanced.h5\"\n",
    "N_TRIALS = 50  # INCREASED from 30\n",
    "TIMEOUT = 120 * 60  # 2 hours instead of 100 minutes\n",
    "\n",
    "# Complete drop list\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    'typical_price', 'vwap_24h', 'close_4h',\n",
    "    'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bollinger_width',\n",
    "    'resistance_level', 'support_level',\n",
    "    'high_low', 'high_close', 'low_close', 'true_range',\n",
    "    'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'CCI', 'stoch_%D', 'parkinson_vol',\n",
    "    'ema_cross_down', 'macd_cross_down', 'ema_cross_up', 'macd_cross_up',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'oversold_reversal', 'overbought_reversal',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'timestamp', 'date', 'Unnamed: 0'\n",
    "]\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# GPU Configuration\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def configure_gpu():\n",
    "    \"\"\"Configure GPU with proper error handling.\"\"\"\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"âœ… GPU configured: {len(gpus)} device(s)\")\n",
    "            return True\n",
    "        except RuntimeError as e:\n",
    "            print(f\"âš ï¸  GPU configuration failed: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"âš ï¸  No GPU detected, using CPU\")\n",
    "        return False\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Custom Precision-Focused Metrics\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def precision_weighted_score(y_true, y_pred, precision_weight=2.0):\n",
    "    \"\"\"Custom metric that emphasizes precision over recall.\"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Custom precision-weighted F-score\n",
    "    score = (1 + precision_weight**2) * precision * recall / (precision_weight**2 * precision + recall)\n",
    "    return score\n",
    "\n",
    "def conservative_precision_score(y_true, y_pred):\n",
    "    \"\"\"Conservative precision metric with bonuses for high precision.\"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Bonus for high precision\n",
    "    precision_bonus = max(0, (precision - 0.6) / 0.4) if precision > 0.6 else 0\n",
    "    \n",
    "    # Base score with precision emphasis\n",
    "    base_score = precision * 0.7 + recall * 0.3\n",
    "    \n",
    "    # Apply bonus\n",
    "    final_score = base_score + precision_bonus * 0.2\n",
    "    \n",
    "    return max(0, min(1, final_score))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Data Loading and Preprocessing\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess data with comprehensive validation.\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ Loading Bitcoin data for ENHANCED PRECISION GRU...\")\n",
    "    print(\"=\" * 65)\n",
    "    \n",
    "    if not CSV_PATH.exists():\n",
    "        raise FileNotFoundError(f\"âŒ Data file not found: {CSV_PATH}\")\n",
    "    \n",
    "    df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "    print(f\"âœ… Loaded data: {df.shape}\")\n",
    "    \n",
    "    # Filter to stable period\n",
    "    df = df[df.index >= \"2020-01-01\"]\n",
    "    print(f\"ğŸ“… Using data from 2020+: {len(df)} rows\")\n",
    "    \n",
    "    if 'target' not in df.columns:\n",
    "        raise ValueError(\"âŒ Target column not found!\")\n",
    "    \n",
    "    target_dist = df['target'].value_counts().to_dict()\n",
    "    print(f\"ğŸ¯ Target distribution: {target_dist}\")\n",
    "    \n",
    "    # Drop columns\n",
    "    cols_to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    df = df[df[\"target\"].notna()].dropna()\n",
    "    print(f\"ğŸ§¹ After cleaning: {df.shape}\")\n",
    "    \n",
    "    # Validate no data leakage\n",
    "    features = df.drop(columns=\"target\")\n",
    "    forbidden_cols = ['open', 'high', 'low', 'close']\n",
    "    found_forbidden = [col for col in forbidden_cols if col in features.columns]\n",
    "    \n",
    "    if found_forbidden:\n",
    "        raise ValueError(f\"âŒ DATA LEAKAGE: {found_forbidden} in features!\")\n",
    "    \n",
    "    print(f\"âœ… Features ({len(features.columns)}): {list(features.columns)}\")\n",
    "    print(f\"âœ… ENHANCED PRECISION: No price data leakage\")\n",
    "    \n",
    "    target = df[\"target\"].astype(int).values\n",
    "    \n",
    "    if len(df) < 1000:\n",
    "        raise ValueError(f\"âŒ Insufficient data: {len(df)} rows\")\n",
    "    \n",
    "    return features, target, df.index\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Sequence Creation\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def create_sequences(data, labels, window_size):\n",
    "    \"\"\"Create sequences with validation.\"\"\"\n",
    "    if window_size >= len(data):\n",
    "        raise ValueError(f\"Window {window_size} >= data length {len(data)}\")\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(labels[i])\n",
    "    \n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Enhanced Precision-Optimized Objective Function\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def enhanced_precision_objective(trial, data_info):\n",
    "    \"\"\"ENHANCED objective function optimized for PRECISION.\"\"\"\n",
    "    \n",
    "    X_train_scaled, X_val_scaled, y_train, y_val = data_info\n",
    "    \n",
    "    try:\n",
    "        # ENHANCED hyperparameter ranges based on previous results\n",
    "        window_size = trial.suggest_categorical(\"window\", [18, 24, 30, 36, 42])  # Focus on successful windows\n",
    "        n_units = trial.suggest_categorical(\"units\", [64, 96, 128])  # Larger networks only\n",
    "        n_layers = trial.suggest_int(\"layers\", 1, 2)  # Simple architectures\n",
    "        dropout_rate = trial.suggest_float(\"dropout\", 0.15, 0.35)  # Tighter range\n",
    "        learning_rate = trial.suggest_float(\"lr\", 0.0005, 0.003, log=True)  # Focus on working LR range\n",
    "        l2_reg = trial.suggest_float(\"l2\", 1e-5, 1e-3, log=True)  # Better regularization\n",
    "        batch_size = trial.suggest_categorical(\"batch\", [32, 64])\n",
    "        \n",
    "        # ENHANCED threshold tuning - avoid extremes\n",
    "        decision_threshold = trial.suggest_float(\"threshold\", 0.35, 0.55)  # Avoid extreme thresholds\n",
    "        \n",
    "        # Create sequences\n",
    "        X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, window_size)\n",
    "        X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, window_size)\n",
    "        \n",
    "        if len(X_train_seq) < 100 or len(X_val_seq) < 50:\n",
    "            return float('inf')\n",
    "        \n",
    "        if len(np.unique(y_train_seq)) < 2 or len(np.unique(y_val_seq)) < 2:\n",
    "            return float('inf')\n",
    "        \n",
    "        # Build enhanced model\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = keras.Sequential()\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            return_sequences = (i < n_layers - 1)\n",
    "            model.add(keras.layers.GRU(\n",
    "                n_units,\n",
    "                return_sequences=return_sequences,\n",
    "                dropout=dropout_rate,\n",
    "                recurrent_dropout=dropout_rate * 0.6,\n",
    "                kernel_regularizer=keras.regularizers.l2(l2_reg),\n",
    "                recurrent_regularizer=keras.regularizers.l2(l2_reg)\n",
    "            ))\n",
    "        \n",
    "        # Enhanced regularization\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "        model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train with enhanced patience\n",
    "        history = model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=60,  # Reduced epochs for efficiency\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val_seq, y_val_seq),\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=12,  # Balanced patience\n",
    "                    restore_best_weights=True,\n",
    "                    verbose=0\n",
    "                )\n",
    "            ],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Evaluate with custom threshold\n",
    "        y_pred_prob = model.predict(X_val_seq, verbose=0).ravel()\n",
    "        y_pred = (y_pred_prob >= decision_threshold).astype(int)\n",
    "        \n",
    "        # Calculate all metrics\n",
    "        precision = precision_score(y_val_seq, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_val_seq, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val_seq, y_pred, zero_division=0)\n",
    "        f_half = fbeta_score(y_val_seq, y_pred, beta=BETA, zero_division=0)\n",
    "        accuracy = accuracy_score(y_val_seq, y_pred)\n",
    "        \n",
    "        # Custom precision metrics\n",
    "        precision_weighted = precision_weighted_score(y_val_seq, y_pred, PRECISION_WEIGHT)\n",
    "        conservative_precision = conservative_precision_score(y_val_seq, y_pred)\n",
    "        \n",
    "        # Store metrics\n",
    "        trial.set_user_attr(\"precision\", precision)\n",
    "        trial.set_user_attr(\"recall\", recall)\n",
    "        trial.set_user_attr(\"f1_score\", f1)\n",
    "        trial.set_user_attr(\"f_half_score\", f_half)\n",
    "        trial.set_user_attr(\"accuracy\", accuracy)\n",
    "        trial.set_user_attr(\"precision_weighted\", precision_weighted)\n",
    "        trial.set_user_attr(\"conservative_precision\", conservative_precision)\n",
    "        trial.set_user_attr(\"decision_threshold\", decision_threshold)\n",
    "        trial.set_user_attr(\"n_positive_predictions\", int(np.sum(y_pred)))\n",
    "        \n",
    "        # ENHANCED scoring with focus on precision\n",
    "        score_f_half = f_half\n",
    "        score_custom = precision_weighted\n",
    "        score_conservative = conservative_precision\n",
    "        \n",
    "        # Precision with minimum recall constraint (enhanced)\n",
    "        if recall >= 0.15:  # Lower minimum recall threshold\n",
    "            score_constrained = precision\n",
    "        else:\n",
    "            score_constrained = precision * (recall / 0.15)\n",
    "        \n",
    "        # Enhanced combination weights\n",
    "        final_score = (\n",
    "            0.45 * score_f_half +         # 45% F0.5 score (increased)\n",
    "            0.30 * score_custom +         # 30% custom precision score  \n",
    "            0.15 * score_conservative +   # 15% conservative score\n",
    "            0.10 * score_constrained      # 10% constrained precision\n",
    "        )\n",
    "        \n",
    "        trial.set_user_attr(\"final_combined_score\", final_score)\n",
    "        \n",
    "        # Cleanup memory\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        return 1.0 - final_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Trial {trial.number} failed: {e}\")\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        return float('inf')\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Enhanced Progress Callback\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def enhanced_precision_callback(study, trial):\n",
    "    \"\"\"Enhanced progress callback with detailed metrics.\"\"\"\n",
    "    \n",
    "    if trial.state == optuna.trial.TrialState.COMPLETE:\n",
    "        attrs = trial.user_attrs\n",
    "        precision = attrs.get('precision', 0)\n",
    "        recall = attrs.get('recall', 0)\n",
    "        f1 = attrs.get('f1_score', 0)\n",
    "        f_half = attrs.get('f_half_score', 0)\n",
    "        threshold = attrs.get('decision_threshold', 0.5)\n",
    "        combined_score = attrs.get('final_combined_score', 0)\n",
    "        n_pos = attrs.get('n_positive_predictions', 0)\n",
    "        \n",
    "        best_score = 1 - study.best_value if study.best_value != float('inf') else 0\n",
    "        \n",
    "        print(f\"âœ… Trial {trial.number:2d} | P={precision:.3f} R={recall:.3f} F1={f1:.3f} \"\n",
    "              f\"F0.5={f_half:.3f} | Thr={threshold:.2f} Pos={n_pos} | Combined={combined_score:.3f} | Best={best_score:.3f}\")\n",
    "        \n",
    "        # Highlight high precision trials\n",
    "        if precision >= 0.55:\n",
    "            print(f\"   ğŸ¯ HIGH PRECISION TRIAL! Conservative={attrs.get('conservative_precision', 0):.3f}\")\n",
    "    \n",
    "    elif trial.state == optuna.trial.TrialState.PRUNED:\n",
    "        print(f\"â­ï¸  Trial {trial.number:2d}: PRUNED\")\n",
    "    elif trial.state == optuna.trial.TrialState.FAIL:\n",
    "        print(f\"âŒ Trial {trial.number:2d}: FAILED\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Main Enhanced Precision Optimization Pipeline\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ ENHANCED PRECISION-OPTIMIZED GRU SEARCH\")\n",
    "    print(\"ğŸ¯ Maximizing PRECISION with improved parameters\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"ğŸ“Š Using F{BETA} score (Î²={BETA}) - 2x weight to PRECISION\")\n",
    "    print(f\"ğŸ¯ Enhanced with {N_TRIALS} trials and focused ranges\")\n",
    "    \n",
    "    try:\n",
    "        # Configure GPU\n",
    "        gpu_available = configure_gpu()\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        features, target, dates = load_and_preprocess_data()\n",
    "        \n",
    "        # Proper scaling\n",
    "        split_idx = int(len(features) * (1 - VAL_FRAC))\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(features.iloc[:split_idx])\n",
    "        \n",
    "        X_train_scaled = scaler.transform(features.iloc[:split_idx])\n",
    "        X_val_scaled = scaler.transform(features.iloc[split_idx:])\n",
    "        y_train = target[:split_idx]\n",
    "        y_val = target[split_idx:]\n",
    "        \n",
    "        print(f\"ğŸ“Š Train: {len(X_train_scaled)} samples, Val: {len(X_val_scaled)} samples\")\n",
    "        \n",
    "        # Save scaler\n",
    "        joblib.dump(scaler, \"gru_enhanced_precision_scaler.pkl\")\n",
    "        \n",
    "        # Prepare data\n",
    "        data_info = (X_train_scaled, X_val_scaled, y_train, y_val)\n",
    "        \n",
    "        # Create enhanced study\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "            pruner=optuna.pruners.MedianPruner(\n",
    "                n_startup_trials=8,  # More startup trials\n",
    "                n_warmup_steps=5\n",
    "            ),\n",
    "            study_name=\"gru_enhanced_precision\"\n",
    "        )\n",
    "        \n",
    "        # Run enhanced optimization\n",
    "        print(f\"\\nğŸ” Starting ENHANCED PRECISION optimization...\")\n",
    "        print(f\"   Focus: Precision with focused parameter ranges\")\n",
    "        print(f\"   Trials: {N_TRIALS}, Timeout: {TIMEOUT//60}min\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        study.optimize(\n",
    "            lambda trial: enhanced_precision_objective(trial, data_info),\n",
    "            n_trials=N_TRIALS,\n",
    "            timeout=TIMEOUT,\n",
    "            show_progress_bar=True,\n",
    "            callbacks=[enhanced_precision_callback]\n",
    "        )\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Enhanced results analysis\n",
    "        print(f\"\\nğŸ† ENHANCED PRECISION OPTIMIZATION COMPLETED\")\n",
    "        print(\"=\" * 55)\n",
    "        \n",
    "        completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "        \n",
    "        if completed_trials:\n",
    "            best_combined_score = 1 - study.best_value\n",
    "            best_trial = study.best_trial\n",
    "            \n",
    "            print(f\"â­ Best combined score: {best_combined_score:.4f}\")\n",
    "            print(f\"ğŸ“Š Completed trials: {len(completed_trials)}\")\n",
    "            print(f\"â±ï¸  Total time: {total_time/60:.1f} minutes\")\n",
    "            \n",
    "            # Best trial metrics\n",
    "            if hasattr(best_trial, 'user_attrs'):\n",
    "                attrs = best_trial.user_attrs\n",
    "                print(f\"\\nğŸ¯ BEST ENHANCED PRECISION METRICS:\")\n",
    "                print(f\"   Precision: {attrs.get('precision', 'N/A'):.4f} â­\")\n",
    "                print(f\"   Recall: {attrs.get('recall', 'N/A'):.4f}\")\n",
    "                print(f\"   F0.5-score: {attrs.get('f_half_score', 'N/A'):.4f}\")\n",
    "                print(f\"   F1-score: {attrs.get('f1_score', 'N/A'):.4f}\")\n",
    "                print(f\"   Decision threshold: {attrs.get('decision_threshold', 'N/A'):.3f}\")\n",
    "                print(f\"   Positive predictions: {attrs.get('n_positive_predictions', 'N/A')}\")\n",
    "            \n",
    "            print(f\"\\nğŸ¯ ENHANCED BEST PARAMETERS:\")\n",
    "            for param, value in study.best_params.items():\n",
    "                print(f\"   {param:15s}: {value}\")\n",
    "            \n",
    "            # Save enhanced results\n",
    "            enhanced_params = {\n",
    "                **study.best_params,\n",
    "                \"optimization_type\": \"enhanced_precision\",\n",
    "                \"beta_score\": BETA,\n",
    "                \"precision_weight\": PRECISION_WEIGHT,\n",
    "                \"n_trials\": N_TRIALS,\n",
    "                \"best_metrics\": {\n",
    "                    k: float(v) if isinstance(v, (int, float, np.number)) else v\n",
    "                    for k, v in best_trial.user_attrs.items()\n",
    "                    if k in ['precision', 'recall', 'f_half_score', 'f1_score', 'decision_threshold', 'final_combined_score']\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(\"gru_enhanced_precision_params.json\", \"w\") as f:\n",
    "                json.dump(enhanced_params, f, indent=2)\n",
    "            \n",
    "            print(f\"\\nâœ… Enhanced precision parameters saved!\")\n",
    "            print(f\"ğŸ¯ Target: >0.60 precision with balanced recall\")\n",
    "            \n",
    "        else:\n",
    "            print(\"âŒ No trials completed successfully!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Enhanced optimization failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a31e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  No GPU detected, using CPU\n",
      "ğŸš€ GRU Multi-Configuration Performance Test\n",
      "=======================================================\n",
      "ğŸ“Š Loading and preprocessing data...\n",
      "   Loaded data: (11476, 66)\n",
      "   After cleaning: (11476, 20)\n",
      "   Features: 19\n",
      "   Target distribution: [5618 5858]\n",
      "   Train samples: 9,180\n",
      "   Val samples: 2,296\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¬ Testing Configuration 1/6: Trial_4_Balanced\n",
      "======================================================================\n",
      "   Window: 30, Units: 128, Layers: 1\n",
      "   Dropout: 0.347, LR: 0.001995, L2: 2.50e-05\n",
      "   Batch: 64, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.547, R=0.424, F1=0.478, F0.5=0.517\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,150\n",
      "   Val sequences: 2,266\n",
      "   ğŸš€ Training model...\n",
      "   â±ï¸  Training completed in 0:01:25.188557 (41 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ğŸ“Š Results:\n",
      "   â”œâ”€ Precision: 0.555 (expected: 0.547) âœ… [+0.008]\n",
      "   â”œâ”€ Recall:    0.366 (expected: 0.424) âŒ [-0.058]\n",
      "   â”œâ”€ F1 Score:  0.441 (expected: 0.478) âŒ [-0.037]\n",
      "   â”œâ”€ F0.5 Score: 0.503 (expected: 0.517) âœ… [-0.014]\n",
      "   â”œâ”€ Accuracy:  0.518\n",
      "   â”œâ”€ AUC:       0.535\n",
      "   â””â”€ Positive predictions: 777\n",
      "   ğŸ’¾ Model saved: gru_trial_4_balanced.h5\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¬ Testing Configuration 2/6: Trial_6_HighPrecision\n",
      "======================================================================\n",
      "   Window: 42, Units: 96, Layers: 1\n",
      "   Dropout: 0.172, LR: 0.000529, L2: 1.87e-04\n",
      "   Batch: 64, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.556, R=0.221, F1=0.316, F0.5=0.427\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,138\n",
      "   Val sequences: 2,254\n",
      "   ğŸš€ Training model...\n",
      "   â±ï¸  Training completed in 0:02:49.410080 (60 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ğŸ“Š Results:\n",
      "   â”œâ”€ Precision: 0.536 (expected: 0.556) âŒ [-0.020]\n",
      "   â”œâ”€ Recall:    0.484 (expected: 0.221) âœ… [+0.263]\n",
      "   â”œâ”€ F1 Score:  0.509 (expected: 0.316) âœ… [+0.193]\n",
      "   â”œâ”€ F0.5 Score: 0.525 (expected: 0.427) âœ… [+0.098]\n",
      "   â”œâ”€ Accuracy:  0.514\n",
      "   â”œâ”€ AUC:       0.520\n",
      "   â””â”€ Positive predictions: 1058\n",
      "   ğŸ’¾ Model saved: gru_trial_6_highprecision.h5\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¬ Testing Configuration 3/6: Trial_8_MaxPrecision\n",
      "======================================================================\n",
      "   Window: 24, Units: 128, Layers: 1\n",
      "   Dropout: 0.252, LR: 0.001056, L2: 2.78e-05\n",
      "   Batch: 64, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.585, R=0.111, F1=0.187, F0.5=0.316\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,156\n",
      "   Val sequences: 2,272\n",
      "   ğŸš€ Training model...\n",
      "   â±ï¸  Training completed in 0:00:23.845321 (19 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ğŸ“Š Results:\n",
      "   â”œâ”€ Precision: 0.527 (expected: 0.585) âŒ [-0.058]\n",
      "   â”œâ”€ Recall:    0.435 (expected: 0.111) âœ… [+0.324]\n",
      "   â”œâ”€ F1 Score:  0.477 (expected: 0.187) âœ… [+0.290]\n",
      "   â”œâ”€ F0.5 Score: 0.505 (expected: 0.316) âœ… [+0.189]\n",
      "   â”œâ”€ Accuracy:  0.504\n",
      "   â”œâ”€ AUC:       0.515\n",
      "   â””â”€ Positive predictions: 974\n",
      "   ğŸ’¾ Model saved: gru_trial_8_maxprecision.h5\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¬ Testing Configuration 4/6: Trial_16_Conservative\n",
      "======================================================================\n",
      "   Window: 36, Units: 96, Layers: 2\n",
      "   Dropout: 0.301, LR: 0.001232, L2: 6.27e-05\n",
      "   Batch: 32, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.577, R=0.213, F1=0.311, F0.5=0.430\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,144\n",
      "   Val sequences: 2,260\n",
      "   ğŸš€ Training model...\n",
      "   â±ï¸  Training completed in 0:03:35.994361 (50 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ğŸ“Š Results:\n",
      "   â”œâ”€ Precision: 0.543 (expected: 0.577) âŒ [-0.034]\n",
      "   â”œâ”€ Recall:    0.384 (expected: 0.213) âœ… [+0.171]\n",
      "   â”œâ”€ F1 Score:  0.450 (expected: 0.311) âœ… [+0.139]\n",
      "   â”œâ”€ F0.5 Score: 0.501 (expected: 0.430) âœ… [+0.071]\n",
      "   â”œâ”€ Accuracy:  0.512\n",
      "   â”œâ”€ AUC:       0.529\n",
      "   â””â”€ Positive predictions: 831\n",
      "   ğŸ’¾ Model saved: gru_trial_16_conservative.h5\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¬ Testing Configuration 5/6: Trial_20_Moderate\n",
      "======================================================================\n",
      "   Window: 36, Units: 96, Layers: 2\n",
      "   Dropout: 0.261, LR: 0.000857, L2: 4.03e-05\n",
      "   Batch: 32, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.530, R=0.723, F1=0.612, F0.5=0.560\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,144\n",
      "   Val sequences: 2,260\n",
      "   ğŸš€ Training model...\n",
      "   â±ï¸  Training completed in 0:03:40.015653 (48 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ğŸ“Š Results:\n",
      "   â”œâ”€ Precision: 0.537 (expected: 0.530) âœ… [+0.007]\n",
      "   â”œâ”€ Recall:    0.386 (expected: 0.723) âŒ [-0.337]\n",
      "   â”œâ”€ F1 Score:  0.449 (expected: 0.612) âŒ [-0.163]\n",
      "   â”œâ”€ F0.5 Score: 0.498 (expected: 0.560) âŒ [-0.062]\n",
      "   â”œâ”€ Accuracy:  0.508\n",
      "   â”œâ”€ AUC:       0.529\n",
      "   â””â”€ Positive predictions: 843\n",
      "   ğŸ’¾ Model saved: gru_trial_20_moderate.h5\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¬ Testing Configuration 6/6: Trial_28_BestOverall\n",
      "======================================================================\n",
      "   Window: 36, Units: 96, Layers: 2\n",
      "   Dropout: 0.294, LR: 0.001390, L2: 2.52e-04\n",
      "   Batch: 32, Threshold: 0.5 (fixed)\n",
      "   Expected: P=0.522, R=0.991, F1=0.683, F0.5=0.576\n",
      "   Note: Expected values were from optimized thresholds, actual results may differ\n",
      "   Train sequences: 9,144\n",
      "   Val sequences: 2,260\n",
      "   ğŸš€ Training model...\n",
      "   â±ï¸  Training completed in 0:06:04.638538 (49 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ğŸ“Š Results:\n",
      "   â”œâ”€ Precision: 0.551 (expected: 0.522) âœ… [+0.029]\n",
      "   â”œâ”€ Recall:    0.437 (expected: 0.991) âŒ [-0.554]\n",
      "   â”œâ”€ F1 Score:  0.488 (expected: 0.683) âŒ [-0.195]\n",
      "   â”œâ”€ F0.5 Score: 0.524 (expected: 0.576) âŒ [-0.052]\n",
      "   â”œâ”€ Accuracy:  0.522\n",
      "   â”œâ”€ AUC:       0.526\n",
      "   â””â”€ Positive predictions: 933\n",
      "   ğŸ’¾ Model saved: gru_trial_28_bestoverall.h5\n",
      "\n",
      "================================================================================\n",
      "ğŸ† MULTI-CONFIGURATION TEST RESULTS\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Performance Summary (Successful: 6/6):\n",
      "                          Precision  Recall     F1   F0.5    AUC   Status\n",
      "--------------------------------------------------------------------------------\n",
      "Trial_4_Balanced              0.555   0.366  0.441  0.503  0.535   âœ… Good\n",
      "Trial_6_HighPrecision         0.536   0.484  0.509  0.525  0.520 âš ï¸  Poor\n",
      "Trial_8_MaxPrecision          0.527   0.435  0.477  0.505  0.515 âš ï¸  Poor\n",
      "Trial_16_Conservative         0.543   0.384  0.450  0.501  0.529 âš ï¸  Poor\n",
      "Trial_20_Moderate             0.537   0.386  0.449  0.498  0.529 âš ï¸  Poor\n",
      "Trial_28_BestOverall          0.551   0.437  0.488  0.524  0.526 âš ï¸  Poor\n",
      "\n",
      "ğŸ† Top Performers:\n",
      "   ğŸ¯ Best Precision: Trial_4_Balanced (0.555)\n",
      "   ğŸ“Š Best F0.5:      Trial_6_HighPrecision (0.525)\n",
      "   âš–ï¸  Best Balanced:  Trial_6_HighPrecision (0.509)\n",
      "\n",
      "ğŸ“ Files Generated:\n",
      "   â€¢ gru_multi_config_results_20250613_113821.json - Complete test results\n",
      "   â€¢ gru_multi_config_scaler.pkl - Feature scaler\n",
      "   â€¢ gru_trial_*.h5 - Individual trained models\n",
      "\n",
      "ğŸ’¡ Recommendation:\n",
      "   Use Trial_6_HighPrecision for precision-focused trading\n",
      "\n",
      "ğŸ‰ Multi-configuration test complete!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gru_multi_config_test.py\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Tests multiple GRU configurations from optimization results.\n",
    "Trains each config and provides detailed performance summary.\n",
    "Identifies the best performing configuration for final training.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, \n",
    "                             fbeta_score, accuracy_score, roc_auc_score,\n",
    "                             confusion_matrix, classification_report)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Setup\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Configure GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ… GPU configured: {len(gpus)} device(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš ï¸  GPU configuration failed: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No GPU detected, using CPU\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Configuration\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC = 0.20\n",
    "BETA = 0.5  # For F0.5 score (precision-focused)\n",
    "EPOCHS = 60\n",
    "EARLY_STOP = 15\n",
    "\n",
    "# Complete drop columns list (same as optimization)\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    'typical_price', 'vwap_24h', 'close_4h',\n",
    "    'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bollinger_width',\n",
    "    'resistance_level', 'support_level',\n",
    "    'high_low', 'high_close', 'low_close', 'true_range',\n",
    "    'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'CCI', 'stoch_%D', 'parkinson_vol',\n",
    "    'ema_cross_down', 'macd_cross_down', 'ema_cross_up', 'macd_cross_up',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'oversold_reversal', 'overbought_reversal',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'timestamp', 'date', 'Unnamed: 0'\n",
    "]\n",
    "\n",
    "# Top 6 configurations from your optimization results (threshold fixed at 0.5)\n",
    "TEST_CONFIGS = [\n",
    "    {\n",
    "        'name': 'Trial_4_Balanced',\n",
    "        'window': 30, 'units': 128, 'layers': 1, 'dropout': 0.3473773873201034,\n",
    "        'lr': 0.0019947718789028682, 'l2': 2.497073714505272e-05, 'batch': 64,\n",
    "        'expected': {'precision': 0.547, 'recall': 0.424, 'f1': 0.478, 'f05': 0.517}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Trial_6_HighPrecision',\n",
    "        'window': 42, 'units': 96, 'layers': 1, 'dropout': 0.17157828539866088,\n",
    "        'lr': 0.0005289646680152981, 'l2': 0.000187422109855557, 'batch': 64,\n",
    "        'expected': {'precision': 0.556, 'recall': 0.221, 'f1': 0.316, 'f05': 0.427}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Trial_8_MaxPrecision',\n",
    "        'window': 24, 'units': 128, 'layers': 1, 'dropout': 0.2521494605155131,\n",
    "        'lr': 0.0010562796147104163, 'l2': 2.781093697926551e-05, 'batch': 64,\n",
    "        'expected': {'precision': 0.585, 'recall': 0.111, 'f1': 0.187, 'f05': 0.316}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Trial_16_Conservative',\n",
    "        'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.30094837842359834,\n",
    "        'lr': 0.0012323935680785315, 'l2': 6.268172739785502e-05, 'batch': 32,\n",
    "        'expected': {'precision': 0.577, 'recall': 0.213, 'f1': 0.311, 'f05': 0.430}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Trial_20_Moderate',\n",
    "        'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.26126299099534406,\n",
    "        'lr': 0.0008574666921947649, 'l2': 4.0337715213162597e-05, 'batch': 32,\n",
    "        'expected': {'precision': 0.530, 'recall': 0.723, 'f1': 0.612, 'f05': 0.560}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Trial_28_BestOverall',\n",
    "        'window': 36, 'units': 96, 'layers': 2, 'dropout': 0.2944123891707492,\n",
    "        'lr': 0.0013899204674669833, 'l2': 0.0002516233411563695, 'batch': 32,\n",
    "        'expected': {'precision': 0.522, 'recall': 0.991, 'f1': 0.683, 'f05': 0.576}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Fixed threshold for all configurations\n",
    "DECISION_THRESHOLD = 0.5\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Helper Functions\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def create_sequences(data, labels, window_size):\n",
    "    \"\"\"Create sequences for time series data.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(labels[i])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "def build_gru_model(config, n_features):\n",
    "    \"\"\"Build GRU model with given configuration.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    for i in range(config['layers']):\n",
    "        return_sequences = (i < config['layers'] - 1)\n",
    "        model.add(keras.layers.GRU(\n",
    "            config['units'],\n",
    "            return_sequences=return_sequences,\n",
    "            dropout=config['dropout'],\n",
    "            recurrent_dropout=config['dropout'] * 0.6,\n",
    "            kernel_regularizer=keras.regularizers.l2(config['l2']),\n",
    "            recurrent_regularizer=keras.regularizers.l2(config['l2'])\n",
    "        ))\n",
    "    \n",
    "    model.add(keras.layers.Dropout(config['dropout']))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=config['lr']),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_prob, config_name, expected_metrics):\n",
    "    \"\"\"Calculate comprehensive metrics.\"\"\"\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    f05 = fbeta_score(y_true, y_pred, beta=BETA, zero_division=0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Calculate differences from expected\n",
    "    precision_diff = precision - expected_metrics['precision']\n",
    "    recall_diff = recall - expected_metrics['recall']\n",
    "    f1_diff = f1 - expected_metrics['f1']\n",
    "    f05_diff = f05 - expected_metrics['f05']\n",
    "    \n",
    "    metrics = {\n",
    "        'config_name': config_name,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'f05_score': f05,\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc,\n",
    "        'n_positive_predictions': int(np.sum(y_pred)),\n",
    "        'expected_precision': expected_metrics['precision'],\n",
    "        'expected_recall': expected_metrics['recall'],\n",
    "        'expected_f1': expected_metrics['f1'],\n",
    "        'expected_f05': expected_metrics['f05'],\n",
    "        'precision_diff': precision_diff,\n",
    "        'recall_diff': recall_diff,\n",
    "        'f1_diff': f1_diff,\n",
    "        'f05_diff': f05_diff,\n",
    "        'confusion_matrix': confusion_matrix(y_true, y_pred).tolist()\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Data Loading and Preprocessing\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"ğŸš€ GRU Multi-Configuration Performance Test\")\n",
    "print(\"=\" * 55)\n",
    "print(\"ğŸ“Š Loading and preprocessing data...\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df[df.index >= \"2020-01-01\"]  # Same as optimization\n",
    "print(f\"   Loaded data: {df.shape}\")\n",
    "\n",
    "# Clean data\n",
    "if 'target' not in df.columns:\n",
    "    raise ValueError(\"âŒ Target column not found!\")\n",
    "\n",
    "# Drop columns\n",
    "cols_to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "df = df[df[\"target\"].notna()].dropna()\n",
    "print(f\"   After cleaning: {df.shape}\")\n",
    "\n",
    "# Prepare features and target\n",
    "features = df.drop(columns=\"target\")\n",
    "target = df[\"target\"].astype(int).values\n",
    "n_features = features.shape[1]\n",
    "\n",
    "print(f\"   Features: {n_features}\")\n",
    "print(f\"   Target distribution: {np.bincount(target)}\")\n",
    "\n",
    "# Scale features\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features.iloc[:split_idx])\n",
    "\n",
    "X_train_scaled = scaler.transform(features.iloc[:split_idx])\n",
    "X_val_scaled = scaler.transform(features.iloc[split_idx:])\n",
    "y_train = target[:split_idx]\n",
    "y_val = target[split_idx:]\n",
    "\n",
    "print(f\"   Train samples: {len(X_train_scaled):,}\")\n",
    "print(f\"   Val samples: {len(X_val_scaled):,}\")\n",
    "\n",
    "# Save scaler for later use\n",
    "joblib.dump(scaler, \"gru_multi_config_scaler.pkl\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Test Each Configuration\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "results = []\n",
    "\n",
    "for i, config in enumerate(TEST_CONFIGS, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ”¬ Testing Configuration {i}/6: {config['name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Display configuration\n",
    "    print(f\"   Window: {config['window']}, Units: {config['units']}, Layers: {config['layers']}\")\n",
    "    print(f\"   Dropout: {config['dropout']:.3f}, LR: {config['lr']:.6f}, L2: {config['l2']:.2e}\")\n",
    "    print(f\"   Batch: {config['batch']}, Threshold: {DECISION_THRESHOLD} (fixed)\")\n",
    "    \n",
    "    # Expected performance\n",
    "    exp = config['expected']\n",
    "    print(f\"   Expected: P={exp['precision']:.3f}, R={exp['recall']:.3f}, F1={exp['f1']:.3f}, F0.5={exp['f05']:.3f}\")\n",
    "    print(f\"   Note: Expected values were from optimized thresholds, actual results may differ\")\n",
    "    \n",
    "    try:\n",
    "        # Create sequences\n",
    "        X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, config['window'])\n",
    "        X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, config['window'])\n",
    "        \n",
    "        print(f\"   Train sequences: {len(X_train_seq):,}\")\n",
    "        print(f\"   Val sequences: {len(X_val_seq):,}\")\n",
    "        \n",
    "        # Build model\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        model = build_gru_model(config, n_features)\n",
    "        \n",
    "        print(\"   ğŸš€ Training model...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Train model\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=EARLY_STOP,\n",
    "                restore_best_weights=True,\n",
    "                verbose=0\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=7,\n",
    "                min_lr=1e-7,\n",
    "                verbose=0\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=config['batch'],\n",
    "            validation_data=(X_val_seq, y_val_seq),\n",
    "            callbacks=callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        training_time = datetime.now() - start_time\n",
    "        epochs_trained = len(history.history['loss'])\n",
    "        \n",
    "        print(f\"   â±ï¸  Training completed in {training_time} ({epochs_trained} epochs)\")\n",
    "        \n",
    "        # Evaluate model\n",
    "        y_pred_prob = model.predict(X_val_seq, verbose=0).ravel()\n",
    "        y_pred = (y_pred_prob >= DECISION_THRESHOLD).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(y_val_seq, y_pred, y_pred_prob, config['name'], config['expected'])\n",
    "        metrics['training_time_seconds'] = training_time.total_seconds()\n",
    "        metrics['epochs_trained'] = epochs_trained\n",
    "        metrics['config'] = {k: v for k, v in config.items() if k not in ['name', 'expected']}\n",
    "        metrics['config']['threshold_used'] = DECISION_THRESHOLD\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\n   ğŸ“Š Results:\")\n",
    "        print(f\"   â”œâ”€ Precision: {metrics['precision']:.3f} (expected: {exp['precision']:.3f}) \"\n",
    "              f\"{'âœ…' if metrics['precision_diff'] >= -0.02 else 'âŒ'} [{metrics['precision_diff']:+.3f}]\")\n",
    "        print(f\"   â”œâ”€ Recall:    {metrics['recall']:.3f} (expected: {exp['recall']:.3f}) \"\n",
    "              f\"{'âœ…' if metrics['recall_diff'] >= -0.02 else 'âŒ'} [{metrics['recall_diff']:+.3f}]\")\n",
    "        print(f\"   â”œâ”€ F1 Score:  {metrics['f1_score']:.3f} (expected: {exp['f1']:.3f}) \"\n",
    "              f\"{'âœ…' if metrics['f1_diff'] >= -0.02 else 'âŒ'} [{metrics['f1_diff']:+.3f}]\")\n",
    "        print(f\"   â”œâ”€ F0.5 Score: {metrics['f05_score']:.3f} (expected: {exp['f05']:.3f}) \"\n",
    "              f\"{'âœ…' if metrics['f05_diff'] >= -0.02 else 'âŒ'} [{metrics['f05_diff']:+.3f}]\")\n",
    "        print(f\"   â”œâ”€ Accuracy:  {metrics['accuracy']:.3f}\")\n",
    "        print(f\"   â”œâ”€ AUC:       {metrics['auc']:.3f}\")\n",
    "        print(f\"   â””â”€ Positive predictions: {metrics['n_positive_predictions']}\")\n",
    "        \n",
    "        # Save model if it meets expectations\n",
    "        model_filename = f\"gru_{config['name'].lower()}.h5\"\n",
    "        model.save(model_filename)\n",
    "        print(f\"   ğŸ’¾ Model saved: {model_filename}\")\n",
    "        \n",
    "        results.append(metrics)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Training failed: {str(e)}\")\n",
    "        error_metrics = {\n",
    "            'config_name': config['name'],\n",
    "            'error': str(e),\n",
    "            'status': 'failed'\n",
    "        }\n",
    "        results.append(error_metrics)\n",
    "    \n",
    "    finally:\n",
    "        # Cleanup\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Final Analysis and Summary\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ğŸ† MULTI-CONFIGURATION TEST RESULTS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Filter successful results\n",
    "successful_results = [r for r in results if 'error' not in r]\n",
    "\n",
    "if successful_results:\n",
    "    print(f\"\\nğŸ“Š Performance Summary (Successful: {len(successful_results)}/{len(TEST_CONFIGS)}):\")\n",
    "    print(f\"{'':25s} {'Precision':>9s} {'Recall':>7s} {'F1':>6s} {'F0.5':>6s} {'AUC':>6s} {'Status':>8s}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for result in successful_results:\n",
    "        status = \"âœ… Good\" if result['precision_diff'] >= -0.02 and result['f05_diff'] >= -0.02 else \"âš ï¸  Poor\"\n",
    "        print(f\"{result['config_name']:25s} {result['precision']:>9.3f} {result['recall']:>7.3f} \"\n",
    "              f\"{result['f1_score']:>6.3f} {result['f05_score']:>6.3f} {result['auc']:>6.3f} {status:>8s}\")\n",
    "    \n",
    "    # Find best performers\n",
    "    best_precision = max(successful_results, key=lambda x: x['precision'])\n",
    "    best_f05 = max(successful_results, key=lambda x: x['f05_score'])\n",
    "    best_balanced = max(successful_results, key=lambda x: x['f1_score'])\n",
    "    \n",
    "    print(f\"\\nğŸ† Top Performers:\")\n",
    "    print(f\"   ğŸ¯ Best Precision: {best_precision['config_name']} ({best_precision['precision']:.3f})\")\n",
    "    print(f\"   ğŸ“Š Best F0.5:      {best_f05['config_name']} ({best_f05['f05_score']:.3f})\")\n",
    "    print(f\"   âš–ï¸  Best Balanced:  {best_balanced['config_name']} ({best_balanced['f1_score']:.3f})\")\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    summary = {\n",
    "        \"timestamp\": timestamp + \"Z\",\n",
    "        \"test_type\": \"multi_configuration_comparison\",\n",
    "        \"configurations_tested\": len(TEST_CONFIGS),\n",
    "        \"successful_configs\": len(successful_results),\n",
    "        \"dataset_info\": {\n",
    "            \"total_samples\": len(df),\n",
    "            \"train_samples\": len(X_train_scaled),\n",
    "            \"val_samples\": len(X_val_scaled),\n",
    "            \"features\": n_features\n",
    "        },\n",
    "        \"best_performers\": {\n",
    "            \"best_precision\": best_precision['config_name'],\n",
    "            \"best_f05\": best_f05['config_name'],\n",
    "            \"best_balanced\": best_balanced['config_name']\n",
    "        },\n",
    "        \"detailed_results\": results\n",
    "    }\n",
    "    \n",
    "    results_filename = f\"gru_multi_config_results_{timestamp}.json\"\n",
    "    with open(results_filename, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nğŸ“ Files Generated:\")\n",
    "    print(f\"   â€¢ {results_filename} - Complete test results\")\n",
    "    print(f\"   â€¢ gru_multi_config_scaler.pkl - Feature scaler\")\n",
    "    print(f\"   â€¢ gru_trial_*.h5 - Individual trained models\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ Recommendation:\")\n",
    "    if best_f05['f05_score'] >= 0.5:\n",
    "        print(f\"   Use {best_f05['config_name']} for precision-focused trading\")\n",
    "    elif best_balanced['f1_score'] >= 0.6:\n",
    "        print(f\"   Use {best_balanced['config_name']} for balanced performance\")\n",
    "    else:\n",
    "        print(f\"   Consider additional hyperparameter tuning or different approach\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No configurations completed successfully!\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Multi-configuration test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d45bfb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  No GPU detected, using CPU\n",
      "ğŸš€ GRU Trial 28 Final Training\n",
      "=============================================\n",
      "ğŸ¯ Configuration: BestOverall (0.551 precision, 0.437 recall)\n",
      "ğŸ“Š Loading and preprocessing data...\n",
      "   Loaded data: (11476, 66)\n",
      "   After cleaning: (11476, 20)\n",
      "   Features: 19\n",
      "   Target distribution: [5618 5858]\n",
      "   Train samples: 9,180\n",
      "   Val samples: 2,296\n",
      "   Scaler saved: gru_trial28_scaler.pkl\n",
      "\n",
      "ğŸ”„ Creating sequences (window=36)...\n",
      "   Train sequences: 9,144\n",
      "   Val sequences: 2,260\n",
      "\n",
      "ğŸ—ï¸ Building GRU model...\n",
      "   Units: 96, Layers: 2\n",
      "   Dropout: 0.294, LR: 0.001390\n",
      "   L2: 2.52e-04, Batch: 32\n",
      "\n",
      "ğŸ“‹ Model architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                               </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                    </span>â”ƒ<span style=\"font-weight: bold\">           Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                                  â”‚ ?                               â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                                â”‚ ?                               â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                          â”‚ ?                               â”‚                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                              â”‚ ?                               â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gru (\u001b[38;5;33mGRU\u001b[0m)                                  â”‚ ?                               â”‚       \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                                â”‚ ?                               â”‚       \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                          â”‚ ?                               â”‚                 \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                              â”‚ ?                               â”‚       \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training model...\n",
      "   Epochs: 80, Early stopping: 15\n",
      "   Expected performance: P=0.551, R=0.437\n",
      "Epoch 1/80\n",
      "286/286 - 7s - 24ms/step - accuracy: 0.5024 - loss: 0.7586 - val_accuracy: 0.4996 - val_loss: 0.7292 - learning_rate: 0.0014\n",
      "Epoch 2/80\n",
      "286/286 - 4s - 15ms/step - accuracy: 0.5094 - loss: 0.7253 - val_accuracy: 0.4867 - val_loss: 0.7220 - learning_rate: 0.0014\n",
      "Epoch 3/80\n",
      "286/286 - 6s - 20ms/step - accuracy: 0.5046 - loss: 0.7160 - val_accuracy: 0.4796 - val_loss: 0.7143 - learning_rate: 0.0014\n",
      "Epoch 4/80\n",
      "286/286 - 9s - 30ms/step - accuracy: 0.5107 - loss: 0.7094 - val_accuracy: 0.4823 - val_loss: 0.7135 - learning_rate: 0.0014\n",
      "Epoch 5/80\n",
      "286/286 - 8s - 30ms/step - accuracy: 0.5086 - loss: 0.7052 - val_accuracy: 0.4996 - val_loss: 0.7036 - learning_rate: 0.0014\n",
      "Epoch 6/80\n",
      "286/286 - 8s - 30ms/step - accuracy: 0.5172 - loss: 0.7020 - val_accuracy: 0.4987 - val_loss: 0.7010 - learning_rate: 0.0014\n",
      "Epoch 7/80\n",
      "286/286 - 8s - 30ms/step - accuracy: 0.5197 - loss: 0.6986 - val_accuracy: 0.4956 - val_loss: 0.7012 - learning_rate: 0.0014\n",
      "Epoch 8/80\n",
      "286/286 - 8s - 29ms/step - accuracy: 0.5226 - loss: 0.6978 - val_accuracy: 0.4929 - val_loss: 0.6995 - learning_rate: 0.0014\n",
      "Epoch 9/80\n",
      "286/286 - 8s - 30ms/step - accuracy: 0.5137 - loss: 0.6972 - val_accuracy: 0.5000 - val_loss: 0.6975 - learning_rate: 0.0014\n",
      "Epoch 10/80\n",
      "286/286 - 8s - 30ms/step - accuracy: 0.5122 - loss: 0.6960 - val_accuracy: 0.4929 - val_loss: 0.6967 - learning_rate: 0.0014\n",
      "Epoch 11/80\n",
      "286/286 - 9s - 30ms/step - accuracy: 0.5182 - loss: 0.6953 - val_accuracy: 0.5084 - val_loss: 0.6953 - learning_rate: 0.0014\n",
      "Epoch 12/80\n",
      "286/286 - 9s - 31ms/step - accuracy: 0.5112 - loss: 0.6950 - val_accuracy: 0.5208 - val_loss: 0.6942 - learning_rate: 0.0014\n",
      "Epoch 13/80\n",
      "286/286 - 9s - 31ms/step - accuracy: 0.5172 - loss: 0.6943 - val_accuracy: 0.5106 - val_loss: 0.6941 - learning_rate: 0.0014\n",
      "Epoch 14/80\n",
      "286/286 - 9s - 30ms/step - accuracy: 0.5165 - loss: 0.6940 - val_accuracy: 0.5150 - val_loss: 0.6936 - learning_rate: 0.0014\n",
      "Epoch 15/80\n",
      "286/286 - 9s - 30ms/step - accuracy: 0.5139 - loss: 0.6939 - val_accuracy: 0.5288 - val_loss: 0.6933 - learning_rate: 0.0014\n",
      "Epoch 16/80\n",
      "286/286 - 7s - 24ms/step - accuracy: 0.5196 - loss: 0.6935 - val_accuracy: 0.5217 - val_loss: 0.6930 - learning_rate: 0.0014\n",
      "Epoch 17/80\n",
      "286/286 - 4s - 15ms/step - accuracy: 0.5162 - loss: 0.6934 - val_accuracy: 0.5235 - val_loss: 0.6932 - learning_rate: 0.0014\n",
      "Epoch 18/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5167 - loss: 0.6932 - val_accuracy: 0.5181 - val_loss: 0.6934 - learning_rate: 0.0014\n",
      "Epoch 19/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5196 - loss: 0.6933 - val_accuracy: 0.5164 - val_loss: 0.6928 - learning_rate: 0.0014\n",
      "Epoch 20/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5171 - loss: 0.6931 - val_accuracy: 0.5208 - val_loss: 0.6931 - learning_rate: 0.0014\n",
      "Epoch 21/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5160 - loss: 0.6934 - val_accuracy: 0.5084 - val_loss: 0.6934 - learning_rate: 0.0014\n",
      "Epoch 22/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5140 - loss: 0.6931 - val_accuracy: 0.5009 - val_loss: 0.6943 - learning_rate: 0.0014\n",
      "Epoch 23/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5171 - loss: 0.6935 - val_accuracy: 0.5221 - val_loss: 0.6931 - learning_rate: 0.0014\n",
      "Epoch 24/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5160 - loss: 0.6937 - val_accuracy: 0.5133 - val_loss: 0.6946 - learning_rate: 0.0014\n",
      "Epoch 25/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5180 - loss: 0.6938 - val_accuracy: 0.5195 - val_loss: 0.6936 - learning_rate: 0.0014\n",
      "Epoch 26/80\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0006949602393433452.\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5189 - loss: 0.6936 - val_accuracy: 0.5204 - val_loss: 0.6938 - learning_rate: 0.0014\n",
      "Epoch 27/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5180 - loss: 0.6930 - val_accuracy: 0.5257 - val_loss: 0.6931 - learning_rate: 6.9496e-04\n",
      "Epoch 28/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5231 - loss: 0.6927 - val_accuracy: 0.5150 - val_loss: 0.6938 - learning_rate: 6.9496e-04\n",
      "Epoch 29/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5208 - loss: 0.6928 - val_accuracy: 0.5195 - val_loss: 0.6935 - learning_rate: 6.9496e-04\n",
      "Epoch 30/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5180 - loss: 0.6930 - val_accuracy: 0.5221 - val_loss: 0.6931 - learning_rate: 6.9496e-04\n",
      "Epoch 31/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5187 - loss: 0.6928 - val_accuracy: 0.5199 - val_loss: 0.6931 - learning_rate: 6.9496e-04\n",
      "Epoch 32/80\n",
      "286/286 - 4s - 15ms/step - accuracy: 0.5235 - loss: 0.6926 - val_accuracy: 0.5181 - val_loss: 0.6931 - learning_rate: 6.9496e-04\n",
      "Epoch 33/80\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0003474801196716726.\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5217 - loss: 0.6925 - val_accuracy: 0.5164 - val_loss: 0.6939 - learning_rate: 6.9496e-04\n",
      "Epoch 34/80\n",
      "286/286 - 4s - 14ms/step - accuracy: 0.5192 - loss: 0.6921 - val_accuracy: 0.5230 - val_loss: 0.6931 - learning_rate: 3.4748e-04\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\n",
      "â±ï¸  Training completed in 0:03:20.715130 (34 epochs)\n",
      "\n",
      "ğŸ“Š Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ˆ Final Results:\n",
      "   Precision: 0.536 (expected: 0.551) [-0.015]\n",
      "   Recall:    0.516 (expected: 0.437) [+0.079]\n",
      "   F1 Score:  0.526 (expected: 0.488) [+0.038]\n",
      "   F0.5 Score: 0.532 (expected: 0.524) [+0.008]\n",
      "   Accuracy:  0.516\n",
      "   AUC:       0.527\n",
      "   Positive predictions: 1130\n",
      "\n",
      "ğŸ“‹ Confusion Matrix:\n",
      "[[561 524]\n",
      " [569 606]]\n",
      "\n",
      "ğŸ“‹ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.50      0.52      0.51      1085\n",
      "          Up       0.54      0.52      0.53      1175\n",
      "\n",
      "    accuracy                           0.52      2260\n",
      "   macro avg       0.52      0.52      0.52      2260\n",
      "weighted avg       0.52      0.52      0.52      2260\n",
      "\n",
      "\n",
      "ğŸ“ Generating predictions CSV...\n",
      "   Predictions saved: gru_trial28_predictions.csv\n",
      "   Total predictions: 2,260\n",
      "\n",
      "ğŸ“‹ Sample predictions:\n",
      "          timestamp  prob_up  prob_down  winning_prob  prediction  actual\n",
      "2024-03-16 12:00:00 0.519279   0.480721      0.519279           1       1\n",
      "2024-03-16 16:00:00 0.520203   0.479797      0.520203           1       0\n",
      "2024-03-16 20:00:00 0.519091   0.480909      0.519091           1       0\n",
      "2024-03-17 00:00:00 0.519558   0.480442      0.519558           1       1\n",
      "2024-03-17 04:00:00 0.521405   0.478595      0.521405           1       1\n",
      "2024-03-17 08:00:00 0.520473   0.479527      0.520473           1       1\n",
      "2024-03-17 12:00:00 0.516235   0.483765      0.516235           1       1\n",
      "2024-03-17 16:00:00 0.512534   0.487466      0.512534           1       1\n",
      "2024-03-17 20:00:00 0.505149   0.494851      0.505149           1       0\n",
      "2024-03-18 00:00:00 0.497947   0.502053      0.502053           0       1\n",
      "\n",
      "ğŸ’¾ Saving model and summary...\n",
      "\n",
      "ğŸ‰ Trial 28 Final Training Complete!\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“ˆ Performance Summary:\n",
      "   Precision: 0.536 (target: 0.551)\n",
      "   Recall: 0.516 (target: 0.437)\n",
      "   F1 Score: 0.526 (target: 0.488)\n",
      "   F0.5 Score: 0.532 (target: 0.524)\n",
      "   AUC: 0.527\n",
      "\n",
      "ğŸ“ Files Generated:\n",
      "   â€¢ gru_trial28_final.h5 - Trained GRU model\n",
      "   â€¢ gru_trial28_scaler.pkl - Feature scaler\n",
      "   â€¢ gru_trial28_predictions.csv - Validation predictions (2,260 rows)\n",
      "   â€¢ gru_trial28_training_summary.json - Complete training summary\n",
      "\n",
      "ğŸ¯ Model ready for production trading!\n",
      "   Expected: ~55% precision with ~44% recall\n",
      "   Configuration: 36-window, 96-unit, 2-layer GRU\n",
      "\n",
      "âœ¨ Training pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gru_trial28_final_training.py\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Final training of Trial 28 (BestOverall) GRU configuration.\n",
    "Trains the model and generates predictions CSV in the exact format requested.\n",
    "\n",
    "Trial 28 Config: 0.551 precision, 0.437 recall, 0.488 F1, 0.524 F0.5\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, \n",
    "                             fbeta_score, accuracy_score, roc_auc_score,\n",
    "                             confusion_matrix, classification_report)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Setup\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Configure GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ… GPU configured: {len(gpus)} device(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš ï¸  GPU configuration failed: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No GPU detected, using CPU\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Configuration\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC = 0.20\n",
    "DECISION_THRESHOLD = 0.5\n",
    "EPOCHS = 80\n",
    "EARLY_STOP = 15\n",
    "\n",
    "# Output files\n",
    "MODEL_OUT = \"gru_trial28_final.h5\"\n",
    "SCALER_OUT = \"gru_trial28_scaler.pkl\"\n",
    "PREDICTIONS_OUT = \"gru_trial28_predictions.csv\"\n",
    "SUMMARY_JSON = \"gru_trial28_training_summary.json\"\n",
    "\n",
    "# Complete drop columns list (same as optimization)\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    'typical_price', 'vwap_24h', 'close_4h',\n",
    "    'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bollinger_width',\n",
    "    'resistance_level', 'support_level',\n",
    "    'high_low', 'high_close', 'low_close', 'true_range',\n",
    "    'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'CCI', 'stoch_%D', 'parkinson_vol',\n",
    "    'ema_cross_down', 'macd_cross_down', 'ema_cross_up', 'macd_cross_up',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'oversold_reversal', 'overbought_reversal',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'timestamp', 'date', 'Unnamed: 0'\n",
    "]\n",
    "\n",
    "# Trial 28 Optimal Configuration\n",
    "TRIAL28_CONFIG = {\n",
    "    'name': 'Trial_28_BestOverall',\n",
    "    'window': 36,\n",
    "    'units': 96,\n",
    "    'layers': 2,\n",
    "    'dropout': 0.2944123891707492,\n",
    "    'lr': 0.0013899204674669833,\n",
    "    'l2': 0.0002516233411563695,\n",
    "    'batch': 32,\n",
    "    'expected_performance': {\n",
    "        'precision': 0.551,\n",
    "        'recall': 0.437,\n",
    "        'f1': 0.488,\n",
    "        'f05': 0.524\n",
    "    }\n",
    "}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Helper Functions\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def create_sequences(data, labels, window_size):\n",
    "    \"\"\"Create sequences for time series data.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(labels[i])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "def build_gru_model(config, n_features):\n",
    "    \"\"\"Build GRU model with Trial 28 configuration.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    for i in range(config['layers']):\n",
    "        return_sequences = (i < config['layers'] - 1)\n",
    "        model.add(keras.layers.GRU(\n",
    "            config['units'],\n",
    "            return_sequences=return_sequences,\n",
    "            dropout=config['dropout'],\n",
    "            recurrent_dropout=config['dropout'] * 0.6,\n",
    "            kernel_regularizer=keras.regularizers.l2(config['l2']),\n",
    "            recurrent_regularizer=keras.regularizers.l2(config['l2'])\n",
    "        ))\n",
    "    \n",
    "    model.add(keras.layers.Dropout(config['dropout']))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=config['lr']),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Data Loading and Preprocessing\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"ğŸš€ GRU Trial 28 Final Training\")\n",
    "print(\"=\" * 45)\n",
    "print(\"ğŸ¯ Configuration: BestOverall (0.551 precision, 0.437 recall)\")\n",
    "print(\"ğŸ“Š Loading and preprocessing data...\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df[df.index >= \"2020-01-01\"]  # Same as optimization\n",
    "print(f\"   Loaded data: {df.shape}\")\n",
    "\n",
    "# Clean data\n",
    "if 'target' not in df.columns:\n",
    "    raise ValueError(\"âŒ Target column not found!\")\n",
    "\n",
    "# Drop columns\n",
    "cols_to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "df = df[df[\"target\"].notna()].dropna()\n",
    "print(f\"   After cleaning: {df.shape}\")\n",
    "\n",
    "# Prepare features and target\n",
    "features = df.drop(columns=\"target\")\n",
    "target = df[\"target\"].astype(int).values\n",
    "n_features = features.shape[1]\n",
    "\n",
    "print(f\"   Features: {n_features}\")\n",
    "print(f\"   Target distribution: {np.bincount(target)}\")\n",
    "\n",
    "# Scale features\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features.iloc[:split_idx])\n",
    "\n",
    "X_train_scaled = scaler.transform(features.iloc[:split_idx])\n",
    "X_val_scaled = scaler.transform(features.iloc[split_idx:])\n",
    "y_train = target[:split_idx]\n",
    "y_val = target[split_idx:]\n",
    "\n",
    "print(f\"   Train samples: {len(X_train_scaled):,}\")\n",
    "print(f\"   Val samples: {len(X_val_scaled):,}\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, SCALER_OUT)\n",
    "print(f\"   Scaler saved: {SCALER_OUT}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Create Sequences\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ”„ Creating sequences (window={TRIAL28_CONFIG['window']})...\")\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, TRIAL28_CONFIG['window'])\n",
    "X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, TRIAL28_CONFIG['window'])\n",
    "\n",
    "print(f\"   Train sequences: {len(X_train_seq):,}\")\n",
    "print(f\"   Val sequences: {len(X_val_seq):,}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Build and Train Model\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ—ï¸ Building GRU model...\")\n",
    "print(f\"   Units: {TRIAL28_CONFIG['units']}, Layers: {TRIAL28_CONFIG['layers']}\")\n",
    "print(f\"   Dropout: {TRIAL28_CONFIG['dropout']:.3f}, LR: {TRIAL28_CONFIG['lr']:.6f}\")\n",
    "print(f\"   L2: {TRIAL28_CONFIG['l2']:.2e}, Batch: {TRIAL28_CONFIG['batch']}\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_gru_model(TRIAL28_CONFIG, n_features)\n",
    "\n",
    "# Display model summary\n",
    "print(f\"\\nğŸ“‹ Model architecture:\")\n",
    "model.summary(line_length=100)\n",
    "\n",
    "# Prepare callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=EARLY_STOP,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=7,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸš€ Training model...\")\n",
    "print(f\"   Epochs: {EPOCHS}, Early stopping: {EARLY_STOP}\")\n",
    "print(f\"   Expected performance: P={TRIAL28_CONFIG['expected_performance']['precision']:.3f}, \"\n",
    "      f\"R={TRIAL28_CONFIG['expected_performance']['recall']:.3f}\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=TRIAL28_CONFIG['batch'],\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "training_time = datetime.now() - start_time\n",
    "epochs_trained = len(history.history['loss'])\n",
    "\n",
    "print(f\"\\nâ±ï¸  Training completed in {training_time} ({epochs_trained} epochs)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Evaluate Model\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ“Š Evaluating model...\")\n",
    "\n",
    "y_pred_prob = model.predict(X_val_seq, verbose=0).ravel()\n",
    "y_pred = (y_pred_prob >= DECISION_THRESHOLD).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_val_seq, y_pred, zero_division=0)\n",
    "recall = recall_score(y_val_seq, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_val_seq, y_pred, zero_division=0)\n",
    "f05 = fbeta_score(y_val_seq, y_pred, beta=0.5, zero_division=0)\n",
    "accuracy = accuracy_score(y_val_seq, y_pred)\n",
    "auc = roc_auc_score(y_val_seq, y_pred_prob)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nğŸ“ˆ Final Results:\")\n",
    "expected = TRIAL28_CONFIG['expected_performance']\n",
    "print(f\"   Precision: {precision:.3f} (expected: {expected['precision']:.3f}) \"\n",
    "      f\"[{precision - expected['precision']:+.3f}]\")\n",
    "print(f\"   Recall:    {recall:.3f} (expected: {expected['recall']:.3f}) \"\n",
    "      f\"[{recall - expected['recall']:+.3f}]\")\n",
    "print(f\"   F1 Score:  {f1:.3f} (expected: {expected['f1']:.3f}) \"\n",
    "      f\"[{f1 - expected['f1']:+.3f}]\")\n",
    "print(f\"   F0.5 Score: {f05:.3f} (expected: {expected['f05']:.3f}) \"\n",
    "      f\"[{f05 - expected['f05']:+.3f}]\")\n",
    "print(f\"   Accuracy:  {accuracy:.3f}\")\n",
    "print(f\"   AUC:       {auc:.3f}\")\n",
    "print(f\"   Positive predictions: {np.sum(y_pred)}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val_seq, y_pred)\n",
    "print(f\"\\nğŸ“‹ Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nğŸ“‹ Classification Report:\")\n",
    "print(classification_report(y_val_seq, y_pred, target_names=[\"Down\", \"Up\"]))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Generate Predictions CSV\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ“ Generating predictions CSV...\")\n",
    "\n",
    "# Get validation timestamps (accounting for window offset)\n",
    "val_start_idx = split_idx + TRIAL28_CONFIG['window']\n",
    "val_timestamps = df.index[val_start_idx:val_start_idx + len(y_pred_prob)]\n",
    "\n",
    "# Calculate probabilities\n",
    "prob_up = y_pred_prob\n",
    "prob_down = 1.0 - prob_up\n",
    "winning_prob = np.maximum(prob_up, prob_down)\n",
    "\n",
    "# Create predictions dataframe\n",
    "predictions_df = pd.DataFrame({\n",
    "    'timestamp': val_timestamps.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'prob_up': prob_up,\n",
    "    'prob_down': prob_down,\n",
    "    'winning_prob': winning_prob,\n",
    "    'prediction': y_pred,\n",
    "    'actual': y_val_seq\n",
    "})\n",
    "\n",
    "# Save predictions CSV\n",
    "predictions_df.to_csv(PREDICTIONS_OUT, index=False, float_format='%.6f')\n",
    "\n",
    "print(f\"   Predictions saved: {PREDICTIONS_OUT}\")\n",
    "print(f\"   Total predictions: {len(predictions_df):,}\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(f\"\\nğŸ“‹ Sample predictions:\")\n",
    "print(predictions_df.head(10).to_string(index=False))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Save Model and Summary\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ’¾ Saving model and summary...\")\n",
    "\n",
    "# Save model\n",
    "model.save(MODEL_OUT)\n",
    "\n",
    "# Create comprehensive summary\n",
    "summary = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "    \"model_type\": \"GRU_Trial28_BestOverall\",\n",
    "    \"configuration\": TRIAL28_CONFIG,\n",
    "    \"dataset_info\": {\n",
    "        \"total_samples\": len(df),\n",
    "        \"train_samples\": len(X_train_scaled),\n",
    "        \"val_samples\": len(X_val_scaled),\n",
    "        \"features\": n_features,\n",
    "        \"window_size\": TRIAL28_CONFIG['window'],\n",
    "        \"train_period\": f\"{df.index[0]} to {df.index[split_idx-1]}\",\n",
    "        \"val_period\": f\"{df.index[split_idx]} to {df.index[-1]}\"\n",
    "    },\n",
    "    \"training_info\": {\n",
    "        \"epochs_trained\": epochs_trained,\n",
    "        \"training_time_seconds\": training_time.total_seconds(),\n",
    "        \"early_stopping_patience\": EARLY_STOP,\n",
    "        \"final_train_loss\": float(history.history['loss'][-1]),\n",
    "        \"final_val_loss\": float(history.history['val_loss'][-1]),\n",
    "        \"best_val_loss\": float(min(history.history['val_loss']))\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1_score\": float(f1),\n",
    "        \"f05_score\": float(f05),\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"auc\": float(auc),\n",
    "        \"decision_threshold\": DECISION_THRESHOLD,\n",
    "        \"positive_predictions\": int(np.sum(y_pred)),\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    },\n",
    "    \"expected_vs_actual\": {\n",
    "        \"precision_diff\": float(precision - expected['precision']),\n",
    "        \"recall_diff\": float(recall - expected['recall']),\n",
    "        \"f1_diff\": float(f1 - expected['f1']),\n",
    "        \"f05_diff\": float(f05 - expected['f05'])\n",
    "    },\n",
    "    \"class_distribution\": {\n",
    "        \"train_positive_rate\": float(np.mean(y_train)),\n",
    "        \"val_positive_rate\": float(np.mean(y_val)),\n",
    "        \"train_counts\": [int(np.sum(y_train == 0)), int(np.sum(y_train == 1))],\n",
    "        \"val_counts\": [int(np.sum(y_val == 0)), int(np.sum(y_val == 1))]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "with open(SUMMARY_JSON, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Final Report\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ‰ Trial 28 Final Training Complete!\")\n",
    "print(f\"â•\" * 50)\n",
    "print(f\"ğŸ“ˆ Performance Summary:\")\n",
    "print(f\"   Precision: {precision:.3f} (target: 0.551)\")\n",
    "print(f\"   Recall: {recall:.3f} (target: 0.437)\")\n",
    "print(f\"   F1 Score: {f1:.3f} (target: 0.488)\")\n",
    "print(f\"   F0.5 Score: {f05:.3f} (target: 0.524)\")\n",
    "print(f\"   AUC: {auc:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Files Generated:\")\n",
    "print(f\"   â€¢ {MODEL_OUT} - Trained GRU model\")\n",
    "print(f\"   â€¢ {SCALER_OUT} - Feature scaler\")\n",
    "print(f\"   â€¢ {PREDICTIONS_OUT} - Validation predictions ({len(predictions_df):,} rows)\")\n",
    "print(f\"   â€¢ {SUMMARY_JSON} - Complete training summary\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Model ready for production trading!\")\n",
    "print(f\"   Expected: ~55% precision with ~44% recall\")\n",
    "print(f\"   Configuration: 36-window, 96-unit, 2-layer GRU\")\n",
    "\n",
    "# Cleanup\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nâœ¨ Training pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47ea7d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  No GPU detected, using CPU\n",
      "ğŸš€ GRU Trial 28 Final Training\n",
      "=============================================\n",
      "ğŸ¯ Configuration: BestOverall (0.551 precision, 0.437 recall)\n",
      "ğŸ“Š Loading and preprocessing data...\n",
      "   Loaded data: (11476, 66)\n",
      "   After cleaning: (11476, 20)\n",
      "   Features: 19\n",
      "   Target distribution: [5618 5858]\n",
      "   Train samples: 9,180\n",
      "   Val samples: 2,296\n",
      "   Scaler saved: gru_trial28_scaler.pkl\n",
      "\n",
      "ğŸ”„ Creating sequences (window=30)...\n",
      "   Train sequences: 9,150\n",
      "   Val sequences: 2,266\n",
      "\n",
      "ğŸ—ï¸ Building GRU model...\n",
      "   Units: 128, Layers: 1\n",
      "   Dropout: 0.347, LR: 0.001995\n",
      "   L2: 2.50e-05, Batch: 64\n",
      "\n",
      "ğŸ“‹ Model architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                               </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                    </span>â”ƒ<span style=\"font-weight: bold\">           Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                                  â”‚ ?                               â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                          â”‚ ?                               â”‚                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                              â”‚ ?                               â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gru (\u001b[38;5;33mGRU\u001b[0m)                                  â”‚ ?                               â”‚       \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                          â”‚ ?                               â”‚                 \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                              â”‚ ?                               â”‚       \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training model...\n",
      "   Epochs: 80, Early stopping: 15\n",
      "   Expected performance: P=0.547, R=0.424\n",
      "Epoch 1/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5014 - loss: 0.7136 - val_accuracy: 0.4965 - val_loss: 0.7100 - learning_rate: 0.0020\n",
      "Epoch 2/80\n",
      "143/143 - 1s - 9ms/step - accuracy: 0.5014 - loss: 0.7054 - val_accuracy: 0.4943 - val_loss: 0.7075 - learning_rate: 0.0020\n",
      "Epoch 3/80\n",
      "143/143 - 1s - 9ms/step - accuracy: 0.5082 - loss: 0.6999 - val_accuracy: 0.5132 - val_loss: 0.7022 - learning_rate: 0.0020\n",
      "Epoch 4/80\n",
      "143/143 - 1s - 9ms/step - accuracy: 0.5153 - loss: 0.6976 - val_accuracy: 0.5035 - val_loss: 0.7038 - learning_rate: 0.0020\n",
      "Epoch 5/80\n",
      "143/143 - 1s - 9ms/step - accuracy: 0.5217 - loss: 0.6962 - val_accuracy: 0.4996 - val_loss: 0.7028 - learning_rate: 0.0020\n",
      "Epoch 6/80\n",
      "143/143 - 1s - 9ms/step - accuracy: 0.5144 - loss: 0.6969 - val_accuracy: 0.4978 - val_loss: 0.7039 - learning_rate: 0.0020\n",
      "Epoch 7/80\n",
      "143/143 - 1s - 10ms/step - accuracy: 0.5252 - loss: 0.6954 - val_accuracy: 0.5000 - val_loss: 0.7013 - learning_rate: 0.0020\n",
      "Epoch 8/80\n",
      "143/143 - 1s - 10ms/step - accuracy: 0.5233 - loss: 0.6953 - val_accuracy: 0.5057 - val_loss: 0.7020 - learning_rate: 0.0020\n",
      "Epoch 9/80\n",
      "143/143 - 1s - 10ms/step - accuracy: 0.5190 - loss: 0.6957 - val_accuracy: 0.5097 - val_loss: 0.7002 - learning_rate: 0.0020\n",
      "Epoch 10/80\n",
      "143/143 - 1s - 10ms/step - accuracy: 0.5212 - loss: 0.6957 - val_accuracy: 0.5040 - val_loss: 0.7001 - learning_rate: 0.0020\n",
      "Epoch 11/80\n",
      "143/143 - 2s - 17ms/step - accuracy: 0.5246 - loss: 0.6948 - val_accuracy: 0.4960 - val_loss: 0.7032 - learning_rate: 0.0020\n",
      "Epoch 12/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5214 - loss: 0.6953 - val_accuracy: 0.4974 - val_loss: 0.7009 - learning_rate: 0.0020\n",
      "Epoch 13/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5303 - loss: 0.6946 - val_accuracy: 0.4960 - val_loss: 0.7049 - learning_rate: 0.0020\n",
      "Epoch 14/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5248 - loss: 0.6956 - val_accuracy: 0.5035 - val_loss: 0.7033 - learning_rate: 0.0020\n",
      "Epoch 15/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5286 - loss: 0.6955 - val_accuracy: 0.5000 - val_loss: 0.7033 - learning_rate: 0.0020\n",
      "Epoch 16/80\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0009973859414458275.\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5295 - loss: 0.6946 - val_accuracy: 0.5044 - val_loss: 0.7009 - learning_rate: 0.0020\n",
      "Epoch 17/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5356 - loss: 0.6929 - val_accuracy: 0.5146 - val_loss: 0.6990 - learning_rate: 9.9739e-04\n",
      "Epoch 18/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5316 - loss: 0.6927 - val_accuracy: 0.5102 - val_loss: 0.7001 - learning_rate: 9.9739e-04\n",
      "Epoch 19/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5356 - loss: 0.6923 - val_accuracy: 0.5177 - val_loss: 0.6975 - learning_rate: 9.9739e-04\n",
      "Epoch 20/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5427 - loss: 0.6915 - val_accuracy: 0.5137 - val_loss: 0.6978 - learning_rate: 9.9739e-04\n",
      "Epoch 21/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5376 - loss: 0.6921 - val_accuracy: 0.5071 - val_loss: 0.7003 - learning_rate: 9.9739e-04\n",
      "Epoch 22/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5349 - loss: 0.6927 - val_accuracy: 0.5146 - val_loss: 0.6979 - learning_rate: 9.9739e-04\n",
      "Epoch 23/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5410 - loss: 0.6917 - val_accuracy: 0.5146 - val_loss: 0.6991 - learning_rate: 9.9739e-04\n",
      "Epoch 24/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5411 - loss: 0.6909 - val_accuracy: 0.5115 - val_loss: 0.6994 - learning_rate: 9.9739e-04\n",
      "Epoch 25/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5401 - loss: 0.6907 - val_accuracy: 0.5132 - val_loss: 0.7007 - learning_rate: 9.9739e-04\n",
      "Epoch 26/80\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004986929707229137.\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5438 - loss: 0.6910 - val_accuracy: 0.5093 - val_loss: 0.7024 - learning_rate: 9.9739e-04\n",
      "Epoch 27/80\n",
      "143/143 - 3s - 20ms/step - accuracy: 0.5478 - loss: 0.6895 - val_accuracy: 0.5146 - val_loss: 0.7009 - learning_rate: 4.9869e-04\n",
      "Epoch 28/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5434 - loss: 0.6899 - val_accuracy: 0.5093 - val_loss: 0.7006 - learning_rate: 4.9869e-04\n",
      "Epoch 29/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5436 - loss: 0.6898 - val_accuracy: 0.5044 - val_loss: 0.7015 - learning_rate: 4.9869e-04\n",
      "Epoch 30/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5475 - loss: 0.6895 - val_accuracy: 0.5110 - val_loss: 0.7012 - learning_rate: 4.9869e-04\n",
      "Epoch 31/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5494 - loss: 0.6883 - val_accuracy: 0.5079 - val_loss: 0.7005 - learning_rate: 4.9869e-04\n",
      "Epoch 32/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5497 - loss: 0.6893 - val_accuracy: 0.5150 - val_loss: 0.7016 - learning_rate: 4.9869e-04\n",
      "Epoch 33/80\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00024934648536145687.\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5523 - loss: 0.6891 - val_accuracy: 0.5079 - val_loss: 0.7019 - learning_rate: 4.9869e-04\n",
      "Epoch 34/80\n",
      "143/143 - 3s - 19ms/step - accuracy: 0.5539 - loss: 0.6875 - val_accuracy: 0.5106 - val_loss: 0.7023 - learning_rate: 2.4935e-04\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\n",
      "â±ï¸  Training completed in 0:01:21.100067 (34 epochs)\n",
      "\n",
      "ğŸ“Š Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ˆ Final Results:\n",
      "   Precision: 0.555 (expected: 0.547) [+0.008]\n",
      "   Recall:    0.359 (expected: 0.424) [-0.065]\n",
      "   F1 Score:  0.436 (expected: 0.478) [-0.042]\n",
      "   F0.5 Score: 0.500 (expected: 0.517) [-0.017]\n",
      "   Accuracy:  0.518\n",
      "   AUC:       0.532\n",
      "   Positive predictions: 760\n",
      "\n",
      "ğŸ“‹ Confusion Matrix:\n",
      "[[751 338]\n",
      " [755 422]]\n",
      "\n",
      "ğŸ“‹ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.50      0.69      0.58      1089\n",
      "          Up       0.56      0.36      0.44      1177\n",
      "\n",
      "    accuracy                           0.52      2266\n",
      "   macro avg       0.53      0.52      0.51      2266\n",
      "weighted avg       0.53      0.52      0.50      2266\n",
      "\n",
      "\n",
      "ğŸ“ Generating predictions CSV...\n",
      "   Predictions saved: gru_trial28_predictions.csv\n",
      "   Total predictions: 2,266\n",
      "\n",
      "ğŸ“‹ Sample predictions:\n",
      "          timestamp  prob_up  prob_down  winning_prob  prediction  actual\n",
      "2024-03-15 12:00:00 0.593111   0.406889      0.593111           1       1\n",
      "2024-03-15 16:00:00 0.631037   0.368963      0.631037           1       0\n",
      "2024-03-15 20:00:00 0.597687   0.402313      0.597687           1       1\n",
      "2024-03-16 00:00:00 0.556668   0.443332      0.556668           1       0\n",
      "2024-03-16 04:00:00 0.525571   0.474429      0.525571           1       0\n",
      "2024-03-16 08:00:00 0.502145   0.497855      0.502145           1       0\n",
      "2024-03-16 12:00:00 0.490238   0.509762      0.509762           0       1\n",
      "2024-03-16 16:00:00 0.487143   0.512857      0.512857           0       0\n",
      "2024-03-16 20:00:00 0.520760   0.479240      0.520760           1       0\n",
      "2024-03-17 00:00:00 0.550666   0.449334      0.550666           1       1\n",
      "\n",
      "ğŸ’¾ Saving model and summary...\n",
      "\n",
      "ğŸ‰ Trial 28 Final Training Complete!\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ“ˆ Performance Summary:\n",
      "   Precision: 0.555 (target: 0.551)\n",
      "   Recall: 0.359 (target: 0.437)\n",
      "   F1 Score: 0.436 (target: 0.488)\n",
      "   F0.5 Score: 0.500 (target: 0.524)\n",
      "   AUC: 0.532\n",
      "\n",
      "ğŸ“ Files Generated:\n",
      "   â€¢ gru_trial28_final.h5 - Trained GRU model\n",
      "   â€¢ gru_trial28_scaler.pkl - Feature scaler\n",
      "   â€¢ gru_trial28_predictions.csv - Validation predictions (2,266 rows)\n",
      "   â€¢ gru_trial28_training_summary.json - Complete training summary\n",
      "\n",
      "ğŸ¯ Model ready for production trading!\n",
      "   Expected: ~55% precision with ~44% recall\n",
      "   Configuration: 36-window, 96-unit, 2-layer GRU\n",
      "\n",
      "âœ¨ Training pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gru_trial28_final_training.py\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Final training of Trial 28 (BestOverall) GRU configuration.\n",
    "Trains the model and generates predictions CSV in the exact format requested.\n",
    "\n",
    "Trial 28 Config: 0.551 precision, 0.437 recall, 0.488 F1, 0.524 F0.5\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, \n",
    "                             fbeta_score, accuracy_score, roc_auc_score,\n",
    "                             confusion_matrix, classification_report)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Setup\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Configure GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ… GPU configured: {len(gpus)} device(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš ï¸  GPU configuration failed: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No GPU detected, using CPU\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Configuration\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "CSV_PATH = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "                r\"\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "\n",
    "VAL_FRAC = 0.20\n",
    "DECISION_THRESHOLD = 0.5\n",
    "EPOCHS = 80\n",
    "EARLY_STOP = 15\n",
    "\n",
    "# Output files\n",
    "MODEL_OUT = \"gru_trial28_final.h5\"\n",
    "SCALER_OUT = \"gru_trial28_scaler.pkl\"\n",
    "PREDICTIONS_OUT = \"gru_trial28_predictions.csv\"\n",
    "SUMMARY_JSON = \"gru_trial28_training_summary.json\"\n",
    "\n",
    "# Complete drop columns list (same as optimization)\n",
    "DROP_COLS = [\n",
    "    'open', 'high', 'low', 'close',\n",
    "    'typical_price', 'vwap_24h', 'close_4h',\n",
    "    'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50',\n",
    "    'bollinger_upper', 'bollinger_lower', 'bollinger_width',\n",
    "    'resistance_level', 'support_level',\n",
    "    'high_low', 'high_close', 'low_close', 'true_range',\n",
    "    'volume_mean_20', 'MACD_line', 'MACD_signal',\n",
    "    'volatility_regime', 'CCI', 'stoch_%D', 'parkinson_vol',\n",
    "    'ema_cross_down', 'macd_cross_down', 'ema_cross_up', 'macd_cross_up',\n",
    "    'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "    'break_upper_band', 'break_lower_band', 'rsi_oversold', 'rsi_overbought',\n",
    "    'above_sma20', 'above_sma50', 'ema7_above_ema21', 'macd_positive',\n",
    "    'volume_breakout', 'volume_breakdown', 'stoch_overbought', 'stoch_oversold',\n",
    "    'cci_overbought', 'cci_oversold', 'trending_market',\n",
    "    'oversold_reversal', 'overbought_reversal',\n",
    "    'bullish_scenario_1', 'bullish_scenario_2', 'bullish_scenario_3',\n",
    "    'bullish_scenario_4', 'bullish_scenario_5', 'bullish_scenario_6',\n",
    "    'bearish_scenario_1', 'bearish_scenario_2', 'bearish_scenario_3',\n",
    "    'bearish_scenario_4', 'bearish_scenario_6',\n",
    "    'timestamp', 'date', 'Unnamed: 0'\n",
    "]\n",
    "\n",
    "# Trial 28 Optimal Configuration\n",
    "TRIAL28_CONFIG =     {\n",
    "        'name': 'Trial_4_Balanced',\n",
    "        'window': 30, 'units': 128, 'layers': 1, 'dropout': 0.3473773873201034,\n",
    "        'lr': 0.0019947718789028682, 'l2': 2.497073714505272e-05, 'batch': 64,\n",
    "        'expected_performance': {'precision': 0.547, 'recall': 0.424, 'f1': 0.478, 'f05': 0.517}\n",
    "    }\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Helper Functions\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def create_sequences(data, labels, window_size):\n",
    "    \"\"\"Create sequences for time series data.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(labels[i])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int8)\n",
    "\n",
    "def build_gru_model(config, n_features):\n",
    "    \"\"\"Build GRU model with Trial 28 configuration.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    for i in range(config['layers']):\n",
    "        return_sequences = (i < config['layers'] - 1)\n",
    "        model.add(keras.layers.GRU(\n",
    "            config['units'],\n",
    "            return_sequences=return_sequences,\n",
    "            dropout=config['dropout'],\n",
    "            recurrent_dropout=config['dropout'] * 0.6,\n",
    "            kernel_regularizer=keras.regularizers.l2(config['l2']),\n",
    "            recurrent_regularizer=keras.regularizers.l2(config['l2'])\n",
    "        ))\n",
    "    \n",
    "    model.add(keras.layers.Dropout(config['dropout']))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=config['lr']),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Data Loading and Preprocessing\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"ğŸš€ GRU Trial 28 Final Training\")\n",
    "print(\"=\" * 45)\n",
    "print(\"ğŸ¯ Configuration: BestOverall (0.551 precision, 0.437 recall)\")\n",
    "print(\"ğŸ“Š Loading and preprocessing data...\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(CSV_PATH, index_col=0, parse_dates=True)\n",
    "df = df[df.index >= \"2020-01-01\"]  # Same as optimization\n",
    "print(f\"   Loaded data: {df.shape}\")\n",
    "\n",
    "# Clean data\n",
    "if 'target' not in df.columns:\n",
    "    raise ValueError(\"âŒ Target column not found!\")\n",
    "\n",
    "# Drop columns\n",
    "cols_to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "df = df[df[\"target\"].notna()].dropna()\n",
    "print(f\"   After cleaning: {df.shape}\")\n",
    "\n",
    "# Prepare features and target\n",
    "features = df.drop(columns=\"target\")\n",
    "target = df[\"target\"].astype(int).values\n",
    "n_features = features.shape[1]\n",
    "\n",
    "print(f\"   Features: {n_features}\")\n",
    "print(f\"   Target distribution: {np.bincount(target)}\")\n",
    "\n",
    "# Scale features\n",
    "split_idx = int(len(df) * (1 - VAL_FRAC))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features.iloc[:split_idx])\n",
    "\n",
    "X_train_scaled = scaler.transform(features.iloc[:split_idx])\n",
    "X_val_scaled = scaler.transform(features.iloc[split_idx:])\n",
    "y_train = target[:split_idx]\n",
    "y_val = target[split_idx:]\n",
    "\n",
    "print(f\"   Train samples: {len(X_train_scaled):,}\")\n",
    "print(f\"   Val samples: {len(X_val_scaled):,}\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, SCALER_OUT)\n",
    "print(f\"   Scaler saved: {SCALER_OUT}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Create Sequences\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ”„ Creating sequences (window={TRIAL28_CONFIG['window']})...\")\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, TRIAL28_CONFIG['window'])\n",
    "X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, TRIAL28_CONFIG['window'])\n",
    "\n",
    "print(f\"   Train sequences: {len(X_train_seq):,}\")\n",
    "print(f\"   Val sequences: {len(X_val_seq):,}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Build and Train Model\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ—ï¸ Building GRU model...\")\n",
    "print(f\"   Units: {TRIAL28_CONFIG['units']}, Layers: {TRIAL28_CONFIG['layers']}\")\n",
    "print(f\"   Dropout: {TRIAL28_CONFIG['dropout']:.3f}, LR: {TRIAL28_CONFIG['lr']:.6f}\")\n",
    "print(f\"   L2: {TRIAL28_CONFIG['l2']:.2e}, Batch: {TRIAL28_CONFIG['batch']}\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_gru_model(TRIAL28_CONFIG, n_features)\n",
    "\n",
    "# Display model summary\n",
    "print(f\"\\nğŸ“‹ Model architecture:\")\n",
    "model.summary(line_length=100)\n",
    "\n",
    "# Prepare callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=EARLY_STOP,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=7,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸš€ Training model...\")\n",
    "print(f\"   Epochs: {EPOCHS}, Early stopping: {EARLY_STOP}\")\n",
    "print(f\"   Expected performance: P={TRIAL28_CONFIG['expected_performance']['precision']:.3f}, \"\n",
    "      f\"R={TRIAL28_CONFIG['expected_performance']['recall']:.3f}\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=TRIAL28_CONFIG['batch'],\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "training_time = datetime.now() - start_time\n",
    "epochs_trained = len(history.history['loss'])\n",
    "\n",
    "print(f\"\\nâ±ï¸  Training completed in {training_time} ({epochs_trained} epochs)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Evaluate Model\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ“Š Evaluating model...\")\n",
    "\n",
    "y_pred_prob = model.predict(X_val_seq, verbose=0).ravel()\n",
    "y_pred = (y_pred_prob >= DECISION_THRESHOLD).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_val_seq, y_pred, zero_division=0)\n",
    "recall = recall_score(y_val_seq, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_val_seq, y_pred, zero_division=0)\n",
    "f05 = fbeta_score(y_val_seq, y_pred, beta=0.5, zero_division=0)\n",
    "accuracy = accuracy_score(y_val_seq, y_pred)\n",
    "auc = roc_auc_score(y_val_seq, y_pred_prob)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nğŸ“ˆ Final Results:\")\n",
    "expected = TRIAL28_CONFIG['expected_performance']\n",
    "print(f\"   Precision: {precision:.3f} (expected: {expected['precision']:.3f}) \"\n",
    "      f\"[{precision - expected['precision']:+.3f}]\")\n",
    "print(f\"   Recall:    {recall:.3f} (expected: {expected['recall']:.3f}) \"\n",
    "      f\"[{recall - expected['recall']:+.3f}]\")\n",
    "print(f\"   F1 Score:  {f1:.3f} (expected: {expected['f1']:.3f}) \"\n",
    "      f\"[{f1 - expected['f1']:+.3f}]\")\n",
    "print(f\"   F0.5 Score: {f05:.3f} (expected: {expected['f05']:.3f}) \"\n",
    "      f\"[{f05 - expected['f05']:+.3f}]\")\n",
    "print(f\"   Accuracy:  {accuracy:.3f}\")\n",
    "print(f\"   AUC:       {auc:.3f}\")\n",
    "print(f\"   Positive predictions: {np.sum(y_pred)}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val_seq, y_pred)\n",
    "print(f\"\\nğŸ“‹ Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nğŸ“‹ Classification Report:\")\n",
    "print(classification_report(y_val_seq, y_pred, target_names=[\"Down\", \"Up\"]))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Generate Predictions CSV\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ“ Generating predictions CSV...\")\n",
    "\n",
    "# Get validation timestamps (accounting for window offset)\n",
    "val_start_idx = split_idx + TRIAL28_CONFIG['window']\n",
    "val_timestamps = df.index[val_start_idx:val_start_idx + len(y_pred_prob)]\n",
    "\n",
    "# Calculate probabilities\n",
    "prob_up = y_pred_prob\n",
    "prob_down = 1.0 - prob_up\n",
    "winning_prob = np.maximum(prob_up, prob_down)\n",
    "\n",
    "# Create predictions dataframe\n",
    "predictions_df = pd.DataFrame({\n",
    "    'timestamp': val_timestamps.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'prob_up': prob_up,\n",
    "    'prob_down': prob_down,\n",
    "    'winning_prob': winning_prob,\n",
    "    'prediction': y_pred,\n",
    "    'actual': y_val_seq\n",
    "})\n",
    "\n",
    "# Save predictions CSV\n",
    "predictions_df.to_csv(PREDICTIONS_OUT, index=False, float_format='%.6f')\n",
    "\n",
    "print(f\"   Predictions saved: {PREDICTIONS_OUT}\")\n",
    "print(f\"   Total predictions: {len(predictions_df):,}\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(f\"\\nğŸ“‹ Sample predictions:\")\n",
    "print(predictions_df.head(10).to_string(index=False))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Save Model and Summary\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ’¾ Saving model and summary...\")\n",
    "\n",
    "# Save model\n",
    "model.save(MODEL_OUT)\n",
    "\n",
    "# Create comprehensive summary\n",
    "summary = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "    \"model_type\": \"GRU_Trial28_BestOverall\",\n",
    "    \"configuration\": TRIAL28_CONFIG,\n",
    "    \"dataset_info\": {\n",
    "        \"total_samples\": len(df),\n",
    "        \"train_samples\": len(X_train_scaled),\n",
    "        \"val_samples\": len(X_val_scaled),\n",
    "        \"features\": n_features,\n",
    "        \"window_size\": TRIAL28_CONFIG['window'],\n",
    "        \"train_period\": f\"{df.index[0]} to {df.index[split_idx-1]}\",\n",
    "        \"val_period\": f\"{df.index[split_idx]} to {df.index[-1]}\"\n",
    "    },\n",
    "    \"training_info\": {\n",
    "        \"epochs_trained\": epochs_trained,\n",
    "        \"training_time_seconds\": training_time.total_seconds(),\n",
    "        \"early_stopping_patience\": EARLY_STOP,\n",
    "        \"final_train_loss\": float(history.history['loss'][-1]),\n",
    "        \"final_val_loss\": float(history.history['val_loss'][-1]),\n",
    "        \"best_val_loss\": float(min(history.history['val_loss']))\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1_score\": float(f1),\n",
    "        \"f05_score\": float(f05),\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"auc\": float(auc),\n",
    "        \"decision_threshold\": DECISION_THRESHOLD,\n",
    "        \"positive_predictions\": int(np.sum(y_pred)),\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    },\n",
    "    \"expected_vs_actual\": {\n",
    "        \"precision_diff\": float(precision - expected['precision']),\n",
    "        \"recall_diff\": float(recall - expected['recall']),\n",
    "        \"f1_diff\": float(f1 - expected['f1']),\n",
    "        \"f05_diff\": float(f05 - expected['f05'])\n",
    "    },\n",
    "    \"class_distribution\": {\n",
    "        \"train_positive_rate\": float(np.mean(y_train)),\n",
    "        \"val_positive_rate\": float(np.mean(y_val)),\n",
    "        \"train_counts\": [int(np.sum(y_train == 0)), int(np.sum(y_train == 1))],\n",
    "        \"val_counts\": [int(np.sum(y_val == 0)), int(np.sum(y_val == 1))]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "with open(SUMMARY_JSON, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Final Report\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(f\"\\nğŸ‰ Trial 28 Final Training Complete!\")\n",
    "print(f\"â•\" * 50)\n",
    "print(f\"ğŸ“ˆ Performance Summary:\")\n",
    "print(f\"   Precision: {precision:.3f} (target: 0.551)\")\n",
    "print(f\"   Recall: {recall:.3f} (target: 0.437)\")\n",
    "print(f\"   F1 Score: {f1:.3f} (target: 0.488)\")\n",
    "print(f\"   F0.5 Score: {f05:.3f} (target: 0.524)\")\n",
    "print(f\"   AUC: {auc:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Files Generated:\")\n",
    "print(f\"   â€¢ {MODEL_OUT} - Trained GRU model\")\n",
    "print(f\"   â€¢ {SCALER_OUT} - Feature scaler\")\n",
    "print(f\"   â€¢ {PREDICTIONS_OUT} - Validation predictions ({len(predictions_df):,} rows)\")\n",
    "print(f\"   â€¢ {SUMMARY_JSON} - Complete training summary\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Model ready for production trading!\")\n",
    "print(f\"   Expected: ~55% precision with ~44% recall\")\n",
    "print(f\"   Configuration: 36-window, 96-unit, 2-layer GRU\")\n",
    "\n",
    "# Cleanup\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nâœ¨ Training pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35df662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\src\\Models\\models\\models\\gru_trial28_predictions.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ca4d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Evaluation at threshold 0.5:\n",
      "Precision: 0.528\n",
      "Recall   : 0.951\n",
      "F1 Score : 0.679\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the predictions CSV\n",
    "csv_path = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\src\\Models\\models\\models\\gru_trial28_f05_preds.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Ensure column names are correct and lowercase\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Extract actual and predicted values\n",
    "y_true = df['actual']\n",
    "y_pred = df['prediction']  # prediction at threshold 0.5\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "# Print results\n",
    "print(\"ğŸ“Š Evaluation at threshold 0.5:\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall   : {recall:.3f}\")\n",
    "print(f\"F1 Score : {f1:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

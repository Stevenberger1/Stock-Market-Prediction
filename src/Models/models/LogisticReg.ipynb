{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d5abe9e",
   "metadata": {},
   "source": [
    "# In this notebook we will create the LogisticRegression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb92670",
   "metadata": {},
   "source": [
    "DROP_COLS = ['open', 'high', 'low', 'high_low', 'high_close', 'low_close', 'typical_price',\n",
    "             'volume_breakout', 'volume_breakdown', 'break_upper_band', 'break_lower_band',\n",
    "             'vol_spike_1_5x',\n",
    "             'overbought_reversal', 'oversold_reversal', 'macd_cross_up',\n",
    "             'macd_cross_down', 'macd_rising', 'bollinger_upper', 'bollinger_lower',\n",
    "             'MACD_line', 'MACD_signal', 'stoch_%D', 'momentum_alignment',\n",
    "             'bullish_scenario_1', 'bullish_scenario_5', 'bearish_scenario_1']\n",
    "\n",
    "Dataset shape: (15855, 46)\n",
    "Target distribution: {1: 8097, 0: 7758}\n",
    "Train: (12684, 46) | Test: (3171, 46)\n",
    "\n",
    "üîç Running search 1/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 1 finished in 84.7s (best CV wF0.5 = 0.564)\n",
    "\n",
    "üîç Running search 2/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 2 finished in 194.9s (best CV wF0.5 = 0.566)\n",
    "\n",
    "üåü Overall best CV wF0.5 = 0.566\n",
    "\n",
    "üåü Best parameters:\n",
    "   logreg__C             : 0.00407559644007287\n",
    "   logreg__class_weight  : None\n",
    "   logreg__l1_ratio      : 0.5\n",
    "   logreg__penalty       : elasticnet\n",
    "\n",
    "üìä HOLD-OUT METRICS\n",
    "   Accuracy    : 0.534\n",
    "   Precision   : 0.551\n",
    "   Recall      : 0.581\n",
    "   F1          : 0.566\n",
    "   wF Œ≤=0.5    : 0.557\n",
    "   ROC-AUC     : 0.548\n",
    "\n",
    "üèÖ Top-15 absolute coefficients:\n",
    "buying_pressure   -0.084537\n",
    "stoch_%K          -0.038546\n",
    "bb_position       -0.025447\n",
    "MACD_histogram    -0.015845\n",
    "cci_oversold       0.012325\n",
    "obv_rising_24h    -0.002853\n",
    "above_sma20       -0.001778\n",
    "cci_overbought    -0.001013\n",
    "stoch_oversold     0.000942\n",
    "near_lower_band    0.000287\n",
    "EMA_7              0.000000\n",
    "EMA_21             0.000000\n",
    "close              0.000000\n",
    "volume             0.000000\n",
    "atr_14             0.000000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe7780",
   "metadata": {},
   "source": [
    "DROP_COLS = ['open', 'high', 'low', 'high_low', 'high_close', 'low_close', 'typical_price',\n",
    "             'MACD_line', 'MACD_signal',  'momentum_alignment',\n",
    "             'bullish_scenario_1', 'bullish_scenario_5', 'bearish_scenario_1']\n",
    "\n",
    "\n",
    "Dataset shape: (15855, 59)\n",
    "Target distribution: {1: 8097, 0: 7758}\n",
    "Train: (12684, 59) | Test: (3171, 59)\n",
    "\n",
    "üîç Running search 1/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 1 finished in 101.3s (best CV wF0.5 = 0.564)\n",
    "\n",
    "üîç Running search 2/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 2 finished in 164.6s (best CV wF0.5 = 0.566)\n",
    "\n",
    "üåü Overall best CV wF0.5 = 0.566\n",
    "\n",
    "üåü Best parameters:\n",
    "   logreg__C             : 0.00407559644007287\n",
    "   logreg__class_weight  : None\n",
    "   logreg__l1_ratio      : 0.5\n",
    "   logreg__penalty       : elasticnet\n",
    "\n",
    "üìä HOLD-OUT METRICS\n",
    "   Accuracy    : 0.534\n",
    "   Precision   : 0.551\n",
    "   Recall      : 0.581\n",
    "   F1          : 0.566\n",
    "   wF Œ≤=0.5    : 0.557\n",
    "   ROC-AUC     : 0.548\n",
    "\n",
    "üèÖ Top-15 absolute coefficients:\n",
    "buying_pressure   -0.084537\n",
    "stoch_%K          -0.038547\n",
    "bb_position       -0.025443\n",
    "MACD_histogram    -0.015845\n",
    "cci_oversold       0.012325\n",
    "obv_rising_24h    -0.002853\n",
    "above_sma20       -0.001780\n",
    "cci_overbought    -0.001014\n",
    "stoch_oversold     0.000941\n",
    "near_lower_band    0.000288\n",
    "EMA_7              0.000000\n",
    "bollinger_lower    0.000000\n",
    "bollinger_upper    0.000000\n",
    "CCI                0.000000\n",
    "bollinger_width    0.000000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c01c18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0373baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (15855, 46)\n",
      "Target distribution: {1: 8097, 0: 7758}\n",
      "Train: (12684, 46) | Test: (3171, 46)\n",
      "\n",
      "üîç Running search 1/2...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Search 1 finished in 84.7s (best CV wF0.5 = 0.564)\n",
      "\n",
      "üîç Running search 2/2...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Search 2 finished in 194.9s (best CV wF0.5 = 0.566)\n",
      "\n",
      "üåü Overall best CV wF0.5 = 0.566\n",
      "\n",
      "üåü Best parameters:\n",
      "   logreg__C             : 0.00407559644007287\n",
      "   logreg__class_weight  : None\n",
      "   logreg__l1_ratio      : 0.5\n",
      "   logreg__penalty       : elasticnet\n",
      "\n",
      "üìä HOLD-OUT METRICS\n",
      "   Accuracy    : 0.534\n",
      "   Precision   : 0.551\n",
      "   Recall      : 0.581\n",
      "   F1          : 0.566\n",
      "   wF Œ≤=0.5    : 0.557\n",
      "   ROC-AUC     : 0.548\n",
      "\n",
      "üèÖ Top-15 absolute coefficients:\n",
      "buying_pressure   -0.084537\n",
      "stoch_%K          -0.038546\n",
      "bb_position       -0.025447\n",
      "MACD_histogram    -0.015845\n",
      "cci_oversold       0.012325\n",
      "obv_rising_24h    -0.002853\n",
      "above_sma20       -0.001778\n",
      "cci_overbought    -0.001013\n",
      "stoch_oversold     0.000942\n",
      "near_lower_band    0.000287\n",
      "EMA_7              0.000000\n",
      "EMA_21             0.000000\n",
      "close              0.000000\n",
      "volume             0.000000\n",
      "atr_14             0.000000\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "#  LOGISTIC-REGRESSION  HYPER-TUNER  (precision-weighted FŒ≤=0.5)\n",
    "# =============================================================\n",
    "import numpy as np, pandas as pd, time, sys, warnings\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import (precision_score, recall_score, make_scorer,\n",
    "                             accuracy_score, f1_score, roc_auc_score)\n",
    "from scipy.stats import loguniform\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1) CONFIGURATION\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "CSV_FILE   = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "TIME_COL   = \"timestamp\"\n",
    "TARGET_COL = \"target\"\n",
    "START_DATE = \"2018-01-01\"\n",
    "TEST_FRAC  = 0.20\n",
    "\n",
    "DROP_COLS = ['open', 'high', 'low', 'high_low', 'high_close', 'low_close', 'typical_price',\n",
    "             'volume_breakout', 'volume_breakdown', 'break_upper_band', 'break_lower_band',\n",
    "             'vol_spike_1_5x',\n",
    "             'overbought_reversal', 'oversold_reversal', 'macd_cross_up',\n",
    "             'macd_cross_down', 'macd_rising', 'bollinger_upper', 'bollinger_lower',\n",
    "             'MACD_line', 'MACD_signal', 'stoch_%D', 'momentum_alignment',\n",
    "             'bullish_scenario_1', 'bullish_scenario_5', 'bearish_scenario_1']\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 2) LOAD & VALIDATE DATA\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if not CSV_FILE.exists():\n",
    "    sys.exit(f\"‚ùå File not found: {CSV_FILE}\")\n",
    "\n",
    "df = pd.read_csv(CSV_FILE, parse_dates=[TIME_COL]).set_index(TIME_COL).sort_index()\n",
    "df = df.loc[START_DATE:].copy()\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    sys.exit(f\"‚ùå '{TARGET_COL}' column missing!\")\n",
    "\n",
    "X = df.drop(columns=[c for c in DROP_COLS if c in df.columns] + [TARGET_COL], errors=\"ignore\")\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Data checks\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"‚ö†Ô∏è Missing values detected!\")\n",
    "    print(X.isnull().sum()[X.isnull().sum() > 0])\n",
    "if y.sum() / len(y) < 0.01 or y.sum() / len(y) > 0.99:\n",
    "    print(\"‚ö†Ô∏è Highly imbalanced target!\")\n",
    "\n",
    "# Chronological split\n",
    "split = int(len(df) * (1 - TEST_FRAC))\n",
    "X_tr, X_te = X.iloc[:split], X.iloc[split:]\n",
    "y_tr, y_te = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "print(f\"Train: {X_tr.shape} | Test: {X_te.shape}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 3) CUSTOM SCORER: PRECISION-WEIGHTED FŒ≤ (Œ≤ = 0.5)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def f_beta_half(y_true, y_pred):\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score(y_true, y_pred, zero_division=0)\n",
    "    beta = 0.5\n",
    "    return (1 + beta**2) * p * r / (beta**2 * p + r) if (p + r) > 0 else 0.0\n",
    "\n",
    "weighted_f = make_scorer(f_beta_half, greater_is_better=True)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 4) PIPELINE AND PARAMETER SEARCHES\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(max_iter=4000, solver='saga', n_jobs=1))\n",
    "])\n",
    "\n",
    "# Separate hyperparameter sets to avoid l1_ratio conflicts\n",
    "param_dist_list = [\n",
    "    {\n",
    "        \"logreg__penalty\": ['l1', 'l2', 'none'],\n",
    "        \"logreg__C\": loguniform(1e-3, 1e2),\n",
    "        \"logreg__class_weight\": [None, 'balanced']\n",
    "    },\n",
    "    {\n",
    "        \"logreg__penalty\": ['elasticnet'],\n",
    "        \"logreg__C\": loguniform(1e-3, 1e2),\n",
    "        \"logreg__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "        \"logreg__class_weight\": [None, 'balanced']\n",
    "    }\n",
    "]\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "best_score = -np.inf\n",
    "best_estimator = None\n",
    "best_params = None\n",
    "\n",
    "for i, param_dist in enumerate(param_dist_list):\n",
    "    print(f\"\\nüîç Running search {i+1}/{len(param_dist_list)}...\")\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe, param_distributions=param_dist,\n",
    "        n_iter=30, cv=cv, scoring=weighted_f,\n",
    "        random_state=42, n_jobs=-1, verbose=1\n",
    "    )\n",
    "    t0 = time.time()\n",
    "    search.fit(X_tr, y_tr)\n",
    "    print(f\"Search {i+1} finished in {time.time()-t0:.1f}s \"\n",
    "          f\"(best CV wF0.5 = {search.best_score_:.3f})\")\n",
    "\n",
    "    if search.best_score_ > best_score:\n",
    "        best_score = search.best_score_\n",
    "        best_estimator = search.best_estimator_\n",
    "        best_params = search.best_params_\n",
    "\n",
    "print(f\"\\nüåü Overall best CV wF0.5 = {best_score:.3f}\")\n",
    "print(\"\\nüåü Best parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"   {k:<22}: {v}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 5) HOLD-OUT VALIDATION\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "y_pred = best_estimator.predict(X_te)\n",
    "y_prob = best_estimator.predict_proba(X_te)[:, 1]\n",
    "\n",
    "def show(name, val):\n",
    "    print(f\"   {name:<12}: {val:.3f}\")\n",
    "\n",
    "print(\"\\nüìä HOLD-OUT METRICS\")\n",
    "show(\"Accuracy\",  accuracy_score(y_te, y_pred))\n",
    "show(\"Precision\", precision_score(y_te, y_pred, zero_division=0))\n",
    "show(\"Recall\",    recall_score   (y_te, y_pred, zero_division=0))\n",
    "show(\"F1\",        f1_score       (y_te, y_pred, zero_division=0))\n",
    "show(\"wF Œ≤=0.5\",  f_beta_half    (y_te, y_pred))\n",
    "show(\"ROC-AUC\",   roc_auc_score  (y_te, y_prob))\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 6) TOP COEFFICIENTS\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "coefs = best_estimator.named_steps['logreg'].coef_[0]\n",
    "coef_df = (pd.Series(coefs, index=X_tr.columns)\n",
    "             .sort_values(key=np.abs, ascending=False)\n",
    "             .head(15))\n",
    "print(\"\\nüèÖ Top-15 absolute coefficients:\")\n",
    "print(coef_df.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4ed07",
   "metadata": {},
   "source": [
    "# 2016\n",
    "Dataset shape: (20230, 43)\n",
    "Target distribution: {1: 10486, 0: 9744}\n",
    "Train: (16184, 43) | Test: (4046, 43)\n",
    "\n",
    "üîç Running search 1/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 1 finished in 61.4s (best CV wF0.5 = 0.571)\n",
    "\n",
    "üîç Running search 2/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 2 finished in 78.7s (best CV wF0.5 = 0.571)\n",
    "\n",
    "üåü Overall best CV wF0.5 = 0.571\n",
    "\n",
    "üåü Best parameters:\n",
    "   logreg__C             : 0.0010847546640130735\n",
    "   logreg__class_weight  : None\n",
    "   logreg__penalty       : l1\n",
    "\n",
    "üìä HOLD-OUT METRICS\n",
    "   Accuracy    : 0.514\n",
    "   Precision   : 0.514\n",
    "   Recall      : 1.000\n",
    "   F1          : 0.679\n",
    "   wF Œ≤=0.5    : 0.569\n",
    "   ROC-AUC     : 0.500\n",
    "\n",
    "üèÖ Top-15 absolute coefficients:\n",
    "close              0.0\n",
    "volume             0.0\n",
    "EMA_7              0.0\n",
    "EMA_21             0.0\n",
    "SMA_20             0.0\n",
    "SMA_50             0.0\n",
    "RSI                0.0\n",
    "MACD_histogram     0.0\n",
    "OBV                0.0\n",
    "bollinger_width    0.0\n",
    "CCI                0.0\n",
    "stoch_%K           0.0\n",
    "true_range         0.0\n",
    "atr_14             0.0\n",
    "atr_ratio          0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd172154",
   "metadata": {},
   "source": [
    "# 2018\n",
    "\n",
    "Dataset shape: (15855, 43)\n",
    "Target distribution: {1: 8097, 0: 7758}\n",
    "Train: (12684, 43) | Test: (3171, 43)\n",
    "\n",
    "üîç Running search 1/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 1 finished in 44.7s (best CV wF0.5 = 0.564)\n",
    "\n",
    "üîç Running search 2/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 2 finished in 57.9s (best CV wF0.5 = 0.566)\n",
    "\n",
    "üåü Overall best CV wF0.5 = 0.566\n",
    "\n",
    "üåü Best parameters:\n",
    "   logreg__C             : 0.00407559644007287\n",
    "   logreg__class_weight  : None\n",
    "   logreg__l1_ratio      : 0.5\n",
    "   logreg__penalty       : elasticnet\n",
    "\n",
    "üìä HOLD-OUT METRICS\n",
    "   Accuracy    : 0.533\n",
    "   Precision   : 0.550\n",
    "   Recall      : 0.580\n",
    "   F1          : 0.565\n",
    "   wF Œ≤=0.5    : 0.556\n",
    "   ROC-AUC     : 0.548\n",
    "\n",
    "üèÖ Top-15 absolute coefficients:\n",
    "buying_pressure   -0.084441\n",
    "stoch_%K          -0.038582\n",
    "bb_position       -0.026366\n",
    "MACD_histogram    -0.016438\n",
    "cci_oversold       0.012545\n",
    "above_sma20       -0.001973\n",
    "cci_overbought    -0.001100\n",
    "stoch_oversold     0.001039\n",
    "EMA_7              0.000000\n",
    "volume             0.000000\n",
    "close              0.000000\n",
    "CCI                0.000000\n",
    "bollinger_width    0.000000\n",
    "OBV                0.000000\n",
    "RSI                0.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac972725",
   "metadata": {},
   "source": [
    "# 2020\n",
    "Dataset shape: (11476, 43)\n",
    "Target distribution: {1: 5858, 0: 5618}\n",
    "Train: (9180, 43) | Test: (2296, 43)\n",
    "\n",
    "üîç Running search 1/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 1 finished in 59.9s (best CV wF0.5 = 0.564)\n",
    "\n",
    "üîç Running search 2/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 2 finished in 79.8s (best CV wF0.5 = 0.566)\n",
    "\n",
    "üåü Overall best CV wF0.5 = 0.566\n",
    "\n",
    "üåü Best parameters:\n",
    "   logreg__C             : 0.0011972422479639326\n",
    "   logreg__class_weight  : None\n",
    "   logreg__l1_ratio      : 0.1\n",
    "   logreg__penalty       : elasticnet\n",
    "\n",
    "üìä HOLD-OUT METRICS\n",
    "   Accuracy    : 0.524\n",
    "   Precision   : 0.543\n",
    "   Recall      : 0.520\n",
    "   F1          : 0.532\n",
    "   wF Œ≤=0.5    : 0.539\n",
    "   ROC-AUC     : 0.538\n",
    "\n",
    "üèÖ Top-15 absolute coefficients:\n",
    "buying_pressure   -0.067897\n",
    "cci_oversold       0.042164\n",
    "stoch_%K          -0.026609\n",
    "bb_position       -0.021885\n",
    "OBV               -0.011750\n",
    "above_sma20       -0.009549\n",
    "MACD_histogram    -0.009038\n",
    "roc_4h            -0.008540\n",
    "roc_24h           -0.005527\n",
    "volume_mean_20     0.004016\n",
    "trend_alignment   -0.003884\n",
    "stoch_oversold     0.003269\n",
    "CCI               -0.001185\n",
    "SMA_50             0.000000\n",
    "RSI                0.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b397f7",
   "metadata": {},
   "source": [
    "# 2022\n",
    "\n",
    "Dataset shape: (7091, 43)\n",
    "Target distribution: {1: 3588, 0: 3503}\n",
    "Train: (5672, 43) | Test: (1419, 43)\n",
    "\n",
    "üîç Running search 1/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 1 finished in 15.7s (best CV wF0.5 = 0.547)\n",
    "\n",
    "üîç Running search 2/2...\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "Search 2 finished in 22.1s (best CV wF0.5 = 0.547)\n",
    "\n",
    "üåü Overall best CV wF0.5 = 0.547\n",
    "\n",
    "üåü Best parameters:\n",
    "   logreg__C             : 0.008260808399079604\n",
    "   logreg__class_weight  : balanced\n",
    "   logreg__l1_ratio      : 0.3\n",
    "   logreg__penalty       : elasticnet\n",
    "\n",
    "üìä HOLD-OUT METRICS\n",
    "   Accuracy    : 0.520\n",
    "   Precision   : 0.528\n",
    "   Recall      : 0.615\n",
    "   F1          : 0.568\n",
    "   wF Œ≤=0.5    : 0.543\n",
    "   ROC-AUC     : 0.535\n",
    "\n",
    "üèÖ Top-15 absolute coefficients:\n",
    "buying_pressure    -0.100669\n",
    "bb_position        -0.046825\n",
    "stoch_%K           -0.045410\n",
    "bollinger_width     0.042166\n",
    "ema_cross_up       -0.028177\n",
    "cci_oversold        0.024635\n",
    "ema_cross_down     -0.006773\n",
    "resistance_level    0.005348\n",
    "trend_alignment    -0.004268\n",
    "true_range          0.003770\n",
    "support_level       0.002116\n",
    "OBV                -0.001177\n",
    "CCI                 0.000000\n",
    "SMA_50              0.000000\n",
    "RSI                 0.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddb89e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading and preparing data...\n",
      "Dataset shape: (15855, 43)\n",
      "Features: ['close', 'volume', 'EMA_7', 'EMA_21', 'SMA_20', 'SMA_50', 'RSI', 'MACD_histogram', 'OBV', 'bollinger_width', 'CCI', 'stoch_%K', 'true_range', 'atr_14', 'atr_ratio', 'parkinson_vol', 'vwap_24h', 'price_vs_vwap', 'volume_mean_20', 'volume_ratio', 'buying_pressure', 'adx', 'trending_market', 'volatility_regime', 'fear_greed_score', 'roc_4h', 'roc_24h', 'bb_position', 'rsi_overbought', 'rsi_oversold', 'above_sma20', 'above_sma50', 'ema7_above_ema21', 'ema_cross_up', 'ema_cross_down', 'macd_positive', 'stoch_overbought', 'stoch_oversold', 'cci_overbought', 'cci_oversold', 'resistance_level', 'support_level', 'trend_alignment']\n",
      "Target distribution: {1: 8097, 0: 7758}\n",
      "Target balance: 0.511 (positive class rate)\n",
      "Train: (12684, 43) | Test: (3171, 43)\n",
      "Train period: 2018-01-01 00:00:00 to 2023-10-16 12:00:00\n",
      "Test period: 2023-10-16 16:00:00 to 2025-03-28 00:00:00\n",
      "\n",
      "ü§ñ Building model with optimal parameters...\n",
      "Optimal parameters:\n",
      "   C              : 0.00407559644007287\n",
      "   class_weight   : None\n",
      "   l1_ratio       : 0.5\n",
      "   penalty        : elasticnet\n",
      "\n",
      "üöÄ Training model...\n",
      "‚úÖ Model trained in 0.10 seconds\n",
      "\n",
      "üìà TRAINING SET EVALUATION METRICS\n",
      "==================================================\n",
      "   Accuracy       : 0.5419\n",
      "   Precision      : 0.5444\n",
      "   Recall         : 0.6010\n",
      "   F1 Score       : 0.5713\n",
      "   F-beta (Œ≤=0.5) : 0.5548\n",
      "   ROC-AUC        : 0.5561\n",
      "\n",
      "üìà TEST SET EVALUATION METRICS\n",
      "==================================================\n",
      "   Accuracy       : 0.5326\n",
      "   Precision      : 0.5498\n",
      "   Recall         : 0.5803\n",
      "   F1 Score       : 0.5646\n",
      "   F-beta (Œ≤=0.5) : 0.5556\n",
      "   ROC-AUC        : 0.5476\n",
      "\n",
      "üìã DETAILED CLASSIFICATION REPORT (Test Set)\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Signal       0.51      0.48      0.50      1515\n",
      "      Signal       0.55      0.58      0.56      1656\n",
      "\n",
      "    accuracy                           0.53      3171\n",
      "   macro avg       0.53      0.53      0.53      3171\n",
      "weighted avg       0.53      0.53      0.53      3171\n",
      "\n",
      "\n",
      "üî¢ CONFUSION MATRIX (Test Set)\n",
      "===================================\n",
      "True Negatives:     728\n",
      "False Positives:    787\n",
      "False Negatives:    695\n",
      "True Positives:     961\n",
      "\n",
      "üèÜ TOP 20 MOST IMPORTANT FEATURES\n",
      "==================================================\n",
      "Top 20 features by absolute coefficient:\n",
      " 1. üìâ buying_pressure          :  -0.0844\n",
      " 2. üìâ stoch_%K                 :  -0.0386\n",
      " 3. üìâ bb_position              :  -0.0264\n",
      " 4. üìâ MACD_histogram           :  -0.0164\n",
      " 5. üìà cci_oversold             :   0.0125\n",
      " 6. üìâ above_sma20              :  -0.0020\n",
      " 7. üìâ cci_overbought           :  -0.0011\n",
      " 8. üìà stoch_oversold           :   0.0010\n",
      " 9. üìâ EMA_7                    :   0.0000\n",
      "10. üìâ volume                   :   0.0000\n",
      "11. üìâ close                    :   0.0000\n",
      "12. üìâ CCI                      :   0.0000\n",
      "13. üìâ bollinger_width          :   0.0000\n",
      "14. üìâ OBV                      :   0.0000\n",
      "15. üìâ RSI                      :   0.0000\n",
      "16. üìâ SMA_20                   :   0.0000\n",
      "17. üìâ SMA_50                   :   0.0000\n",
      "18. üìâ EMA_21                   :   0.0000\n",
      "19. üìâ atr_14                   :   0.0000\n",
      "20. üìâ volume_mean_20           :   0.0000\n",
      "\n",
      "üíæ Saving model to models\\logistic_regression_btc_model.pkl\n",
      "‚úÖ Model saved successfully!\n",
      "\n",
      "============================================================\n",
      "üéØ TRAINING SUMMARY\n",
      "============================================================\n",
      "Model Type:           Logistic Regression (ElasticNet)\n",
      "Training Time:        0.10 seconds\n",
      "Features Used:        43\n",
      "Training Samples:     12,684\n",
      "Test Samples:         3,171\n",
      "\n",
      "Key Performance Metrics (Test Set):\n",
      "  ‚Ä¢ Accuracy:         0.5326\n",
      "  ‚Ä¢ Precision:        0.5498\n",
      "  ‚Ä¢ Recall:           0.5803\n",
      "  ‚Ä¢ F-beta (Œ≤=0.5):   0.5556\n",
      "  ‚Ä¢ ROC-AUC:          0.5476\n",
      "============================================================\n",
      "\n",
      "üîÆ Model ready for predictions!\n",
      "Use predict_signal(features_dict) for new predictions\n",
      "Model saved to: models\\logistic_regression_btc_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "#  LOGISTIC-REGRESSION  TRAINER  (with optimal parameters)\n",
    "# =============================================================\n",
    "import numpy as np, pandas as pd, time, joblib, warnings\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (precision_score, recall_score, accuracy_score, \n",
    "                             f1_score, roc_auc_score, classification_report, \n",
    "                             confusion_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1) CONFIG  ‚Äì EDIT HERE\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "CSV_FILE   = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_with_features_4h.csv\")\n",
    "TIME_COL   = \"timestamp\"\n",
    "TARGET_COL = \"target\"\n",
    "\n",
    "START_DATE = \"2018-01-01\"\n",
    "TEST_FRAC  = 0.20\n",
    "\n",
    "# OPTIMAL PARAMETERS (from hyperparameter tuning)\n",
    "OPTIMAL_PARAMS = {\n",
    "    'C': 0.00407559644007287,\n",
    "    'class_weight': None,\n",
    "    'l1_ratio': 0.5,\n",
    "    'penalty': 'elasticnet'\n",
    "}\n",
    "\n",
    "DROP_COLS = ['open', 'high', 'low', 'high_low', 'high_close', 'low_close', 'typical_price',\n",
    "            'volume_breakout', 'volume_breakdown', 'break_upper_band', 'break_lower_band',\n",
    "            'vol_spike_1_5x', 'near_upper_band', 'near_lower_band',\n",
    "            'overbought_reversal', 'oversold_reversal', 'macd_cross_up',\n",
    "            'macd_cross_down', 'macd_rising', 'bollinger_upper', 'bollinger_lower',\n",
    "            'MACD_line', 'MACD_signal', 'stoch_%D', 'momentum_alignment', 'obv_rising_24h',\n",
    "            'bullish_scenario_1', 'bullish_scenario_5', 'bearish_scenario_1']\n",
    "\n",
    "# Model save path\n",
    "MODEL_SAVE_PATH = Path(\"models/logistic_regression_btc_model.pkl\")\n",
    "MODEL_SAVE_PATH.parent.mkdir(exist_ok=True)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 2)  LOAD  &  SPLIT DATA\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if not CSV_FILE.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå File not found: {CSV_FILE}\")\n",
    "\n",
    "print(\"üìä Loading and preparing data...\")\n",
    "df = (pd.read_csv(CSV_FILE, parse_dates=[TIME_COL])\n",
    "        .set_index(TIME_COL).sort_index())\n",
    "df = df.loc[START_DATE:].copy()\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise KeyError(f\"‚ùå '{TARGET_COL}' column missing!\")\n",
    "\n",
    "X = df.drop(columns=[c for c in DROP_COLS if c in df.columns] + [TARGET_COL],\n",
    "            errors=\"ignore\")\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Data validation\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
    "print(f\"Target balance: {y.mean():.3f} (positive class rate)\")\n",
    "\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"‚ö†Ô∏è Warning: Missing values detected\")\n",
    "    missing_cols = X.isnull().sum()[X.isnull().sum() > 0]\n",
    "    print(missing_cols)\n",
    "\n",
    "# Time-based split\n",
    "split = int(len(df) * (1 - TEST_FRAC))\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "print(f\"Train: {X_train.shape} | Test: {X_test.shape}\")\n",
    "print(f\"Train period: {X_train.index[0]} to {X_train.index[-1]}\")\n",
    "print(f\"Test period: {X_test.index[0]} to {X_test.index[-1]}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 3) CUSTOM METRICS\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def f_beta_score(y_true, y_pred, beta=0.5):\n",
    "    \"\"\"Calculate F-beta score with specified beta (default 0.5 for precision focus)\"\"\"\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score(y_true, y_pred, zero_division=0)\n",
    "    if p + r == 0:\n",
    "        return 0.0\n",
    "    return (1 + beta**2) * p * r / (beta**2 * p + r)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_prob, dataset_name=\"\"):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    print(f\"\\nüìà {dataset_name} EVALUATION METRICS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'F1 Score': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'F-beta (Œ≤=0.5)': f_beta_score(y_true, y_pred, beta=0.5),\n",
    "        'ROC-AUC': roc_auc_score(y_true, y_prob)\n",
    "    }\n",
    "    \n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"   {metric:<15}: {value:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 4) BUILD AND TRAIN MODEL\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\nü§ñ Building model with optimal parameters...\")\n",
    "print(\"Optimal parameters:\")\n",
    "for param, value in OPTIMAL_PARAMS.items():\n",
    "    print(f\"   {param:<15}: {value}\")\n",
    "\n",
    "# Create pipeline with optimal parameters\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(\n",
    "        C=OPTIMAL_PARAMS['C'],\n",
    "        penalty=OPTIMAL_PARAMS['penalty'],\n",
    "        l1_ratio=OPTIMAL_PARAMS['l1_ratio'],\n",
    "        class_weight=OPTIMAL_PARAMS['class_weight'],\n",
    "        max_iter=4000,\n",
    "        solver='saga',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nüöÄ Training model...\")\n",
    "start_time = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚úÖ Model trained in {training_time:.2f} seconds\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 5) EVALUATE MODEL\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Training set evaluation\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_train_prob = pipeline.predict_proba(X_train)[:, 1]\n",
    "train_metrics = evaluate_model(y_train, y_train_pred, y_train_prob, \"TRAINING SET\")\n",
    "\n",
    "# Test set evaluation\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "y_test_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "test_metrics = evaluate_model(y_test, y_test_pred, y_test_prob, \"TEST SET\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 6) DETAILED ANALYSIS\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\nüìã DETAILED CLASSIFICATION REPORT (Test Set)\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_test_pred, target_names=['No Signal', 'Signal']))\n",
    "\n",
    "print(\"\\nüî¢ CONFUSION MATRIX (Test Set)\")\n",
    "print(\"=\"*35)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(f\"True Negatives:  {cm[0,0]:>6}\")\n",
    "print(f\"False Positives: {cm[0,1]:>6}\")\n",
    "print(f\"False Negatives: {cm[1,0]:>6}\")\n",
    "print(f\"True Positives:  {cm[1,1]:>6}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 7) FEATURE IMPORTANCE (COEFFICIENTS)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\nüèÜ TOP 20 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get feature coefficients\n",
    "feature_names = X_train.columns\n",
    "coefficients = pipeline.named_steps['logreg'].coef_[0]\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(\"Top 20 features by absolute coefficient:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(20).iterrows()):\n",
    "    direction = \"üìà\" if row['coefficient'] > 0 else \"üìâ\"\n",
    "    print(f\"{i+1:>2}. {direction} {row['feature']:<25}: {row['coefficient']:>8.4f}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 8) SAVE MODEL\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(f\"\\nüíæ Saving model to {MODEL_SAVE_PATH}\")\n",
    "model_data = {\n",
    "    'pipeline': pipeline,\n",
    "    'feature_names': list(X_train.columns),\n",
    "    'optimal_params': OPTIMAL_PARAMS,\n",
    "    'train_metrics': train_metrics,\n",
    "    'test_metrics': test_metrics,\n",
    "    'feature_importance': feature_importance,\n",
    "    'training_info': {\n",
    "        'train_shape': X_train.shape,\n",
    "        'test_shape': X_test.shape,\n",
    "        'train_period': (str(X_train.index[0]), str(X_train.index[-1])),\n",
    "        'test_period': (str(X_test.index[0]), str(X_test.index[-1])),\n",
    "        'training_time': training_time,\n",
    "        'target_balance': y.mean()\n",
    "    }\n",
    "}\n",
    "\n",
    "joblib.dump(model_data, MODEL_SAVE_PATH)\n",
    "print(\"‚úÖ Model saved successfully!\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 9) SUMMARY\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model Type:           Logistic Regression (ElasticNet)\")\n",
    "print(f\"Training Time:        {training_time:.2f} seconds\")\n",
    "print(f\"Features Used:        {len(X_train.columns)}\")\n",
    "print(f\"Training Samples:     {len(X_train):,}\")\n",
    "print(f\"Test Samples:         {len(X_test):,}\")\n",
    "print(f\"\")\n",
    "print(\"Key Performance Metrics (Test Set):\")\n",
    "print(f\"  ‚Ä¢ Accuracy:         {test_metrics['Accuracy']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision:        {test_metrics['Precision']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall:           {test_metrics['Recall']:.4f}\")\n",
    "print(f\"  ‚Ä¢ F-beta (Œ≤=0.5):   {test_metrics['F-beta (Œ≤=0.5)']:.4f}\")\n",
    "print(f\"  ‚Ä¢ ROC-AUC:          {test_metrics['ROC-AUC']:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Quick prediction function for future use\n",
    "def predict_signal(features_dict):\n",
    "    \"\"\"\n",
    "    Make prediction on new data\n",
    "    \n",
    "    Args:\n",
    "        features_dict: Dictionary with feature names as keys and values as numpy array or list\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (prediction, probability)\n",
    "    \"\"\"\n",
    "    features_df = pd.DataFrame([features_dict])\n",
    "    features_df = features_df.reindex(columns=X_train.columns, fill_value=0)\n",
    "    \n",
    "    prediction = pipeline.predict(features_df)[0]\n",
    "    probability = pipeline.predict_proba(features_df)[0, 1]\n",
    "    \n",
    "    return prediction, probability\n",
    "\n",
    "print(f\"\\nüîÆ Model ready for predictions!\")\n",
    "print(f\"Use predict_signal(features_dict) for new predictions\")\n",
    "print(f\"Model saved to: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

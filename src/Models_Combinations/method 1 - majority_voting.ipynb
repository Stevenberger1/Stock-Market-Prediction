{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7059c042",
   "metadata": {},
   "source": [
    "# in this notebook we will train the first combation method - majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfac139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3828\\3317383661.py:54: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ts = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\", utc=True)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3828\\3317383661.py:54: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ts = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\", utc=True)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3828\\3317383661.py:54: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ts = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\", utc=True)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3828\\3317383661.py:54: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ts = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\", utc=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Loading prediction files â€¦\n",
      "Rows after inner-join & cut-to-latest-start: 3,105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1013/1013 [00:04<00:00, 213.17combo/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ combos done in 4.8 s\n",
      "\n",
      "Top-10 ensembles by F1:\n",
      "                    models  n_models  precision   recall       f1\n",
      "      gru+lstm+rf+cnn_lstm         4   0.615721 0.174074 0.271415\n",
      "          cnn+gru+lstm+xgb         4   0.614391 0.205556 0.308048\n",
      "catboost+gru+lgbm+cnn_lstm         4   0.614000 0.189506 0.289623\n",
      "           cnn+gru+lstm+rf         4   0.613828 0.224691 0.328965\n",
      "      gru+lgbm+rf+cnn_lstm         4   0.612981 0.157407 0.250491\n",
      "          gru+lgbm+lstm+rf         4   0.611307 0.213580 0.316560\n",
      "    catboost+gru+lgbm+lstm         4   0.611285 0.240741 0.345438\n",
      "      catboost+gru+lgbm+rf         4   0.608215 0.237654 0.341767\n",
      "catboost+gru+lstm+cnn_lstm         4   0.608084 0.213580 0.316126\n",
      "  catboost+gru+rf+cnn_lstm         4   0.607018 0.213580 0.315982\n",
      "\n",
      "Best single model : tcn  F1=0.6857\n",
      "Best ensemble     : gru+lstm+rf+cnn_lstm  F1=0.2714\n",
      "Improvement       : -0.4143 (-60.42 %)\n",
      "\n",
      "ğŸ’¾ Files written: majority_vote_results.csv, individual_model_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exhaustive Majority-Voting Grid Search (10 models, combos 2-10)\n",
    "==============================================================\n",
    "\n",
    "â€¢ Aligns on latest common start date\n",
    "â€¢ Verifies all 'actual' columns match\n",
    "â€¢ Evaluates 1 013 subsets with hard vote\n",
    "â€¢ Writes:\n",
    "    - majority_vote_results.csv\n",
    "    - individual_model_metrics.csv\n",
    "\"\"\"\n",
    "\n",
    "import itertools, sys, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    accuracy_score, confusion_matrix\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CONFIG\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "BASE = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "            r\"\\Stock-Market-Prediction\\Final_runs_csv\")\n",
    "\n",
    "FILES = {\n",
    "    \"catboost\" : \"catboost_trial57_predictions.csv\",\n",
    "    \"cnn\"      : \"cnn_predictions.csv\",\n",
    "    \"gru\"      : \"gru_trial28_f05_preds.csv\",\n",
    "    \"lgbm\"     : \"lgbm_predictions_formatted_backup.csv\",\n",
    "    \"logreg\"   : \"logisticreg_validation_predictions.csv\",\n",
    "    \"lstm\"     : \"lstm_test_predictions.csv\",\n",
    "    \"rf\"       : \"RandomForest_predictions_custom_high_precision.csv\",\n",
    "    \"tcn\"      : \"TCN_Trial_36_predictions.csv\",\n",
    "    \"xgb\"      : \"xgboost_predictions_fixed.csv\",\n",
    "    \"cnn_lstm\" : \"cnn_lstm_val_preds_20250614_142329.csv\",\n",
    "}\n",
    "\n",
    "THRESH = {k: 0.5 for k in FILES}          # per-model probâ†’label threshold\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. LOAD & ALIGN\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "earliest = {}\n",
    "\n",
    "def load_one(path: Path, key: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    if {\"timestamp\", \"prob_up\", \"actual\"} - set(df.columns):\n",
    "        sys.exit(f\"âŒ required cols missing in {path.name}\")\n",
    "\n",
    "    ts = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\", utc=True)\n",
    "    if ts.isna().any():\n",
    "        bad = ts.isna().sum()\n",
    "        sys.exit(f\"âŒ {bad} unparsable timestamps in {path.name}\")\n",
    "\n",
    "    earliest[key] = ts.min()\n",
    "\n",
    "    y_bin = (df[\"prob_up\"].to_numpy() >= THRESH[key]).astype(np.uint8)\n",
    "    return pd.DataFrame({\n",
    "        \"timestamp\": ts,\n",
    "        key: y_bin,\n",
    "        f\"{key}_actual\": df[\"actual\"]\n",
    "    })\n",
    "\n",
    "print(\"ğŸ”§ Loading prediction files â€¦\")\n",
    "merged = None\n",
    "for key, fname in FILES.items():\n",
    "    p = BASE / fname\n",
    "    if not p.exists():\n",
    "        sys.exit(f\"âŒ file not found: {p}\")\n",
    "    part = load_one(p, key)\n",
    "    merged = part if merged is None else merged.merge(part, on=\"timestamp\", how=\"inner\")\n",
    "\n",
    "# â”€â”€ trim to start at the latest model-specific start date\n",
    "start_cut = max(earliest.values())\n",
    "merged = merged[merged[\"timestamp\"] >= start_cut].reset_index(drop=True)\n",
    "print(f\"Rows after inner-join & cut-to-latest-start: {len(merged):,}\")\n",
    "\n",
    "# â”€â”€ verify 'actual' columns identical\n",
    "act_cols = [c for c in merged.columns if c.endswith(\"_actual\")]\n",
    "if not merged[act_cols].eq(merged[act_cols[0]], axis=0).all().all():\n",
    "    sys.exit(\"âŒ 'actual' values differ across files â€“ fix before continuing\")\n",
    "\n",
    "y_true = merged[act_cols[0]].to_numpy(dtype=np.uint8)\n",
    "merged.drop(columns=act_cols, inplace=True)\n",
    "\n",
    "pred_keys = list(FILES.keys())\n",
    "X = merged[pred_keys].to_numpy(dtype=np.uint8)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. EXHAUSTIVE COMBINATION SEARCH (k = 2 â€¦ 10)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def hard_vote(mat: np.ndarray) -> np.ndarray:\n",
    "    return (mat.sum(1) > mat.shape[1] / 2).astype(np.uint8)\n",
    "\n",
    "n = len(pred_keys)\n",
    "total = (2 ** n) - 1 - n\n",
    "results = []\n",
    "\n",
    "t0 = time.time()\n",
    "with tqdm(total=total, unit=\"combo\") as bar:\n",
    "    for k in range(2, n + 1):\n",
    "        for idx in itertools.combinations(range(n), k):\n",
    "            y_pred = hard_vote(X[:, idx])\n",
    "\n",
    "            prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "            rec  = recall_score   (y_true, y_pred, zero_division=0)\n",
    "            f1   = f1_score      (y_true, y_pred, zero_division=0)\n",
    "            acc  = accuracy_score(y_true, y_pred)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "            results.append({\n",
    "                \"models\"   : \"+\".join(pred_keys[i] for i in idx),\n",
    "                \"n_models\" : k,\n",
    "                \"precision\": round(prec, 6),\n",
    "                \"recall\"   : round(rec, 6),\n",
    "                \"f1\"       : round(f1, 6),\n",
    "                \"accuracy\" : round(acc, 6),\n",
    "                \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn\n",
    "            })\n",
    "            bar.update(1)\n",
    "\n",
    "print(f\"ğŸ combos done in {time.time()-t0:.1f} s\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. SINGLE-MODEL METRICS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "indiv = []\n",
    "for i, name in enumerate(pred_keys):\n",
    "    y_pred = X[:, i]\n",
    "    indiv.append({\n",
    "        \"models\": name, \"n_models\": 1,\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\"   : recall_score  (y_true, y_pred, zero_division=0),\n",
    "        \"f1\"       : f1_score      (y_true, y_pred, zero_division=0),\n",
    "        \"accuracy\" : accuracy_score(y_true, y_pred)\n",
    "    })\n",
    "indiv_df = pd.DataFrame(indiv).sort_values(\"f1\", ascending=False)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4. SAVE OUTPUTS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "out_all = BASE / \"majority_vote_results.csv\"\n",
    "out_ind = BASE / \"individual_model_metrics.csv\"\n",
    "\n",
    "(pd.DataFrame(results)\n",
    "   .sort_values([\"precision\", \"recall\", \"f1\"],\n",
    "                ascending=[False, False, True])\n",
    "   .to_csv(out_all, index=False))\n",
    "indiv_df.to_csv(out_ind, index=False)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5. CONSOLE SUMMARY\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nTop-10 ensembles by F1:\")\n",
    "top10 = pd.read_csv(out_all).head(10)\n",
    "print(top10[[\"models\", \"n_models\", \"precision\", \"recall\", \"f1\"]].to_string(index=False))\n",
    "\n",
    "best_single = indiv_df.iloc[0]\n",
    "best_combo  = top10.iloc[0]\n",
    "improv = best_combo[\"f1\"] - best_single[\"f1\"]\n",
    "\n",
    "print(\"\\nBest single model :\",\n",
    "      f\"{best_single['models']}  F1={best_single['f1']:.4f}\")\n",
    "print(\"Best ensemble     :\",\n",
    "      f\"{best_combo['models']}  F1={best_combo['f1']:.4f}\")\n",
    "print(f\"Improvement       : {improv:+.4f} \"\n",
    "      f\"({improv/best_single['f1']*100:+.2f} %)\")\n",
    "print(f\"\\nğŸ’¾ Files written: {out_all.name}, {out_ind.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e5ed73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 combinations â€“ ranked by precision\n",
      "                            models  n_models precision recall     f1\n",
      "              gru+lstm+rf+cnn_lstm         4    0.6157 0.1741 0.2714\n",
      "                  cnn+gru+lstm+xgb         4    0.6144 0.2056 0.3080\n",
      "        catboost+gru+lgbm+cnn_lstm         4    0.6140 0.1895 0.2896\n",
      "                   cnn+gru+lstm+rf         4    0.6138 0.2247 0.3290\n",
      "              gru+lgbm+rf+cnn_lstm         4    0.6130 0.1574 0.2505\n",
      "                  gru+lgbm+lstm+rf         4    0.6113 0.2136 0.3166\n",
      "            catboost+gru+lgbm+lstm         4    0.6113 0.2407 0.3454\n",
      "              catboost+gru+lgbm+rf         4    0.6082 0.2377 0.3418\n",
      "        catboost+gru+lstm+cnn_lstm         4    0.6081 0.2136 0.3161\n",
      "          catboost+gru+rf+cnn_lstm         4    0.6070 0.2136 0.3160\n",
      "           gru+logreg+xgb+cnn_lstm         4    0.6069 0.1963 0.2966\n",
      "             gru+lgbm+xgb+cnn_lstm         4    0.6066 0.1580 0.2507\n",
      "catboost+cnn+gru+lstm+xgb+cnn_lstm         6    0.6066 0.3074 0.4080\n",
      " catboost+cnn+gru+lgbm+rf+cnn_lstm         6    0.6063 0.2870 0.3896\n",
      "catboost+gru+lgbm+lstm+rf+cnn_lstm         6    0.6062 0.2907 0.3930\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the CSV written by the ensemble script\n",
    "BASE   = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\"\n",
    "              r\"\\Stock-Market-Prediction\\Final_runs_csv\")\n",
    "CSV    = BASE / \"majority_vote_results.csv\"\n",
    "\n",
    "# Read, sort, display\n",
    "df = pd.read_csv(CSV)\n",
    "top15 = (df.sort_values([\"precision\", \"f1\", \"recall\"],\n",
    "                        ascending=[False, False, False])\n",
    "           .head(15))\n",
    "\n",
    "print(\"\\nTop 15 combinations â€“ ranked by precision\")\n",
    "print(top15[[\"models\", \"n_models\", \"precision\", \"recall\", \"f1\"]]\n",
    "      .to_string(index=False, formatters={\n",
    "          \"precision\": \"{:.4f}\".format,\n",
    "          \"recall\"   : \"{:.4f}\".format,\n",
    "          \"f1\"       : \"{:.4f}\".format\n",
    "      }))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

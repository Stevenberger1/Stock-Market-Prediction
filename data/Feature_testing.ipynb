{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250f1630",
   "metadata": {},
   "source": [
    "# BTC Hourly Direction Study – Two Labeling Schemes\n",
    "**Dataset**: `gemini_btc_data_final_version.csv`  \n",
    "**File path**: `C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_data_final_version.csv`\n",
    "\n",
    "We will run **two entirely separate experiments** so one crash cannot corrupt the other:\n",
    "\n",
    "| Run | Label | Why we use it |\n",
    "|-----|-------|---------------|\n",
    "| **A** | `direction_quant70` – top/bottom 30 % 1-h returns (drop middle 40 %) | Removes noisy bars; focuses on meaningful moves. |\n",
    "| **B** | `direction_raw` – every bar (up/down) ; plus **high-confidence filter** (`prob ≥ 0.7`) | Uses full data; we act only when the model is very sure. |\n",
    "\n",
    "For each run we compare **Momentum-only features** vs. **All engineered features** and report Accuracy, Precision, Recall, F1, ROC-AUC.  \n",
    "Held-out permutation importances tell which columns truly matter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32664a43",
   "metadata": {},
   "source": [
    "### Feature glossary\n",
    "\n",
    "| Feature                | Formula / window                 | Intuition |\n",
    "|------------------------|-----------------------------------|-----------|\n",
    "| **vol_6h**             | Std. dev. of 1-h returns, 6-hour window | Captures short-term volatility spikes that often precede breakouts. |\n",
    "| **vol_24h**            | Std. dev. of 1-h returns, 24 h window  | Detects high-vol vs. calm regimes over one day. |\n",
    "| **atr_14h**            | Mean of `(high-low)` over last 14 bars | A simpler Average True Range; bigger bars → more movement potential. |\n",
    "| **pos_24h**            | `(close − 24h low) / (24h high − 24h low)` | Where price sits inside its 24-hour range (0 = bottom, 1 = top). |\n",
    "| **boll_b**             | Bollinger %B on a 24-h SMA ±2 σ        | >1 means over-bought; <0 means over-sold relative to band. |\n",
    "| **vol_mean_24h**       | 24-h moving average of **Volume BTC**  | Baseline liquidity level. |\n",
    "| **vol_ratio**          | `Volume / vol_mean_24h`                | >1 = current bar has abnormally high volume (demand shock). |\n",
    "| **vol_pct_change**     | % change in volume vs. 6 bars ago      | Sudden volume jumps ahead of price moves. |\n",
    "| **obv**                | Cumulative Σ (sign(return) × Volume)   | On-Balance Volume; tracks whether volume flows with price. |\n",
    "| **body**               | `close − open`                         | Size / direction of candle body (positive = green bar). |\n",
    "| **upper_shadow**       | `high − max(open, close)`              | Buying rejection wick; long tails can signal reversals. |\n",
    "| **lower_shadow**       | `min(open, close) − low`               | Selling rejection wick. |\n",
    "| **hour_sin / hour_cos**| Sin/Cos of UTC hour (0-23)             | Encode intraday cycle (Asia, EU, US sessions). |\n",
    "| **dow**                | Day-of-week (0 = Mon … 6 = Sun)        | Weekend vs. weekday behaviour. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b9807ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows loaded : 82,519\n",
      "Date span   : 2015-10-08 14:00:00 → 2025-03-27 23:00:00\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# Cell 1 ▸ Imports & load\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib  import Path\n",
    "from sklearn.ensemble   import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score)\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# --- edit your file path here ---\n",
    "CSV = Path(r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\data\\processed\\gemini_btc_data_final_version.csv\")\n",
    "\n",
    "df = (pd.read_csv(CSV, parse_dates=[\"date\"])\n",
    "        .sort_values(\"date\")\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "print(f\"Rows loaded : {len(df):,}\")\n",
    "print(\"Date span   :\", df['date'].min(), \"→\", df['date'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91decbf8",
   "metadata": {},
   "source": [
    "### Basic cleaning\n",
    "1. **Drop** Gemini’s ultra-sparse infancy period (before 2016-04-01).  \n",
    "2. **Forward-fill core OHLCV gaps ≤ 3 hours** so short feed hiccups don’t create NaNs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68ff0f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after cut & ffill: 78576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_17376\\630700829.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[core] = df[core].fillna(method='ffill', limit=3)\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# Cell 2 ▸ Basic cleaning\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "df = df[df['date'] >= '2016-04-01'].copy()\n",
    "\n",
    "core = ['open', 'high', 'low', 'close', 'Volume BTC']\n",
    "df[core] = df[core].fillna(method='ffill', limit=3)\n",
    "\n",
    "print(\"Rows after cut & ffill:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdff5a3",
   "metadata": {},
   "source": [
    "## Feature engineering (safe – guards against ÷0 / ±inf)\n",
    "\n",
    "We create six families:\n",
    "\n",
    "1. **Momentum** (`roc_*`)  \n",
    "2. **Volatility** (`vol_*`, `atr_*`)  \n",
    "3. **Range/position** (`pos_24h`, `boll_b`)  \n",
    "4. **Volume/liquidity** (`vol_ratio`, `vol_pct_change`, `obv`)  \n",
    "5. **Candlestick anatomy** (`body`, `upper_shadow`, `lower_shadow`)  \n",
    "6. **Time seasonality** (`hour_sin`, `hour_cos`, `dow`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b87099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# Cell 3 ▸ Feature engineering (safe)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "EPS = 1e-9\n",
    "\n",
    "# ── 1) Momentum\n",
    "df['roc_4h']  = df['close'].pct_change(4)\n",
    "df['roc_24h'] = df['close'].pct_change(24)\n",
    "df['roc_7d']  = df['close'].pct_change(24*7)\n",
    "df['roc_30d'] = df['close'].pct_change(24*30)\n",
    "\n",
    "# ── 2) Volatility\n",
    "ret = df['close'].pct_change()\n",
    "df['vol_6h']  = ret.rolling(6).std()\n",
    "df['vol_24h'] = ret.rolling(24).std()\n",
    "df['atr_14h'] = (df['high'] - df['low']).rolling(14).mean()\n",
    "\n",
    "# ── 3) Range / position\n",
    "hi24 = df['high'].rolling(24).max()\n",
    "lo24 = df['low'] .rolling(24).min()\n",
    "rng   = (hi24 - lo24).replace(0, EPS)\n",
    "df['pos_24h'] = (df['close'] - lo24) / rng\n",
    "mid24 = df['close'].rolling(24).mean()\n",
    "std24 = df['close'].rolling(24).std().replace(0, EPS)\n",
    "df['boll_b']  = (df['close'] - (mid24 - 2*std24)) / (4*std24)\n",
    "\n",
    "# ── 4) Volume / liquidity\n",
    "df['vol_mean_24h']   = df['Volume BTC'].rolling(24).mean().replace(0, EPS)\n",
    "df['vol_ratio']      = df['Volume BTC'] / df['vol_mean_24h']\n",
    "df['vol_pct_change'] = df['Volume BTC'].pct_change(6)\n",
    "sign = np.sign(df['close'].diff()).fillna(0)\n",
    "df['obv'] = (sign * df['Volume BTC']).cumsum()\n",
    "\n",
    "# ── 5) Candle shape\n",
    "df['body']          = df['close'] - df['open']\n",
    "df['upper_shadow']  = df['high'] - df[['close','open']].max(axis=1)\n",
    "df['lower_shadow']  = df[['close','open']].min(axis=1) - df['low']\n",
    "\n",
    "# ── 6) Time seasonality\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['hour_sin'] = np.sin(2*np.pi*df['hour']/24)\n",
    "df['hour_cos'] = np.cos(2*np.pi*df['hour']/24)\n",
    "df['dow']      = df['date'].dt.dayofweek\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59591889",
   "metadata": {},
   "source": [
    "### Feature family lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b52f2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# Cell 4 ▸ Feature family lists\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "F_MOM  = ['roc_4h','roc_24h','roc_7d','roc_30d']\n",
    "F_VOL  = ['vol_6h','vol_24h','atr_14h']\n",
    "F_RNG  = ['pos_24h','boll_b']\n",
    "F_VLM  = ['vol_ratio','vol_pct_change','obv']\n",
    "F_CDL  = ['body','upper_shadow','lower_shadow']\n",
    "F_TIME = ['hour_sin','hour_cos','dow']\n",
    "ALL_FEATS = F_MOM + F_VOL + F_RNG + F_VLM + F_CDL + F_TIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1a7b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ALL_FEATS] = df[ALL_FEATS].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c64cfe0",
   "metadata": {},
   "source": [
    "# RUN A – Quantile 70/30 label (decisive moves) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f56189ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN A rows : 46859\n",
      "Class balance:\n",
      " direction_quant70\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 5A ▸ Create quantile-based label & mask rows\n",
    "# --- final safety sweep: convert ±inf → NaN and drop those rows -------------\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "ret1h = df['close'].pct_change()\n",
    "up_q, dn_q = ret1h.quantile([0.70, 0.30])\n",
    "df['direction_quant70'] = np.select(\n",
    "    [ret1h >= up_q, ret1h <= dn_q], [1, 0], default=np.nan\n",
    ")\n",
    "\n",
    "mask_A = df[ALL_FEATS].notna().all(axis=1) & df['direction_quant70'].notna()\n",
    "dfa = df.loc[mask_A].reset_index(drop=True)\n",
    "\n",
    "print(\"RUN A rows :\", len(dfa))\n",
    "print(\"Class balance:\\n\", dfa['direction_quant70'].value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8823b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6A ▸ Evaluation helper for one label\n",
    "def eval_run(dataframe, feat_list, label_col, n_splits=5):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    metrics, imps = [], []\n",
    "    for fold,(tr,ts) in enumerate(tscv.split(dataframe)):\n",
    "        Xtr, ytr = dataframe.iloc[tr][feat_list], dataframe.iloc[tr][label_col]\n",
    "        Xts, yts = dataframe.iloc[ts][feat_list], dataframe.iloc[ts][label_col]\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=400, n_jobs=-1,\n",
    "                                     random_state=fold).fit(Xtr, ytr)\n",
    "        y_pred = clf.predict(Xts)\n",
    "        proba  = clf.predict_proba(Xts)[:,1]\n",
    "\n",
    "        metrics.append({\n",
    "            \"accuracy\" : accuracy_score(yts, y_pred),\n",
    "            \"precision\": precision_score(yts, y_pred, zero_division=0),\n",
    "            \"recall\"   : recall_score(yts, y_pred, zero_division=0),\n",
    "            \"f1\"       : f1_score(yts, y_pred, zero_division=0),\n",
    "            \"roc_auc\"  : roc_auc_score(yts, proba),\n",
    "        })\n",
    "\n",
    "        pi = permutation_importance(clf, Xts, yts, scoring=\"accuracy\",\n",
    "                                    n_repeats=10, random_state=fold, n_jobs=-1)\n",
    "        imps.append(pd.Series(pi.importances_mean, index=feat_list))\n",
    "\n",
    "    return pd.DataFrame(metrics).mean().round(3), pd.concat(imps, axis=1).mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bf8bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MOM</th>\n",
       "      <td>0.513</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALL</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  precision  recall     f1  roc_auc\n",
       "MOM     0.513      0.505   0.550  0.526    0.521\n",
       "ALL     0.535      0.526   0.612  0.561    0.554"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7A ▸ Run Momentum vs. ALL for RUN A\n",
    "expA = {}\n",
    "for name, feats in {\"MOM\":F_MOM, \"ALL\":ALL_FEATS}.items():\n",
    "    res, imp = eval_run(dfa, feats, \"direction_quant70\")\n",
    "    expA[name] = res\n",
    "    if name == \"ALL\": impA = imp          # save importances for ALL\n",
    "\n",
    "pd.DataFrame(expA).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bd98fd",
   "metadata": {},
   "source": [
    "### Top-10 generalising features (Run A, ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd77f5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body              0.011666\n",
       "roc_4h            0.008872\n",
       "pos_24h           0.007658\n",
       "boll_b            0.004766\n",
       "upper_shadow      0.004323\n",
       "lower_shadow      0.002799\n",
       "vol_pct_change    0.002287\n",
       "hour_cos          0.001867\n",
       "roc_30d           0.001749\n",
       "vol_ratio         0.001501\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impA.sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bab92e",
   "metadata": {},
   "source": [
    "# RUN B – Raw label (every bar) + confidence filter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbc3feaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN B rows : 77570\n",
      "Class balance:\n",
      " direction_raw\n",
      "1    0.506\n",
      "0    0.494\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 5B ▸ Build raw label and mask\n",
    "df['direction_raw'] = (df['close'].shift(-1) > df['close']).astype(int)\n",
    "mask_B = df[ALL_FEATS].notna().all(axis=1)   # raw label has no NaN\n",
    "dfb    = df.loc[mask_B].reset_index(drop=True)\n",
    "\n",
    "print(\"RUN B rows :\", len(dfb))\n",
    "print(\"Class balance:\\n\", dfb['direction_raw'].value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "706f65e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6B ▸ Evaluation with optional prob threshold (robust to 1-class slices)\n",
    "def eval_runB(dataframe, feat_list, prob_thr=None, n_splits=5):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    rows = []           # store metric dicts\n",
    "    cover = []          # coverage for prob-threshold variant\n",
    "\n",
    "    for fold, (tr, ts) in enumerate(tscv.split(dataframe)):\n",
    "        Xtr, ytr = dataframe.iloc[tr][feat_list], dataframe.iloc[tr]['direction_raw']\n",
    "        Xts, yts = dataframe.iloc[ts][feat_list], dataframe.iloc[ts]['direction_raw']\n",
    "\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=400, n_jobs=-1, random_state=fold\n",
    "        ).fit(Xtr, ytr)\n",
    "\n",
    "        proba = clf.predict_proba(Xts)[:, 1]\n",
    "        y_pred = (proba >= 0.50).astype(int)          # default 0.5 cut\n",
    "\n",
    "        # — optional high-confidence filter —\n",
    "        if prob_thr is not None:\n",
    "            mask = proba >= prob_thr\n",
    "            if mask.sum() == 0:          # nothing meets threshold → skip fold\n",
    "                continue\n",
    "            yts, y_pred, proba = yts[mask], y_pred[mask], proba[mask]\n",
    "            cover.append(mask.mean())\n",
    "\n",
    "        # --- compute metrics safely ---------------------------------\n",
    "        unique = np.unique(yts)\n",
    "        if len(unique) == 1:\n",
    "            roc = np.nan                 # can’t compute ROC-AUC with 1 class\n",
    "        else:\n",
    "            roc = roc_auc_score(yts, proba)\n",
    "\n",
    "        rows.append({\n",
    "            \"accuracy\" : accuracy_score(yts, y_pred),\n",
    "            \"precision\": precision_score(yts, y_pred, zero_division=0),\n",
    "            \"recall\"   : recall_score(yts, y_pred, zero_division=0),\n",
    "            \"f1\"       : f1_score(yts, y_pred, zero_division=0),\n",
    "            \"roc_auc\"  : roc,\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows).mean(numeric_only=True).round(3)\n",
    "    if prob_thr is not None:\n",
    "        out[\"coverage\"] = np.mean(cover) if cover else 0.0\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf41199f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>coverage</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RawFull | MOM</th>\n",
       "      <td>0.503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RawFull | ALL</th>\n",
       "      <td>0.517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RawConf&gt;.7 | ALL</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  accuracy  coverage     f1  precision  recall  roc_auc\n",
       "RawFull | MOM        0.503       NaN  0.527      0.511   0.546    0.504\n",
       "RawFull | ALL        0.517       NaN  0.559      0.521   0.607    0.521\n",
       "RawConf>.7 | ALL     0.550  0.000201  0.613      0.550   0.800    0.583"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7B ▸ Run 3 variants for RUN B\n",
    "expB = {\n",
    "    \"RawFull | MOM\"  : eval_runB(dfb, F_MOM),\n",
    "    \"RawFull | ALL\"  : eval_runB(dfb, ALL_FEATS),\n",
    "    \"RawConf>.7 | ALL\": eval_runB(dfb, ALL_FEATS, prob_thr=0.7)\n",
    "}\n",
    "pd.DataFrame(expB).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b6b3d",
   "metadata": {},
   "source": [
    "## Interpretation guide\n",
    "\n",
    "* **Run A table** (Quant70) – choose the row (MOM vs. ALL) with higher ROC-AUC/F1 to see if extra features help on decisive moves.  \n",
    "* **Run B table** – compare RawFull vs. RawConf > 0.7.  \n",
    "  * If RawConf > 0.7 reaches similar F1 but with, say, 20 % *coverage*, you have a practical high-confidence trading signal.  \n",
    "* **Top-10 importances (Run A)** – columns genuinely driving out-of-sample accuracy.\n",
    "\n",
    "Feel free to tweak:\n",
    "* Quantile thresholds (e.g., 0.75 / 0.25)  \n",
    "* Probability threshold (0.6–0.8)  \n",
    "* Swap RandomForest for XGBoost (drop-in replacement).\n",
    "\n",
    "This notebook is self-contained; each run is isolated so a crash in one loop can’t invalidate the other. Good luck!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

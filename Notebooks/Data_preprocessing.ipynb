{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file contains functions related to loading, cleaning, and preproessing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link to where the data was dowloanded from : https://www.cryptodatadownload.com/data/poloniex/#google_vignette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code loads the data from a path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(csv_path):\n",
    "    # If the first row of your CSV is just a note (e.g. “Data provided by...”),\n",
    "    # then skip it with skiprows=1. If not, set skiprows=0 or remove that parameter.\n",
    "    \n",
    "    df = pd.read_csv(\n",
    "        csv_path,\n",
    "        skiprows=1,            # Adjust if your first row is already column headers\n",
    "        parse_dates=['date'],  # Tells Pandas to convert the 'date' column to datetime64 objects.\n",
    "        infer_datetime_format=True  #Lets Pandas guess the date format more efficiently, which can speed up parsing if your file is big.\n",
    "\n",
    "    )\n",
    "    \n",
    "    #Sets the \"date\" column as the index of the DataFrame.\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    #sorts the DataFrame by the date/time index, just in case the rows were out of order.\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use of the load_data function \n",
    "path_to_csv = r\"C:\\Users\\ADMIN\\Desktop\\Coding_projects\\stock_market_prediction\\Stock-Market-Prediction\\Poloniex_BTCUSDT_1h.csv\"\n",
    "df_prices = load_data(path_to_csv)\n",
    "    \n",
    "print(\"DataFrame shape:\", df_prices.shape)\n",
    "print(df_prices.head())\n",
    "print(df_prices.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "series models:\n",
    "\n",
    "Date/Time : Usually kept as an index.\n",
    "\n",
    "Open, High, Low, Close (OHLC) : Core price features for any trading or forecasting model.\n",
    "\n",
    "Volume : Overall volume is often a good indicator of market interest and liquidity.\n",
    "\n",
    "Trade Count (Optional) : Helps distinguish whether volume came from many small trades or fewer large trades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code Keep only the columns that are most useful for ur dataframe\n",
    "\n",
    "def keep_important_columns(df):\n",
    "\n",
    "    # Define the columns you want to keep\n",
    "    columns_to_keep = [\n",
    "        \"open\",\n",
    "        \"high\",\n",
    "        \"low\",\n",
    "        \"close\",\n",
    "        \"Volume BTC\",   \n",
    "        \"tradeCount\"   \n",
    "    ]\n",
    "    \n",
    "    # Intersect with what actually exists in your DataFrame to avoid KeyErrors\n",
    "    existing_cols = [col for col in columns_to_keep if col in df.columns]\n",
    "    \n",
    "    # Create a reduced DataFrame with only these columns\n",
    "    df_reduced = df[existing_cols].copy()\n",
    "    return df_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use of keep_important_columns\n",
    "df_prices = keep_important_columns(df_prices)\n",
    "print(df_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to CSV\n",
    "#df_prices.to_csv('modified_btc_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a data-quality checker , It identifies common issues in a crypto price DataFrame, such as:\n",
    "\n",
    "Missing Values: Looks for NaN/None in columns.\n",
    "\n",
    "Duplicate Rows: Checks whether any exact duplicates exist.\n",
    "\n",
    "Negative or Zero Price/Volume: Flags rows where prices or volumes are invalid.\n",
    "\n",
    "Out-of-Order Date Index: Ensures that your date index is strictly increasing (important for time-series).\n",
    "\n",
    "Unexpected Data Types: Verifies that “open”, “high”, “low”, “close”, and “volume” columns are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Checker\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def check_data_problems(df):\n",
    "\n",
    "    problems_summary = {}\n",
    "\n",
    "    # 1) Check for missing values\n",
    "    missing = df.isnull().sum()\n",
    "    has_missing = missing.any()\n",
    "    if has_missing:\n",
    "        print(\">> MISSING VALUES found per column:\")\n",
    "        print(missing[missing > 0])\n",
    "        problems_summary['missing_values'] = missing[missing > 0].to_dict()\n",
    "    else:\n",
    "        print(\"No missing values detected.\")\n",
    "        problems_summary['missing_values'] = {}\n",
    "    \n",
    "    # 2) Check for duplicate rows\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    if duplicate_count > 0:\n",
    "        print(f\">> DUPLICATE ROWS found: {duplicate_count}\")\n",
    "        problems_summary['duplicate_rows'] = duplicate_count\n",
    "    else:\n",
    "        print(\"No duplicate rows found.\")\n",
    "        problems_summary['duplicate_rows'] = 0\n",
    "    \n",
    "    # 3) Negative or zero price/volume checks\n",
    "    # Adjust these columns to match your DataFrame (e.g., 'Volume BTC', 'Volume USDT', etc.)\n",
    "    price_cols = [col for col in ['open','high','low','close'] if col in df.columns]\n",
    "    volume_cols = [col for col in ['Volume BTC','Volume USDT','Volume USD','volume'] if col in df.columns]\n",
    "\n",
    "    invalid_prices = {}\n",
    "    for col in price_cols:\n",
    "        # Count how many rows have a non-positive price\n",
    "        non_pos = (df[col] <= 0).sum()\n",
    "        if non_pos > 0:\n",
    "            invalid_prices[col] = non_pos\n",
    "    \n",
    "    invalid_volumes = {}\n",
    "    for col in volume_cols:\n",
    "        non_pos = (df[col] <= 0).sum()\n",
    "        if non_pos > 0:\n",
    "            invalid_volumes[col] = non_pos\n",
    "\n",
    "    if invalid_prices:\n",
    "        print(\">> INVALID (≤0) PRICE VALUES found:\")\n",
    "        for c, count in invalid_prices.items():\n",
    "            print(f\"   Column '{c}': {count} rows\")\n",
    "        problems_summary['invalid_prices'] = invalid_prices\n",
    "    else:\n",
    "        print(\"No invalid (zero/negative) price values found.\")\n",
    "        problems_summary['invalid_prices'] = {}\n",
    "    \n",
    "    if invalid_volumes:\n",
    "        print(\">> INVALID (≤0) VOLUME VALUES found:\")\n",
    "        for c, count in invalid_volumes.items():\n",
    "            print(f\"   Column '{c}': {count} rows\")\n",
    "        problems_summary['invalid_volumes'] = invalid_volumes\n",
    "    else:\n",
    "        print(\"No invalid (zero/negative) volume values found.\")\n",
    "        problems_summary['invalid_volumes'] = {}\n",
    "\n",
    "    # 4) Out-of-order date index check (only if index is datetime-like)\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        # Check if the index is strictly increasing\n",
    "        is_increasing = df.index.is_monotonic_increasing\n",
    "        if not is_increasing:\n",
    "            print(\">> The date index is NOT strictly increasing. Some timestamps may be out of order.\")\n",
    "            problems_summary['date_order'] = \"Not strictly increasing\"\n",
    "        else:\n",
    "            print(\"Date index is in ascending order (strictly increasing).\")\n",
    "            problems_summary['date_order'] = \"Ascending\"\n",
    "    else:\n",
    "        print(\"Index is not a DatetimeIndex (skipping date-order check).\")\n",
    "        problems_summary['date_order'] = None\n",
    "\n",
    "    # 5) Data-type checks for numeric columns\n",
    "    numeric_checks = {}\n",
    "    for col in price_cols + volume_cols:\n",
    "        if col in df.columns:\n",
    "            if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "                numeric_checks[col] = \"Non-numeric type\"\n",
    "    if numeric_checks:\n",
    "        print(\">> NON-NUMERIC COLUMNS found (expected numeric):\")\n",
    "        for c, msg in numeric_checks.items():\n",
    "            print(f\"   Column '{c}' => {msg}\")\n",
    "    else:\n",
    "        print(\"All price/volume columns have numeric types.\")\n",
    "    problems_summary['non_numeric_columns'] = numeric_checks\n",
    "\n",
    "    print(\"\\n=== DATA QUALITY CHECK COMPLETE ===\\n\")\n",
    "    return problems_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Run the data-quality checker \n",
    "problems_report = check_data_problems(df_prices)\n",
    "\n",
    "# 4. If you want to do something programmatic with the results:\n",
    "print(\"Problems Summary (as dict):\")\n",
    "print(problems_report)\n",
    "\n",
    "'''problems found :\n",
    "No missing values detected.\n",
    ">> DUPLICATE ROWS found: 3357\n",
    "No invalid (zero/negative) price values found.\n",
    ">> INVALID (≤0) VOLUME VALUES found:\n",
    "   Column 'Volume BTC': 4458 rows\n",
    "Date index is in ascending order (strictly increasing).\n",
    "All price/volume columns have numeric types.\n",
    "\n",
    "=== DATA QUALITY CHECK COMPLETE ===\n",
    "\n",
    "Problems Summary (as dict):\n",
    "{'missing_values': {}, 'duplicate_rows': 3357, 'invalid_prices': {}, 'invalid_volumes': {'Volume BTC': 4458}, 'date_order': 'Ascending', 'non_numeric_columns': {}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows considered duplicates (including the first occurrence): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Open, High, Low, Close, Volume, Dividends, Stock Splits]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will return every row that has a duplicate somewhere else\n",
    "duplicates_all = df[df.duplicated(keep=False)]\n",
    "\n",
    "print(f\"Total rows considered duplicates (including the first occurrence): {len(duplicates_all)}\")\n",
    "duplicates_all.head(10)  # display a few rows\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
